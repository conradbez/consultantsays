Karel co-leads the Firm’s Operations practice and Internet of Things (IoT) group in Asia. Since joining the Firm in 1997, Karel has worked across multiple industries including advanced industries, automotive, electronics, energy and materials, technology, as well as private equity.
October 16, 2018 Nearly every global manufacturer seems to be testing Industrial Internet of Things (IIoT) technology, but in a recent McKinsey survey, nearly 70 percent of business executives said that their IoT initiatives are stuck in pilot purgatory, unable to reach company-wide scale. Furthermore, respondents said that only 15 percent of IIoT initiatives move to scale within one year, and a quarter of these initiatives extend longer than two years in pilot mode.
Clearly, this is not ideal, as pilots alone do not deliver the bottom-line impact companies need to remain competitive in the Industry 4.0 era. Even worse, because pilots do not encompass the full spectrum of what is possible with IoT-led technology transformation, these initiatives too often get cancelled because of the lack of a long-term vision and roadmap. But there is good news: designing the information technology/operational technology (IT/OT) architecture properly will enable companies to architect robust IIoT pilots that can rapidly scale.
Given that pilots often get bogged down because they’re too narrow to scale well, it’s imperative to design use cases so that they deliver end-to-end value for company-wide benefits. That also means addressing the overall IT/OT architecture design from the get-go to encompass the breadth of use cases. And with the IT/OT environment becoming more complex every day, the goal must be to sequence use cases based on two considerations:
The priority of the use cases to the enterprise, based on predetermined KPIs that are linked to business value creation, and The ability of technology to support these use cases, while in parallel building both the technology stack (also known as the “platform”) and the applications specific to those use cases.
In our previous post, we described the factors that make constructing a scalable technology stack especially challenging in an industrial setting, such as the complexity of the industrial-automation ecosystem, the alphabet soup of sensor subsystems, legacy machines that are still unconnected, and poor collaboration between IT and OT departments.
Consequently, industrial companies often struggle to determine how best to source a solution that truly unlocks value from data and analytics. Vendors of all types are introducing new technology to capitalize on this trend, as they seek to secure a portion of the multi-billion-dollar market (exhibit).
Exhibit We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
At one end, traditional industry-automation vendors that are established incumbents, with strong positions in control points, are introducing complementary IoT solutions to help manufacturers deploy an end-to-end IIoT platform. The playing field also comprises established vendors from both the OT and IT stack, each with strengths in different technologies. Some vendors are attempting to create portfolios that span most of the IT/OT automation stack, while others are steadfast in their commitment to a focused area of expertise.
We looked at five of the top automation vendors and found that most are expanding their IIoT portfolio and capabilities. The overall landscape thus remains unsettled. For example, just among this vendor subset, there are almost 50 proprietary offerings in more mature areas of the stack, such as manufacturing execution systems and similar technologies—and standardization across industry use cases has yet to take off. We also found that several major vendors lack offerings in areas such as building automation, human-machine interfaces, and sensors and RFID.
To add another layer of complexity, traditional software vendors are competing for their share of the industrial-cloud ecosystem. Most approach the ecosystem from bottom up, with initial success as an infrastructure-as-a-service (IaaS) provider, leading to vertical integration in platform-as-a-service (PaaS), and finally leading to non-industrial software-as-a-service (SaaS). The natural extension is then to enable industrial SaaS.
As with the automation stack, there are several major players competing but there is no clear leader. For plant operators, it’s therefore nearly impossible to predict who will come out on top, leaving internal teams to navigate a complex landscape of evolving technology offerings from vendors with whom they have an established and amicable relationship—both on the IT and OT side. The only clear message right now is that no single vendor will likely be able to solve all of a company’s requirements.
Knowing your starting point and destination can help make even the most complex journey navigable. This is true of developing an IIoT stack capable of scaling. We recommend our clients take the following steps when initiating an IIoT pilot. Over the next few blog posts, we will deep-dive on each of the following steps with examples where applicable.
Start by generating a solid list of use cases. Focus not only within the four walls of a given plant, but also extend into supply chain and design, with a view to enabling digitization of complete value chains. This exercise doesn’t have to be exhaustive, but it should be representative of the things the stack needs to be able to do for you. For each use case, you can then determine the tech-stack requirements, which collectively will show what the tech stack will have to deliver to achieve scale at the right speed and cost.
Focus not only within the four walls of a given plant, but also extend into supply chain and design, with a view to enabling digitization of complete value chains. This exercise doesn’t have to be exhaustive, but it should be representative of the things the stack needs to be able to do for you. For each use case, you can then determine the tech-stack requirements, which collectively will show what the tech stack will have to deliver to achieve scale at the right speed and cost. Develop a future-state reference architecture based on business need. Begin with an assessment of your current IT/OT stack, from plant level to the whole enterprise, looking at everything from technology architecture to manufacturing applications and tools. Also review previous IIoT pilots, identifying pain points that prevented projects from moving forward.
Begin with an assessment of your current IT/OT stack, from plant level to the whole enterprise, looking at everything from technology architecture to manufacturing applications and tools. Also review previous IIoT pilots, identifying pain points that prevented projects from moving forward. Incorporate data expertise up front. Avoid delays and needless iteration during implementation by having data scientists, who know the data they will need to have when building their analytics models, participate in the design of the reference architecture. The data scientists will also need to work with the process engineers to ensure that the data can be both collected accurately at source and aggregated into the right location at the right time.
Avoid delays and needless iteration during implementation by having data scientists, who know the data they will need to have when building their analytics models, participate in the design of the reference architecture. The data scientists will also need to work with the process engineers to ensure that the data can be both collected accurately at source and aggregated into the right location at the right time. Define a core architecture choice. Assess the pros and cons of selecting a single platform, an ecosystem of vendors, or a hybrid approach, before aligning on an overall direction.
Assess the pros and cons of selecting a single platform, an ecosystem of vendors, or a hybrid approach, before aligning on an overall direction. Recommend tech choices specific to use cases. Agree on tech-stack requirements for prioritized use cases and compile decision criteria. Tailor existing evaluations of IIoT platform providers against the decision criteria to identify top choices.
Agree on tech-stack requirements for prioritized use cases and compile decision criteria. Tailor existing evaluations of IIoT platform providers against the decision criteria to identify top choices. Chose vendors based on both tech capacity and human capability. While getting the right tech is essential, getting it to work depends on system-integration capabilities as well.
Deploy technology for prioritized use cases in the short term. For the prioritized use cases, invite a curated list of vendors into your organization’s ecosystem.
For the prioritized use cases, invite a curated list of vendors into your organization’s ecosystem. For the long term, create and align IT/OT roadmaps. Draft consistent IT and OT roadmaps that align with your organization’s broader business goals and underlying tech, then syndicate and refine them—noting that the time scale will be very different from a multi-year ERP implementation.
Following this approach will help your company navigate the complexities of the IIoT landscape to capture value quickly. Watch this space for more on each of the steps listed above.
The authors would like to thank Mike Coxon, Subu Naranayan and Bodo Koerber for their contributions to this post.We as the IoT practice of Deloitte Germany are delighted to introduce our new blog today.As part of the global IoT initiative at Deloitte, the German practice drives business-value focused IoT solutions from the very first idea to the global operation. We offer detailed insights into the possibilities and sustainable value of IoT solutions and develop custom strategies across industries.
On this blog, we share learnings from our IoT projects and introduce best practices as well as our Point of Views. We offer additional findings, statistics and analyses, publish interviews with IoT experts and keep you up to date about major IoT developments.
Initially established in summer 2016, we have since grown into a team of 40+ practitioners led by Dr. Gunther Wagner and Andreas Staffen. To name just a few, let us introduce ourselves as some of the contributors to this blog.
Nowadays, billions of interconnected sensors and devices are enabled and qualified to exchange data in real-time. Together, they form the Internet of Things, enabling critical insights, greater efficiency, and new business models in dozens of industries, creating trillions of dollars of value globally.
We focus on the corporate application of IoT solutions in specific organizations rather than single end-user devices, which is reflected in how we approach IoT. Our work spans from the identification of suitable strategic courses of action, over respective technology and organizational transformation to a steady optimization of operation and delivery principles. More details regarding our IoT service offerings are following in a separate blog post.
Get in touch with our team to start a conversation about how your organization can leverage the full potential of the Internet of Things.The role of IoT in the manufacturing industry is increasing. Gartner forecasts 20 billion internet-connected things by 2020. Although it is not about general-purpose devices, but about dedicated-function objects, such as jet engines, connected cars or even coffee machines. Besides new business applications, IoT solutions enable businesses to analyze data generated by IoT edge devices and use these insights as a basis to improve business decisions. This article focuses on the IoT platform as one essential component of this development as well as introduces the Deloitte Digital Platform (D²P), which allows you to integrate and collaborate with data coming from various systems, devices, applications and human interaction.
A lack of interface and communication standards lead to a gap between IoT edge devices and business applications. An IoT platform closes this gap by acting as a middleware, which mediates between the two ends. However, modern IoT platforms go one-step further by adding functionality to the hardware and application layer. For this reason, capabilities for edge data processing or complex data analytic algorithms can also belong to the functionality set of an IoT platform. In general, IoT platforms are all about enabling businesses to build IoT solutions faster, cheaper and better, by solving problems and complexities related to the interoperability between infrastructure and business applications.The Internet of Things (IoT) is playing an increasingly important role not only in industry, but also in our daily life. A basic understanding of the relevant technologies, procedures and tools is very helpful in order to benefit from the tremendous opportunities of the IoT as an IT professional, manager and entrepreneur. Therefore, Deloitte’s IoT Community hosted the IoT Bootcamp for industry partners at the Deloitte Digital Factory in Dusseldorf on December 5th and 6th 2019.Niccolò Machiavelli, one of history’s great futurists, might have predicted the Internet of Things (IoT) when he wrote, “There is nothing more difficult to take in hand, more perilous to conduct, or more uncertain in its success, than to take the lead in the introduction of a new order of things.” The IoT’s early innovators, who have grappled with mixed overall demand, a lack of consistent standards, and other challenges, would agree that their road has been difficult. But, like other visionaries before them, they have persisted in establishing a new order because they see the promise ahead.
Both consumers and the media are fascinated by IoT innovations that have already hit the market. These “smart” devices have sensors that communicate seamlessly over the Internet with other devices or the cloud, generating data that make the world safer, more productive, and healthier. In just a few years, some IoT devices have become standard, including thermostats that automatically adjust the temperature and production-line sensors that inform workshop supervisors of machine condition. Now innovators want to enable more sophisticated IoT technologies for self-driving cars, drone-delivery services, and other advanced applications.
Although some analysts are excited about the IoT’s potential, others have argued that it is overhyped. We take a more balanced view, based on our extensive research as well as our direct work with IoT application developers and their customers. Like the optimists, we believe that the IoT could have a significant, and possibly revolutionary, impact across society. But we also think that the lead time to achieve these benefits, as well as the widespread adoption of IoT applications, may take longer than anticipated. The uptake of IoT applications could be particularly slow in the industrial sector, since companies are often constrained by long capital cycles, organizational inertia, and a shortage of talented staff that can develop and deploy IoT solutions.
For semiconductor companies, which are looking for new sources of revenue, the rate of IoT adoption is an important concern. In this article, we will look at the case for optimism, as well as the reasons for more modest expectations. We will also examine new technologies that could accelerate the IoT’s growth and product-development strategies that semiconductor companies could implement to increase the appeal of IoT offerings.
If we look at the IoT’s recent growth, the optimists have reason to be encouraged. Consumers are more connected than ever, owning an average of four IoT devices that communicate with the cloud. Globally, an estimated 127 new devices connect to the Internet every second. A report from the McKinsey Global Institute estimates that the IoT could have an annual economic impact of $3.9 trillion to $11.1 trillion by 2025 across many different settings, including factories, cities, retail environments, and the human body (Exhibit 1).
Exhibit 1 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
The IoT is also benefiting from infrastructure improvements that have enhanced connectivity. For example, only 20 percent of the global population is now covered by low-power, wide-area networks (LPWANs) that allow long-range communications among connected devices while optimizing both costs and power-consumption requirements. By 2022, however, we expect that 100 percent of the population will have LPWAN coverage. Similarly, technological advances are reducing power requirements, decreasing costs, and promoting the development of more integrated IoT solutions. Consider lidar sensors, the laser-based sensor packages that scan and detect surroundings, which are essential for autonomous driving. Their price has declined more than 10-fold over the past eight years and is expected to drop more than 65-fold over the next two. This decrease, combined with the increased technological sophistication of lidar, is contributing to the development of fully autonomous cars, which could constitute 25 percent of all vehicle purchases by 2035.
Many experts view the IoT’s slower-than-expected growth within the industrial sector with particular concern. To gain more perspective, we investigated how industrial companies are using IoT applications and tried to estimate whether business-to-business (B2B) growth might accelerate. In addition to basic research, we interviewed and surveyed over 100 leaders from various industries, including public sector and utilities, discrete manufacturing, oil and gas, mining, telecommunications, technology, media, healthcare, and pharmaceuticals.
Our interviews revealed that most businesses are adopting the IoT only to a limited extent. With the exception of oil and gas and mining, leaders from all industries reported that their companies often received real-time data from IoT sensors. However, most leaders reported that their enterprise deployments were still at proof-of-concept stage, and none have yet embarked on large-scale programs (Exhibit 2).
Exhibit 2 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Although IoT sensors collect vast stores of data, a recent report from MGI showed that companies do not analyze most of them. For example, on an oil rig that had 30,000 sensors, managers examined only 1 percent of data. What’s more, business leaders seldom consider information from IoT sensors when making important decisions, including those related to maintenance planning or automation procedures. Their reluctance to examine IoT data stems from several factors, including a lack of data-analytics staff, but the most important reason is simple: as humans, we prefer to consult other people for advice or to look back on our own experience, when making decisions. Although hard data from IoT devices are more complete and objective, we tend to assign them less value. Before IoT data gain a more prominent role in corporate decision making, business leaders and other important managers—maintenance supervisors, field service technicians, and retail merchandisers, to name just a few—will have to appreciate their value.
In our survey, respondents favored simple use cases that enable tracking data and sending status alerts related to changes in the physical world (Exhibit 3). Some companies, for instance, have placed sensors in food packaging that track a product’s location throughout the distribution supply chain. Simple tracking and alert functions are relatively easy to deploy because they do not require advanced analytics, complex algorithms, or data-science capabilities, allowing them to generate value quickly. Although some innovators are enthusiastic about IoT applications for optimization and prediction, we expect that most customers will remain focused on simple use cases, at least for the immediate future. And that means they will not obtain full value from the IoT.
Exhibit 3 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
IoT devices, connected cars, and edge gateways are all potential entry points for a cyberattack—and we recently saw the full extent of this vulnerability. In the 2016 Mirai botnet attack, hackers specifically targeted IoT devices, including appliances and routers, and disrupted many major Internet service providers. The attack, the most significant of its kind, was possible only because of human weakness—a failure to reset generic or default password and username combinations. This attack, and others like it, demonstrate that IoT vulnerabilities often result from a lack of basic care in managing and maintaining devices. Such weaknesses cannot be eliminated through encryption, attack-detection programs, biometric-access control, or other sophisticated technologies. That means companies that want to expand their IoT efforts will need to launch comprehensive security initiatives that address weaknesses resulting from both technological vulnerabilities and a lack of caution among those who use IoT devices.
A few important, and potentially disruptive, developments could accelerate IoT uptake and create opportunities for semiconductor players.
Video analytics—the application of sophisticated algorithms to video feeds—is spurring the creation of new IoT applications and use cases. For instance, data analysts can now examine customer demographics by applying sophisticated algorithms to videos taken as shoppers browse through merchandise. Recent evidence also suggests that the IoT will benefit from audio captured on microphones.
The costs associated with video and audio feeds are falling, with sensors now embedded in devices at low cost—under $2 each. The data gathered from these feeds are extremely rich, diverse, and relevant to many widely used IoT applications. Lower data-communication rates, the growth of 5G data networks, and ongoing decreases in cloud-storage costs will continue to encourage developers to find new uses for video and audio.
For semiconductor companies, the increased importance of IoT video and audio feeds may create an opportunity to combine hardware with end-to-end approaches for analytics and control. They will have to move quickly to meet customer needs, however, since the technology related to advanced applications, such as those that use analytics to recognize faces, is evolving rapidly. Semiconductor customers may be particularly interested in products that integrate hardware and software more closely, as well as new architectures that optimize transmission, processing, and analytics on devices, in the network, and in the cloud.
The advent of standards that support truly LPWANs, including LoRa, NarrowBand IOT, and Sigfox, will enable large-scale sensor deployment of IoT applications in many areas, including agriculture (analysis of soil conditions), safety (citywide monitoring of air quality), and productivity (real-time logistical tracking along the supply chain). But the growth of the IoT, combined with the increase in sensors and connectivity, will also make it more challenging to provide power to untethered devices and sending nodes. Even with long-life battery technology, many of these devices can only function for a few months without a recharge.
Energy harvesting, a process in which energy derived from external sources is captured and stored for use in wireless devices, might resolve power-related issues. Although solar energy could provide an answer for many IoT applications, semiconductor companies should also investigate other sources, such as wind, thermal energy (derived from heat), and kinetic energy (derived from an object’s motion). Optimizing energy harvesting, management, and storage will require companies to create innovative designs, at both the silicon and system level.
As the IoT expands, innovators are rapidly developing complementary architectures that combine the following two important features:
the power of the cloud, which offers robust storage and greatly extensible computing power at low cost
the ability to process and store data on a device (or edge), or within a network at gateways that connect multiple end-devices to the cloud
Multiple IT architectures with these properties have already reached the market, each offering a compelling approach. But semiconductor companies have an opportunity to go further—and to make more rapid progress—in defining the future architecture of the IoT. In particular, they should focus on products related to video and audio sensors, since these devices are proliferating and generating significant amounts of data.
Many IoT applications require data to be processed on the devices themselves. For instance, applications for autonomous driving, surveillance, and security all have strict latency specifications that require systems to respond immediately after data input. To meet these requirements, the IoT devices that collect the data must process them and use the output to make decisions. Applications that require on-device processing are power hungry and include relatively expensive components, such as multiple application processors. Semiconductor companies could take the lead in optimizing on-device solutions for these applications. For instance, they could create edge-device solutions for autonomous control, facial recognition, and audio analytics, all of which have different hardware and software requirements with respect to computing performance, signal processing, and storage.
Before any company explores IoT opportunities, it should take a new look at strategy, including the factors that it considers when developing solutions.
Both developers and business leaders often focus on the technological potential of the IoT, including its ability to collect and analyze vast stores of data. But technological advances alone will not make an IoT application more valuable or desirable to customers. Instead, developers should focus on outcomes—how a new application will improve safety, financial returns (for businesses), and convenience.
Consider, for example, the outcomes that one airplane manufacturer achieved by using IoT sensors to monitor jet-engine performance. By providing real-time data, the sensors immediately alert the manufacturer about potential problems, which makes it easy to conduct preventive maintenance and maximize uptime. Other sensors help with parts-inventory management. Together, these IoT enhancements have contributed to 9 percent revenue growth and a 30 percent increase in engine availability. That means airplanes spend more miles in the air and less time on the ground, consistently reducing overall operating costs.
To focus on outcomes, companies will have to coordinate activities across the value chain. In addition to providing the technology and data that enable the IoT, they will need to adapt their business models—a difficult process, in our experience, since incumbents often resist change. If they fail to evolve, a start-up or another disruptive player may take the lead in establishing a new approach to IoT application development, especially if new investors emerge to finance innovative ventures.
As companies shift their focus from technology to outcomes, they will need to provide incentives that encourage upstream vendors and customers to support the use of their applications.
Just as IoT innovators tend to focus on technology, many IoT marketing materials try to appeal to customers by discussing the latest product upgrade, including better sensors, connectivity, computing power, and analytics. But our experience has consistently offered one clear insight: users, both personal and industrial, are more likely to adopt IoT technologies that generate a positive emotional reaction. Consider smart homes, where technology companies have recently won many customers by offering voice-based products—devices with basic conversational abilities that often respond to a name, just like a person. For instance, Amazon’s Echo, a smart-home speaker, answers to the name Alexa and can respond to basic commands and questions. Such qualities may create an emotional connection between users and devices, and they could be partly responsible for the strong sales of voice-based products.
As technology companies develop new IoT offerings, they should ask digital designers to provide insights about customer behavior, since this information might help them create products that prompt strong positive feelings and accelerate adoption rates. As always, products will also need strong technical and analytical capabilities, but companies are more accustomed to delivering such features.
Current IoT trends create an uncertain and sometimes confusing picture of the sector’s future prospects. When we look at the evidence in total, however, we believe that the IoT is poised to serve as a major growth driver for semiconductor companies. Adoption rates have risen more slowly than expected, but that should not be a reason for pessimism, since many IoT technologies are immature or undergoing development. Semiconductor companies and other players can still undertake new strategies to accelerate IoT growth. Rather than focusing on technology upgrades, they could develop IoT products that truly improve customer outcomes for cost, performance, and other important metrics. They could also emphasize design-driven insights about customer needs, including the product features that generate a positive emotional response. This new approach to development will be challenging, but it will accelerate IoT adoption and help more customers, both personal and industrial, achieve benefits from this exciting new technology.Digitization in companies is advancing more and more. Even though processes are increasingly being carried out electronically, logistics service providers often receive their orders outside the transport systems - often still via analog channels. This increases the effort required on the part of logistics service providers to record shipment data.
In order to optimize the yard planning, staff utilization and operational processes, an increasing number of clients is asking their logistics providers to book dedicated time windows to pick-up and deliver goods. The booking of the time windows usually needs to take place 24h before pick-up/delivery. The booking itself causes additional effort for the logistics providers and reduces efficiency. In addition to that, the flexibility to plan the pick-up/delivery tour is reduced which can negatively affect the utilization of the available loading capacity.
Customers are increasingly demanding reliable transparency on the status of shipments from their service providers. This requirement presents logistics companies with an enormous challenge. On the one hand, the recording of the conventional barcode by warehouse personnel is time-consuming and therefore inefficient. On the other hand, additional information, such as temperature or vibrations, must be transmitted to the customer more frequently. Current transport systems are often not suited to provide this type of information.
In the event that companies do not transmit their shipment data electronically, the data must be recorded by the service provider. This entails the risk of incorrect information being recorded, which is even increased by the existing shortage of skilled workers and outsourcing. In addition, shipments cannot be reloaded as long as the shipment data has not been recorded. In reality, this repeatedly leads to delays in operational processes.The Internet of Things (IoT) can not only help you get ahead today, its powerful outcomes and analytics can propel your business far into the future. Deloitte can help companies harness the power of IoT to deliver transformative outcomes and tangible business value.Maria is the Lead Enterprise Agility Partner in Deloitte’s Consulting Practice in Asia-Pacific. Maria has worked with a wide variety of teams, leaders, and organisations to re-wire their management philosophy and enable the shift in thinking required for her clients across Asia-Pacific to deliver projects better, with more value, sooner, safer and happier. She has been working with her clients to create customer-centric, high performance delivery, and learning ecosystems across industries, particularly with extensive experience in financial services, telecommunications, and energy & resources. Based on her technology delivery background, Maria’s approach to change and leveraging new ways of working is pragmatic and has an effective balance between delivery and an outcome focussed mindset and culture.Nowadays, Agile methodologies have well and truly arrived in most organizations. The complexity of digital opportunities and the unpredictability of customers and competitors are both on the rise, making it impossible to predict what businesses will need in the future. That is why Agile is such a decisive factor to enhance organization’s responsiveness towards volatility. Strategy management has to evolve as well, which is where Agile concepts come into play. More...A blog delivering insights into the latest discussions, trends and lessons from the front line on Agile. Deloitte is a pre-eminent Agile advisor and a leading expert on Agile, providing tailored solutions across various organisations, industries, and projects, at any scale.
Agile is a set of principles and practices based around the concept of iterative and incremental development, with collaboration between teams at its cornerstone. Agile approaches to delivery can increase quality, reduce waste, improve predictability and boost morale in organisations.
Our experts in Agile will provide their views on the latest developments within the Agile community, developed through first-hand experience across a range of industries and services, and will help keep you up to date with the tools and considerations needed for successful Agile development.Searching “what is agile?” we find words like “iterative development, software delivery, self-organising teams, scrum, and sprint”. If you’re reading this blog, you’re probably familiar with most of these terms, and you may even be thinking about Agile at scale, or “Enterprise Agility”. As we start to scale agile, the human aspects tend to be outweighed by a focus on execution. However in our experience, there are a small number of factors that become critical to truly realising benefits as organisations begin to scale Continuous Delivery, DevOps or Agile principles beyond 1-2 teams, and start looking at a whole function or even an entire organisation….
So what do we mean by human aspects? … It’s anything and everything to do with an organisation and its people, how they work together, and its workforce.
In a series of blog posts, we will explore these critical human aspects by asking the question: “What practical steps can we take to start making a difference?” With the first of the series focusing on Leadership.
We are quite excited to see some really informative research around Agile Leadership emerging. The Puppet + DORA State of DevOps Report examines the idea of transformational leadership, and Deloitte’s 2017 Human Capital Trends which explores the idea of “hero leader”, and how it can no longer scale, detailing how the US Military has reinvented itself as a network of teams.
As we begin to explore the idea of Leadership in an Agile environment, we are immediately compelled to examine what leadership means alongside (increasingly) autonomous / self-managed teams. What is the role of leadership in these new ways of working? Is a different type of leadership needed? Are leadership roles needed at all?
Our view is that leadership is becoming more diffused across the organisation rather than the traditional approach where it is distilled in discrete roles at the top of an organisation. More and more, leadership is a capability that is integral to all roles, at all levels of the organisation, irrespective of whether a role has direct reports or not. This means there will be far fewer roles that are considered “only leadership”, and even when these discrete leadership roles exist, what they do is changing significantly.
There are some well documented examples of this in practice; LeLoux explores a number of these in his seminal book: Reinventing Organizations. Atlassian’s (the now famous Australian start-up that even AFR now considers the “coolest company in Australia”) focuses their leadership teams almost exclusively on the “sustainability of the eco-system”. Leaders amplify the company’s vision and purpose, develop “the guard-rails” that enable everyone to deliver great customer outcomes, and identifying potential threats by assessing their ongoing competitive position.
And Microsoft who’s transformation from “a battleship to 3000 canoes”, has been underpinned by leaders who focus on translating customer value into outcomes, challenging the norm, and inspiring people.
One of the key characteristics is authenticity. Authentic leaders communicate their team / organisation’s purpose in a practical way. Their passion for the customer is infectious and creates the oxygen for teams to take meaningful action rather than waiting to be “told what to do”.
This is tightly coupled with coaching. Coaching has become a core tenant of leadership, incorporating both personal recognition of great work, as well as creating an environment of- and space for- continuous development and collective accountability that encourages personal and collaborative reflection in the absence of blame.
Demonstrate empathy, care and inclusion – taking the time to seek out people’s stories and experiences, encouraging them to be themselves at work, and connecting personal interests to organisational purpose and customer outcomes. These leadership behaviours encouraging engagement and wellness that research is showing drives improved performance.
Research from Bersin by Deloitte found that inclusive leadership is one of the most significant driver of employee engagement. This is because when people feel included they feel safe; safety enables people to suspend self-interest, and it’s only when we can suspend self-interest that it possible for effective teams that are focused on delivering customer outcomes.
So on reflection… authenticity, coaching, empathy, care and inclusion; these are not aspects of leadership that most people would disagree with, but neither are the first words that would come to mind if you asked 100 people from a corporate Family Feud audience.
Start with purpose and customer ; have your team members spend (more) time with customers, sharing their stories, and demonstrate your personal connection to customer outcomes.
and ; have your team members spend (more) time with customers, sharing their stories, and demonstrate your personal connection to customer outcomes. Think differently by spending more time conceptualising possibilities, seeking out divergent views, and embracing complexity, and less time formulating specific strategies and plans.
by spending more time conceptualising possibilities, seeking out divergent views, and embracing complexity, and less time formulating specific strategies and plans. Act differently by playing an active role in multiple teams, embracing the Agile tools and ceremonies that your teams are using, and spend more time coaching and less directing.
by playing an active role in multiple teams, embracing the Agile tools and ceremonies that your teams are using, and spend more time coaching and less directing. React differently by explicitly tolerating risk and celebrating experimentation, demonstrating resilience when things don’t work perfectly the first time and consciously not laying blame.
So in summary, as a leader and influencer in your organisation the first port of call to scaling Agile is to take conscious control of your own “leadership style”, start thinking, acting and reacting differently, and you’ll begin to see the benefits we’ve discussed above. This can be the case, even when the rest of the organisation around you hasn’t changed. However to take those benefits to the next level and successfully scale even further, the next factor you would likely consider will be organisational structure. We’ll cover this in our next blog in this series.
You can find further Deloitte thinking and resources here. We would recommend the following further reading:It’s no secret that the success of any program hinges on senior executive ownership, support and their ability to cascade messaging down to all layers of an organisation. What’s also trending in Agile is the movement from leader-led change to intent-based leadership. Leadership should be viewed as a set of behaviours, not only a role. As such, leaders should empower passionate individuals to lead from all levels within the organisation.
Agile requires cultural change, not just technology. Every person up and down the chain should be versed in the language of agile, and be guided by a single framework and approach for doing so. Pilots enable you to slice off a sliver of the business, fundamentally transform this small group’s way of working, demonstrate benefits and then scale. Starting lots of little ‘spot fires’ such as this around the organisation will attract others, and draw them in to the movement.
Wise companies will proactively consider what they can learn from organisation models being created within digital-native companies. Removal of silos and hierarchy, with the blending of roles can help to create autonomous teams. When structures cannot be changed, alternatives such as creating ‘guilds’ – voluntary communities of like-minded people that come together to discuss topics of interest – can help create pockets of agile evangelists.
The ‘spot fires’ mentioned in the point on culture, are also a way of winning hearts when it comes to targets and incentives. Leaders should strive for voluntary participation over mandated participation, so that it becomes every individual’s idea and prerogative to operate in this new way. Key to this is addressing the genuine needs of people – get to the heart of the noble purpose so people are motivated intrinsically.
Only in an environment where people feel safe to play with ideas, and where they are recognised and rewarded for being agile will it occur. Something as simple as buying ‘failure cupcakes’ at the end of a sprint can help set in motion this new paradigm. Building elements of gamification, playfulness and fun into team challenges and goals can also help drive creativity, innovation and agility.
In summary, to make an organisation truly agile, companies need to focus on the five building blocks of an effective environment: leadership, culture, organisation design, targets and incentives, and celebrating outcomes. Get these right, and the rest will follow.Someone posted an article on LinkedIn the other day claiming “Agile is Dead”. The comments that followed were more interesting than the actual article. Many people were bashing agile frameworks. It is no secret that organizations have spend a lot of money on doing agile and many times never really achieved being agile. Right now, SAFe (Scaled Agile Framework) is trending and many of my clients are implementing it. But methodologies and frameworks are nothing more than a set of guiding principles for delivering software. At the end of the day, doing agile comes down to the three things:
A framework is only as good as the people, processes, and organizational structures that use it. Silos with competing goals always trump frameworks. Each silo creates an unnecessary handoff and increases wait time. Too often, additional processes get added to deal with the interaction between silos.
Then there is the people part. I am old enough to remember when all projects managers had to be PMBOK certified which trained project managers how to follow a set of processes and procedures (framework) to navigate the waterfall methodology. When we moved to agile, all these people were retrained and became certified scrum masters. Unfortunately, they still had the old command and control, sequential mindset and most agile efforts became “Wagile” — waterfall with daily standups.
The point here is it takes much more than a few training classes or certifications to change the mindset. This is a transformation and requires an investment in organizational change management to get the value out of the new frameworks.
All the process in the world can’t fix a bad architecture. To do agile, one must have an architecture that supports being agile. Characteristics of an agile architecture include:
Service-oriented — opposite of Monoliths, the system is made up of small parts that can be deployed separately
Testable — system supports testing hypothesis with methods such as A/B testing, feature flags, chaos engineering, etc.
The more a system supports the characteristics above, the more agility can be achieved. Not all systems need to implement all of those characteristics, but each characteristic can reduce manual intervention, allow for more frequent deployments and quicker MTTR, reduce widespread system outages, and provide for better availability. It can also reduce the amount of unexpected work which is probably the biggest single issue all agile frameworks struggle to deal with.
Even if you have an agile architecture and your agile framework is being executed flawlessly, if your operations people and processes are not in alignment, the whole house of cards will come tumbling down.
There is a lot disruption in operations these days. DevOps has played a huge roll in getting developers and operators collaborating better. Operations is now being thought of earlier in the lifecycle and teams are designing for ops. Companies are reevaluating their operating models and investigating newer practices such as Site Reliability Engineering (SRE), accepting that testing in production is a good thing (if done right), moving from reactive to proactive operations, embracing observability, and much more. As we move to more agile architectures, it’s common sense that we need to embrace more agile methods of operations.
The list goes on and on. I have yet to see a framework that even mentions most of these characteristics. The frameworks focus mostly on how to manage backlogs which is important, but if the software and the operations of that software does not promote agility, the framework is not going save you.
Organizations should focus more on being agile rather than doing agile. Being agile requires more than a framework. It is a mindset and it should be applied everywhere, not just in Dev and Ops. The Security and Governance teams need to be agile. Procurement can’t take six months to procure a software product. Decisionmakers need to come to conclusions in a timely manner. Processes that take forever should be redesigned. Approvals should not take forever. You get the point.
Being agile is a cultural issue and should be treated as one. If you want to make your organization agile, adopting a framework is only one piece of the puzzle. In fact, many teams that I have seen that are truly agile use no framework at all. They do a good job of managing a backlog and they do a great job of collaborating, writing good software, automating everything they can, and recovering from issues quickly. At the end of the day, agility can be measured by customer satisfaction. If the customer is getting their demands met, the system is reliable, and issues are resolved quickly, it really doesn’t matter what framework you use.Despite the apparent threat, Enterprise Agility does not spell the end of Architecture but in fact can be a catalyst for change and disruption. Whether a company is Waterfall, Agile or Hybrid, architects will always be required to support technology decisions and align IT to business strategy[2][5]. These outcomes remain as critical as ever, but how they are reached will be vastly different. In this blog we will discuss four ways Enterprise Agility will redefine Architecture. Get ready.
1. Architects will be less involved with delivering things but more involved with ensuring the right things are delivered
There is a misconception that architects spend all of their time ‘doing’ architecture and producing complex diagrams[4]. It’s the organisational decision-making process that the architect must drive before an artefact is delivered, however, that really matters. Reaching consensus on complex decisions involving diverse stakeholders with competing views is where the architect is irreplaceable[12]. Be it navigating emerging technologies, legacy system replacement, or completing post M&A consolidation roadmaps; as Agility scales, the need to make these architectural decisions in a timely manner goes up. The need for Architects to support this goes up.
This doesn’t mean architects won’t produce any diagrams, but enabling the best technology decisions to be made is where the value of architecture will be realised in an Agile Enterprise[3][4]
Intentional architecture is the traditional up-front, plan based architecture that most of us are familiar with. The Architecture is designed and handed over to development teams to build. The more detailed the architecture the more ‘intentional’ it becomes.
There is little doubt that in a fixed-price contract world, having as much detail as possible up front is a necessity. And in general, updates are avoided at all cost for fear of the change request. But in an Agile Enterprise, procurement functions will evolve along with the Architecture function. And through a combination of incentive-based or time and materials contracting[21][22][23], this evolution will permit Product Owners to inspect and adapt.
So for the architect, as agility scales, a degree of up front planning remains essential. But defining detailed architectures across large time horizons is no longer required. Architectural work will be decomposed into smaller packages and managed in a ‘just in time’ fashion[11][12][13]. The Scaled Agile Framework (SAFe) provides an example of this with its Architectural Runway that is used to ensure technical dependencies are always delivered at least one sprint before the application functionality that needs it[10][11][17]Finally, at the core of transforming recruitment, should be the Agile principles. By changing the decision criteria for how you select a new hire, you can prioritise the talent you want most in the organisation. This gives you a workforce of individuals culturally aligned to your strategy and ways of working.
Changing the decision criteria to be Agile involves re-writing position descriptions to be light and flexible. This ensures that you don’t become locked into hiring for a position that, by the time you fill the role, is no longer relevant. Bersin by Deloitte wrote, in a piece titled ‘The end of the job as we know it’, that companies should be hiring “for values, innate skills, and fit, not for experience.” This means replacing your traditional job description with value descriptions instead, speaking to the inherent Agile cultural attitudes required in the position, like agility and comfort with ambiguity. In the Agile Manifesto, this is best denoted by the value of “Responding to change over following a plan”. The focus of good Agile job descriptions, should be on flexing positions, so that HR is building complete teams, rather than attempting to hire the ‘every man’ candidate.
The best example of this is the technology giant Google, who openly targets individuals for a quality called ‘Googleyness’. Head of People Operations, Lazlo Bock , defines this as:
A certain dose of intellectual humility (it’s hard to learn if you can’t admit that you might be wrong),
Comfort with ambiguity (we don’t know how our business will evolve, and navigating Google internally requires dealing with a lot of ambiguity), and
None of those elements would make a classic job description, but they do focus on what Google treasures most, a person’s values. They search for the right fit, not the right set of functional skills.
Applying an Agile mindset to recruitment is not simple. It spans a range of elements from redefining selection criteria, to re-inventing the hiring process. However embedding Agile within your recruitment practices is crucial in supporting an Agile organisation.
Our challenge to you is to look at how your recruiting currently operates, and determine where you can leverage Agile principles to improve the process. Even if it is as simple as giving new hires feedback forms so they can reflect on their experience of the hiring process, you’ll see the benefits that greater transparency and Agile provides.Both agile and mindfulness practitioners place importance on the ability to understand and respond to the needs of others. In an agile context, customers are critical stakeholders requiring compassion, empathy and deep understanding. Mindfulness emphasises the importance of regulation and control of self-emotion in order to better understand and respond to the emotional needs of others, which are relevant skills for an agile team.
Self-organising teams advocate the importance of positive team dynamics as well as the unique contribution of each team member, encouraging collaboration, and face to face communication. Mindfulness can help cultivate team wellness and empathy by encouraging practitioners to control and focus their emotions. This promotes a purposeful, flexible, and open state of attention that ultimately drives intention. By embracing this open attentiveness, mindfulness practitioners increase the likelihood of developing and sustaining positive, respectful, and resilient relationships within their team. This is critical to an effective agile practice, as collaboration, good communication and positive teaming are at agile’s core. Consequently, team productivity can be enhanced by promoting stronger, more engaged, and collaborative teams.
By developing, strengthening and leveraging emotional intelligence through mindfulness techniques, such as focussed attention, agile teams can increase team performance and foster customer empathy through a more in-depth understanding of team dynamics and individual needs.
Simplicity is a fundamental principle of both agile and mindfulness which follows the basic premise: a focus on high value yet simple processes and solutions will reduce waste (e.g. of time, energy, or cost) and increase quality (e.g. of software, communication, or life).
Mindfulness practitioners advocate the importance of de-cluttering to create the emotional and physical space necessary to develop awareness, focused attention, and sustainable living. De-cluttering practices, which can be either physical (such as voluntary simplicity which means to reduce materialism and consumerism, a re-assessment or minimalist re-design of your surroundings, or literally de-cluttering surfaces and spaces in your physical environment), or spiritual (such as letting go of negativity, uncertainty and mental “noise”) ultimately increases quality of life through a focus on value rather than abundance.
In an agile context the focus on simplicity manifests itself in simple design, succinct meetings and communication, continuous integration, story cards, minimal but clear roles, and sprint boards (to name a few). As an example, the physical sprint board puts the agile simplicity principle (“Simplicity – the art of maximising the amount of work not done – is essential”) to practice and facilitates visibility of work not done. The sprint board enables the agile team to organise activities so that those of the highest value are prioritised, reducing waste and maximising efficiency.
Simplicity is a key component in both agile and mindfulness, with focus placed on value and a deliberate effort to remove redundancy. Agile teams can further develop day-to-day simplicity through mindful practices, such as intentional physical and emotional de-cluttering.
Agile enthusiasts embrace changing requirements and environments, those practicing mindfulness also develop the flexibility to accept and respond, rather than react to change.
Mindfulness practitioners advocate that adaptability stems directly from acceptance of the transient and fluid nature of life. The ability to maintain a purposeful, flexible, and open state of attention increases quality of life and sustainability.
Likewise, agile teams maintain the mindset that change is expected and welcome, identifying flexible boundaries, and designing processes and expected outcomes which enable adaptability. Cross-functional, self-organising agile teams that value constant communication, continuous validation, and incremental product evolution are well placed to respond to changing requirements and shifting landscapes.
For both mindfulness and agile, it is communication and contact with the present moment that establishes the foundation for adaptability and increases the likelihood of resilience and stability.
Agile teams can apply their practiced adaptive mindset to leverage mindful techniques, such as acknowledgement and acceptance of change, which can help to remove human emotion (reactive behaviour) from decision making during periods of change.
Another fundamental principle of both agile and mindfulness is controlled and targeted focus on one task at a time. The value and objectives of the focus principle are similar to those of the Simplicity principle – high value yet simple processes and solutions will reduce waste and increase quality.
Mindfulness practitioners advocate the importance of awareness and control in order to focus completely on a single task. Similarly, agile practitioners advocate that productivity is increased through focus on one task at a time, enabled by small engaged teams, short targeted sprints, visibility of activity and direction (agile boards), and regular communication to maintain awareness of blockers and impediments to progress.
Both approaches support the view that the cost of context switching (reduced focus and concentration and ultimately decreased productivity) greatly outweighs any perceived benefit to efficiency or progress.
Agile teams advocate singular focus, however this is not to say that there is no challenge in doing so at an individual level. By using mindfulness practices, such as control of attention, agile teams can turbocharge their ability to filter out distraction, and focus only on the task with the greatest business value.
The core areas of commonality between agile and mindfulness are also some of the defining characteristics of each approach: People, Simplicity, Adaptability, and Focus. Agile teams can leverage the touchpoints with mindfulness to maximise their existing skillsets and ultimately achieve their goals. As an example, mindfulness promises to enhance and enrich interpersonal communication, while agile projects sink or swim on the quality and timeliness of the interactions between all of the project’s stakeholders (including the agile team itself). The two approaches are complementary.
While both agile and mindfulness have been described as “buzzwords” and are being referenced and discussed across multiple forums and platforms, neither introduce any complex or ground-breaking new concepts. In fact, the four principles discussed in this article, which sound very much like common sense, are a reminder that in the 21st century – an era dominated by disruption, technology and immediacy, there is great value to be gained in getting back to basics.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.Traditionally, leaders have been encouraged to dynamically reallocate capital to the most pressing and attractive opportunities. This focus remains today, but many companies face a challenge: human capital is now the scarcer of the two main capitals. Companies that manage talent with the same rigor they do financial capital, treating it like the precious resource it is, typically see better results. They reallocate talent to high-value areas and push talent management to the top of their growth ...Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.Developing a successful strategy is essential to simplifying the complexities of transformation. These key areas to consider can empower your transformation strategy and clarify the road ahead for digital controllership.Imagine you work for a company that has a busy season—the annual crunch time for achieving results. Everyone works at full stretch for six weeks, and then there’s a lull before the next cycle gets under way. If you’re designing a learning program, when should you schedule it? Most designers would probably say after the rush, when people can spare time out of their everyday routine. But is that the right answer? We don’t think so. With this timing, the next busy season could be eight or nine ...Coleads the Organization Practice globally and is one of the leading experts in transformational change
Coleads the Organization Practice globally and is head of McKinsey’s OrgSolutions group, helping clients organize in an integrated way by applying analytics methodologies and tools to improve culture, talent, change management, agility, and leadership
November 27, 2017 Let’s face it. Our hyper-dynamic, hyper-competitive and hyper-connected world has become a breeding ground for hyper-advice. Over 10,000 business books appear annually (and that doesn’t count the thousands of articles, blog posts, podcasts and video lectures produced). Search the internet for how to motivate employees and hundreds of thousands of results emerge in roughly half a second!
So, why are we at McKinsey & Company launching a weekly blog that risks simply adding to the clutter? We are hopeful that our weekly Insights on Leadership & Organization will be a one-stop shop where leaders can find impactful, fact-based and pragmatic advice – in 600 words or less.
We don’t want this to be run-of-the-mill head-nodding material. All up, as a firm we invest over $400 million annually in knowledge development, and we want you to benefit from that investment by providing genuinely provocative ideas that recalibrate and expand your thinking. Then we want to do that again. And again.
For this blog, we will address a range of both timely and timeless topics related to leading organizations and that apply to every leader, whether you’re a leader in an investment bank or a not-for-profit. Or whether you’re in India or Indiana. Over time, we will explore four principal areas:
Increasing organizational agility to effectively adapt to and shape market changes with speed. This requires organizations to master the paradox of being nimble in innovating and executing rapidly, while at the same time capturing the benefits of stability and harnessing the virtues of size and consistency.
to effectively adapt to and shape market changes with speed. This requires organizations to master the paradox of being nimble in innovating and executing rapidly, while at the same time capturing the benefits of stability and harnessing the virtues of size and consistency. Converting talent to value by combining traditional methods with advanced analytics-based methods to forecast talent supply and demand based on the business strategy; and improving how needed talent is identified, attracted, placed, developed, evaluated and retained—all the way from the front line to the C-suite.
by combining traditional methods with advanced analytics-based methods to forecast talent supply and demand based on the business strategy; and improving how needed talent is identified, attracted, placed, developed, evaluated and retained—all the way from the front line to the C-suite. Managing culture and change to deliver sustainable results and create lasting competitive advantage. This includes the tools and methods to overcome the digital, customer-centric, simplification, risk management, and numerous other large-scale transformation challenges that today’s global enterprises face.
to deliver sustainable results and create lasting competitive advantage. This includes the tools and methods to overcome the digital, customer-centric, simplification, risk management, and numerous other large-scale transformation challenges that today’s global enterprises face. Maximizing merger impact by building M&A capability to be ready to make the right deals happen—and then, once one does, developing and executing the right master plan related to governance, sources of value, organization, talent, capability building, and cultural and technology alignment.
Put simply, our goal is to help leaders lead better so, in turn, their organizations will be more successful and their employees’ experiences more meaningful and fulfilling.The IMA® (Institute of Management Accountants), the association of accountants and financial professionals in business, held its 2019 Annual Conference and Expo (ACE2019) this past June in San Diego, California. The event officially celebrated the Institute of Management Accountant’s 100-year anniversary with a special Centennial Celebration honoring IMA’s thriving global community of accounting and finance professionals. Attendees had the opportunity to network with other industry professionals, hear presentations from leaders, and choose from more than 75 job-relevant sessions tracks designed for management accountants to customize their learning experience on topics ranging from corporate governance to technology and finance trends for the future.
As a diamond level sponsor, Deloitte had the opportunity to attend the action-packed conference and deliver presentations on specialty topics. Deloitte delivered a specialty breakout session on touchless close as well as a general presentation on the Center for Controllership™ during the IMA annual conference dinner.
To gather some insights and perspectives that may help us with future conferences and projects with IMA, we caught up with our presenters and some of the attendees to hear about some of their highlights from the experience and insights they were able to take away from the conference.Though major crises may inflict significant economic damage, they can also inspire innovation. From digital connectivity to diversity, this issue of Deloitte Review explores innovations that organizations can put to use both now and in the future.JH, a partner at Deloitte Risk & Financial Advisory, Deloitte & Touche LLP, as well as Global Risk Advisory leader for the Financial Services Industry, has more than 25 years of risk management experience within the sector. He has deep experience with the complete credit lifecycle, enterprise risk management, operational risk, and integrated compliance risk management. His extensive experience in the area of credit includes quantitative methodology, portfolio analytics, process, and controls, integrating risk management practices, and addressing and resolving the Options Clearing Corporation (OCC) and other regulatory issues. JH has worked with seven of the top 10 credit card providers, four of the top five mortgage originators and servicers, two of the top three student lending organizations, and three of the top five auto loan financing companies. In addition, he has performed training sessions for the American Institute of Certified Public Accountants (AICPA) and the Federal Financial Institutions Examination Council (FFIEC) regulatory round table on accounting issues and pronouncements facing retail credit organizations.You previously joined My Deloitte using the same email. Log in here with your My Deloitte password to link accounts. | | Deloitte users: Log in here one time only with the password you have been using for Dbriefs/My Deloitte.
You've previously logged into My Deloitte with a different account. Link your accounts by re-verifying below, or by logging in with a social media account.After centuries of near uni-directional innovation—from the West to the rest—we are in the early days of a massive rebalancing, aided by connective technologies. Innovation now happens everywhere.
Innovation has always been important to humanity—it’s the driver of increased prosperity and well-being. It has also been steadily increasing in importance to business in a fast-changing, opportunity-rich, and highly competitive world. The evidence is plain, for example, in MBA programs, where innovation courses for the next generation of managers are rapidly proliferating. Bill Gates expressed the point in stark terms: Companies must “innovate or die.”1 So where does innovation come from?
For the last few centuries it came mainly from the West. Certain key ingredients necessary for innovation to flourish were in place in the societies and economies of the Western hemisphere far earlier than elsewhere. This advantage became such a powerful, self-reinforcing phenomenon that many in the West came to view their innovation advantage as something like a birthright, an intrinsic relative strength that could never be taken from them.
But in an enormously important trend for business, that is changing. Now, thanks to spreading economic growth, shifting national priorities and new “open” technologies, innovation comes from everywhere. Players based in emerging economies—and, in the West, many other players who lack the assets of large-scale firms—are becoming forces to reckon with in global innovation systems.
For those responsible for corporate innovation, this shift is challenging much of how they do their work. To keep evolving their offerings and ways of operating, companies are looking beyond their internal research and development functions and connecting with innovators at the fringes of their businesses. This will require different aptitudes and, perhaps harder to put in place, different attitudes. But if they can learn to embrace what is “not invented here,” organizations of all kinds can participate in an exciting new world of innovation possibilities.
If you think about what is required for innovation, it comes down to a few basic elements and conditions. Raw intellect is required to produce novel ideas. But ideas are only a small first step in the innovation process; there must also be incentives for inventors to turn those ideas into reality. Putting them into production and bringing them to market at scale requires substantial infrastructure. And since that requires investment far in advance of the hoped-for returns, there also need to be infusions of capital.
These came together in the West, both at the level of the economy and within the closed systems of firms. Corporations like Xerox and General Motors pulled together high-intellect groups in lab settings to cook up inventions, all kept tightly under wraps.2 Governments put a priority on fundamental scientific research, and made it easy for commercial entities to capitalize on the publicly funded and “best-in-class” work of universities. Managers devised standard processes by which the most promising possibilities were selected and funded, and leveraged their infrastructure to get them engineered, manufactured, and marketed in a consistent, high-quality fashion. Firms were able to profit handsomely from the bets that paid off. With every subsequent successful innovation, a company’s infrastructure gained scale, improving the chances that the next one would be a success. With such self-reinforcing systems in place, some nations’ economies matured at faster rates than others’. It was hard to see how to break the lock that Western corporations had on innovation.
A key change is in the infrastructure now required—or rather, not required—to bring a good idea to fruition. We are now decades into the revolution unleashed by information and communications technology, and the effect on industries has been a radical “de-verticalization” of the elements required to launch new offerings. Capabilities that were once exclusive to large businesses are now available on efficient open markets. Innovators no longer need to assemble large organizations, let alone make enormous capital outlays for plant and equipment, because infrastructure is available to them on an as-needed basis. Open platforms that enable collaboration are the new infrastructure of innovation.
Indeed, infrastructure these days could even be a liability—the millstone that limits agility. Players with the largest infrastructure in place could find themselves at an innovation disadvantage. We have already witnessed the phenomenon of “leapfrogging”—the upside of having essentially sat out an era of infrastructural investment and, unencumbered by legacy systems, being able to jump more quickly into the next era. This happened 20 years ago in emerging economies with respect to telephony, as their adoption of mobile phones far outpaced mature economies’, thanks to their lack of land lines.3 With new, potentially transformative technologies coming online every few years, from DNA sequencing to 3D manufacturing, there will surely be many other opportunities for seeming laggards to leapfrog leaders.
But infrastructure is not the whole story behind today’s more accessible and democratic innovation. Managers are now more generally knowledgeable about the processes by which ideas are transformed into profitable offerings. “Innovation is revealing its secrets,” as our colleague Larry Keeley, Deloitte Consulting LLP, puts it—among them, that the word innovation has been applied to what are actually multiple different ways and realms in which companies create new value.4 It is not simply about creating new products and services, but also involves systemic changes elsewhere—including financing and business models, new processes, and enhancement to delivery systems and client experience. And scores of tried and tested tactics to drive these changes have been identified and are now available to all.
Would-be innovators are also being fueled by new incentives as governments put new emphasis on innovation. The encouragement goes far beyond specific market interventions such as tax subsidies for pioneers in next-generation technologies like solar power. Particularly in emerging economies, where businesses have prospered by being “fast followers” or suppliers to Western firms, policymakers are encouraging homegrown innovation in numerous ways. See for example figure 1, showing how various countries’ investments in biomedical R&D have grown over time.
Companies are sending the same signals to their employees. When Deloitte surveyed senior executives of global firms in 2013, roughly 60 percent or more of developed-market executives and emerging-market executives reported that company employees, external partners, and company R&D centers are extremely or very important sources of innovation and new ideas for their organizations.5
As for the infusion of capital into new ventures, the importance of that hasn’t gone away—even in an era of what Keeley calls “lightweight innovation.”6 New developments in this area also contribute to the shift we’re describing. Microfinance was a huge early development; it turned people in villages across the developing world into entrepreneurs. More recently, consider the advent of crowd-funding. Using a tool like Kickstarter, which essentially asks customers (or stakeholders) to pitch in small amounts that collectively enable the development of an idea, an innovator can get a project off the ground that, for whatever reason, isn’t a fit for conventional forms of funding such as venture capital. In 2012, the total raised across 308 global crowd-funding platforms was $2.7 billion, an 81 percent increase over 2011, suggesting that this model is still in the earliest stages of explosive growth. When the numbers come in on 2013, the crowdsourcing research firm Massolution expects them to show that some 600 global crowd-funding platforms raised over $5 billion.7
Of course, all the infrastructure, incentives, and infusions of capital in the world can’t achieve innovation if there aren’t good ideas to begin with. When it comes to intellect, no one would claim that the West ever had a monopoly; raw brainpower is evenly distributed in the world. Much of the trend we’re describing is about tapping historically underutilized pools of it. There are also new developments making these pools larger.
The developed world may not have had bigger brains, but it did have huge advantages in education. Note, however, that by 2030, China will have 200 million college graduates, a number that exceeds the entire US workforce. By 2020, India will be producing four times as many college graduates as the United States.8 This dynamic is also reflected in fundamental science: In the 1980s, Asia Pacific accounted for 14 percent of total world science publications; by 2011, the proportion had doubled to 28 percent.9 The most recent rankings from the OECD’s Programme for International Student Assessment (PISA) put Asian education systems on top, especially with regard to math and science. According to these rankings, the top seven regions of the world in math performance are all in Asia (with Shanghai taking first place.)10Moreover, as economic opportunities grow in emerging economies, talent is more likely to stay there, or return after periods of work or education overseas. The Chinese Ministry of Education tracks the numbers of these returning “sea turtles” and reports ever-rising figures.11
Also propelling the talent shift is the rise of digital natives—a global cohort that, thanks to fundamental demographics, is increasingly dominant in the developing world.12 This youthful source of strength will grow along with expanding Internet penetration. (Today, more than 60 percent of the world’s population still lacks reliable Internet access—but that is changing fast.)13 It is clear that emerging-market Millennials are attracted to innovative businesses: In a recent Deloitte survey, more than 86 percent of respondents from this cohort claimed that their employment choices were strongly influenced by a company’s reputation for innovation—a higher proportion than that reported by developed-economy Millennials.14As they attain positions of leadership, expect to see more creative exploitation of the opportunities inherent in 21st-century technology.
Together, these developments are likely to reshape the global business landscape, steadily undermining the historic advantages of incumbents while empowering new actors. As innovation thrives outside large firms, it will also escape its long-time association with the institution-rich economies of the West (figure 2). It will become ever more accessible and open as organizations around the world gain greater (and lower-cost) access to the elements that drive it. Larry Keeley calls it “the biggest revolution in innovation that I have seen in 30 years.”15 Innovation will now come from anywhere—and everywhere.
Managers will need to respond thoughtfully and strategically to this transformation of the innovation ecosystem. First, from a defensive standpoint, they should acknowledge that the threat of disruption—of their products, processes, and business models—is very real, and likely to come from an unexpected direction. More positively and proactively, they should find ways to make the unfolding developments work in their favor.
Business leaders today realize that the smartest people in the world don’t all work within their organizations. How are for-profit companies tapping into the ideas of broader swathes of consumers and idea-generators? Through a growing range of methods. For example, Innocentive, Kaggle, TopCoder, and Gigwalk all allow them to engage external talent to help research and solve problems at a fraction of what it would cost to employ full-time resources, and with many more options than would typically be suggested by expert advisors.16
[The] biggest obstacle to innovation is not the scarcity of ideas—rather, it is the lack of capabilities to engage far-flung and unusual sources of perspective on a regular and ongoing basis.
XPRIZE is in the business of innovation, and it aims big. Its mission: “To bring about radical breakthroughs for the benefits of humanity, thereby inspiring the formation of new industries and the revitalization of markets.”17 How does it do it? By announcing grand challenges with handsome prizes (funded through donations to its nonprofit organization), it has elicited thousands of entries globally to solve complex technological challenges from private space flight to environmental cleanup. These entries have come from major research and traditional innovation hubs, but also from rank amateurs and dilettantes.18
But being “open” is more than issuing challenges to all comers. It calls for a broader intellectual curiosity that involves listening in and observing as creative people address the problems they consider important and interesting. Companies should consider, for example, connecting with the “hackers” in its space. The “maker movement” around the world consists of a vibrant community pushing each other’s skills and ambitions in small-scale fabrication, and some claim that it could form the basis for the next industrial revolution. We know of Western entrepreneurs who have spent months in Shenzhen, the capital of the hacker culture, immersing themselves in the flow of all the component parts of manufactured goods and the know-how of masters in manipulating them.19
Apple’s and Android’s success in pursuing “platform” strategies has been widely observed.20 They provide a foundation on which many external parties can build by designing applications that will run on it. This makes it easy for these parties to create and capture value, and as they do so, the platform itself will become more valuable and its creator more profitable. But to date, relatively few leaders have seriously explored how their own companies could potentially emulate this model.
Platforms, after all, can come in many forms. Take Quirky, a company that was envisioned from its inception to be a platform for independent inventors. Would-be entrepreneurs submit ideas for useful new consumer products, which Quirky engages a crowd to evaluate. For the three product innovations it launches per week, it provides full support from engineering to marketing, and splits any profits between itself, the inventor, and the voting crowd. At the time of writing this article, Quirky has developed over 420 products in this fashion.21
A valuable platform in a more familiar industry context can be found in Chongqing, China, the epicenter of the world’s biggest and most dynamic region engaged in the production of motorcycles.22 One of the largest manufacturers there, Dachangjiang, found itself short of high-quality local suppliers. Rather than try to build a single, verticalized channel of suppliers, however, it broke its design into several modules and, for each, awarded two to three suppliers the responsibility for developing parts.23 The suppliers worked under common, tight timeframes, but were given great latitude to fashion the different modules, and assurance that Dachangjiang would support innovative designs with investments in the appropriate equipment and processes to build them. The suppliers responsible for each module found modes of collaboration that worked for them, and they varied; there were vertically integrated state-owned enterprises, traditional joint ventures, and more loosely coupled arrangements.24 Interestingly, these collaborations didn’t end with participation on Dachangjiang’s platform. Some of them parlayed their new expertise into growth in adjacent markets, such as automotive.25 Thus, not only was Dachangjiang’s need for a vibrant supplier network met, but the network proved capable of far more innovation than would have occurred had it been directed and controlled by a single entity.
In each of these cases, the platform offers standardized interfaces and a plug-in architecture that can be leveraged by third-party innovators. Most of the costs of doing business are already embedded in that infrastructure, making it easier for smaller entrants to participate, either by targeting niche or emerging opportunities, or by offering something better to the platform’s core market. And in each case, the platform thrives because everyone participating in it has a stake in its success. It’s an arrangement that looks increasingly sensible as it becomes harder for individual firms to assemble and own the complete set of capabilities and knowledge required to sense and respond to market opportunities. Platforms are the bases of “business ecosystems,” and a key dimension of future approaches to innovation.
These dynamics point toward a similar conclusion: Leaders today might do well to reprioritize mastering “flows” of innovation over owning “stocks” of intellectual property. Economists have long recognized the important distinction between stocks and flows in terms of capital. But intellectual capital features both, as well. Traditionally, most businesses have focused on the stock—the patents a company owns, for example, and how to protect them. As John Hagel has observed, however, the dynamics of today’s innovation advantages suggest greater focus on the flows—figuring out how to ensure a steady influx of new ideas and a process by which they will rapidly yield value.26 Recall the motorcycle industry example cited above. Dachangjiang prospered more by facilitating flows than it would have by protecting and exploiting existing stocks of industry-relevant knowledge.27
Various technology executives claim that by the end of this decade, everyone on earth will be connected.28 We can therefore expect further acceleration of the tremendous changes already underway, with a continued rebalancing of the contributions to global innovation from emerging economies. The vectors, velocity, and variety of innovation can be altered fundamentally and permanently.
Today, awareness of the power and potential of this shift is limited. After all, it challenges more than a hundred years of history, and undermines deeply embedded assumptions. But the business world is adapting, and can, in the years ahead, rapidly adjust to the new reality. It will become an increasingly important agenda item for organizations to track, sense, and act upon. Businesses will likely work to develop more accurate sensing mechanisms in order to discover the innovations brewing around the world, and will embrace new models and innovation systems themselves.
The conventional wisdom around keeping a tight hold of ideas could become a drag on organizations that are too slow to let go of it. But as they necessarily engage in new forms of collaboration, many more will discover greater returns from facilitating flows of innovation through open networks. And they will come to recognize that their biggest obstacle to innovation is not the scarcity of ideas—rather it is the lack of capabilities to engage far-flung and unusual sources of perspective on a regular and ongoing basis. And successful innovation will continue to become far less mysterious, as what was once seen as “lightning in a bottle” is increasingly parsed, researched, codified, and turned into reliable (if never foolproof) methods.
Innovation is being democratized away from the insulated confines of the corporate lab and outwards toward the edges of social and market value webs. This transformation is being driven by three factors: the golden age of the platform, rivers of data being shared between connected consumers, and a growing awareness that the final value of things often expands tremendously when users are free to customize, collaborate, and recreate.
The golden age of the platform can be thought of as one of many small operating systems loosely connected. These coupled ecosystems are being developed in ways that allow for individual components to be constantly monitored, tested, altered, swapped out, or shut down. The resulting architectures are cohesive without being deterministic, allowing for rapid innovation at lower cost and without interruption. Success over these platforms is not dependent on accumulated knowledge or embedded infrastructure, so much as on the ability to swarm emerging problems and solutions quickly. Distributed networks of innovators are enabled by the very platforms that they now have the ability to change and improve. And those self-forming bands of problem solvers are essentially location-free.
Increasingly, we live within the so-called Internet of Things, a world in which everyone and everything is connected, with data being the essential lubricant. “Big data” and “analytics” have been buzzwords in the technology and corporate worlds for some time now, but the measurable impact and potential of this data is now starting to become clear. The truly stunning thing about big data is not how much of it there is, but its breadth of distribution. Current sensing, pulsing, and polling devices built into our digital worlds allow us to see one another, both as individuals and collectively, with the clarity that makes smart, data-driven, innovation possible practically everywhere.
As these ecosystems have developed, and as the amount and quality of data has improved, an enormous opportunity zone has opened. Salesforce has over 1 million developers, most of whom are not on our payroll, who customize the Salesforce platform at the point of usage to unlock value which often remains hidden to us at the hub. Rather than fight that, we run the company to magnify the innovation quotient at those distant transactional edges. End users might now find themselves delighted by the contributions of the whole ecosystem—customers, partners, and ISVs—augmenting the innovation they’re used to, delivered by the folks at Salesforce.com.We as the IoT practice of Deloitte Germany are delighted to introduce our new blog today.As part of the global IoT initiative at Deloitte, the German practice drives business-value focused IoT solutions from the very first idea to the global operation. We offer detailed insights into the possibilities and sustainable value of IoT solutions and develop custom strategies across industries.
On this blog, we share learnings from our IoT projects and introduce best practices as well as our Point of Views. We offer additional findings, statistics and analyses, publish interviews with IoT experts and keep you up to date about major IoT developments.
Initially established in summer 2016, we have since grown into a team of 40+ practitioners led by Dr. Gunther Wagner and Andreas Staffen. To name just a few, let us introduce ourselves as some of the contributors to this blog.
Nowadays, billions of interconnected sensors and devices are enabled and qualified to exchange data in real-time. Together, they form the Internet of Things, enabling critical insights, greater efficiency, and new business models in dozens of industries, creating trillions of dollars of value globally.
We focus on the corporate application of IoT solutions in specific organizations rather than single end-user devices, which is reflected in how we approach IoT. Our work spans from the identification of suitable strategic courses of action, over respective technology and organizational transformation to a steady optimization of operation and delivery principles. More details regarding our IoT service offerings are following in a separate blog post.
Get in touch with our team to start a conversation about how your organization can leverage the full potential of the Internet of Things.The Internet of Things (IoT) is playing an increasingly important role not only in industry, but also in our daily life. A basic understanding of the relevant technologies, procedures and tools is very helpful in order to benefit from the tremendous opportunities of the IoT as an IT professional, manager and entrepreneur. Therefore, Deloitte’s IoT Community hosted the IoT Bootcamp for industry partners at the Deloitte Digital Factory in Dusseldorf on December 5th and 6th 2019.Karel co-leads the Firm’s Operations practice and Internet of Things (IoT) group in Asia. Since joining the Firm in 1997, Karel has worked across multiple industries including advanced industries, automotive, electronics, energy and materials, technology, as well as private equity.
October 16, 2018 Nearly every global manufacturer seems to be testing Industrial Internet of Things (IIoT) technology, but in a recent McKinsey survey, nearly 70 percent of business executives said that their IoT initiatives are stuck in pilot purgatory, unable to reach company-wide scale. Furthermore, respondents said that only 15 percent of IIoT initiatives move to scale within one year, and a quarter of these initiatives extend longer than two years in pilot mode.
Clearly, this is not ideal, as pilots alone do not deliver the bottom-line impact companies need to remain competitive in the Industry 4.0 era. Even worse, because pilots do not encompass the full spectrum of what is possible with IoT-led technology transformation, these initiatives too often get cancelled because of the lack of a long-term vision and roadmap. But there is good news: designing the information technology/operational technology (IT/OT) architecture properly will enable companies to architect robust IIoT pilots that can rapidly scale.
Given that pilots often get bogged down because they’re too narrow to scale well, it’s imperative to design use cases so that they deliver end-to-end value for company-wide benefits. That also means addressing the overall IT/OT architecture design from the get-go to encompass the breadth of use cases. And with the IT/OT environment becoming more complex every day, the goal must be to sequence use cases based on two considerations:
The priority of the use cases to the enterprise, based on predetermined KPIs that are linked to business value creation, and The ability of technology to support these use cases, while in parallel building both the technology stack (also known as the “platform”) and the applications specific to those use cases.
In our previous post, we described the factors that make constructing a scalable technology stack especially challenging in an industrial setting, such as the complexity of the industrial-automation ecosystem, the alphabet soup of sensor subsystems, legacy machines that are still unconnected, and poor collaboration between IT and OT departments.
Consequently, industrial companies often struggle to determine how best to source a solution that truly unlocks value from data and analytics. Vendors of all types are introducing new technology to capitalize on this trend, as they seek to secure a portion of the multi-billion-dollar market (exhibit).
Exhibit We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
At one end, traditional industry-automation vendors that are established incumbents, with strong positions in control points, are introducing complementary IoT solutions to help manufacturers deploy an end-to-end IIoT platform. The playing field also comprises established vendors from both the OT and IT stack, each with strengths in different technologies. Some vendors are attempting to create portfolios that span most of the IT/OT automation stack, while others are steadfast in their commitment to a focused area of expertise.
We looked at five of the top automation vendors and found that most are expanding their IIoT portfolio and capabilities. The overall landscape thus remains unsettled. For example, just among this vendor subset, there are almost 50 proprietary offerings in more mature areas of the stack, such as manufacturing execution systems and similar technologies—and standardization across industry use cases has yet to take off. We also found that several major vendors lack offerings in areas such as building automation, human-machine interfaces, and sensors and RFID.
To add another layer of complexity, traditional software vendors are competing for their share of the industrial-cloud ecosystem. Most approach the ecosystem from bottom up, with initial success as an infrastructure-as-a-service (IaaS) provider, leading to vertical integration in platform-as-a-service (PaaS), and finally leading to non-industrial software-as-a-service (SaaS). The natural extension is then to enable industrial SaaS.
As with the automation stack, there are several major players competing but there is no clear leader. For plant operators, it’s therefore nearly impossible to predict who will come out on top, leaving internal teams to navigate a complex landscape of evolving technology offerings from vendors with whom they have an established and amicable relationship—both on the IT and OT side. The only clear message right now is that no single vendor will likely be able to solve all of a company’s requirements.
Knowing your starting point and destination can help make even the most complex journey navigable. This is true of developing an IIoT stack capable of scaling. We recommend our clients take the following steps when initiating an IIoT pilot. Over the next few blog posts, we will deep-dive on each of the following steps with examples where applicable.
Start by generating a solid list of use cases. Focus not only within the four walls of a given plant, but also extend into supply chain and design, with a view to enabling digitization of complete value chains. This exercise doesn’t have to be exhaustive, but it should be representative of the things the stack needs to be able to do for you. For each use case, you can then determine the tech-stack requirements, which collectively will show what the tech stack will have to deliver to achieve scale at the right speed and cost.
Focus not only within the four walls of a given plant, but also extend into supply chain and design, with a view to enabling digitization of complete value chains. This exercise doesn’t have to be exhaustive, but it should be representative of the things the stack needs to be able to do for you. For each use case, you can then determine the tech-stack requirements, which collectively will show what the tech stack will have to deliver to achieve scale at the right speed and cost. Develop a future-state reference architecture based on business need. Begin with an assessment of your current IT/OT stack, from plant level to the whole enterprise, looking at everything from technology architecture to manufacturing applications and tools. Also review previous IIoT pilots, identifying pain points that prevented projects from moving forward.
Begin with an assessment of your current IT/OT stack, from plant level to the whole enterprise, looking at everything from technology architecture to manufacturing applications and tools. Also review previous IIoT pilots, identifying pain points that prevented projects from moving forward. Incorporate data expertise up front. Avoid delays and needless iteration during implementation by having data scientists, who know the data they will need to have when building their analytics models, participate in the design of the reference architecture. The data scientists will also need to work with the process engineers to ensure that the data can be both collected accurately at source and aggregated into the right location at the right time.
Avoid delays and needless iteration during implementation by having data scientists, who know the data they will need to have when building their analytics models, participate in the design of the reference architecture. The data scientists will also need to work with the process engineers to ensure that the data can be both collected accurately at source and aggregated into the right location at the right time. Define a core architecture choice. Assess the pros and cons of selecting a single platform, an ecosystem of vendors, or a hybrid approach, before aligning on an overall direction.
Assess the pros and cons of selecting a single platform, an ecosystem of vendors, or a hybrid approach, before aligning on an overall direction. Recommend tech choices specific to use cases. Agree on tech-stack requirements for prioritized use cases and compile decision criteria. Tailor existing evaluations of IIoT platform providers against the decision criteria to identify top choices.
Agree on tech-stack requirements for prioritized use cases and compile decision criteria. Tailor existing evaluations of IIoT platform providers against the decision criteria to identify top choices. Chose vendors based on both tech capacity and human capability. While getting the right tech is essential, getting it to work depends on system-integration capabilities as well.
Deploy technology for prioritized use cases in the short term. For the prioritized use cases, invite a curated list of vendors into your organization’s ecosystem.
For the prioritized use cases, invite a curated list of vendors into your organization’s ecosystem. For the long term, create and align IT/OT roadmaps. Draft consistent IT and OT roadmaps that align with your organization’s broader business goals and underlying tech, then syndicate and refine them—noting that the time scale will be very different from a multi-year ERP implementation.
Following this approach will help your company navigate the complexities of the IIoT landscape to capture value quickly. Watch this space for more on each of the steps listed above.
The authors would like to thank Mike Coxon, Subu Naranayan and Bodo Koerber for their contributions to this post.Digitization in companies is advancing more and more. Even though processes are increasingly being carried out electronically, logistics service providers often receive their orders outside the transport systems - often still via analog channels. This increases the effort required on the part of logistics service providers to record shipment data.
In order to optimize the yard planning, staff utilization and operational processes, an increasing number of clients is asking their logistics providers to book dedicated time windows to pick-up and deliver goods. The booking of the time windows usually needs to take place 24h before pick-up/delivery. The booking itself causes additional effort for the logistics providers and reduces efficiency. In addition to that, the flexibility to plan the pick-up/delivery tour is reduced which can negatively affect the utilization of the available loading capacity.
Customers are increasingly demanding reliable transparency on the status of shipments from their service providers. This requirement presents logistics companies with an enormous challenge. On the one hand, the recording of the conventional barcode by warehouse personnel is time-consuming and therefore inefficient. On the other hand, additional information, such as temperature or vibrations, must be transmitted to the customer more frequently. Current transport systems are often not suited to provide this type of information.
In the event that companies do not transmit their shipment data electronically, the data must be recorded by the service provider. This entails the risk of incorrect information being recorded, which is even increased by the existing shortage of skilled workers and outsourcing. In addition, shipments cannot be reloaded as long as the shipment data has not been recorded. In reality, this repeatedly leads to delays in operational processes.The role of IoT in the manufacturing industry is increasing. Gartner forecasts 20 billion internet-connected things by 2020. Although it is not about general-purpose devices, but about dedicated-function objects, such as jet engines, connected cars or even coffee machines. Besides new business applications, IoT solutions enable businesses to analyze data generated by IoT edge devices and use these insights as a basis to improve business decisions. This article focuses on the IoT platform as one essential component of this development as well as introduces the Deloitte Digital Platform (D²P), which allows you to integrate and collaborate with data coming from various systems, devices, applications and human interaction.
A lack of interface and communication standards lead to a gap between IoT edge devices and business applications. An IoT platform closes this gap by acting as a middleware, which mediates between the two ends. However, modern IoT platforms go one-step further by adding functionality to the hardware and application layer. For this reason, capabilities for edge data processing or complex data analytic algorithms can also belong to the functionality set of an IoT platform. In general, IoT platforms are all about enabling businesses to build IoT solutions faster, cheaper and better, by solving problems and complexities related to the interoperability between infrastructure and business applications.Niccolò Machiavelli, one of history’s great futurists, might have predicted the Internet of Things (IoT) when he wrote, “There is nothing more difficult to take in hand, more perilous to conduct, or more uncertain in its success, than to take the lead in the introduction of a new order of things.” The IoT’s early innovators, who have grappled with mixed overall demand, a lack of consistent standards, and other challenges, would agree that their road has been difficult. But, like other visionaries before them, they have persisted in establishing a new order because they see the promise ahead.
Both consumers and the media are fascinated by IoT innovations that have already hit the market. These “smart” devices have sensors that communicate seamlessly over the Internet with other devices or the cloud, generating data that make the world safer, more productive, and healthier. In just a few years, some IoT devices have become standard, including thermostats that automatically adjust the temperature and production-line sensors that inform workshop supervisors of machine condition. Now innovators want to enable more sophisticated IoT technologies for self-driving cars, drone-delivery services, and other advanced applications.
Although some analysts are excited about the IoT’s potential, others have argued that it is overhyped. We take a more balanced view, based on our extensive research as well as our direct work with IoT application developers and their customers. Like the optimists, we believe that the IoT could have a significant, and possibly revolutionary, impact across society. But we also think that the lead time to achieve these benefits, as well as the widespread adoption of IoT applications, may take longer than anticipated. The uptake of IoT applications could be particularly slow in the industrial sector, since companies are often constrained by long capital cycles, organizational inertia, and a shortage of talented staff that can develop and deploy IoT solutions.
For semiconductor companies, which are looking for new sources of revenue, the rate of IoT adoption is an important concern. In this article, we will look at the case for optimism, as well as the reasons for more modest expectations. We will also examine new technologies that could accelerate the IoT’s growth and product-development strategies that semiconductor companies could implement to increase the appeal of IoT offerings.
If we look at the IoT’s recent growth, the optimists have reason to be encouraged. Consumers are more connected than ever, owning an average of four IoT devices that communicate with the cloud. Globally, an estimated 127 new devices connect to the Internet every second. A report from the McKinsey Global Institute estimates that the IoT could have an annual economic impact of $3.9 trillion to $11.1 trillion by 2025 across many different settings, including factories, cities, retail environments, and the human body (Exhibit 1).
Exhibit 1 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
The IoT is also benefiting from infrastructure improvements that have enhanced connectivity. For example, only 20 percent of the global population is now covered by low-power, wide-area networks (LPWANs) that allow long-range communications among connected devices while optimizing both costs and power-consumption requirements. By 2022, however, we expect that 100 percent of the population will have LPWAN coverage. Similarly, technological advances are reducing power requirements, decreasing costs, and promoting the development of more integrated IoT solutions. Consider lidar sensors, the laser-based sensor packages that scan and detect surroundings, which are essential for autonomous driving. Their price has declined more than 10-fold over the past eight years and is expected to drop more than 65-fold over the next two. This decrease, combined with the increased technological sophistication of lidar, is contributing to the development of fully autonomous cars, which could constitute 25 percent of all vehicle purchases by 2035.
Many experts view the IoT’s slower-than-expected growth within the industrial sector with particular concern. To gain more perspective, we investigated how industrial companies are using IoT applications and tried to estimate whether business-to-business (B2B) growth might accelerate. In addition to basic research, we interviewed and surveyed over 100 leaders from various industries, including public sector and utilities, discrete manufacturing, oil and gas, mining, telecommunications, technology, media, healthcare, and pharmaceuticals.
Our interviews revealed that most businesses are adopting the IoT only to a limited extent. With the exception of oil and gas and mining, leaders from all industries reported that their companies often received real-time data from IoT sensors. However, most leaders reported that their enterprise deployments were still at proof-of-concept stage, and none have yet embarked on large-scale programs (Exhibit 2).
Exhibit 2 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Although IoT sensors collect vast stores of data, a recent report from MGI showed that companies do not analyze most of them. For example, on an oil rig that had 30,000 sensors, managers examined only 1 percent of data. What’s more, business leaders seldom consider information from IoT sensors when making important decisions, including those related to maintenance planning or automation procedures. Their reluctance to examine IoT data stems from several factors, including a lack of data-analytics staff, but the most important reason is simple: as humans, we prefer to consult other people for advice or to look back on our own experience, when making decisions. Although hard data from IoT devices are more complete and objective, we tend to assign them less value. Before IoT data gain a more prominent role in corporate decision making, business leaders and other important managers—maintenance supervisors, field service technicians, and retail merchandisers, to name just a few—will have to appreciate their value.
In our survey, respondents favored simple use cases that enable tracking data and sending status alerts related to changes in the physical world (Exhibit 3). Some companies, for instance, have placed sensors in food packaging that track a product’s location throughout the distribution supply chain. Simple tracking and alert functions are relatively easy to deploy because they do not require advanced analytics, complex algorithms, or data-science capabilities, allowing them to generate value quickly. Although some innovators are enthusiastic about IoT applications for optimization and prediction, we expect that most customers will remain focused on simple use cases, at least for the immediate future. And that means they will not obtain full value from the IoT.
Exhibit 3 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
IoT devices, connected cars, and edge gateways are all potential entry points for a cyberattack—and we recently saw the full extent of this vulnerability. In the 2016 Mirai botnet attack, hackers specifically targeted IoT devices, including appliances and routers, and disrupted many major Internet service providers. The attack, the most significant of its kind, was possible only because of human weakness—a failure to reset generic or default password and username combinations. This attack, and others like it, demonstrate that IoT vulnerabilities often result from a lack of basic care in managing and maintaining devices. Such weaknesses cannot be eliminated through encryption, attack-detection programs, biometric-access control, or other sophisticated technologies. That means companies that want to expand their IoT efforts will need to launch comprehensive security initiatives that address weaknesses resulting from both technological vulnerabilities and a lack of caution among those who use IoT devices.
A few important, and potentially disruptive, developments could accelerate IoT uptake and create opportunities for semiconductor players.
Video analytics—the application of sophisticated algorithms to video feeds—is spurring the creation of new IoT applications and use cases. For instance, data analysts can now examine customer demographics by applying sophisticated algorithms to videos taken as shoppers browse through merchandise. Recent evidence also suggests that the IoT will benefit from audio captured on microphones.
The costs associated with video and audio feeds are falling, with sensors now embedded in devices at low cost—under $2 each. The data gathered from these feeds are extremely rich, diverse, and relevant to many widely used IoT applications. Lower data-communication rates, the growth of 5G data networks, and ongoing decreases in cloud-storage costs will continue to encourage developers to find new uses for video and audio.
For semiconductor companies, the increased importance of IoT video and audio feeds may create an opportunity to combine hardware with end-to-end approaches for analytics and control. They will have to move quickly to meet customer needs, however, since the technology related to advanced applications, such as those that use analytics to recognize faces, is evolving rapidly. Semiconductor customers may be particularly interested in products that integrate hardware and software more closely, as well as new architectures that optimize transmission, processing, and analytics on devices, in the network, and in the cloud.
The advent of standards that support truly LPWANs, including LoRa, NarrowBand IOT, and Sigfox, will enable large-scale sensor deployment of IoT applications in many areas, including agriculture (analysis of soil conditions), safety (citywide monitoring of air quality), and productivity (real-time logistical tracking along the supply chain). But the growth of the IoT, combined with the increase in sensors and connectivity, will also make it more challenging to provide power to untethered devices and sending nodes. Even with long-life battery technology, many of these devices can only function for a few months without a recharge.
Energy harvesting, a process in which energy derived from external sources is captured and stored for use in wireless devices, might resolve power-related issues. Although solar energy could provide an answer for many IoT applications, semiconductor companies should also investigate other sources, such as wind, thermal energy (derived from heat), and kinetic energy (derived from an object’s motion). Optimizing energy harvesting, management, and storage will require companies to create innovative designs, at both the silicon and system level.
As the IoT expands, innovators are rapidly developing complementary architectures that combine the following two important features:
the power of the cloud, which offers robust storage and greatly extensible computing power at low cost
the ability to process and store data on a device (or edge), or within a network at gateways that connect multiple end-devices to the cloud
Multiple IT architectures with these properties have already reached the market, each offering a compelling approach. But semiconductor companies have an opportunity to go further—and to make more rapid progress—in defining the future architecture of the IoT. In particular, they should focus on products related to video and audio sensors, since these devices are proliferating and generating significant amounts of data.
Many IoT applications require data to be processed on the devices themselves. For instance, applications for autonomous driving, surveillance, and security all have strict latency specifications that require systems to respond immediately after data input. To meet these requirements, the IoT devices that collect the data must process them and use the output to make decisions. Applications that require on-device processing are power hungry and include relatively expensive components, such as multiple application processors. Semiconductor companies could take the lead in optimizing on-device solutions for these applications. For instance, they could create edge-device solutions for autonomous control, facial recognition, and audio analytics, all of which have different hardware and software requirements with respect to computing performance, signal processing, and storage.
Before any company explores IoT opportunities, it should take a new look at strategy, including the factors that it considers when developing solutions.
Both developers and business leaders often focus on the technological potential of the IoT, including its ability to collect and analyze vast stores of data. But technological advances alone will not make an IoT application more valuable or desirable to customers. Instead, developers should focus on outcomes—how a new application will improve safety, financial returns (for businesses), and convenience.
Consider, for example, the outcomes that one airplane manufacturer achieved by using IoT sensors to monitor jet-engine performance. By providing real-time data, the sensors immediately alert the manufacturer about potential problems, which makes it easy to conduct preventive maintenance and maximize uptime. Other sensors help with parts-inventory management. Together, these IoT enhancements have contributed to 9 percent revenue growth and a 30 percent increase in engine availability. That means airplanes spend more miles in the air and less time on the ground, consistently reducing overall operating costs.
To focus on outcomes, companies will have to coordinate activities across the value chain. In addition to providing the technology and data that enable the IoT, they will need to adapt their business models—a difficult process, in our experience, since incumbents often resist change. If they fail to evolve, a start-up or another disruptive player may take the lead in establishing a new approach to IoT application development, especially if new investors emerge to finance innovative ventures.
As companies shift their focus from technology to outcomes, they will need to provide incentives that encourage upstream vendors and customers to support the use of their applications.
Just as IoT innovators tend to focus on technology, many IoT marketing materials try to appeal to customers by discussing the latest product upgrade, including better sensors, connectivity, computing power, and analytics. But our experience has consistently offered one clear insight: users, both personal and industrial, are more likely to adopt IoT technologies that generate a positive emotional reaction. Consider smart homes, where technology companies have recently won many customers by offering voice-based products—devices with basic conversational abilities that often respond to a name, just like a person. For instance, Amazon’s Echo, a smart-home speaker, answers to the name Alexa and can respond to basic commands and questions. Such qualities may create an emotional connection between users and devices, and they could be partly responsible for the strong sales of voice-based products.
As technology companies develop new IoT offerings, they should ask digital designers to provide insights about customer behavior, since this information might help them create products that prompt strong positive feelings and accelerate adoption rates. As always, products will also need strong technical and analytical capabilities, but companies are more accustomed to delivering such features.
Current IoT trends create an uncertain and sometimes confusing picture of the sector’s future prospects. When we look at the evidence in total, however, we believe that the IoT is poised to serve as a major growth driver for semiconductor companies. Adoption rates have risen more slowly than expected, but that should not be a reason for pessimism, since many IoT technologies are immature or undergoing development. Semiconductor companies and other players can still undertake new strategies to accelerate IoT growth. Rather than focusing on technology upgrades, they could develop IoT products that truly improve customer outcomes for cost, performance, and other important metrics. They could also emphasize design-driven insights about customer needs, including the product features that generate a positive emotional response. This new approach to development will be challenging, but it will accelerate IoT adoption and help more customers, both personal and industrial, achieve benefits from this exciting new technology.Internet of Things (IoT) technologies have evolved rapidly in recent years and continue to change how we interact with our surroundings. For companies, IoT brings new ways to monitor and manage objects in the physical world, while massive new streams of data offer better avenues for decision making (often mediated by machines). The steady fall in prices of sensors and communications technologies, combined with a parallel rise in understanding of how they can be applied, have raised the strategic importance of IoT. As we have shown elsewhere, this can produce immense value in settings ranging from retail and healthcare to manufacturing and technology.
Despite the promise, we continue to see substantial differences in how well companies apply IoT in their businesses. Targeting IoT applications correctly and managing them effectively is far from easy, leaving many companies stuck and unable to move beyond pilots. To better understand what differentiates successful initiatives from struggling ones, we surveyed IoT executives at 300 companies—those that have moved beyond experiments and have scaled up IoT use in their businesses. We asked them about the practices that directly support their IoT strategy, as well as other factors that may influence it, and sorted leaders from laggards based on their self-reported economic impact from IoT. We found that while a number of IoT “habits” play a role in successes, three are particularly relevant for C-level executives who may be considering heavier investment in IoT or searching for reasons their programs have failed to gain traction.
There’s no single path to IoT success. Some companies focus on connecting existing products to make them more attractive and useful to customers. Others exploit opportunities to achieve operational improvements that increase efficiency and lower costs. Still others push more boldly, using connectivity to create entirely new products or remake business models (even moving into separate IoT businesses). Our survey found that companies that achieved scale in IoT did so by pursuing a variety of strategies—and all with at least some degree of success. However, when we looked more closely at the gains, we found that the most successful companies often played to their strengths—rather than betting on unfamiliar markets or new products (Exhibit 1). These IoT leaders, the group getting the most economic benefit from IoT, were nearly three times more likely to add IoT connectivity to existing products they sell than the laggards were. Conversely, laggards—those in the bottom quintile of economic returns—were significantly more likely to focus on developing new IoT products or services.
Exhibit 1 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Playing to market strengths was the course chosen by strategists at an agricultural-equipment manufacturer, after they observed digital players from outside the industry sizing up opportunities to offer sophisticated analytics services to farmers. In response, the company shifted R&D investments to “IoT-enabled” products and services in existing lines of business. Their new system used farm-based sensors to read soil conditions continuously, relaying the information to a cloud-based analytics platform that farmers could use to monitor variations on their mobile devices. Other sensors tracked irrigation levels and sent alerts whenever moisture readings hit predefined levels demanding attention. With these real-time insights, farmers were able to optimize their water and fertilizer use. That, in turn, increased yields over the growing season while substantially reducing water, fertilizer, and fuel costs for equipment. As the manufacturer added users, the growing quality and breadth of data improved the predictive capabilities of the system, further increasing value to farmers who joined the ecosystem.
The success of the agriculture manufacturer underscores the advantages incumbents often have in their ability to define use cases for IoT that build upon existing product lines, as well as their better line of sight on how improvements can create value for customers.
Many companies become frustrated when they don’t see early signs of transformative impact from an IoT pilot. Our research points to one key reason: a single use case just won’t get you there. Scale, both in terms of number of use cases as well as the breadth of application, helps maximize impact. Leading companies in our survey implemented on average 80 percent more IoT applications than laggards. More widespread usage, it seems, forces a cultural shift. It stokes organizational energy behind changes and creates new mindfulness about the benefits of IoT. In a ripple effect, this momentum often exposes weakness in technology along with gaps in talent—both in terms of in-house IoT skill levels and the numbers of experts needed to implement IoT at scale. This “go big” approach may seem counterintuitive, particularly among executives who have fewer resources to deploy and feel more comfortable focusing on a small number of applications. While a smaller scale may be good for very early days, there is a clear learning curve that companies climb as they add use cases—and one that has a powerful impact. Our research shows that a greater number of use cases correlates with economic success (Exhibit 2), regardless of the use case or type of company.
Exhibit 2 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Take the experience of one major transportation-equipment manufacturer whose initial IoT deployment, executives soon realized, just wasn’t bold enough. It had launched the IoT strategy with four minimum viable products (MVPs) but soon found that this narrow focus wasn’t improving performance as much as expected. A cadre of IoT leaders pushed against voices of caution and expanded the number of MVPs to 11. Executives also found that giving managers a larger number of IoT projects (and products) to oversee focused their attention, creating a bias toward action. That momentum built on itself as the company’s best talent wanted to be part of the innovative push. A broad base of 30 IoT scrum teams, meanwhile, helped loosen bureaucratic decision-making rules. Finally, unexpected efficiencies turned up as engineers were able to use similar data architectures for multiple offerings and found numerous synergies among the digital end products. The more aggressive use-case strategy produced in excess of $1 billion in new revenue.
IoT is one of today’s most promising (and exciting) technologies. But people create the conditions for value creation. IoT has often been portrayed primarily as a technical-implementation challenge, with the drive for adoption spearheaded by specialists in the CIO function. Yet time and again we see that deriving real business gains from IoT efforts requires changes to a business process—the hard job of modifying the way a company does things. Connecting production equipment to the internet, for example, will allow a company to manage usage more effectively and predict when maintenance is needed. However, if the surrounding business processes aren’t modified and optimized, then value won’t be maximized.
Those second-order challenges were manifest at one metals manufacturer. The company had connected three rolling mills with sensors in an IoT deployment. The goal was to capture and analyze previously unused data from the machines. Executives were pleased that they were able to get the system up and running in just three weeks, to help solve nagging capacity constraints at the facility. However, there was a problem: the insights generated by the system weren’t being used by the frontline employees.
The management team responded by modifying a range of plant-floor processes. For starters, they simplified the complex analytics that the system was churning out, synthesizing the output into one number that measured operator wait time. This change enabled line operators to recognize immediately when bottlenecks in the process were forming. The company then changed the inspection routes of plant-area supervisors, whereby they circled back to bottlenecked lines four times daily, checking in with the operators on how many times they had to wait—and why. Those discussions resulted in a change to daily plant-area “huddles” that included the operators, who were given greater latitude to adjust frontline processes to resolve underlying issues before they caused product flow backups. The IoT-informed process changes had a big effect. Operators were able to identify several hidden causes of slowdowns and stoppages, issues that earlier problem-solving efforts had missed. Overall equipment efficiency increased by 50 percent, saving hundreds of millions of dollars in planned capital expenditures.
This metals manufacturer learned that, in order to maximize IoT value, people have to behave differently, make decisions differently, and operate in a new normal of rapid information flow. It’s not surprising, then, that IoT leaders were three times more likely than IoT laggards to claim that having a strong ability to manage business-process change was a top-three IoT capability.
As we noted earlier, companies need to be attuned to other reasons why IoT deployment may fall short. For one thing, if the CEO and top team aren’t focused on potential IoT gains, providing visible encouragement (and adequate resources) for the efforts, they are likely to stall. Leaders need also to be mindful that IoT increases the potential for privacy breaches and data-security risks, since there are many more information nodes for hackers to penetrate. These risks need robust and continuous management, and those costs need to be incorporated into projected returns. Finally, even companies with a good IoT track record shouldn’t think they can go it alone. Technical IoT ecosystems are growing—and improving—by the day. Collaboration, often with smaller players that have high levels of expertise in areas such as software development, will provide a solid source of competitive advantage. That will help companies accelerate their programs and better position themselves to become IoT leaders.January 31, 2019 Business-process optimization has always been a labor- and time-intensive activity. The traditional method for uncovering the root causes of process problems—value stream mapping—involves a team, a room, and a stack of Post-it notes. Mapping the loops and alternative pathways involved in a process such as order-to-cash, claims processing, or source-to-pay can reveal plenty of hidden waste. And bringing different stakeholders together in a room can be an excellent way to create an end-to-end perspective on processes that may involve multiple stakeholders, sites, and business functions.
Traditional process mapping has an important weakness, however, in addition to the many hours of work it requires. It often relies on estimates for how long individual process steps take, or how often variances occur. As a result, these maps inadvertently represent the biases and misunderstandings of their creators. That can lead companies to miss important issues, or to focus too much attention on problems that occur infrequently and cost the business little.
Enter the new digitally-enabled world of intelligent process analytics. Every piece of information that flows through a business today generates its own digital trail, creating a plethora of data revealing where the information went and when. Now, a new generation of smart analytical tools allows companies to use that data to see what is really going on in their back-office operations.
These “process mining” tools can rapidly analyze thousands of transactions to reveal the underlying process flows. More powerfully still, they allow managers to slice business process data in multiple ways. They can show exactly which types of invoices are most likely to require manual rework, for example, or they can automatically generate key performance indicators, segmenting them by task type, customer, or operations team. Or they can monitor the effectiveness of new digital workflows, identifying the categories of task that still escape from digital process flows and demand manual intervention.
These tools can also help with the design of process changes or automation efforts. They allow companies to validate the effectiveness of those changes as they roll out. And because they can deliver useful results quickly and easily, process mining systems are especially useful in agile development environments, where robotic process automation and other new digital approaches are introduced in a rapid, iterative way.
Process mining solves several major challenges. It brings speed, analytical power, and fact-based rigor to the problem of uncovering the sources of waste, inefficiency, and lost value in business operations. But, on their own, these tools can’t do anything about fixing those problems. That’s where the hard work starts.
The smartest of analytical tools can only deliver value if they are used in the context of a wider transformation effort. Companies still need teams of people with the skills, influence and motivation to design effective processes and select appropriate performance indicators, to turn analytical insights into concrete plans of action, and then to test, roll out and sustain those processes. And the cross-functional and interconnected nature of business processes means they will also need to carefully coordinate multiple improvements to avoid introducing new problems and unintended consequences elsewhere.
We are excited about the potential for emerging process mining technologies. We have already seen companies use them to great effect in a number of different sectors. But we also know that a diagnosis is not a cure. Without the right approach, expertise, and energy to transform insights into lasting change, companies risk gaining scant return on their investment in these tools.
The authors wish to thank Klaus Kunkel, Rohit Panikkar, and Samir Singh for their contributions to this blog post.The IMA® (Institute of Management Accountants), the association of accountants and financial professionals in business, held its 2019 Annual Conference and Expo (ACE2019) this past June in San Diego, California. The event officially celebrated the Institute of Management Accountant’s 100-year anniversary with a special Centennial Celebration honoring IMA’s thriving global community of accounting and finance professionals. Attendees had the opportunity to network with other industry professionals, hear presentations from leaders, and choose from more than 75 job-relevant sessions tracks designed for management accountants to customize their learning experience on topics ranging from corporate governance to technology and finance trends for the future.
As a diamond level sponsor, Deloitte had the opportunity to attend the action-packed conference and deliver presentations on specialty topics. Deloitte delivered a specialty breakout session on touchless close as well as a general presentation on the Center for Controllership™ during the IMA annual conference dinner.
To gather some insights and perspectives that may help us with future conferences and projects with IMA, we caught up with our presenters and some of the attendees to hear about some of their highlights from the experience and insights they were able to take away from the conference.Insert Custom CSS fragment. Do not delete! This box/component contains code needed on this page. This message will not be visible when page is activated.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.May 21, 2020 Stefano is a McKinsey Digital engagement manager based in Singapore. He conducts more than 30 interviews a year for both digital and generalist consulting roles. Focusing mostly on campus interviews (e.g., INSEAD), he also participates in experienced professional interviews.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
I love meeting new people through our recruiting process and learning about their backgrounds and experiences, as well as their approach to problem solving. People are what drive the firm, and recruitment is how we attract and hire exceptional talent.
I think of recruiting as a two-way process in which the candidates can learn more about the firm, the kind of work we do and the impact we have, and about the people who may become their colleagues. I am very excited at the end of an interview when the candidate has a chance to ask questions. I see this as an opportunity to get them even more excited about the prospect of joining us.
One memorable moment was when I interviewed a candidate who was at a remote mine site in West Africa, which meant he had to conduct interview via video on his phone. He had to travel to the nearest village to get strong mobile reception, which meant he was going to participate in the interview on the street. It was funny to see other people walking behind him and curiously trying to figure out what the phone call was about. I was impressed and appreciated his willingness to interview in an unconventional setting.
Don’t neglect the personal experience part of the interview. Make sure you prepare as much for that portion as for the case studies. Be sure to focus on experiences in which you were really challenged and stretched, and walk the interviewer through some of the details of your experiences. For example, share what you felt or how you handled a particular situation and bring your leadership, entrepreneurship, and personal impact to life.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Stefano graduated from Florida State University with a Bachelors in Economics. He started his career at BHP Billiton, the mining company, in commercial functions in Singapore as a marketing manager. After six years, he left to pursue his MBA at INSEAD and worked at two consulting firms based in Australia and Singapore. In 2018, Stefano joined McKinsey Digital.
Outside of work, Stefano loves to travel. He enjoys exploring cities he travels to for client work. These days he enjoys playing hide-and-seek with his daughter and watching live streams of the Bolshoi Theater Ballet and the Kruger Park safaris.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.May 13, 2019 When we talk to clients about their hiring process, we often get questions on assessments. In particular, one question we often see is starkly simple yet deceptively difficult to answer—which hiring assessments, among the sea of available options, are best? We believe that this question belies a broader misunderstanding of assessments.
Assessments are simply a standardized means of collecting information about an applicant to help with hiring or promotion decisions. It is a broad category and can take the form of a standardized written assessment, a resume screen or an interview. There is not one assessment that is a gold standard to be used universally across all roles—it depends on what characteristics matter for the role in question (see our previous post for more on that process).
If there isn’t direct science linking the assessment to job performance or to the characteristic that matters for the job in question, don’t use it.
In this third and final part on hiring, we dispel four of the most pervasive, detrimental myths regarding the use of assessments in hiring.
1. The more assessments, the better. Despite what many think, using more assessments is not always better—and can often be worse than using too few. Using additional assessments that do not meaningfully distinguish who is best suited for the job will result in worse hiring decisions than if these additional data points were not used at all. Worse yet, too many lengthy assessments can negatively influence the candidate experience and decrease the size of the candidate pool. In one case, a staffing firm we worked with found that long screening assessments were causing otherwise promising candidates to drop out of the process, thereby driving down the quality of hires.
Using less scientific tools, like an unstructured interview, introduce noise to the decision-making process and may bias against certain types of applicants. Simple advice—if there isn’t direct science linking the assessment to job performance or to the characteristic you’ve determined matters for the job in question, don’t use it.
2. Assessments that use the latest machine learning/AI are better than long established assessments. While we share the enthusiasm for the potential of advanced technologies and techniques (e.g., gamified assessments), we shouldn’t throw the baby out with the bath water.
It is important that new approaches are held to the same standards of integrity to which we hold more traditional assessments. Decades of research has shown that traditional assessments of cognitive ability and personality traits (e.g., conscientiousness) are still some of the best predictors out there.
At a minimum, assessment vendors should have technical documentation describing the reliability, validity and prescribed uses of their assessments. Also pay attention to any information on test bias, administration requirements and potentially available databases for scoring and test interpretation.
3. Hiring assessments are only for hiring decisions. Just because they’re often called hiring assessments doesn’t mean their usefulness stops there. All too often, organizations are sitting on a treasure trove of information about their employees from the hiring assessment process, but once the hiring decision is made everyone forgets about this data.
We maintain that this data can be very useful for onboarding and ongoing learning & development of new hires. Perhaps your organization has hired a new technical product manager who you learned during the interview has less experience in AI products. We highly recommend leveraging this assessment information to create a tailored training plan for their first 6 months on the job.
4. Standardized assessments are less useful for leadership positions. When used in the right way, we have found that assessments have a place across the hierarchy. As with entry-level positions, having a structured approach to gather information on leaders via assessments is helpful. With leaders, though, the degree and type of information needed to make quality decisions is necessarily different. Although a two-hour cognitive ability assessment may be overkill, concrete information about leaders’ interpersonal and working style may be worthy of exploring in a short personality assessment or structured interview.
By tackling these 4 assessment myths, in addition to navigating the 3 main challenges that make hiring difficult and following these 3 concrete steps to improve your hiring process, your organization will be well on its way to winning with talent.August 12, 2019 Imagine if an agency, retailer or bank could map its audience’s journey, fully understanding the experiences, actions and pain points that both drive and undermine the organizational decision-making process. Recent McKinsey research shows that most companies struggle with decision-making—particularly cross-cutting decisions where the process is often not only complex, but also unclear. Our research into the impact of decision-making shows that organizations with high velocity and quality decision-making generate 2.5 times higher growth, two times higher profit and 30 percent higher returns on invested capital. But how to take these insights and translate them into practical, tactical actions for your organization?
This question is what inspired DecisionLab, which was developed to empower organizations to map their most important, value-creating processes and clarify roles and responsibilities through an immersive experience. The objective is to inspire collaboration and help users drill down into their processes to ensure optimal internal operations—ultimately delivering a better experience for those they serve.
A state government agency wanted to implement an agency-wide transformation to modernize the way they work, redesigning processes to provide higher-quality, faster and more efficient services to citizens.
For this particular case, the first task was to prioritize processes for the redesign, identifying the most impactful in terms of volume and citizens served. This involved mapping out the citizen journey, charting actions and decisions at low points in the citizen experience, and spotting problems to solve.
One identified low point was when a citizen appealed an agency decision. Mapping out the process revealed that nobody was taking accountability, and as a result, the appeal process would typically last seven months or longer.
A logical next step was creating total transparency, then immediately moving into process redesign and streamlining by removing unnecessary steps and clarifying decision rights—and accountability—with a RACI framework. The estimated impact is inspiring: The seven-month appeals process is now projected to last just one month.
Another example is a performing arts center that was also grappling with decision-making. It operated in a matrix, struggling with how to prioritize demands on limited resources and lacking clarity on who had final rights for important cross-cutting decisions.
We began by conducting interviews with senior leaders to gather perspectives on strengths, weaknesses and priority processes, and by codifying the current state, including roles and responsibilities as well as pain points.
We then conducted a workshop to test a proposed redesign of a decision-making process. We walked through a scenario with the full executive team, debating key areas of tension, enabling us to adjust in real time.
The result was alignment on the new process as well as roles and responsibilities for improvement. We also equipped the leadership team with a simple framework to establish decision rights in the future.
In a challenging and highly competitive market, a consumer technology company created a new business unit focused on customer experience and shifted to a more formal organizational model. However, the redesign lacked clarity on decision rights among business units, slowing decision-making.
We conducted interviews with leadership to understand the core issues surrounding this ambiguity. We codified the current state in real time and captured where pain points existed. Then, in a workshop with the top team, we co-created life-like scenarios with unclear decision rights.
For example, we explored an internal disagreement on the location and color of a new brand icon on the website. Who takes the decision: the market-specific business unit, or the new customer experience business unit?
The process helped facilitate this conversation and ultimately led to working through challenges differently than leadership had in the past. With the new process in place, the company now makes faster decisions.Maria is the Lead Enterprise Agility Partner in Deloitte’s Consulting Practice in Asia-Pacific. Maria has worked with a wide variety of teams, leaders, and organisations to re-wire their management philosophy and enable the shift in thinking required for her clients across Asia-Pacific to deliver projects better, with more value, sooner, safer and happier. She has been working with her clients to create customer-centric, high performance delivery, and learning ecosystems across industries, particularly with extensive experience in financial services, telecommunications, and energy & resources. Based on her technology delivery background, Maria’s approach to change and leveraging new ways of working is pragmatic and has an effective balance between delivery and an outcome focussed mindset and culture.Nowadays, Agile methodologies have well and truly arrived in most organizations. The complexity of digital opportunities and the unpredictability of customers and competitors are both on the rise, making it impossible to predict what businesses will need in the future. That is why Agile is such a decisive factor to enhance organization’s responsiveness towards volatility. Strategy management has to evolve as well, which is where Agile concepts come into play. More...A blog delivering insights into the latest discussions, trends and lessons from the front line on Agile. Deloitte is a pre-eminent Agile advisor and a leading expert on Agile, providing tailored solutions across various organisations, industries, and projects, at any scale.
Agile is a set of principles and practices based around the concept of iterative and incremental development, with collaboration between teams at its cornerstone. Agile approaches to delivery can increase quality, reduce waste, improve predictability and boost morale in organisations.
Our experts in Agile will provide their views on the latest developments within the Agile community, developed through first-hand experience across a range of industries and services, and will help keep you up to date with the tools and considerations needed for successful Agile development.Searching “what is agile?” we find words like “iterative development, software delivery, self-organising teams, scrum, and sprint”. If you’re reading this blog, you’re probably familiar with most of these terms, and you may even be thinking about Agile at scale, or “Enterprise Agility”. As we start to scale agile, the human aspects tend to be outweighed by a focus on execution. However in our experience, there are a small number of factors that become critical to truly realising benefits as organisations begin to scale Continuous Delivery, DevOps or Agile principles beyond 1-2 teams, and start looking at a whole function or even an entire organisation….
So what do we mean by human aspects? … It’s anything and everything to do with an organisation and its people, how they work together, and its workforce.
In a series of blog posts, we will explore these critical human aspects by asking the question: “What practical steps can we take to start making a difference?” With the first of the series focusing on Leadership.
We are quite excited to see some really informative research around Agile Leadership emerging. The Puppet + DORA State of DevOps Report examines the idea of transformational leadership, and Deloitte’s 2017 Human Capital Trends which explores the idea of “hero leader”, and how it can no longer scale, detailing how the US Military has reinvented itself as a network of teams.
As we begin to explore the idea of Leadership in an Agile environment, we are immediately compelled to examine what leadership means alongside (increasingly) autonomous / self-managed teams. What is the role of leadership in these new ways of working? Is a different type of leadership needed? Are leadership roles needed at all?
Our view is that leadership is becoming more diffused across the organisation rather than the traditional approach where it is distilled in discrete roles at the top of an organisation. More and more, leadership is a capability that is integral to all roles, at all levels of the organisation, irrespective of whether a role has direct reports or not. This means there will be far fewer roles that are considered “only leadership”, and even when these discrete leadership roles exist, what they do is changing significantly.
There are some well documented examples of this in practice; LeLoux explores a number of these in his seminal book: Reinventing Organizations. Atlassian’s (the now famous Australian start-up that even AFR now considers the “coolest company in Australia”) focuses their leadership teams almost exclusively on the “sustainability of the eco-system”. Leaders amplify the company’s vision and purpose, develop “the guard-rails” that enable everyone to deliver great customer outcomes, and identifying potential threats by assessing their ongoing competitive position.
And Microsoft who’s transformation from “a battleship to 3000 canoes”, has been underpinned by leaders who focus on translating customer value into outcomes, challenging the norm, and inspiring people.
One of the key characteristics is authenticity. Authentic leaders communicate their team / organisation’s purpose in a practical way. Their passion for the customer is infectious and creates the oxygen for teams to take meaningful action rather than waiting to be “told what to do”.
This is tightly coupled with coaching. Coaching has become a core tenant of leadership, incorporating both personal recognition of great work, as well as creating an environment of- and space for- continuous development and collective accountability that encourages personal and collaborative reflection in the absence of blame.
Demonstrate empathy, care and inclusion – taking the time to seek out people’s stories and experiences, encouraging them to be themselves at work, and connecting personal interests to organisational purpose and customer outcomes. These leadership behaviours encouraging engagement and wellness that research is showing drives improved performance.
Research from Bersin by Deloitte found that inclusive leadership is one of the most significant driver of employee engagement. This is because when people feel included they feel safe; safety enables people to suspend self-interest, and it’s only when we can suspend self-interest that it possible for effective teams that are focused on delivering customer outcomes.
So on reflection… authenticity, coaching, empathy, care and inclusion; these are not aspects of leadership that most people would disagree with, but neither are the first words that would come to mind if you asked 100 people from a corporate Family Feud audience.
Start with purpose and customer ; have your team members spend (more) time with customers, sharing their stories, and demonstrate your personal connection to customer outcomes.
and ; have your team members spend (more) time with customers, sharing their stories, and demonstrate your personal connection to customer outcomes. Think differently by spending more time conceptualising possibilities, seeking out divergent views, and embracing complexity, and less time formulating specific strategies and plans.
by spending more time conceptualising possibilities, seeking out divergent views, and embracing complexity, and less time formulating specific strategies and plans. Act differently by playing an active role in multiple teams, embracing the Agile tools and ceremonies that your teams are using, and spend more time coaching and less directing.
by playing an active role in multiple teams, embracing the Agile tools and ceremonies that your teams are using, and spend more time coaching and less directing. React differently by explicitly tolerating risk and celebrating experimentation, demonstrating resilience when things don’t work perfectly the first time and consciously not laying blame.
So in summary, as a leader and influencer in your organisation the first port of call to scaling Agile is to take conscious control of your own “leadership style”, start thinking, acting and reacting differently, and you’ll begin to see the benefits we’ve discussed above. This can be the case, even when the rest of the organisation around you hasn’t changed. However to take those benefits to the next level and successfully scale even further, the next factor you would likely consider will be organisational structure. We’ll cover this in our next blog in this series.
You can find further Deloitte thinking and resources here. We would recommend the following further reading:It’s no secret that the success of any program hinges on senior executive ownership, support and their ability to cascade messaging down to all layers of an organisation. What’s also trending in Agile is the movement from leader-led change to intent-based leadership. Leadership should be viewed as a set of behaviours, not only a role. As such, leaders should empower passionate individuals to lead from all levels within the organisation.
Agile requires cultural change, not just technology. Every person up and down the chain should be versed in the language of agile, and be guided by a single framework and approach for doing so. Pilots enable you to slice off a sliver of the business, fundamentally transform this small group’s way of working, demonstrate benefits and then scale. Starting lots of little ‘spot fires’ such as this around the organisation will attract others, and draw them in to the movement.
Wise companies will proactively consider what they can learn from organisation models being created within digital-native companies. Removal of silos and hierarchy, with the blending of roles can help to create autonomous teams. When structures cannot be changed, alternatives such as creating ‘guilds’ – voluntary communities of like-minded people that come together to discuss topics of interest – can help create pockets of agile evangelists.
The ‘spot fires’ mentioned in the point on culture, are also a way of winning hearts when it comes to targets and incentives. Leaders should strive for voluntary participation over mandated participation, so that it becomes every individual’s idea and prerogative to operate in this new way. Key to this is addressing the genuine needs of people – get to the heart of the noble purpose so people are motivated intrinsically.
Only in an environment where people feel safe to play with ideas, and where they are recognised and rewarded for being agile will it occur. Something as simple as buying ‘failure cupcakes’ at the end of a sprint can help set in motion this new paradigm. Building elements of gamification, playfulness and fun into team challenges and goals can also help drive creativity, innovation and agility.
In summary, to make an organisation truly agile, companies need to focus on the five building blocks of an effective environment: leadership, culture, organisation design, targets and incentives, and celebrating outcomes. Get these right, and the rest will follow.Someone posted an article on LinkedIn the other day claiming “Agile is Dead”. The comments that followed were more interesting than the actual article. Many people were bashing agile frameworks. It is no secret that organizations have spend a lot of money on doing agile and many times never really achieved being agile. Right now, SAFe (Scaled Agile Framework) is trending and many of my clients are implementing it. But methodologies and frameworks are nothing more than a set of guiding principles for delivering software. At the end of the day, doing agile comes down to the three things:
A framework is only as good as the people, processes, and organizational structures that use it. Silos with competing goals always trump frameworks. Each silo creates an unnecessary handoff and increases wait time. Too often, additional processes get added to deal with the interaction between silos.
Then there is the people part. I am old enough to remember when all projects managers had to be PMBOK certified which trained project managers how to follow a set of processes and procedures (framework) to navigate the waterfall methodology. When we moved to agile, all these people were retrained and became certified scrum masters. Unfortunately, they still had the old command and control, sequential mindset and most agile efforts became “Wagile” — waterfall with daily standups.
The point here is it takes much more than a few training classes or certifications to change the mindset. This is a transformation and requires an investment in organizational change management to get the value out of the new frameworks.
All the process in the world can’t fix a bad architecture. To do agile, one must have an architecture that supports being agile. Characteristics of an agile architecture include:
Service-oriented — opposite of Monoliths, the system is made up of small parts that can be deployed separately
Testable — system supports testing hypothesis with methods such as A/B testing, feature flags, chaos engineering, etc.
The more a system supports the characteristics above, the more agility can be achieved. Not all systems need to implement all of those characteristics, but each characteristic can reduce manual intervention, allow for more frequent deployments and quicker MTTR, reduce widespread system outages, and provide for better availability. It can also reduce the amount of unexpected work which is probably the biggest single issue all agile frameworks struggle to deal with.
Even if you have an agile architecture and your agile framework is being executed flawlessly, if your operations people and processes are not in alignment, the whole house of cards will come tumbling down.
There is a lot disruption in operations these days. DevOps has played a huge roll in getting developers and operators collaborating better. Operations is now being thought of earlier in the lifecycle and teams are designing for ops. Companies are reevaluating their operating models and investigating newer practices such as Site Reliability Engineering (SRE), accepting that testing in production is a good thing (if done right), moving from reactive to proactive operations, embracing observability, and much more. As we move to more agile architectures, it’s common sense that we need to embrace more agile methods of operations.
The list goes on and on. I have yet to see a framework that even mentions most of these characteristics. The frameworks focus mostly on how to manage backlogs which is important, but if the software and the operations of that software does not promote agility, the framework is not going save you.
Organizations should focus more on being agile rather than doing agile. Being agile requires more than a framework. It is a mindset and it should be applied everywhere, not just in Dev and Ops. The Security and Governance teams need to be agile. Procurement can’t take six months to procure a software product. Decisionmakers need to come to conclusions in a timely manner. Processes that take forever should be redesigned. Approvals should not take forever. You get the point.
Being agile is a cultural issue and should be treated as one. If you want to make your organization agile, adopting a framework is only one piece of the puzzle. In fact, many teams that I have seen that are truly agile use no framework at all. They do a good job of managing a backlog and they do a great job of collaborating, writing good software, automating everything they can, and recovering from issues quickly. At the end of the day, agility can be measured by customer satisfaction. If the customer is getting their demands met, the system is reliable, and issues are resolved quickly, it really doesn’t matter what framework you use.Despite the apparent threat, Enterprise Agility does not spell the end of Architecture but in fact can be a catalyst for change and disruption. Whether a company is Waterfall, Agile or Hybrid, architects will always be required to support technology decisions and align IT to business strategy[2][5]. These outcomes remain as critical as ever, but how they are reached will be vastly different. In this blog we will discuss four ways Enterprise Agility will redefine Architecture. Get ready.
1. Architects will be less involved with delivering things but more involved with ensuring the right things are delivered
There is a misconception that architects spend all of their time ‘doing’ architecture and producing complex diagrams[4]. It’s the organisational decision-making process that the architect must drive before an artefact is delivered, however, that really matters. Reaching consensus on complex decisions involving diverse stakeholders with competing views is where the architect is irreplaceable[12]. Be it navigating emerging technologies, legacy system replacement, or completing post M&A consolidation roadmaps; as Agility scales, the need to make these architectural decisions in a timely manner goes up. The need for Architects to support this goes up.
This doesn’t mean architects won’t produce any diagrams, but enabling the best technology decisions to be made is where the value of architecture will be realised in an Agile Enterprise[3][4]
Intentional architecture is the traditional up-front, plan based architecture that most of us are familiar with. The Architecture is designed and handed over to development teams to build. The more detailed the architecture the more ‘intentional’ it becomes.
There is little doubt that in a fixed-price contract world, having as much detail as possible up front is a necessity. And in general, updates are avoided at all cost for fear of the change request. But in an Agile Enterprise, procurement functions will evolve along with the Architecture function. And through a combination of incentive-based or time and materials contracting[21][22][23], this evolution will permit Product Owners to inspect and adapt.
So for the architect, as agility scales, a degree of up front planning remains essential. But defining detailed architectures across large time horizons is no longer required. Architectural work will be decomposed into smaller packages and managed in a ‘just in time’ fashion[11][12][13]. The Scaled Agile Framework (SAFe) provides an example of this with its Architectural Runway that is used to ensure technical dependencies are always delivered at least one sprint before the application functionality that needs it[10][11][17]Finally, at the core of transforming recruitment, should be the Agile principles. By changing the decision criteria for how you select a new hire, you can prioritise the talent you want most in the organisation. This gives you a workforce of individuals culturally aligned to your strategy and ways of working.
Changing the decision criteria to be Agile involves re-writing position descriptions to be light and flexible. This ensures that you don’t become locked into hiring for a position that, by the time you fill the role, is no longer relevant. Bersin by Deloitte wrote, in a piece titled ‘The end of the job as we know it’, that companies should be hiring “for values, innate skills, and fit, not for experience.” This means replacing your traditional job description with value descriptions instead, speaking to the inherent Agile cultural attitudes required in the position, like agility and comfort with ambiguity. In the Agile Manifesto, this is best denoted by the value of “Responding to change over following a plan”. The focus of good Agile job descriptions, should be on flexing positions, so that HR is building complete teams, rather than attempting to hire the ‘every man’ candidate.
The best example of this is the technology giant Google, who openly targets individuals for a quality called ‘Googleyness’. Head of People Operations, Lazlo Bock , defines this as:
A certain dose of intellectual humility (it’s hard to learn if you can’t admit that you might be wrong),
Comfort with ambiguity (we don’t know how our business will evolve, and navigating Google internally requires dealing with a lot of ambiguity), and
None of those elements would make a classic job description, but they do focus on what Google treasures most, a person’s values. They search for the right fit, not the right set of functional skills.
Applying an Agile mindset to recruitment is not simple. It spans a range of elements from redefining selection criteria, to re-inventing the hiring process. However embedding Agile within your recruitment practices is crucial in supporting an Agile organisation.
Our challenge to you is to look at how your recruiting currently operates, and determine where you can leverage Agile principles to improve the process. Even if it is as simple as giving new hires feedback forms so they can reflect on their experience of the hiring process, you’ll see the benefits that greater transparency and Agile provides.Both agile and mindfulness practitioners place importance on the ability to understand and respond to the needs of others. In an agile context, customers are critical stakeholders requiring compassion, empathy and deep understanding. Mindfulness emphasises the importance of regulation and control of self-emotion in order to better understand and respond to the emotional needs of others, which are relevant skills for an agile team.
Self-organising teams advocate the importance of positive team dynamics as well as the unique contribution of each team member, encouraging collaboration, and face to face communication. Mindfulness can help cultivate team wellness and empathy by encouraging practitioners to control and focus their emotions. This promotes a purposeful, flexible, and open state of attention that ultimately drives intention. By embracing this open attentiveness, mindfulness practitioners increase the likelihood of developing and sustaining positive, respectful, and resilient relationships within their team. This is critical to an effective agile practice, as collaboration, good communication and positive teaming are at agile’s core. Consequently, team productivity can be enhanced by promoting stronger, more engaged, and collaborative teams.
By developing, strengthening and leveraging emotional intelligence through mindfulness techniques, such as focussed attention, agile teams can increase team performance and foster customer empathy through a more in-depth understanding of team dynamics and individual needs.
Simplicity is a fundamental principle of both agile and mindfulness which follows the basic premise: a focus on high value yet simple processes and solutions will reduce waste (e.g. of time, energy, or cost) and increase quality (e.g. of software, communication, or life).
Mindfulness practitioners advocate the importance of de-cluttering to create the emotional and physical space necessary to develop awareness, focused attention, and sustainable living. De-cluttering practices, which can be either physical (such as voluntary simplicity which means to reduce materialism and consumerism, a re-assessment or minimalist re-design of your surroundings, or literally de-cluttering surfaces and spaces in your physical environment), or spiritual (such as letting go of negativity, uncertainty and mental “noise”) ultimately increases quality of life through a focus on value rather than abundance.
In an agile context the focus on simplicity manifests itself in simple design, succinct meetings and communication, continuous integration, story cards, minimal but clear roles, and sprint boards (to name a few). As an example, the physical sprint board puts the agile simplicity principle (“Simplicity – the art of maximising the amount of work not done – is essential”) to practice and facilitates visibility of work not done. The sprint board enables the agile team to organise activities so that those of the highest value are prioritised, reducing waste and maximising efficiency.
Simplicity is a key component in both agile and mindfulness, with focus placed on value and a deliberate effort to remove redundancy. Agile teams can further develop day-to-day simplicity through mindful practices, such as intentional physical and emotional de-cluttering.
Agile enthusiasts embrace changing requirements and environments, those practicing mindfulness also develop the flexibility to accept and respond, rather than react to change.
Mindfulness practitioners advocate that adaptability stems directly from acceptance of the transient and fluid nature of life. The ability to maintain a purposeful, flexible, and open state of attention increases quality of life and sustainability.
Likewise, agile teams maintain the mindset that change is expected and welcome, identifying flexible boundaries, and designing processes and expected outcomes which enable adaptability. Cross-functional, self-organising agile teams that value constant communication, continuous validation, and incremental product evolution are well placed to respond to changing requirements and shifting landscapes.
For both mindfulness and agile, it is communication and contact with the present moment that establishes the foundation for adaptability and increases the likelihood of resilience and stability.
Agile teams can apply their practiced adaptive mindset to leverage mindful techniques, such as acknowledgement and acceptance of change, which can help to remove human emotion (reactive behaviour) from decision making during periods of change.
Another fundamental principle of both agile and mindfulness is controlled and targeted focus on one task at a time. The value and objectives of the focus principle are similar to those of the Simplicity principle – high value yet simple processes and solutions will reduce waste and increase quality.
Mindfulness practitioners advocate the importance of awareness and control in order to focus completely on a single task. Similarly, agile practitioners advocate that productivity is increased through focus on one task at a time, enabled by small engaged teams, short targeted sprints, visibility of activity and direction (agile boards), and regular communication to maintain awareness of blockers and impediments to progress.
Both approaches support the view that the cost of context switching (reduced focus and concentration and ultimately decreased productivity) greatly outweighs any perceived benefit to efficiency or progress.
Agile teams advocate singular focus, however this is not to say that there is no challenge in doing so at an individual level. By using mindfulness practices, such as control of attention, agile teams can turbocharge their ability to filter out distraction, and focus only on the task with the greatest business value.
The core areas of commonality between agile and mindfulness are also some of the defining characteristics of each approach: People, Simplicity, Adaptability, and Focus. Agile teams can leverage the touchpoints with mindfulness to maximise their existing skillsets and ultimately achieve their goals. As an example, mindfulness promises to enhance and enrich interpersonal communication, while agile projects sink or swim on the quality and timeliness of the interactions between all of the project’s stakeholders (including the agile team itself). The two approaches are complementary.
While both agile and mindfulness have been described as “buzzwords” and are being referenced and discussed across multiple forums and platforms, neither introduce any complex or ground-breaking new concepts. In fact, the four principles discussed in this article, which sound very much like common sense, are a reminder that in the 21st century – an era dominated by disruption, technology and immediacy, there is great value to be gained in getting back to basics.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.Developing a successful strategy is essential to simplifying the complexities of transformation. These key areas to consider can empower your transformation strategy and clarify the road ahead for digital controllership.Traditionally, leaders have been encouraged to dynamically reallocate capital to the most pressing and attractive opportunities. This focus remains today, but many companies face a challenge: human capital is now the scarcer of the two main capitals. Companies that manage talent with the same rigor they do financial capital, treating it like the precious resource it is, typically see better results. They reallocate talent to high-value areas and push talent management to the top of their growth ...The IMA® (Institute of Management Accountants), the association of accountants and financial professionals in business, held its 2019 Annual Conference and Expo (ACE2019) this past June in San Diego, California. The event officially celebrated the Institute of Management Accountant’s 100-year anniversary with a special Centennial Celebration honoring IMA’s thriving global community of accounting and finance professionals. Attendees had the opportunity to network with other industry professionals, hear presentations from leaders, and choose from more than 75 job-relevant sessions tracks designed for management accountants to customize their learning experience on topics ranging from corporate governance to technology and finance trends for the future.
As a diamond level sponsor, Deloitte had the opportunity to attend the action-packed conference and deliver presentations on specialty topics. Deloitte delivered a specialty breakout session on touchless close as well as a general presentation on the Center for Controllership™ during the IMA annual conference dinner.
To gather some insights and perspectives that may help us with future conferences and projects with IMA, we caught up with our presenters and some of the attendees to hear about some of their highlights from the experience and insights they were able to take away from the conference.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.Though major crises may inflict significant economic damage, they can also inspire innovation. From digital connectivity to diversity, this issue of Deloitte Review explores innovations that organizations can put to use both now and in the future.Imagine you work for a company that has a busy season—the annual crunch time for achieving results. Everyone works at full stretch for six weeks, and then there’s a lull before the next cycle gets under way. If you’re designing a learning program, when should you schedule it? Most designers would probably say after the rush, when people can spare time out of their everyday routine. But is that the right answer? We don’t think so. With this timing, the next busy season could be eight or nine ...Coleads the Organization Practice globally and is one of the leading experts in transformational change
Coleads the Organization Practice globally and is head of McKinsey’s OrgSolutions group, helping clients organize in an integrated way by applying analytics methodologies and tools to improve culture, talent, change management, agility, and leadership
November 27, 2017 Let’s face it. Our hyper-dynamic, hyper-competitive and hyper-connected world has become a breeding ground for hyper-advice. Over 10,000 business books appear annually (and that doesn’t count the thousands of articles, blog posts, podcasts and video lectures produced). Search the internet for how to motivate employees and hundreds of thousands of results emerge in roughly half a second!
So, why are we at McKinsey & Company launching a weekly blog that risks simply adding to the clutter? We are hopeful that our weekly Insights on Leadership & Organization will be a one-stop shop where leaders can find impactful, fact-based and pragmatic advice – in 600 words or less.
We don’t want this to be run-of-the-mill head-nodding material. All up, as a firm we invest over $400 million annually in knowledge development, and we want you to benefit from that investment by providing genuinely provocative ideas that recalibrate and expand your thinking. Then we want to do that again. And again.
For this blog, we will address a range of both timely and timeless topics related to leading organizations and that apply to every leader, whether you’re a leader in an investment bank or a not-for-profit. Or whether you’re in India or Indiana. Over time, we will explore four principal areas:
Increasing organizational agility to effectively adapt to and shape market changes with speed. This requires organizations to master the paradox of being nimble in innovating and executing rapidly, while at the same time capturing the benefits of stability and harnessing the virtues of size and consistency.
to effectively adapt to and shape market changes with speed. This requires organizations to master the paradox of being nimble in innovating and executing rapidly, while at the same time capturing the benefits of stability and harnessing the virtues of size and consistency. Converting talent to value by combining traditional methods with advanced analytics-based methods to forecast talent supply and demand based on the business strategy; and improving how needed talent is identified, attracted, placed, developed, evaluated and retained—all the way from the front line to the C-suite.
by combining traditional methods with advanced analytics-based methods to forecast talent supply and demand based on the business strategy; and improving how needed talent is identified, attracted, placed, developed, evaluated and retained—all the way from the front line to the C-suite. Managing culture and change to deliver sustainable results and create lasting competitive advantage. This includes the tools and methods to overcome the digital, customer-centric, simplification, risk management, and numerous other large-scale transformation challenges that today’s global enterprises face.
to deliver sustainable results and create lasting competitive advantage. This includes the tools and methods to overcome the digital, customer-centric, simplification, risk management, and numerous other large-scale transformation challenges that today’s global enterprises face. Maximizing merger impact by building M&A capability to be ready to make the right deals happen—and then, once one does, developing and executing the right master plan related to governance, sources of value, organization, talent, capability building, and cultural and technology alignment.
Put simply, our goal is to help leaders lead better so, in turn, their organizations will be more successful and their employees’ experiences more meaningful and fulfilling.JH, a partner at Deloitte Risk & Financial Advisory, Deloitte & Touche LLP, as well as Global Risk Advisory leader for the Financial Services Industry, has more than 25 years of risk management experience within the sector. He has deep experience with the complete credit lifecycle, enterprise risk management, operational risk, and integrated compliance risk management. His extensive experience in the area of credit includes quantitative methodology, portfolio analytics, process, and controls, integrating risk management practices, and addressing and resolving the Options Clearing Corporation (OCC) and other regulatory issues. JH has worked with seven of the top 10 credit card providers, four of the top five mortgage originators and servicers, two of the top three student lending organizations, and three of the top five auto loan financing companies. In addition, he has performed training sessions for the American Institute of Certified Public Accountants (AICPA) and the Federal Financial Institutions Examination Council (FFIEC) regulatory round table on accounting issues and pronouncements facing retail credit organizations.Mark Bethell is a partner in the UK EERM practice. Mark rejoined Deloitte in 2015 after spending four years at a global FTSE 5 company. Whilst working there Mark led the design and implementation of a global third party risk management framework. Mark’s other roles whilst there included membership of the internal audit leadership team with accountability for all internal audit work performed in relation to the extended enterprise (contractors, suppliers and joint ventures). Since returning to Deloitte, Mark has led a number of projects to help clients across many industries manage the risks associated with the extended enterprise. He has helped his clients to design, build, and implement third party risk management frameworks and design and operate large-scale, global programs of third party audits covering a variety of risk types. Mark specializes particularly in the implementation of EERM managed services for his clients, and in the ongoing development of technologies to support automated risk screening and monitoring.Grocery stores have been venturing into the digital world for years now. It’s almost unthinkable to walk into a grocery store without a loyalty card these days. And during this pandemic, we’ve seen how online purchasing of groceries has stepped up and is going to be further refined. These two digital forays alone offer grocers a wealth of personal data to use. The question, then is, should they, and to what extent?With the recent spike in demand for electric vehicles, socially conscious consumers are questioning the provenance of battery materials used to produce these vehicles. Mining companies are under pressure to create a more transparent interface with their customers—an aspect outlined in our Tracking the trends 2019 report.
In this blog, Tim Biggs explains that with the complex supply chains of today, traceability of minerals could be a challenge. He recommends mining companies to invest in technologies like blockchain that can trace a mineral from its origin to destination.As the future of work unfolds, adaptable learning organizations will likely stay ahead of their competition, attract the best and the brightest prospects, and manage market movements with their customer base with more agility. Learning leaders are well positioned to lead the charge to develop an adept workforce that can not only respond to rapid shifts in markets, but also thrive in them as well.
HR professionals use virtual reality to facilitate employee training and increase retention. Sports reporters use natural language generators to automatically recap games and to highlight interesting statistics. Actuaries use cognitive computing to automatically evaluate data, compute results, and predict new patterns. Professionals across many industries engage employers in alternative work arrangements through the gig economy. This future of work is rapidly becoming reality as technology develops exponentially. Exponential professionals are those who capitalize on the shifting workplace by embracing new technology, leave behind traditional automatable tasks, and apply their uniquely human skill set to more high-value, strategic roles.
AI. Automation. Machine Learning. Natural Language Processing & Generation. New technology is rapidly disrupting and transforming the nature of work and the identity of professions by enabling humans and machines to work together, side by side. A new breed of professional is rising to navigate this shifting landscape by embracing technology, leaving behind traditional tasks, and applying a uniquely human skill set to focus on higher-value, strategic roles. Enter the exponential professional.
Is capitalism broken? Rising inequality, high profile corporate failures and the potential for technology to displace millions of workers has prompted many to ask this question. It will be part of the discussion at Davos this week, where world leaders will debate what’s holding back inclusive economic growth. They’ll also question how ready we are for the Fourth Industrial Revolution – the blurring of technology into all aspects of our daily lives – and whether businesses are doing enough to manage the impact of automation on the workforce.
Mornings are easier than ever for me. True, I need to be careful shaving around the RFID chip in my chin. That’s a small price to pay for not having to look around the house for my wallet and keys, which I no longer need because that tiny chip and biometrics lock my front door and start my car, which now drives itself. And if something goes wrong on the road and I arrive at the hospital unconscious, my RFID chip will present my medical history to emergency room doctors.
The rise of robots in organizations has resulted in two schools of thought—those who believe robots will replace humans and those who believe robots will help humans perform better.
Industry has used robots for decades. They were once confined to safety cages in manufacturing facilities, programmed to perform one task perfectly, over and over again.
The future workplace is going to require a change in organizational culture, and this needs to come from the boardroom.
Today’s interview is with Erica Volini, who is the US Human Capital leader for Deloitte Consulting. Erica joins me today to talk about the Future Of Work, the implications for organizations, organizational transformation, Digital DNA and how the employee experience fits into all of this.
Mix smart machines, businesses as platforms, and diverse teams solving complex problems, add a whole lot of uncertainty, and you have a recipe for the future of work. Jeff Schwartz ’87, a principal at Deloitte, discusses how leaders can navigate fast-approaching opportunities and challenges.
By 2025, cognitive technologies — that’s robots, AI, machine learning and automation — will replace 7% of jobs in the U.S. By 2033, economists predict AI could convert 30 percent of full-time jobs today into augmented services completed through a collaboration of human and automated labor.
Your organization, like most of those we see, is probably already incorporating contingent workers in your talent mix, and likely seeing year-over-year increases in the number of contingent workers in your workforce.
We recently sat down with Josh Bersin, the Founder of Bersin, to discuss where he believes the future of work is heading towards, and what the most important aspects to consider within that would be.
The head of one of Australia’s biggest professional services firms believes public negativity and misconceptions are preventing Australia from fully embracing automation. Deloitte chief executive Cindy Hook, who also heads a Business Council of Australia committee looking at the workplace, says business and government “need to change the narrative” that automation, robotics and digitisation will eliminate jobs, “because that’s not the case”.
As organizations navigate technological and societal shifts, corporate boards will have a critical role to play. Diversity of thought—and of people—will be more vital than ever to ensure that boards are considering different perspectives and exploring challenges from every angle.
What skills are essentially human? It’s a question that many HR professionals never thought they’d need to answer. But with the advent of AI, robotics, sensors, and cognitive computing, that’s what every HR professional should be asking—because the future of work is here.
On Tuesday, I participated in a panel discussion hosted by the Organisation for Economic Co-operation and Development (OECD) on the rapidly evolving workforce and the role business can play in navigating these changes.
We are living in an age of disruption. More than 50 years after the formulation of Moore’s law – which holds that computing power doubles on capability every 18 to 24 months – technologies such as artificial intelligence (AI), mobile platforms, sensors, robotics, and social collaboration systems are becoming more pervasive before revolutionizing the way we live, work, and communicate.
As I prepared for my time in Davos, I spent some time thinking about what the biggest takeaways will be. Clearly, based on the recent buzz over the past year, the future of work and how to navigate it is on many people’s mind. The fact is that we are already living this future and to be successful in the next three to five years we will all have to embrace constant change.
The world of work is rapidly changing as we deal with new technologies, AI, generational changes, and a more interconnected organization. What are HR’s mandates in this new world? Moreover, how can HR add value in organization design, driving new models of leadership, driving engagement, and improving organizational culture?
The phrase “Future of Work,” has become a buzz word. (I found 48 million Google hits on the phrase.) There are are suddenly hundreds of conferences, books, and articles on the topic, covering everything from artificial intelligence to robotics to income inequality and contingent labor.You previously joined My Deloitte using the same email. Log in here with your My Deloitte password to link accounts. | | Deloitte users: Log in here one time only with the password you have been using for Dbriefs/My Deloitte.
You've previously logged into My Deloitte with a different account. Link your accounts by re-verifying below, or by logging in with a social media account.Dr. Dhar is Vice Chairman and US Life Sciences and Health Care (LSHC) Industry Leader for Deloitte LLP leading the overall strategic direction for the life sciences and health care practices, including audit, consulting, tax, and advisory services. He is a respected health futurist and sought-after digital disrupter. Asif helps Governments, Life Sciences and Health Care clients reinvent wellness, solve disease, address pandemics and tackle health inequities. He is also Deloitte’s Lead Partner for the Firm’s US Food and Drug Administration (FDA) relationship and responsible for all work Deloitte performs with and for the Agency. His perspectives on real world evidence, regulatory sciences, digital health, and innovation are sought by clients around the world. Asif’s passion for the LSHC industry is evident in all that he does – as a pioneering thought leader who helped establish a framework for the Future of Health, formed ConvergeHEALTH, an award winning life sciences and health care software solution, and helped frame numerous COVID-19 health-oriented reboot and recovery solutions. He advises some of the world’s most innovative companies and Governmental agencies tackling disease and public health.The people who make up Deloitte come from just about every background and area of study and nearly every spot on the globe. Meet our professionals, and learn more about what life at Deloitte is like.Insert Custom CSS fragment. Do not delete! This box/component contains code needed on this page. This message will not be visible when page is activated.The Federal Government just threw $18 billion dollars at the Australian economy between now and mid-2021 – of which a striking $11 billion will be in the pockets of the punters and of businesses in the next three months alone. The Reserve Bank has already cut interest rates, with a further cut in the offing when they meet again in early April. That’s big bucks. But just how much help does that combination deliver to the Australian economy?Governments around the world have responded to the pandemic by borrowing, and spending, on a vast scale, equivalent to 12% of world GDP. Twelve years ago, in the financial crisis, monetary policy did the heavy lifting in supporting growth. Now, with interest rates near zero, the burden has fallen on fiscal policy.
Join our next fortnightly COVID-19 webinar, focussing on building resilience, on Thursday, 5 November, at 13:00 GMT. Register for this and our upcoming webinars.
Governments around the world have responded to the pandemic by borrowing, and spending, on a vast scale, equivalent to 12% of world GDP. Twelve years ago, in the financial crisis, monetary policy did the heavy lifting in supporting growth. Now, with interest rates near zero, the burden has fallen on fiscal policy.
The level of government debt fluctuates over time, with war and recession driving it higher, and faster growth bringing it down. Four decades of expansion after the second world war shrank UK public sector debt from a wartime peak of 250% of GDP to 30% by the mid-1990s, close to the lowest-ever level. Since then it has risen inexorably, to 40% on the eve of the financial crisis and 75% in its wake, 103% today and, on IMF forecasts, a likely 115% in 2023.
This is a historic shift, one which takes debt to levels which have only ever been seen in the wake of the Napoleonic war and the first and second world wars.
The surge in public debt in the financial crisis led, as growth came back, to programmes of tax rises and spending cuts across the West as governments sought to reduce borrowing. A broad coalition of mainstream political parties and international institutions including the IMF and the European Commission favoured curbing levels of debt.
The concern was that high debt levels would make countries more vulnerable to future shocks and make it harder for governments to counter them. Shortly before becoming chancellor of the exchequer, George Osbourne remarked that “while private sector debt was the cause of this crisis, public sector debt is likely to be the cause of the next one”. The widely held view was, as Mr Osborne subsequently put it, “the time to repair the roof was when the sun is shining”.
In the US Harvard economists Carmen Reinhart and Kenneth Rogoff warned that debt-to-GDP in excess of 90% would pose a significant obstacle to longer-term growth. They argued that high and rising debt levels could cause investors to take fright, and demand higher interest rates for holding government debt, which would push up borrowing costs and lead to painful budget cuts. Their research was widely cited by politicians in the West at the time.
Since then public sector austerity has, in many countries, only slowed the rate of growth of public debt, rather than reduced it. Yet there has been no backlash in public debt markets. On the contrary, weak economic activity and low inflation have increased the allure of government bonds to investors, driving interest rates on them ever lower. In the UK the willingness of financial markets to finance government borrowing, weak growth and fatigue with austerity slowed the process of debt reduction. Indeed, the government proclaimed the end of austerity three years ago despite the fact that the UK is continuing to run a budget deficit.
So the pandemic arrived into a world of already elevated government borrowing, where traditional rules of balancing the books held less sway. The pandemic has dealt a further blow to such notions. High levels of public borrowing are here for some time to come.
The zeitgeist on public debt has been transformed. In an inversion of its advice a decade ago, the IMF has been joined by leading central banks in urging governments not to tighten fiscal policy and prematurely cut off the recovery, while the European Commission is embarking on an unprecedented programme of joint-EU debt issuance. There are no signs that voters are keen on either spending cuts or tax hikes to rein in the deficit.
So why, as countries exceed the 90% marker set out by Reinhart and Rogoff, are policymakers not talking about austerity?
Debt financing costs have fallen still further, making it much easier for governments to finance borrowing. The UK government currently pays interest of 0.2% to borrow for ten years, less than a quarter the rate at the start of the year. As a result the UK’s overall debt financing costs are lower now than they were with far lower debt levels a year ago.
In a perilous world the safety offered by government bonds is more attractive than ever. Quantitative easing programmes have made central banks big buyers of government debt, further fuelling demand and driving down interest rates.
As the economy recovers, and the growth rate outstrips the low interest rate on this debt, the ratio of debt-to-GDP should begin to unwind organically. Even if interest rates do rise, the average maturity of UK government debt is 15 years, meaning the overall financing costs are unlikely to
In the higher interest rate era of the 1970–90s it was thought that high levels of public borrowing and spending might ‘crowd out’ private sector borrowing and activity. Today, with activity vastly below normal levels, the problem is of excess capacity and insufficient demand. With the private sector unable to do so, the government becomes, in Keynesian terms, the borrower and spender of last resort.
This story is playing out in the US election, where investors appear to see the benefits of greater fiscal stimulus under a Biden administration more than outweighing any negative effects from higher taxes or greater regulation.
The IMF has observed that the current backdrop of cheap money and insufficient demand creates the perfect environment for greater public investment. The fastest returns come, according to the Fund, from smaller or modular projects like infrastructure maintenance or renewable energy installations that are labour-intensive and can be rolled out quickly. The biggest projects operate with longer leads and carry the risk of cost overruns and delays.
None of this is to say that the limits to public borrowing have been removed. If the economy fails to recover to pre-pandemic rates of growth, the government could be faced with a permanent imbalance between the burden of public debt and the economy’s ability to finance it. The picture could worsen further if inflation were to rise markedly, driving investors to demand higher yields on government debt. Past debt crises have come out of the blue, as bond markets can quickly change their minds about fundamentals.
But for now borrowing and spending is the only game in town. The UK’s new lockdown has already triggered the extension of the furlough scheme. More spending is sure to follow, as it will if Joe Biden wins the presidency and secures the US Senate. The attitude of policymakers has changed. The balance of opinion has shifted to maintaining fiscal support, until the recovery is secure, something which is looking ever more distant. We are in an age of bigger, more activist government.
PS: Joe Biden is the strong favourite to win Tuesday’s US presidential election. The electoral model run by Nate Silver, the US pollster, puts the probability of a Biden win at 89%. The Economist’s model assumes an even higher probability, of 96%. The New York Times estimates that even if the polls were as wrong as they were in 2016 Mr Biden would still win by a wide margin. However, it is quite likely that a clear victor will not emerge on election night, and, possibly for weeks or, indeed, months. Mr Trump has questioned the validity of postal votes and suggested he might refuse to concede defeat. This could lead to days or weeks of uncertainty and legal battles in the case of a close outcome.
As president, Mr Biden would have discretion over trade matters, foreign policy and regulation, areas in which he could reverse many of Mr Trump's policies. But to pass tax and spending legislation, Mr Biden would need the Democrats to take control of the Senate. With a Biden win seen by many as a foregone conclusion the Senate battle is likely to be a major focus on election night. Most forecasters expect the Democrats to take the Senate, though this is likely to be a closer fight than for the presidency. A Biden administration is committed to raise income and capital tax rates on higher earners and partially reverse Mr Trump's corporate tax cuts. A Democrat president and Senate would probably increase public spending significantly, with a pandemic recovery package and a programme of green infrastructure, healthcare, education and R&D expenditure. Other Biden policies would strengthen the position of workers, including a higher federal minimum wage and paid family and medical leave. Our reading is that investors tend to see the beneficial effect of greater fiscal stimulus on the economy under a Biden administration outweighing the drag from higher taxes and increased regulation.Dr. Kalish is the Chief Global Economist of Deloitte Touche Tohmatsu Ltd. He is a specialist in global economic issues as well as the effects of economic, demographic, and social trends on the global business environment. He advises Deloitte clients as well as Deloitte’s leadership on economic issues and their impact on business strategy. In addition, he has given numerous presentations to corporations and trade organizations on topics related to the global economy. He is widely traveled and has given presentations in 47 countries on six continents. He has been quoted by the Wall Street Journal, The Economist, and The Financial Times. Dr. Kalish holds a bachelor’s degree in economics from Vassar College and a PhD in international economics from Johns Hopkins University.Join our next fortnightly COVID-19 webinar, focussing on building resilience, on Thursday, 5 November, at 13:00 GMT: https://event.webcasts.com/starthere.jsp?ei=1365454&tp_key=8f4d835e66&sti=mmb
Governments around the world have responded to the pandemic by borrowing, and spending, on a vast scale, equivalent to 12% of world GDP. Twelve years ago, in the financial crisis, monetary policy did the heavy lifting in supporting growth. Now, with interest rates near zero, the burden has fallen on fiscal policy.
The level of government debt fluctuates over time, with war and recession driving it higher, and faster growth bringing it down. Four decades of expansion after the second world war shrank UK public sector debt from a wartime peak of 250% of GDP to 30% by the mid-1990s, close to the lowest-ever level. Since then it has risen inexorably, to 40% on the eve of the financial crisis and 75% in its wake, 103% today and, on IMF forecasts, a likely 115% in 2023.Canadian retail sales dropped in March. Auto sales fell in April. Households took on more debt in the first quarter, with the debt-to-income ratio rising to 177. Consumer spending is key to the economic recovery. Expenditure is expected to recover, but the pace of growth is likely to be slow.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.New research from Deloitte Access Economics shows that Australia’s economy – and $680 billion in economic potential – relies on climate action (A new choice - Australia's climate for growth).
The research is aimed at flipping the debate on how we discuss climate change to better consider the economic cost of not acting and the costs and benefits of taking action. Essentially, climate change is not a scenario – it is a reality which now must be reflected in the baseline for the economy. This new baseline for the economy has the damages from climate change built in and it shows the extensive, and confronting, costs associated with inaction, against a new growth recovery scenario of net zero.
Taken today , more than 30% of employed Australians and over 30% of national income sit in industries exposed to economic disruption and risk from climate change and unplanned economic transition
, more than 30% of employed Australians and over 30% of national income sit in industries exposed to economic disruption and risk from climate change and unplanned economic transition By 2070 – in the lifetime of Australians in their 20s, 30s and 40s today – the economic cost of doing nothing is an economy which is 6% smaller, a $3.4 trillion loss in GDP in present value terms, and with 880,000 fewer jobs
– in the lifetime of Australians in their 20s, 30s and 40s today – the economic cost of doing nothing is an economy which is 6% smaller, a $3.4 trillion loss in GDP in present value terms, and with 880,000 fewer jobs In contrast, a new growth recovery, delivering net zero by 2050 and consistent with keeping global warming to 1.5°C, could add $680 billion (in present value terms) and grow the economy by 2.6% in 2070, adding more than 250,000 jobs.
There isn’t a ‘no cost’ option. The report sets the benchmark of economic growth – one where damages from global warming are included – against which the cost of inaction or the costs and benefits of action should be assessed.
Principal report author, and Deloitte Access Economics lead partner, Dr Pradeep Philip, said: “The costs of climate change are still rising each year, as are the costs associated with reducing the risks it presents. Climate change is no longer a possibility. It is a reality. Doing nothing is now a policy choice, and it is costly. “
Business is increasingly leading the call for action on climate change, wary of the commercial and economic risks and beginning to understand the calculus of acting versus not acting. This is seen in a variety of areas. Increasingly, investors are calling out the carbon footprint of companies and demanding explanations from boards and management at annual general meetings. This is supported by shareholder activism, and consumer choices, demanding to know the carbon footprint of a company and its product, and that of the supply chain as well.
The report notes that policies aimed at strengthening economic growth can support low-emission pathways, and actions to stimulate investment in low-emission investments can strengthen economic growth job creation.The actions of policymakers have had a catalytic effect on equity markets since late March. We must hope that these actions prove as successful in supporting growth beyond the downturn.
The latest release of our chart book “The COVID-19 crisis: Economic impact and policy responses”, is available. The report aims to provide a graphical overview of the key economic developments of the COVID-19 crisis. Do feel free to use any of the charts in your own presentations.
Join our “Responding to COVID-19” webinar every Thursday at 13:00 GMT. Each week a panel of Deloitte experts are assessing the latest health, business and economic developments and discussing how organisations can navigate the emerging challenges. Register here for this Thursday’s webinar, on 23 April.
Economists are still coming to grips with the reality of a freezing of economic activity. Last week the International Monetary Fund warned that the coming downturn was likely to be the worst for the global economy since the Great Depression of the early 1930s.
On the same day the UK’s official forecaster, the Office for Budget Responsibility, said that a three-month lockdown could cause the UK economy to contract by 35% in the second quarter of this year. This is an astonishing hit, roughly equivalent to unwinding 16 years of growth in just three months. Meanwhile economists at the St Louis Federal Reserve estimate that the US unemployment rate could rise to 30%.
The US S&P 500 index has risen by 28% from the low it hit on 23 March and is only 15% below the all-time peak reached in February. Other major equity indices have seen significant, though lesser gains. After the longest US equity bull market in history, and with the world heading into what looks likely to be the deepest downturn in over a century, the S&P 500 is only back to the levels of last summer.
A vast programme of central bank and government stimulus has bolstered equities even as forecasts for growth have gone into freefall. The boost to global activity from easier fiscal policy, through increased public spending and tax cuts, is far greater than in 2008–09, and especially strong in Japan, the US, Germany and the UK. Governments are seeking to help corporates and households through the crisis with loans, tax holidays and a range of measures to support incomes. Central banks have re-started their programmes of asset purchases to boost liquidity, drive down interest rates and bolster risk assets. The Federal Reserve has gone further, promised unlimited quantitative easing, and, for the first time, promised to buy riskier, sub-investment grade, or junk bonds. The message is that policymakers will do whatever it takes to support growth and markets.
Investors have taken note. Their renewed enthusiasm for equities seems to be predicated on the idea that it is unwise to fight central banks - if central banks want to raise asset prices they have infinite ability to create money, and to make it happen. The hope, too, is that easier monetary and fiscal conditions will ensure that the slowdown is short-lived and that activity, and profits, will bounce back next year. In a world of ever-lower interest rates, equities do offer investors the prospect of long-term income. Markets have probably also taken some encouragement from signs of a peak in COVID-19 infections and a partial and cautious easing of restrictions in some European countries.
Yet, as far as the economy is concerned, we are in perilous waters. The scale of the downturn and the timing, and magnitude, of any recovery, are unknowable. Central banks and governments will not be able to prevent all damage to the productive capacity of the economy. If the legacy of this crisis is deep economic disruption, elevated debt levels and greater caution, long-term growth is likely to suffer.
The actions of policymakers have had a catalytic effect on equity markets since late March. We must hope that these actions prove as successful in supporting growth beyond the downturn.At the start of this journey we recognize that there’s a lot we don’t know and we’ll need input from the best minds—but it’s a journey we’d like you to take with us here and via social media. Think of it as a “making of” documentary—but instead of finding out how that CGI dragon works, we’re sharing the blow-by-blow of achieving a real live, game-changing goal.
Make no mistake, seamless, integrated mobility will be a game-changer and this is a once-in-a-generation opportunity to set it up right. Read on and find out about our first steps in this effort.
Before we even held our first meeting last month to discuss the project, the big question was—who can provide the kind of input we need? Based on Deloitte’s experience and the deep relationships we’ve built across the mobility ecosystem, we know cooperation and collaboration between the public and private sector will be critical to this effort. So it was natural to include representatives from government to offer the citizen perspective. Global leaders in freight and transport could provide a wider and experienced view of the challenges this industry experiences. Cars are a large part of the mobility ecosystem, so auto manufacturers were a must. And to give the project innovative and new thinking, start-ups in the mobility space were also actively engaged.
It’s an exciting and eclectic group we’ve gathered—and to give them full freedom to float their ideas and speak their minds, we won’t name them here. Because candid opinions and open exchange were what we were looking for at our first session (which took place at a Deloitte Greenhouse in Berlin, a space wholly dedicated to spurring innovative thinking). We had a lot to do at this meeting, including pulling together a unified vision for a SIMSystem based on an honest assessment of its potential and feasibility.
To get ideas flowing we used a video Deloitte’s Future of Mobility Practice produced called Ben’s Journey as a jumping off point. It details one possible way, out of thousands, that an average citizen—in this case, Ben—can move from point A to point B in the new mobility ecosystem. It shows how he can seamlessly assemble the transportation options he prefers and how they empower him to tailor the way he interacts and connects with them. It’s an example of a fully realized future state of mobility. A corresponding SIMSystem framework was presented from which the reality of Ben’s journey could be built while also exploring the wider movement of goods and passengers across geographies.
We asked, is Ben’s Journey really feasible? What needs to happen to get a SIMSystem off the ground? The answers, while they became clear after much discussion, are anything but easy. Interoperability, governance, technological capabilities, customer-centric design, data privacy, and cybersecurity—emerged as some serious challenges to be overcome. But some equally serious solutions were also floated, such as public-private partnerships and collaboration, standardized language and data exchanges, and information sharing. If done right, we can help accelerate adoption to connect cities and rural areas and address many of the inefficiencies, friction, and inequities of today’s transportation systems.
Our thinkers then broke into groups to tackle some specific and real challenges that a SIMSystem poses and needs to address. They studied mobility use cases that entailed the coordinated movement of people and products across geographies and during crises. They contemplated the difficulty of taking existing mobility systems and transitioning to a SIMSystem. They examined the ability of local networks to scale up and global ones to scale down. The discussions sought to map the intricacies of these situations—which are substantial once teased out. But more on that in my next blog.
So where did we end up? After dialogue and debate we were able to agree on the basic components of a SIMSystem and its scope. Just as important, we identified the major sticking points and what implementation would need to look like.
While we never thought this would be a ride without bumps, we now understand just how many factors have to be considered to make seamless mobility real (check out our session graphic and you’ll get a feel for the true complexity). But knowing where we are on this road and where we want to go is a good start.Last week, the Federal government released its much anticipated economic and fiscal update. It confirmed what we already knew – that COVID-19 has seen the single largest disruption to our way of life and economy since the Second World War. And this certainly reflected in the figures. Deloitte’s detailed review of the update can be found here.
The official forecasts for growth in the economy very much reflect the COVID recession – real Gross Domestic Product (GDP) is expected to have fallen by 0.25% in 2019-20, with the COVID-hit June quarter more than wiping out previous gains. The economy is then forecast to contract by 2.5% in 2020-21 as the country climbs only slowly out of the COVID hole, and weak consumer and business confidence weigh heavily on activity. This also factors in Victoria’s economy starting to open up again from late August, although a projection that remains highly problematic.
The unemployment rate is expected to peak at around 9.25% in the December quarter of 2020. Unemployment tends to increase faster than it decreases, and as a result, the rate is likely to remain above pre-COVID-19 levels for several years. The loosening of conditions in the labour market will weigh on already sluggish wage gains, which will in turn see little growth in inflation over the next year.The Internet of Things (IoT) can not only help you get ahead today, its powerful outcomes and analytics can propel your business far into the future. Deloitte can help companies harness the power of IoT to deliver transformative outcomes and tangible business value.Innovation, transformation and leadership occur in many ways. At Deloitte, our ability to help solve clients’ most complex issues is distinct. We deliver strategy and implementation, from a business and technology view, to help you lead in the markets where you compete.October 8, 2018 Approximately 70 percent of executives responding to a recent McKinsey Global Industry 4.0 Expert Survey said their organization considers Industry 4.0 as the top priority. Given that a 2015 McKinsey Global Institute report predicted that the Internet of Things—which is just one out of a wide range of Industry 4.0 technologies—could generate $1-3.7 trillion in value for factories by 2025, the business case for prioritizing Industry 4.0 is clear. But the 2018 survey found that progress remains unexpectedly slow.
The reason: Pilot purgatory. As they endeavor to capture trillions of dollars in value, companies worldwide are testing their priority Industry 4.0 use cases by launching an average of about eight pilots. Companies in China and India are pushing even harder, at an average of ten pilots (Exhibit 1).
Exhibit 1 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
But only 30 percent of the pilots end up reaching scale across the entire organization. Put differently, companies are failing to capture value from 70 percent of their pilots (Exhibit 2). Moreover, the pilots are too slow. Some 85 percent of the companies surveyed spend more than one year in pilot mode, while 28 percent spend more than two years. For companies to begin to capture the predicted trillions of dollars in value, they must move more pilots to scale faster.
Exhibit 2 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Companies usually head into Industry 4.0 pilots with the intention of expanding them company-wide. Too often, however, the pilots are essentially one-offs that fail to anticipate critical requirements in expanding from self-contained pilots to enterprise scale. Industry 4.0 (and IIoT) therefore remains in purgatory.
Through our work with clients on the manufacturing front lines, and in a host of realistic learning environments, we have identified three steps that help expand a successful pilot across an enterprise.
Start with the appropriate executive sponsorship and operating model, defining the roles and accountabilities for the business-unit, IT, and operations teams, along with the digital and analytics experts—all of whom need to work together and acquire the right talent.
Choose use cases carefully. Start by identifying the ones that create the most value and are easiest to implement; these can serve as lighthouses to demonstrate technological capabilities and potential impact. Embedding these cases into business routines then ensures that analytic insights don’t end up only in the back office but are used every day by the managers, supervisors, and operators who make the decisions that will enable the plant to run better.
As important as the first two steps are, they’re also conceptually simple, if sometimes a challenge to achieve in practice. It’s the third step in IT/OT convergence that can turn into a high barrier. The complexities of IT/OT technology are genuinely difficult to tackle, especially because on most factory floors, the links between IT and OT tend to be immature in unique ways. We refer to this as the last-mile IT/OT problem.
Within the IT/OT last mile, five issues combine to prevent manufacturers from scaling Industry 4.0 and IIoT.
Complex, heterogeneous environment: A typical medium-size plant has over 200 individual pieces of equipment, purchased at different times from a variety of suppliers. Each supplier has its own automation capabilities, hardware and software platforms, and communications protocols. This context makes it very difficult to collect, integrate, and contextualize data. Moreover, some equipment manufacturers offer data-analytical insights as a value-added service, creating further potential wrinkles in data accessibility. And the industrial-automation stack of hardware and software is itself highly complex, comprising everything from manufacturing-execution systems (MES), maintenance-software packages, production-scheduling software, and distributed-control systems, through to enterprise resource planning and product-lifecycle management.
A typical medium-size plant has over 200 individual pieces of equipment, purchased at different times from a variety of suppliers. Each supplier has its own automation capabilities, hardware and software platforms, and communications protocols. This context makes it very difficult to collect, integrate, and contextualize data. Moreover, some equipment manufacturers offer data-analytical insights as a value-added service, creating further potential wrinkles in data accessibility. And the industrial-automation stack of hardware and software is itself highly complex, comprising everything from manufacturing-execution systems (MES), maintenance-software packages, production-scheduling software, and distributed-control systems, through to enterprise resource planning and product-lifecycle management. Old unconnected machines: It is not uncommon to find aging, uninstrumented equipment on the factory floor, as replacement cycles for heavy assets often last decades. Difficult or extreme operating environments, such as the intricacies of a paint shop, are further barriers for data capture. Finding ways to instrument these assets is therefore an imperative for driving IoT at scale. Also, equipment that has already been instrumented frequently relies on legacy software systems, such as late-90s desktop-based machine-control systems, with data stored offline in spreadsheets. At one site we examined, for example, 90 percent of data from the MES was purged every 30 days (except for parameters required for reporting to major customers).
It is not uncommon to find aging, uninstrumented equipment on the factory floor, as replacement cycles for heavy assets often last decades. Difficult or extreme operating environments, such as the intricacies of a paint shop, are further barriers for data capture. Finding ways to instrument these assets is therefore an imperative for driving IoT at scale. Also, equipment that has already been instrumented frequently relies on legacy software systems, such as late-90s desktop-based machine-control systems, with data stored offline in spreadsheets. At one site we examined, for example, 90 percent of data from the MES was purged every 30 days (except for parameters required for reporting to major customers). Security concerns: Some manufacturers are reluctant to move data to the cloud, preferring an IoT solution that offers a mix of sensor-based edge analytics for critical process control and on-premises solutions for predictive analytics.
Some manufacturers are reluctant to move data to the cloud, preferring an IoT solution that offers a mix of sensor-based edge analytics for critical process control and on-premises solutions for predictive analytics. Limited last-mile OT capabilities at scale: Fundamentally, delivering Industry 4.0 at scale requires the ability to extract, interpret, and harmonize data from disparate systems that were not designed to work together. When building towards an IIoT platform, whether internally or with a third party, organizations must ensure that they can find capable OT service providers—ones that can support plants in locations across a wide-ranging footprint while harmonizing the collection (and connectivity) of data captured in the plant from PLCs, sensors, and historians. Without this step, the best analytic models and user interfaces will not have the data required to deliver the value expected from them.
Fundamentally, delivering Industry 4.0 at scale requires the ability to extract, interpret, and harmonize data from disparate systems that were not designed to work together. When building towards an IIoT platform, whether internally or with a third party, organizations must ensure that they can find capable OT service providers—ones that can support plants in locations across a wide-ranging footprint while harmonizing the collection (and connectivity) of data captured in the plant from PLCs, sensors, and historians. Without this step, the best analytic models and user interfaces will not have the data required to deliver the value expected from them. Poor collaboration between IT and OT: Often the problem is due to the historic lack of connection between IT activities and OT activities, typically by onsite manufacturing process engineers. OT’s goals usually focus on current performance, business-as-usual predictability, and avoiding disturbances to a system that works; IT favors security and trusted technology providers, often those that have a large installed base already. Different levels of focus on user management versus machine management yield very different problem-solving approaches. Consequently, getting the IT and OT staffs working together from the start is a must.
Being aware of last-mile IT/OT issues will help build a technical foundation that supports the full-scale roll-out of Industry 4.0 pilots. But careful planning that addresses the people issues of culture, process, and prioritization is equally important. Indeed, in our work with manufacturers, the specific success factors we’ve seen for sustained value capture point more to the human side of the equation: for example, leaders who are fully engaged, vendors who act as partners, and talent who have (and develop) the right skills.
Manufacturers should reflect on a few essential questions that help address the last-mile IT/OT challenges:
How mature are our plants with respect t0 last-mile IT/OT, and how can we better understand their IT/OT challenges?
How should we balance investment in additional data collection versus in getting more value from the 99 percent of our current data that is likely sitting unused?
How can we use previous industrial-automation investments, in systems such as MES and DCS, to help achieve speed and scale in building our IoT architecture?
To maximize our returns, how much of our last-mile IT/OT investment should be at plant level (sensors, connectivity, edge devices), and how much in broader IoT architecture (platform, cloud, application layers)?
Addressing these questions in the IT/OT context takes isn’t easy, and we’ll discuss them in more detail in our next post. We’ll also provide guidance on designing pilots that not only create tangible results, but also provide a foundation for a repeatable, timely rollout process that delivers value in months rather than years.
The authors wish to thank Ani Bhalekar, Karel Eloot, and Bodo Koerber for their contributions to this post.The Deloitte Digital IoT practice is a dynamic blend of technologists, strategists, and designers who use technology, data, and science to drive major business innovation. By mixing in creative vision and significant industry expertise, our IoT practice is helping our clients reimagine—and rewire—business-as-usual.
Think big. Start small. Scale fast. With us, it all starts with exploring the art of the possible. Once we have options for ideas, we help clients sort through the noise by starting small with a project that offers demonstrated ROI and tangible benefits. Utilizing engineers, cloud-based platforms, and sensor kits we can quickly create mock-ups and prototypes to show clients what’s possible. If the solution seems like it’s working, we iterate on it, tweak it, enhance it, and work with others to scale the project.
Our objective is to use IoT as a medium for helping clients transform their businesses, realize tangible value, and deliver powerful outcomes. We have a network of IoT consultants all over the world focusing on the organizational implications of IoT in areas like security and privacy, technology, strategy, architecture, analytics, and implementation.We approach every IoT project with a value-focused mindset.
Turnkey IoT—A low-cost, low-risk approach to accelerating IoT implementation that combines best-of-breed hardware, software, analytics, security, insights, and implementation strategy services into industry-tailored, pre-configured solutions with a focus on predictive maintenance & asset monitoring, asset performance management, and asset tracking use cases.
Retail 360—Clients can demo a custom solution that provides an omni-channel shopping experience to customers via a mobile app (EngageMe) and in-store inventory management capabilities to retailers via a web app (Store 360°). This helps customers get the experience they desire while retailers meet goals for increased sales and operational efficiency.
Patient 360—This IoT-based, care-coordination platform empowers patients, providers, payers, and the pharmaceutical industry. It can deliver better patient experiences by providing data and analysis to improve patient care as well as productivity in the healthcare marketplace.
Tech Map—To assist clients in evaluating the technology landscape for Smart Cities, we created IoT vendor maps that Deloitte practitioners use as an internal tool to rank vendors within technical categories and highlight the breadth and depth of their capabilities.Karel co-leads the Firm’s Operations practice and Internet of Things (IoT) group in Asia. Since joining the Firm in 1997, Karel has worked across multiple industries including advanced industries, automotive, electronics, energy and materials, technology, as well as private equity.
July 16, 2019 In an earlier blog post, we demonstrated how manufacturers’ efforts to capture value from the Industrial Internet of Things (IIoT) are often stymied by a breakdown at the convergence between their existing operational technology (OT) systems—their things—and the new information technology (IT) systems needed to drive a transformational digital operation.
We refer to this as the “last-mile IT/OT problem,” which results from the failure to properly plan, design, and build an IT/OT architecture from the outset that is capable of driving use-case pilots to scale. We identified the steps manufacturers should take to ensure that their IIoT stack isn’t holding them back, with this post as the first of a series of deep dives into how to put these steps into practice. Bear in mind that the steps aren’t strictly linear: in trying to deliver a whole program of IIoT initiatives, a pragmatic, integrated approach considers steps in tandem as needed to keep initiatives on track and out of one another’s way. But there is a general interplay between them.
Because selecting use cases is the starting point of any transformation, getting this step right is critical (Exhibit 1). All too often we see manufacturers start with technology in mind and then try to build a business case around it, and this sets them up to fail. From the outset, it’s essential for business KPIs to lead IIoT transformations, and for each potential use case to be tested against the business value that it is trying to create. In some cases, the best solution may not be a technology play at all.
Exhibit 1 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
But before making any judgment, bear in mind that it’s also important to avoid looking for business problems only within the four walls of the plant. By extending your gaze all the way from the supply chain to marketing, sales, and after-sales service, you can see opportunities to reinvent the complete value chain through digital technologies, rather than simply installing multiple “point” solutions that convert analog practices into their digital equivalents. It’s the difference between using technology to make an inefficient process run faster, and using technology to create a new process that dramatically opens up new opportunities and increases value creation.
Because use cases are typically selected to address immediate business needs, they are not enough on their own to deliver the sustainable new business model that an end-to-end digital transformation promises. But they are the building blocks of this transformation, and stack enough of them together and you can reap enormous dividends. Use cases also have a second, often under-appreciated, role. Because they solve for a particular problem or business need, they deliver the short-term wins necessary to capture immediate impact and prove the benefits of transformation to everyone from the frontline to the boardroom.
While we recommend implementing multiple use cases to drive a significant business transformation, this is not to say that single use cases or a related group of use cases in one area of a business cannot deliver significant impact. For instance:
A global basic-materials company introduced driverless trucks into several of its larger sites, which not only cut costs and improved safety but also outperformed the manned fleet by an average of more than 10 percent.
An automaker improved job satisfaction and reduced the time workers spent waiting between tasks by more than 75 percent—by teaming workers with collaborative robots on one of the most important assembly tasks for final product quality.
But by multiplying these gains across use cases spread throughout the value chain, the truly transformative power of digitizing operations starts to come into view. The implementation of each new use case also part funds the establishment of the IIoT platform infrastructure by delivering its own positive ROI, so the number of use cases a manufacturer could implement can be quite large.
Once an ambitious list of potential use cases is confirmed, they need to be tested against several criteria in addition to their impact on the business. These include whether technology to drive the use case is mature and readily available from established vendors, and whether the organization currently has the capacity to deliver the use case using that technology. While there are clear benefits to being a first mover, it’s also worth looking at what competitors are doing and whether the use case has been adopted at scale elsewhere in the industry to deliver significant benefit.
One way of testing use cases against these criteria is to feed them into a prioritization funnel with successively tighter filters at each stage. Only use cases that pass through all the filters and emerge from the narrow end of the funnel get sequenced for implementation. Because a typical manufacturer is likely to need 10–15 use cases just to drive the manufacturing part of its IIoT transformation—expanding this to all functions up and down the value chain will require many more—this approach is not for the faint at heart. One manufacturer put around 50 potential use cases through a prioritization tunnel to end up with around 15 use cases they needed to meet their game-changing business objectives around quality and cost optimization, as well as worker productivity (Exhibit 2).
Exhibit 2 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
The prioritization filter should also give a good idea of how to sequence the rollout of use cases. The next steps are to determine which technology solutions from the many options in the tech ecosystem will power them, identify the tech stack requirements for each one, and select the platform that will tie them all together. We will come back to these steps in future articles.Explore the inner workings of the Internet of Things in this deep dive into some of the technologies that make it possible.
If you’ve ever seen the “check engine” light come on in your car and had the requisite repairs done in a timely way, you’ve benefited from an early-stage manifestation of what today is known as the Internet of Things (IoT). Something about your car’s operation—an action—triggered a sensor,1 which communicated the data to a monitoring device. The significance of these data was determined based on aggregated information and prior analysis. The light came on, which in turn triggered a trip to the garage and necessary repairs.
In 1991 Mark Weiser, then of Xerox PARC, saw beyond these simple applications. Extrapolating trends in technology, he described “ubiquitous computing,” a world in which objects of all kinds could sense, communicate, analyze, and act or react to people and other machines autonomously, in a manner no more intrusive or noteworthy than how we currently turn on a light or open a tap.
One way of capturing the process implicit in Weiser’s model is as an Information Value Loop with discrete but connected stages. An action in the world allows us to create information about that action, which is then communicated and aggregated across time and space, allowing us to analyze those data in the service of modifying future acts.
Although this process is generic, it is perhaps increasingly relevant, for the future Weiser imagined is more and more upon us—not thanks to any one technological advance or even breakthrough but, rather, due to a confluence of improvements to a suite of technologies that collectively have reached levels of performance that enable complete systems relevant to a human-sized world.
As illustrated in figure 2 below, each stage of the value loop is connected to the subsequent stage by a specific set of technologies, defined below.
The business implications of the IoT are explored in an ongoing series of Deloitte reports. These articles examine the IoT’s impact on strategy, customer value, analytics, security, and a wide variety of specific applications. Yet just as a good chef should have some understanding of how the stove works, managers hoping to embed IoT-enabled capabilities in their strategies are well served to gain a general understanding of the technologies themselves.
To that end, this document serves as a technical primer on some of the technologies that currently drive the IoT. Its structure follows that of the technologies that connect the stages of the Information Value Loop: sensors, networks, standards, augmented intelligence, and augmented behavior. Each section in the report provides an overview of the respective technology—including factors that drive adoption as well as challenges that the technology must overcome to achieve widespread adoption. We also present an end-to-end IoT technology architecture that guides the development and deployment of Internet of Things systems. Our intent, in this primer, is not to describe every conceivable aspect of the IoT or its enabling technologies but, rather, to provide managers an easy reference as they explore IoT solutions and plan potential implementations. Our hope is that this report will help demystify the underlying technologies that comprise the IoT value chain and explain how these technologies collectively relate to a larger strategic framework.
Most “things,” from automobiles to Zambonis, the human body included, have long operated “dark,” with their location, position, and functional state unknown or even unknowable. The strategic significance of the IoT is born of the ever-advancing ability to break that constraint, and to create information, without human observation, in all manner of circumstances that were previously invisible. What allows us to create information from action is the use of sensors, a generic term intended to capture the concept of a sensing system comprising sensors, microcontrollers, modem chips, power sources, and other related devices.
A sensor converts a non-electrical input into an electrical signal that can be sent to an electronic circuit. The Institute of Electrical and Electronics Engineers (IEEE) provides a formal definition:
An electronic device that produces electrical, optical, or digital data derived from a physical condition or event. Data produced from sensors is then electronically transformed, by another device, into information (output) that is useful in decision making done by “intelligent” devices or individuals (people).7
The technological complement to a sensor is an actuator, a device that converts an electrical signal into action, often by converting the signal to nonelectrical energy, such as motion. A simple example of an actuator is an electric motor that converts electrical energy into mechanical energy. Sensors and actuators belong to the broader category of transducers: A sensor converts energy of different forms into electrical energy; a transducer is a device that converts one form of energy (electrical or not) into another (electrical or not). For example, a loudspeaker is a transducer because it converts an electrical signal into a magnetic field and, subsequently, into acoustic waves.
Different sensors capture different types of information. Accelerometers measure linear acceleration, detecting whether an object is moving and in which direction,8 while gyroscopes measure complex motion in multiple dimensions by tracking an object’s position and rotation. By combining multiple sensors, each serving different purposes, it is possible to build complex value loops that exploit many different types of information. For example:
Canary : A home security system that comes with a combination of temperature, motion, light, and humidity sensors. Computer vision algorithms analyze patterns in behaviors of people and pets, while machine learning algorithms improve the accuracy of security alerts over time. 9
: A home security system that comes with a combination of temperature, motion, light, and humidity sensors. algorithms analyze patterns in behaviors of people and pets, while algorithms improve the accuracy of security alerts over time. Thingsee: A do-it-yourself IoT device that individuals can use to combine sensors such as accelerometers, gyroscopes, and magnetometers with other sensors that measure temperature, humidity, pressure, and light in order to collect personally interesting data.10
Sensors are often categorized based on their power sources: active versus passive. Active sensors emit energy of their own and then sense the response of the environment to that energy. Radio Detection and Ranging (RADAR) is an example of active sensing: A RADAR unit emits an electromagnetic signal that bounces off a physical object and is “sensed” by the RADAR system. Passive sensors simply receive energy (in whatever form) that is produced external to the sensing device. A standard camera is embedded with a passive sensor—it receives signals in the form of light and captures them on a storage device.
Passive sensors require less energy, but active sensors can be used in a wider range of environmental conditions. For example, RADAR provides day and night imaging capacity undeterred by clouds and vegetation, while cameras require light provided by an external source.11
Figure 4 provides an illustrative list of 13 types of sensors based on the functions they perform; they could be active or passive per the description above.
Of course, the choice of a specific sensor is primarily a function of the signal to be measured (for example, position versus motion sensors). There are, however, several generic factors that determine the suitability of a sensor for a specific application. These include, but are not limited to, the following:12
Accuracy : A measure of how precisely a sensor reports the signal. For example, when the water content is 52 percent, a sensor that reports 52.1 percent is more accurate than one that reports it as 51.5 percent.
: A measure of how precisely a sensor reports the signal. For example, when the water content is 52 percent, a sensor that reports 52.1 percent is more accurate than one that reports it as 51.5 percent. Repeatability : A sensor’s performance in consistently reporting the same response when subjected to the same input under constant environmental conditions.
: A sensor’s performance in consistently reporting the same response when subjected to the same input under constant environmental conditions. Range : The band of input signals within which a sensor can perform accurately. Input signals beyond the range lead to inaccurate output signals and potential damage to sensors.
: The band of input signals within which a sensor can perform accurately. Input signals beyond the range lead to inaccurate output signals and potential damage to sensors. Noise : The fluctuations in the output signal resulting from the sensor or the external environment.
: The fluctuations in the output signal resulting from the sensor or the external environment. Resolution : The smallest incremental change in the input signal that the sensor requires to sense and report a change in the output signal.
: The smallest incremental change in the input signal that the sensor requires to sense and report a change in the output signal. Selectivity: The sensor’s ability to selectively sense and report a signal. An example of selectivity is an oxygen sensor’s ability to sense only the O 2 component despite the presence of other gases.
Any of these factors can impact the reliability of the data received and therefore the value of the data itself.
There are three primary factors driving the deployment of sensor technology: price, capability, and size. As sensors get less expensive, “smarter,” and smaller, they can be used in a wider range of applications and can generate a wider range of data at a lower cost.13
Cheaper sensors : The price of sensors has consistently fallen over the past several years as shown in figure 5, and these price declines are expected to continue into the future. 14 For example, the average cost of an accelerometer now stands at 40 cents, compared to $2 in 2006. 15 Sensors vary widely in price, but many are now cheap enough to support broad business applications.
: The price of sensors has consistently fallen over the past several years as shown in figure 5, and these price declines are expected to continue into the future. For example, the average cost of an accelerometer now stands at 40 cents, compared to $2 in 2006. Sensors vary widely in price, but many are now cheap enough to support broad business applications. Smarter sensors : As discussed earlier, a sensor does not function by itself—it is a part of a larger system that comprises microprocessors, modem chips, power sources, and other related devices. Over the last two decades, microprocessors’ computational power has improved, doubling every three years (see figure 6).
: As discussed earlier, a sensor does not function by itself—it is a part of a larger system that comprises microprocessors, modem chips, power sources, and other related devices. Over the last two decades, microprocessors’ computational power has improved, doubling every three years (see figure 6). Smaller sensors: There has been a rapid growth in the use of smaller sensors that can be embedded in smartphones and wearables. Micro-electro-mechanical systems (MEMS) sensors—small devices that combine digital electronics and mechanical components—have the potential to drive wider IoT applications.16 The average number of sensors on a smartphone has increased from three (accelerometer, proximity, ambient light) in 2007 to at least ten (including advanced sensors such as fingerprint- and gesture-based sensors) in 2014. Similarly, biosensors that can be worn and even ingested present new opportunities for the health care industry.
Even in cases where sensors are sufficiently small, smart, and inexpensive, challenges remain. Among them are power consumption, data security, and interoperability.
Power consumption : Sensors are powered either through in-line connections or batteries. 17 In-line power sources are constant but may be impractical or expensive in many instances. Batteries may represent a convenient alternative, but battery life, charging, and replacement, especially in remote areas, may represent significant issues. 18 There are two dimensions to power: Efficiency: Thanks to advanced silicon technologies, some sensors can now stay live on batteries for over 10 years, thus reducing battery replacement cost and efforts. 19 However, improved efficiency is counterbalanced by the power needed for increased numbers of sensors. Hence, systems’ overall power consumption often does not decrease or may, in fact, increase; this is an underlying challenge, as both energy and financial resources are finite. Source: While sensors often depend on batteries, energy harvesting of alternative energy sources such as solar energy may provide some alternatives, at a minimum providing support during the battery changing time. 20 However, energy harvesters that are currently available are expensive, and companies are hesitant to make that investment (installation plus maintenance costs) given the unreliability associated with the supply of alternative power. 21
: Sensors are powered either through in-line connections or batteries. In-line power sources are constant but may be impractical or expensive in many instances. Batteries may represent a convenient alternative, but battery life, charging, and replacement, especially in remote areas, may represent significant issues. There are two dimensions to power:
Security of sensors : Executives considering IoT deployments often cite security as a key concern. 22 Tackling the problem at the source may be a logical approach. Complex cryptographic algorithms might ensure data integrity, though sensors’ relatively low processing power, the low memory available to them, and concerns about power consumption may all limit the ability to provide this security. Companies need to be mindful of the constraints involved as they plan their IoT deployments. 23
: Executives considering IoT deployments often cite security as a key concern. Tackling the problem at the source may be a logical approach. Complex cryptographic algorithms might ensure data integrity, though sensors’ relatively low processing power, the low memory available to them, and concerns about power consumption may all limit the ability to provide this security. Companies need to be mindful of the constraints involved as they plan their IoT deployments. Interoperability: Most of the sensor systems currently in operation are proprietary and are designed for specific applications. This leads to interoperability issues in heterogeneous sensor systems related to communication, exchange, storage and security of data, and scalability. Communication protocols are required to facilitate communication between heterogeneous sensor systems. Due to various limitations such as low processing power, memory capacity, and power availability at the sensor level, lightweight communication protocols are preferable.24 Constrained Application Protocol (CoAP) is an open-source protocol that transfers data packets in a format that is lighter than that of other protocols such as Hypertext Transfer Protocol (HTTP), a protocol familiar to many, as it appears in most web addresses. While CoAP is well suited for energy-constrained sensor systems, it does not come with in-built security features, and additional protocols are needed to secure intercommunications between sensor systems.25
Information that sensors create rarely attains its maximum value at the time and place of creation. The signals from sensors often must be communicated to other locations for aggregation and analysis. This typically involves transmitting data over a network.
Sensors and other devices are connected to networks using various networking devices such as hubs, gateways, routers, network bridges, and switches, depending on the application. For example, laptops, tablets, mobile phones, and other devices are often connected to a network, such as Wi-Fi, using a networking device (in this case, a Wi-Fi router).
The first step in the process of transferring data from one machine to another via a network is to uniquely identify each of the machines. The IoT requires a unique name for each of the “things” on the network. Network protocols are a set of rules that define how computers identify each other. Broadly, network protocols can be proprietary or open. Proprietary network protocols allow identification and authorization to machines with specific hardware and software, making customization easier and allowing manufacturers to differentiate their offerings. Open protocols allow interoperability across heterogeneous devices, thus improving scalability.26
Internet Protocol (IP) is an open protocol that provides unique addresses to various Internet-connected devices; currently, there are two versions of IP: IP version 4 (IPv4) and IP version 6 (IPv6). IP was used to address computers before it began to be used to address other devices. About 4 billion IPv4 addresses out of its capacity of 6 billion addresses have already been used. IPv6 has superior scalability with approximately 3.4x1038 unique addresses compared to the 6 billion addresses supported by IPv4. Since the number of devices connected to the Internet is estimated to be 26 billion as of 2015 and projected to grow to 50 billion or more by 2020, the adoption of IPv6 has served as a key enabler of the IoT.
Network technologies are classified broadly as wired or wireless. With the continuous movement of users and devices, wireless networks provide convenience through almost continuous connectivity, while wired connections are still useful for relatively more reliable, secured, and high-volume network routes.27
The choice of a network technology depends largely on the geographical range to be covered. When data have to be transferred over short distances (for example, inside a room), devices can use wireless personal area network (PAN) technologies such as Bluetooth and ZigBee as well as wired connections through technologies such as Universal Serial Bus (USB). When data have to be transferred over a relatively bigger area such as an office, devices could use local area network (LAN) technologies. Examples of wired LAN technologies include Ethernet and fiber optics. Wireless LAN networks include technologies such as Wi-Fi. When data are to be transferred over a wider area beyond buildings and cities, an internetwork called wide area network (WAN) is set up by connecting a number of local area networks through routers. The Internet is an example of a WAN.
Data transfer rates and energy requirements are two key considerations when selecting a network technology for a given application. Technologies such as 4G (LTE, LTE-A) and 5G are favorable for IoT applications, given their high data transfer rates. Technologies such as Bluetooth Low Energy and Low Power Wi-Fi are well suited for energy-constrained devices.
Below, we discuss select wireless network technologies that could be used for IoT applications. For each of the following technologies, we discuss bandwidth rates, recent advances, and limitations. The technologies discussed below are representative, and the choice of an appropriate technology depends on the application at hand and the features of that technology.
Introduced in 1999, Bluetooth technology is a wireless technology known for its ability to transfer data over short distances in personal area networks.28 Bluetooth Low Energy (BLTE) is a recent addition to the Bluetooth technology and consumes about half the power of a Bluetooth Classic device, the original version of Bluetooth.29 The energy efficiency of BLTE is attributable to the shorter scanning time needed for BLTE devices to detect other devices: 0.6 to 1.2 milliseconds (ms) compared to 22.5 ms for Bluetooth Classic. 30 In addition, the efficient transfer of data during the transmitting and receiving states enables BLTE to deliver higher energy efficiency compared to Bluetooth Classic. Higher energy efficiency comes at the cost of lower data rates: BLTE supports 260 kilobits per second (Kbps) while Bluetooth Classic supports up to 2.1 Mbps.31
Existing penetration, coupled with low device costs, positions BLTE as a technology well suited for IoT applications. However, interoperability is the persistent bottleneck here as well: BLTE is compatible with only the relatively newer dual-mode Bluetooth devices (called dual mode because they support BLTE as well as Bluetooth Classic), not the legacy Bluetooth Classic devices.32
Although Ethernet has been in use since the 1970s, Wi-Fi is a more recent wireless technology that is widely popular and known for its high-speed data transfer rates in personal and local area networks.
Typically, Wi-Fi devices keep latency, or delays in the transmission of data, low by remaining active even when no data are being transmitted. Such Wi-Fi connections are often set up with a dedicated power line or batteries that need to be charged after a couple of hours of use. Higher-cost, lower-power Wi-Fi devices “sleep” when not transmitting data and need just 10 milliseconds to “wake up” when called upon.33 Low Power Wi-Fi with batteries can be used for remote sensing and control applications.
Introduced in 2001, WiMAX was developed by the European Telecommunications Standards Institute (ETSI) in cooperation with IEEE. WiMAX 2 is the latest technology in the WiMAX family. WiMAX 2 offers maximum data speed of 1 Gbps compared to 100 Mbps by WiMAX.34
In addition to higher data speeds, WiMAX 2 has better backward compatibility than WiMAX: WiMAX 2 network operators can provide seamless service by using 3G or 2G networks when required. By way of comparison, Long Term Evolution (LTE) and LTE-A, described below, also allow backward compatibility.
Long Term Evolution, a wireless wide-area network technology, was developed by members of the 3rd Generation Partnership Project body in 2008. This technology offers data speeds of up to 300 Mbps.35
LTE-Advanced (LTE-A) is a recent addition to the LTE technology that offers still-higher data rates of 1 Gbps compared to 300 Mbps by LTE.36 There is debate among industry practitioners on whether LTE is truly a 4G technology: Many consider LTE a pre-4G technology and LTE-A a true 4G technology.37 Given its high bandwidth and low latency, LTE is touted as the more-promising technology for IoT applications; however, the underlying network infrastructure remains under development, as described in the challenges below.
Weightless is a wireless open-standard WAN technology introduced in early 2014. Weightless uses unused bandwidth originally intended for TV broadcast to transfer data; based on the technical process of dynamic spectrum allocation, it can travel longer distances and penetrate through walls.38
Weightless can provide data rates between 2.5 Kbps to 16 Mbps in a wireless range of up to five kilometers, with batteries lasting up to 10 years.39 Weightless devices remain in standby mode, waking up every 15 minutes and staying active for 100 milliseconds to sync up and act on any messages; this leads to a certain latency.40 Given these characteristics, Weightless connections appear to be better- suited for delivering short messages in widespread machine-to-machine communications.
Networks are able to transfer data at higher speeds, at lower costs, and with lower energy requirements than ever before. Also, with the introduction of IPv6, the number of connected devices is rising rapidly. As a result, we are seeing an increasingly diverse composition of connected devices, from laptops and smartphones to home appliances, vehicles, traffic signals, and wind turbines. Such diversity in the nature of connected devices is driving a wider-scale adoption of an extensive range of network technologies.
Data rates : In the last 30 years, data rates have increased from 2 Kbps to 1 Gbps, facilitating seamless transfer of heavy data files (see figure 8 for various cellular-technology generations). The transition from the first cellular generation to the second changed the way communication messages were sent—from analog signals to digital signals. The transition from the second to the third generation marked a leap in capability, enabling users to share multimedia content over high-speed connections.
: In the last 30 years, data rates have increased from 2 Kbps to 1 Gbps, facilitating seamless transfer of heavy data files (see figure 8 for various cellular-technology generations). The transition from the first cellular generation to the second changed the way communication messages were sent—from analog signals to digital signals. The transition from the second to the third generation marked a leap in capability, enabling users to share multimedia content over high-speed connections. Internet transit prices : The Internet transit price is the price charged by an Internet service provider (ISP) to transfer data from one point in the network to another. Since no single ISP can cover the worldwide network, the ISPs rely on each other to transfer data using network interconnections through gateways. 41 Internet transit prices have come down in recent years due to technology developments such as the global increase in submarine cabling, the rising use of wavelength division multiplexing by ISPs, the transition to higher-capacity bandwidth connections, and increased competition between ISPs. 42 In 2003, it cost $120 to transfer 1 Mbps in the United States; as of 2015, the cost has come down to 63 cents (see figure 9).
: The Internet transit price is the price charged by an Internet service provider (ISP) to transfer data from one point in the network to another. Since no single ISP can cover the worldwide network, the ISPs rely on each other to transfer data using network interconnections through gateways. Internet transit prices have come down in recent years due to technology developments such as the global increase in submarine cabling, the rising use of wavelength division multiplexing by ISPs, the transition to higher-capacity bandwidth connections, and increased competition between ISPs. In 2003, it cost $120 to transfer 1 Mbps in the United States; as of 2015, the cost has come down to 63 cents (see figure 9). Power efficiency : Availability of power-efficient networks is critical given the increase in the number of connected devices. Bluetooth Low Energy has a power consumption of 0.153 μW/bit (0.153 microwatts consumed in transferring 1 bit of data; 1 byte = 8 bits), about 50 percent lower than that of Bluetooth Classic. 43
: Availability of power-efficient networks is critical given the increase in the number of connected devices. Bluetooth Low Energy has a power consumption of 0.153 μW/bit (0.153 microwatts consumed in transferring 1 bit of data; 1 byte = 8 bits), about 50 percent lower than that of Bluetooth Classic. IPv6 adoption: Given IPv6’s massive identification space, new devices are typically IPv6-based, while companies are transitioning existing devices from IPv4 to IPv6. In 2015, according to Cisco, the number of IPv6-capable websites increased by 33 percent over the prior year.44 By 2018, 50 percent of all fixed and mobile device connections are expected to be IPv6-based, compared to 16 percent in 2013.45
Even though network technologies have improved in terms of higher data rates and lower costs, there are challenges associated with interconnections, penetration, security, and power consumption.
Interconnections : Metcalfe’s Law states that “the value of a network is proportional to the square of the number of compatibly communicating devices.” There is limited value in connecting the devices to the Internet; companies can create enhanced value by connecting devices to the network and to each other. Different network technologies require gateways to connect with each other. This adds cost and complexity, which can often make security management more difficult.
: Metcalfe’s Law states that “the value of a network is proportional to the square of the number of compatibly communicating devices.” There is limited value in connecting the devices to the Internet; companies can create enhanced value by connecting devices to the network and to each other. Different network technologies require gateways to connect with each other. This adds cost and complexity, which can often make security management more difficult. Network penetration : There is limited penetration of high-bandwidth technologies such as LTE and LTE-A, while 5G technology has yet to arrive. 46 Currently, LTE accounts for only 5 percent of the world’s total mobile connections. LTE penetration as a percentage of connections is 69 percent in South Korea, 46 percent in Japan, and 40 percent in the United States, but its penetration in the developing world stands at just 2 percent. 47 In emerging markets, network operators are treading the slow-and-steady path to LTE infrastructure, given the accompanying high costs and their focus on fully reaping the returns on the investments in 3G technology that they made in the last three to five years.
: There is limited penetration of high-bandwidth technologies such as LTE and LTE-A, while 5G technology has yet to arrive. Currently, LTE accounts for only 5 percent of the world’s total mobile connections. LTE penetration as a percentage of connections is 69 percent in South Korea, 46 percent in Japan, and 40 percent in the United States, but its penetration in the developing world stands at just 2 percent. In emerging markets, network operators are treading the slow-and-steady path to LTE infrastructure, given the accompanying high costs and their focus on fully reaping the returns on the investments in 3G technology that they made in the last three to five years. Security : With a growing number of sensor systems being connected to the network, there is an increasing need for effective authentication and access control. The Internet Protocol Security (IPSec) suite provides a certain level of secured IP connection between devices; however, there are outstanding risks associated with the security of one or more devices being compromised and the impact of such breaches on connected devices. 48 Maintaining data integrity while remaining energy efficient stands as an enduring challenge.
: With a growing number of sensor systems being connected to the network, there is an increasing need for effective authentication and access control. The Internet Protocol Security (IPSec) suite provides a certain level of secured IP connection between devices; however, there are outstanding risks associated with the security of one or more devices being compromised and the impact of such breaches on connected devices. Maintaining data integrity while remaining energy efficient stands as an enduring challenge. Power: Devices connected to a network consume power, and providing a continuous power source is a pressing concern for the IoT. Depending on the application, a combination of techniques such as power-aware routing and sleep-scheduling protocols can help improve power management in networks. Power-aware routing protocols determine the routing decision based on the most energy-efficient route for transmitting data packets; sleep-scheduling protocols define how devices can “sleep” and remain inactive for better energy efficiency without impacting the output.
The third stage in the Information Value Loop—aggregate—refers to a variety of activities including data handling, processing, and storage. Data collected by sensors in different locations are aggregated so that meaningful conclusions can be drawn. Aggregation increases the value of data by increasing, for example, the scale, scope, and frequency of data available for analysis. Aggregation is achieved through the use of various standards depending on the IoT application at hand. According to the International Organization for Standardization (ISO), “a standard is a document that provides requirements, specifications, guidelines or characteristics that can be used consistently to ensure that materials, products, processes and services are fit for their purpose.”49
Two broad types of standards relevant for the aggregation process are technology standards (including network protocols, communication protocols, and data-aggregation standards) and regulatory standards (related to security and privacy of data, among other issues).
We discuss technology standards in the “Enabling technology standards” discussion later in this section. The second type of standards relates to regulatory standards that will play an important role in shaping the IoT landscape. There is a need for clear regulations related to the collection, handling, ownership, use, and sale of the data. Within the context of expanding IoT applications, it is worthwhile to consider the US Federal Trade Commission’s privacy and security recommendations dubbed the Fair Information Practice Principles (FIPPs) and described below.50
Choice and notice: The principle of choice and notice states that entities that collect data should give users the option to choose what they reveal and notify users when their personal information is being recorded. This may not be required for IoT applications that aggregate information, de-linked to any specific individual.
The principle of choice and notice states that entities that collect data should give users the option to choose what they reveal and notify users when their personal information is being recorded. This may not be required for IoT applications that aggregate information, de-linked to any specific individual. Purpose specification and use limitation: This principle states that entities collecting data must clearly state the purpose to the authority that permits the collection of those data. The use of data must be limited to the purpose specified, although this might hinder creative uses of collected data sets in various IoT applications.
This principle states that entities collecting data must clearly state the purpose to the authority that permits the collection of those data. The use of data must be limited to the purpose specified, although this might hinder creative uses of collected data sets in various IoT applications. Data minimization: The principle of data minimization suggests that a company can collect only the data required for a specific purpose and delete that data after the intended use. This necessarily restricts the scope of analysis that can result from slicing and dicing the IoT data.
The principle of data minimization suggests that a company can collect only the data required for a specific purpose and delete that data after the intended use. This necessarily restricts the scope of analysis that can result from slicing and dicing the IoT data. Security and accountability: This principle states that entities that collect and store data are accountable and must deploy security systems to avoid any unauthorized access, modification, deletion, or use of the data.
It is unclear, as of now, who will design, develop, and implement any regulatory standards specifically tailored to IoT applications. There is discussion about the appropriateness of existing guidelines and whether they are adequate for evolving IoT applications. For example, the US Health Insurance Portability and Accountability Act (HIPAA) governs the protection of medical information collected by doctors, hospitals, and insurance companies.51 However, the act does not extend to information collected through personal wearable devices.52
We just discussed the issues related to regulatory standards. Technology standards, the second type, comprises three elements: network protocols, communication protocols, and data-aggregation standards. Network protocols define how machines identify each other, while communication protocols provide a set of rules or a common language for devices to communicate. Once the devices are “talking” to each other and sharing data, aggregation standards help to aggregate and process the data so that those data become usable.
Network protocols : Network protocols refer to a set of rules by which machines identify and authorize each other. Interoperability issues result from multiple network protocols in existence. In recent years, companies in the IoT value chain have begun working together to help align multiple network protocols. One example is the AllJoyn standard established by Qualcomm in late 2013 that allows devices to discover, connect, and communicate directly with other AllJoyn-enabled products connected to different technologies such as Wi-Fi, Ethernet, and possibly Bluetooth and ZigBee. 53
: Network protocols refer to a set of rules by which machines identify and authorize each other. Interoperability issues result from multiple network protocols in existence. In recent years, companies in the IoT value chain have begun working together to help align multiple network protocols. One example is the AllJoyn standard established by Qualcomm in late 2013 that allows devices to discover, connect, and communicate directly with other AllJoyn-enabled products connected to different technologies such as Wi-Fi, Ethernet, and possibly Bluetooth and ZigBee. Communication protocols: Once devices are connected to a network and they identify each other, communication protocols (a set of rules) provide a common language for devices to communicate. Various communication protocols are used for device-to-device communication; broadly, they vary in the format in which data packets are transferred. There are ongoing efforts to identify protocols better suited to IoT applications. Toward that end, we earlier discussed the advantages and limitations of the Constrained Application Protocol, a communication protocol lighter than other popular protocols such as HTTP.
Once devices are connected to a and they identify each other, communication protocols (a set of rules) provide a common language for devices to communicate. Various communication protocols are used for device-to-device communication; broadly, they vary in the format in which data packets are transferred. There are ongoing efforts to identify protocols better suited to IoT applications. Toward that end, we earlier discussed the advantages and limitations of the Constrained Application Protocol, a communication protocol lighter than other popular protocols such as HTTP. Data aggregation standards: Data collected from multiple devices come in different formats and at different sampling rates—that is, the frequency at which data are collected. One set of data-aggregation tools—Extraction, Transformation, Loading (ETL) tools—aggregate, process, and store data in a format that can be used for analytics applications (see figure 11).54 Extraction refers to acquiring data from multiple sources and multiple formats and then validating to ensure that only data that meet a criterion are included. Transformation includes activities such as splitting, merging, sorting, and transforming the data into a desired format—for example, names can be split into first and last names, while addresses can be merged into city and state format. Loading refers to the process of loading the data into a database that can be used for analytics applications.
Traditional ETL tools aggregate and store the data in relational databases, in which data are organized by establishing relationships based on a unique identifier. It is easy to enter, store, and query structured data in relational databases using structured query language (SQL). The American National Standards Institute standardized SQL as the querying language for relational databases in 1986.55 SQL provides users a medium to communicate with databases and perform tasks such as data modification and retrieval. As the standard, SQL aids aggregation not just in centralized databases (all data stored in a single location) but also in distributed databases (data stored on several computers with concurrent data modifications).
With recent advances in easy and cost-effective availability of large volumes of data, there is a question about the adequacy of traditional ETL tools that can typically handle data in terabytes (1 terabyte = 1012 bytes). Big-data ETL tools developed in recent years can handle a much higher volume of data, such as in petabytes (1 petabyte = 1000 terabytes or 1015 bytes). In addition to handling large volume, big-data tools are also considered to be better suited to handle the variety of incoming data, structured as well as unstructured. Structured data are typically stored in spreadsheets, while unstructured data are collected in the form of images, videos, web pages, emails, blog entries, documents, etc.
Apache Hadoop is a big-data tool useful especially for unstructured data. Based on the Java programming language, Hadoop, developed by the Apache Software Foundation, is an open-source tool useful for processing large data sets. Hadoop enables parallel processing of large data across clusters of computers wherein each computer offers local aggregation and storage.56 Hadoop comprises two major components: MapReduce and Hadoop Distributed File System (HDFS). While MapReduce enables aggregation and parallel processing of large data sets, HDFS is a file-based storage system and a type of “Not only SQL (noSQL)” database. Compared to relational databases, NoSQL databases represent a wider variety of databases that can store unstructured data. Data processed and stored on Hadoop systems can be queried through Hadoop application program interfaces (APIs) that offer an easy user interface to query the data stored on HDFS for analytics applications.
Depending on the type of data and processing, different tools could be used. While MapReduce works on parallel processing, Spark, another big-data tool, works on both parallel processing and in-memory processing.57 Considering storage databases, HDFS is a file-based database that stores batch data such as quarterly and yearly company financial data, while Hbase and Cassandra are event-based storage databases that are useful for storing streaming (or real-time) data such as stock-performance data.58 We discussed select big-data tools above; other tools exist with a range of benefits and limitations, and the choice of a tool depends on the application at hand.
At present, the IoT landscape is in a nascent stage, and existing technology standards serve specific solutions and stakeholder requirements. There are many efforts under way to develop standards that can be adopted more widely. Primarily, we find two types of developments: vendors (across the IoT value chain) coming together to an agreement, and standards bodies (for example, IEEE or ETSI) working to develop a standard that vendors follow. Time will tell which one of these two options will prevail. Ultimately, it might be difficult to have one universal standard or “one ring to rule them all” either at the network or communication protocol level or at the data-aggregation level.
In terms of network and communication protocols, a few large players have at hand a meaningful opportunity to drive the standards that IoT players will follow for years to come. As an example, Qualcomm—with other companies such as Sony, Bosch, and Cisco—has developed the AllSeen Alliance that provides the AllJoyn platform, as described earlier.59 On similar lines, through the Open Interconnect Consortium, Intel launched the open-source IoTivity platform that facilitates device-to-device connectivity.60 IoTivity offers its members a free license of the code, while AllSeen does not. However, AllSeen-compliant devices are already available, while devices compliant with IoTivity are expected to be available by the second half of 2015.61 Both platforms are comparable but not interoperable, just as iOS and Android are.62
Concurrently, various standards bodies are also working to develop standards (for network and communication protocols) that apply to their geographical boundaries and could extend well beyond to facilitate worldwide IoT communications. As an example, the ETSI, which primarily has a focus on Europe, is working to develop an end-to-end architecture called the oneM2M platform that could be used worldwide.63 IEEE, another standards body, is making progress with the IEEE P2413 working group and is coordinating with standards bodies such as ETSI and ISO to develop a global standard by 2016.64
In terms of data aggregation, relational databases and SQL are considered to be the standards for storing and querying structured data. However, we do not yet have a widely used standard for handling unstructured data, even though various big-data tools are available. We discuss this challenge below.
For effective aggregation and use of the data for analysis, there is a need for technical standards to handle unstructured data and legal and regulatory standards to maintain data integrity. There are gaps in people skills to leverage the newer big-data tools, while security remains a major concern, given the fact that all the data are aggregated and processed at this stage of the Information Value Loop.
Standard for handling unstructured data : Structured data are stored in relational databases and queried through SQL. Unstructured data are stored in different types of noSQL databases without a standard querying approach. Hence, new databases created from unstructured data cannot be handled and used by legacy database-management systems that companies typically use, thus restricting their adoption. 65
: Structured data are stored in relational databases and queried through SQL. Unstructured data are stored in different types of noSQL databases without a standard querying approach. Hence, new databases created from unstructured data cannot be handled and used by legacy database-management systems that companies typically use, thus restricting their adoption. Security and privacy issues : There is a need for clear guidelines on the retention, use, and security of the data as well as metadata , the data that describe other data. As discussed earlier, there is a trade-off between the level of security and the memory and bandwidth requirements.
: There is a need for clear guidelines on the retention, use, and security of the data as well as , the data that describe other data. As discussed earlier, there is a trade-off between the level of security and the memory and bandwidth requirements. Regulatory standards for data markets : Data brokers are companies that sell data collected from various sources. Even though data appear to be the currency of the IoT, there is lack of transparency about who gets access to data and how those data are used to develop products or services and sold to advertisers and third parties. A very small fraction of the data collected online is sold online, while a larger share is sold through offline transactions between providers and users. 66 As highlighted by the Federal Trade Commission, there is an increased need for regulation of data brokers. 67
: Data brokers are companies that sell data collected from various sources. Even though data appear to be the currency of the IoT, there is lack of transparency about who gets access to data and how those data are used to develop products or services and sold to advertisers and third parties. A very small fraction of the data collected online is sold online, while a larger share is sold through offline transactions between providers and users. As highlighted by the Federal Trade Commission, there is an increased need for regulation of data brokers. Technical skills to leverage newer aggregation tools: Companies that are keen on leveraging big-data tools often face a shortage of talent to plan, execute, and maintain systems.68 There is an uptrend in the number of engineers being trained to use newer tools such as Spark and MapReduce, but this is far fewer than the number of engineers trained in traditional languages such as SQL.69
Extracting insight from data requires analysis, the fourth stage in the Information Value Loop. Analysis is driven by cognitive technologies and the accompanying models that facilitate the use of cognitive technologies.70 We refer to these enablers collectively as “augmented intelligence” to capture the idea that systems can automate intelligence—a concept that for us includes notions of volition and purpose—in a way that excludes human agency but nevertheless can be supplemented and enhanced.
In the context of the value loop, analysis is useful only to the extent that it informs action. “Analytics typically involves sifting through mountains of what are often confusing and conflicting data—in search of nuggets of insight that may inform better decisions.”71 As figure 12 illustrates, there are three different ways in which analytics can inform action.72
At the lowest level, descriptive analytics tools augment our intelligence by allowing us to work effectively with much larger or more complex data sets than we could otherwise easily handle. Various data visualization tools such as Tableau and SAS Visual Analytics make large data sets more amenable to human comprehension and enable users to identify insights that would otherwise be lost in the huge heap of data.
Predictive analytics is the beginning of keener insight into what might be happening or could happen, given historical trends. Predictive analytics exploits the large quantity and increasing variety of data to build useful models that can correlate seemingly unrelated variables.73 Predictive models are expected to produce more accurate results through machine learning, a process that refers to computer systems’ ability to improve their performance by exposure to data without the need to follow explicitly programmed instructions. For instance, when presented with an information database about credit-card transactions, a machine-learning system discerns patterns that are predictive of fraud. The more transaction data that the system processes, the better its predictions should become.74 Unfortunately, in many practical applications, even seemingly strong correlations are unreliable guides to effective action. Consequently, predictive analytics in itself still relies on human beings to determine what sorts of interventions are likeliest to work.75
Finally, prescriptive analytics takes on the challenge of creating more nearly causal models.76 Prescriptive analytics includes optimization techniques that are based on large data sets, business rules (information on constraints), and mathematical models. Prescriptive algorithms can continuously include new data and improve prescriptive accuracy in decision optimizations. Since prescriptive models provide recommendations on the best course of action, the element of human participation becomes more important; the focus shifts from a purely analytics exercise to behavior change management. We discuss this more in the “Augmented behavior” section.
With advances in cognitive technologies’ ability to process varied forms of information, vision and voice have also become usable. Below, we discuss select cognitive technologies that are experiencing increasing adoption and can be deployed for predictive and prescriptive analytics.78
Computer vision refers to computers’ ability to identify objects, scenes, and activities in images. Computer vision technology uses sequences of imaging-processing operations and other techniques to decompose the task of analyzing images into manageable pieces. Certain techniques, for example, allow for detecting the edges and textures of objects in an image. Classification models may be used to determine whether the features identified in an image are likely to represent a kind of object already known to the system. 79 Computer vision applications are often used in medical imaging to improve diagnosis, prediction, and treatment of diseases. 80
refers to computers’ ability to identify objects, scenes, and activities in images. Computer vision technology uses sequences of imaging-processing operations and other techniques to decompose the task of analyzing images into manageable pieces. Certain techniques, for example, allow for detecting the edges and textures of objects in an image. Classification models may be used to determine whether the features identified in an image are likely to represent a kind of object already known to the system. Computer vision applications are often used in medical imaging to improve diagnosis, prediction, and treatment of diseases. Natural-language processing refers to computers’ ability to work with text the way humans do, extracting meaning from text or even generating text that is readable. Natural-language processing, like computer vision, comprises multiple techniques that may be used together to achieve its goals. Language models, a natural-language processing technique, are used to predict the probability distribution of language expressions—the likelihood that a given string of characters or words is a valid part of a language, for instance. Feature selection may be used to identify the elements of a piece of text that may distinguish one kind of text from another—for example, a spam email versus a legitimate one. 81
refers to computers’ ability to work with text the way humans do, extracting meaning from text or even generating text that is readable. Natural-language processing, like computer vision, comprises multiple techniques that may be used together to achieve its goals. Language models, a natural-language processing technique, are used to predict the probability distribution of language expressions—the likelihood that a given string of characters or words is a valid part of a language, for instance. Feature selection may be used to identify the elements of a piece of text that may distinguish one kind of text from another—for example, a spam email versus a legitimate one. Speech recognition focuses on accurately transcribing human speech. The technology must handle various inherent challenges such as diverse accents, background noise, homophones (for example, “principle” versus “principal”), and speed of speaking. Speech-recognition systems use some of the same techniques as natural-language processing systems, as well as others such as acoustic models that describe sounds and the probability of their occurring in a given sequence in a given language.82 Applications of speech-recognition technologies include medical dictation, hands-free writing, voice control of computer systems, and telephone customer-service applications. Domino’s Pizza, for instance, recently introduced a mobile app that allows customers to use natural speech to place orders.83
Availability of big data—coupled with growth in advanced analytics tools, proprietary as well as open-source—is driving augmented intelligence. Typical intelligence applications are based on batch processing of data; however, the need for timely insights and prompt action is driving a growing adoption of real-time data analysis tools.
Availability of big data : Artificial intelligence models can be improved with large data sets that are more readily available than ever before, thanks to the lower storage costs. Figures 13 and 14 show the recent decline in storage costs alongside the growth in enterprise data over the last decade.
: models can be improved with large data sets that are more readily available than ever before, thanks to the lower storage costs. Figures 13 and 14 show the recent decline in storage costs alongside the growth in enterprise data over the last decade. Growth in crowdsourcing and open-source analytics software : Cloud -based crowdsourcing services are leading to new algorithms and improvements in existing ones at an unprecedented rate. Data scientists across the globe are working to improve the breadth and depth of analytics tools. As an example, the number of R packages (a package includes R functions, data sets, and underlying code in a usable format) has increased 40-fold since 2001 (see figure 15). 84
: -based crowdsourcing services are leading to new algorithms and improvements in existing ones at an unprecedented rate. Data scientists across the globe are working to improve the breadth and depth of analytics tools. As an example, the number of R packages (a package includes R functions, data sets, and underlying code in a usable format) has increased 40-fold since 2001 (see figure 15). Real-time data processing and analysis: Analytics tools such as complex event processing (CEP) enable processing and analysis of data on a real-time or a near-real-time basis, driving timely decision making and action.87 An event is any activity—such as stock trades, sales orders, social media posts, and website clicks—that leads to the creation and potential use of data. CEP tools monitor, process, and analyze streams of data coming from multiple sources to identify movements in data that help identify abnormal events or patterns so that any required action can be taken as quickly as possible. CEP tools can be proprietary or open-source; Apache Spark, discussed earlier, is an example of a big-data tool that offers CEP functionality.CEP is relevant for the IoT in its ability to recognize patterns in massive data sets at low latency rates. A CEP tool identifies patterns by using a variety of techniques such as filtering, aggregation, and correlation to trigger automated action or flag the need for human intervention.86 CEP tools exhibit low latency rates—sometimes less than a second—by using techniques such as continuous querying, in-memory processing, and parallel processing.87 Continuous querying works on the principle of incremental processing. For example, once the system has calculated the average of a million observations, the moment the next data point comes in, the system simply updates the value and doesn’t scan the entire data set to calculate the average; this saves computational time and resources. In-memory processing—the process of storing data in random access memory (RAM) in lieu of hard disks—enables faster data processing. Lastly, parallel processing, the processing of data across clusters of computers, is achieved by partitioning data either by source or type.In the banking industry, CEP plays a key role in cross-selling services. A CEP tool can continuously monitor and analyze a customer’s transactions with the bank through various channels. The tool can be used to monitor any large withdrawals through the ATM or check payments. Further, the tool could correlate the transactions with any accompanying bank-branch transactions such as an address change—potentially indicating a house purchase—and present a cross-selling opportunity, say home insurance, before a competitor draws the customer away.88 Such cross-selling recommendations can then be automatically pushed onto web-based banking systems and concurrently used by bankers, tellers, and call-center representatives.
Limitations of augmented intelligence result from the quality of data, human inability to develop a foolproof model, and legacy systems’ limited ability to handle unstructured and real-time data. Even if both the data and model are shipshape, there could be challenges in human implementation of the recommended action; in the next section, on augmented behavior, we discuss the challenges related to human behavior.
Inaccurate analysis due to flaws in the data and/or model : A lack of data or presence of outliers may lead to false positives or false negatives, thus exposing various algorithmic limitations. Also, if all the decision rules are not correctly laid out, the algorithm could throw incorrect conclusions. For example, a social networking site recently featured the demise of a subscriber’s daughter on an automatically generated dashboard. The model was not programmed to recognize and exclude negative events, thus the faux pas. 89
: A lack of data or presence of outliers may lead to false positives or false negatives, thus exposing various algorithmic limitations. Also, if all the decision rules are not correctly laid out, the algorithm could throw incorrect conclusions. For example, a social networking site recently featured the demise of a subscriber’s daughter on an automatically generated dashboard. The model was not programmed to recognize and exclude negative events, thus the faux pas. Legacy systems’ ability to analyze unstructured data : Legacy systems are well suited to handle structured data ; unfortunately, most IoT/business interactions generate unstructured data. 90 Unstructured data are growing at twice the rate of structured data and already account for 90 percent of all enterprise data. 91 While traditional relational-database systems will continue to be relevant for structured-data management and analysis, a steady influx of IoT-driven applications will require analytics systems that can handle unstructured data without compromising the scope of data.
: Legacy systems are well suited to handle ; unfortunately, most IoT/business interactions generate unstructured data. Unstructured data are growing at twice the rate of structured data and already account for 90 percent of all enterprise data. While traditional relational-database systems will continue to be relevant for structured-data management and analysis, a steady influx of IoT-driven applications will require analytics systems that can handle unstructured data without compromising the scope of data. Legacy systems’ ability to manage real-time data: Traditional analytics software generally works on batch-oriented processing, wherein all the data are loaded in a batch and then analyzed.92 This approach does not deliver the low latency required for near-real-time analysis applications. Predictive applications could be designed to use a combination of batch processing and real-time processing to draw meaningful conclusions.93 Timeliness is a challenge in real-time analytics—that is, what data can be considered truly real?94 Ideally, data are valid the second they are generated; however, because of practical issues related to latency, the meaning of “real time” varies from application to application.
In its simplest sense, the concept of “augmented behavior” is the “doing” of some action that is the result of all the preceding stages of the value loop—from sensing to analysis of data. Augmented behavior, the last phase in the loop, restarts the loop because action leads to creation of data, when configured to do so.
There is a thin line between augmented intelligence and augmented behavior. For our purpose, augmented intelligence drives informed action, while augmented behavior is an observable action in the real world.
Machine-to-machine (M2M) interfaces : M2M interfaces refer to the set of technologies that enable machines to communicate with each other and drive action. In common vernacular, M2M is often used interchangeably with the IoT. 95 For our purposes, though, the IoT is a broader concept that includes machine-to-machine and machine-to-human (M2H) interfaces, as well as support systems that facilitate the management of information in a way that creates value. 96
: M2M interfaces refer to the set of technologies that enable machines to communicate with each other and drive action. In common vernacular, M2M is often used interchangeably with the IoT. For our purposes, though, the IoT is a broader concept that includes machine-to-machine and interfaces, as well as support systems that facilitate the management of information in a way that creates value. Machine-to-human interfaces: We discuss M2H interfaces in the context of individual users; business users of M2H interfaces are discussed in the next element, organizational entities. Based on the data collected and algorithmic calculations, machines have the potential to convey suggestive actions to individuals who then exercise their discretion to take or not to take the recommended action. With human interaction, the IoT discussion shifts into a slightly different direction, toward behavioral sciences, which is distinct from the data science that encapsulates the preceding four stages focused on creating, communicating, aggregating, and analyzing the data to derive meaningful insights. 97
We discuss M2H interfaces in the context of individual users; business users of M2H interfaces are discussed in the next element, organizational entities. Based on the data collected and algorithmic calculations, machines have the potential to convey suggestive actions to individuals who then exercise their discretion to take or not to take the recommended action. With human interaction, the IoT discussion shifts into a slightly different direction, toward behavioral sciences, which is distinct from the data science that encapsulates the preceding four stages focused on creating, communicating, aggregating, and analyzing the data to derive meaningful insights. Organizational entities: Organizations include individuals and machines and thus involve the benefits as well as the challenges of both M2M and M2H interfaces. Managing augmented behavior in organizational entities requires changes in people’s behaviors and organizational processes. Business managers could focus on process redesign based on how information creates value in different ways.98
The enabling technologies for both M2M and M2H interfaces prompt a consideration of the evolution in the role of machines—from simple automation that involves repetitive tasks requiring strength and speed in structured environments to sophisticated applications that require situational awareness and complex decision making in unstructured environments. The shift toward sophisticated automation requires machines to evolve in two ways: improvements in the machine’s cognitive abilities (for example, decision making and judgment) discussed in the previous section and the machine’s execution or actuation abilities (for example, higher precision along with strength and speed). With respect to robots specifically, we present below an overview of how machines have ascended this evolutionary path:
In the late 1940s, a few non-programmable robots were developed; these robots could not be reprogrammed to adjust to changing situations and, as such, merely served as mechanical arms for heavy, repetitive tasks in manufacturing industries.99 In 1954, George Devol developed one of the first programmable robots,100 and in the early 1960s, an increasing number of companies started using programmable robots for industrial automation applications such as warehouse management and machining.101
This period witnessed key developments related to the evolution of adaptive robots.102 As the name suggests, adaptive robots embedded with sensors and sophisticated actuation systems can adapt to a changing environment and can perform tasks with higher precision and complexity compared to earlier robots.103 During this period, robotic machines that could adapt to varying situations were used to identify objects and autonomously take action in applications such as space vehicles, unmanned aerial vehicles, and submarines.104
The development of an open-source robot operating system (developed by the Open Source Robotics Foundation) in 2006 was an important driver enabling the development and testing of various robotic technologies.105 As robots’ intelligence and precision of execution improved, they increasingly started working with human beings on critical tasks such as medical surgeries. Following the US Defense Advanced Research Project Agency’s competition for developing autonomous military vehicles in 2004, many automakers made a headway into military and civilian autonomous vehicles.106 Even though the underlying technology is available, legal and social challenges related to the use of autonomous vehicles are yet to be resolved.
With the availability of big data, cloud-based memory and computing, new cognitive technologies, and machine learning, robots in general seem to be getting better at decision making and are gradually approaching autonomy in many actions. We are witnessing the development of machines that have anthropomorphic features and possess human-like skills such as visual perception and speech recognition.107 Machines are automating intelligence work such as writing news articles and doing legal research—tasks that could be done only by humans earlier.108
Improved functionality at lower prices is driving higher penetration of industrial robots and increasing the adoption of surgical robots, personal-service robots, and so on. For situations where a user needs to take the action, machines are increasingly being developed with basic behavioral-science principles in mind. This allows machines to influence human behaviors in effective ways.
Lower machine prices : The decreasing prices of underlying technologies—such as sensors, network connections, data processing and computing tools, and cloud-based storage—are leading to lower prices of robots. Figures 17 and 18 show a decline in the average selling price of industrial robots alongside increasing unit sales.
: The decreasing prices of underlying technologies—such as sensors, network connections, data processing and computing tools, and cloud-based storage—are leading to lower prices of robots. Figures 17 and 18 show a decline in the average selling price of industrial robots alongside increasing unit sales. Improved machine functionality: As discussed earlier, there is a thin line between augmented intelligence and augmented behavior. An underlying driver for the shift in the use of robots from mundane to sophisticated tasks is the development of elaborate algorithms that focus on the quality of fine decision making in live environments, and not simply a binary “yes/no” decision.Typically, robots made force-fitted decisions based on programmed algorithms, irrespective of the situation and information availability. 109 However, recent advances in robotic control architecture prompt the machine to ask for more information if there is an information insufficiency before taking a decision. 110 For example, a robot offers a pill to the patient and the patient refuses; instead of repeating the same instruction, the robot could analyze the patient’s behavior patterns based on his personal data stored on the cloud and try to deduce the reason for refusal. The robot may also deduce from the environment that the patient has a fever and inform the doctor. One of the many techniques under development enables users to train robots by “rewarding” them in cases where they have made the right decision by telling them so and asking them to continue to do the same—a kind of positive reinforcement. 111
As discussed earlier, there is a thin line between augmented intelligence and augmented behavior. An underlying driver for the shift in the use of robots from mundane to sophisticated tasks is the development of elaborate algorithms that focus on the quality of fine decision making in live environments, and not simply a binary “yes/no” decision.Typically, robots made force-fitted decisions based on programmed algorithms, irrespective of the situation and information availability. However, recent advances in robotic control architecture prompt the machine to ask for more information if there is an information insufficiency before taking a decision. For example, a robot offers a pill to the patient and the patient refuses; instead of repeating the same instruction, the robot could analyze the patient’s behavior patterns based on his personal data stored on the cloud and try to deduce the reason for refusal. The robot may also deduce from the environment that the patient has a fever and inform the doctor. One of the many techniques under development enables users to train robots by “rewarding” them in cases where they have made the right decision by telling them so and asking them to continue to do the same—a kind of positive reinforcement. Machines “influencing” human actions through behavioral-science rationale: Literature suggests that creating a new human behavior is challenging. Creating a new human behavior that endures is even more challenging. Nudge techniques—attempts to influence people’s behaviors—involve the design of choices that prompt them to move from “intention” to “action.”112 For example, placing a fruit at eye level is a nudge technique, while banning junk food is not, according to Richard Thaler and Cass Sunstein.113 Choice designs could be built by consciously choosing the options that should be presented to an individual and the manner in which the options are presented. For example, menus sometimes start with expensive items followed by relatively less expensive ones. This makes the customer feel that she is making a judicious choice by ordering any of the latter items, since her reference price is much higher. Furthermore, a health-conscious restaurateur could place the relatively healthful food items at relatively lower prices and, in so doing, “nudge” the customer to order them.In an analogous fashion, IoT devices can “nudge” human behaviors by establishing a feedback loop. A school in California was trying to find a solution to speeding drivers who were undeterred even by police ticketing. The school authorities experimented with a creative signboard that compared two data points: “your speed” (speed of a passing car measured by a radar sensor) against the “speed limit” of 25 miles/hour. Even though the radar signboard offered drivers no new information—as the dashboard display readily provides driver speed—the signboards “nudged” them into reducing their speed by an average of 10 percent, bringing their speed within the permissible limit or sometimes even lower.115 In a similar way, David Rose helped develop an IoT-connected pill bottle equipped with “GlowCaps” that “nudge” the patient with a flash of light at the predetermined time to take a pill.116In addition to influencing the choices of individuals on a stand-alone basis, IoT devices can also drive adoption by “using” social or peer pressure to achieve a desired result. For example, when a fitness device suggests to an individual that it’s time for a workout, the recommendation may go unheard. However, if the device shows how the user is doing vis-à-vis his peers (lagging or outperforming), the user is potentially more likely to act.117 The manufacturer of an electronic soap dispenser fitted its product with a computer chip that records the frequency with which health care professionals in different hospital wards wash their hands; it then compares these results with World Health Organization standards and conveys the comparisons back to the wards at a group level. Such a process of aggregation and comparison effectively makes personal hygiene a team sport: Each worker, in turn, is effectively “nudged” into a greater awareness of his hygienic habits, as he knows that he is a part of a team effort.118
Other examples abound showing how the IoT can influence human behavior to achieve normative outcomes. The larger point, though, is that the IoT may augment human behavior as much as it augments mechanical behavior. And the interplay between the IoT and human choice will likely only evolve and become more prominent in the years ahead.
There are challenges related to machines’ judgment in unstructured situations and the security of the information informing such judgments. Interoperability is an additional issue when heterogeneous machines must work in tandem in an M2M setup. Beyond the issues related to machine behavior, managing human behaviors in the cases of M2H interfaces and organizational entities present their own challenges.
Machines’ actions in unpredictable situations : Machines are typically considered to be more reliable than human beings in structured environments that can be simulated in programming models; however, in the real world, most situations we encounter are unstructured. 119 In such cases, machines cannot possibly be relied upon completely; as such, the control should fall back to human beings.
: Machines are typically considered to be more reliable than human beings in structured environments that can be simulated in programming models; however, in the real world, most situations we encounter are unstructured. In such cases, machines cannot possibly be relied upon completely; as such, the control should fall back to human beings. Information security and privacy : There is a looming risk of compromise to the machine’s security. An example of a privacy concern relates to an appliance manufacturer that offers televisions with voice-recognition systems. The voice-recognition feature collects information related to not only voice commands but also any other audio information it can sense. 120 This raises concerns about the manner in which the audio information collected by the software will be used—both in benign and personally invasive ways. A benign use could include, for example, the personalization of television advertising. A personally invasive use might be the unauthorized sale of such information.
: There is a looming risk of compromise to the machine’s security. An example of a privacy concern relates to an appliance manufacturer that offers televisions with voice-recognition systems. The voice-recognition feature collects information related to not only voice commands but also any other audio information it can sense. This raises concerns about the manner in which the audio information collected by the software will be used—both in benign and personally invasive ways. A benign use could include, for example, the personalization of television advertising. A personally invasive use might be the unauthorized sale of such information. Machine interoperability : Performance of M2M interfaces is impacted by interoperability challenges resulting from heterogeneous brands, hardware, software, and network connections. There is a need for a convergence of standards, as discussed earlier.That machines perform as desired in a particular context is a matter of getting the technology right, which is currently in an evolving stage. Perfecting human behavior is another matter entirely.
: Performance of M2M interfaces is impacted by interoperability challenges resulting from heterogeneous brands, hardware, software, and network connections. There is a need for a convergence of standards, as discussed earlier.That machines perform as desired in a particular context is a matter of getting the technology right, which is currently in an evolving stage. Perfecting human behavior is another matter entirely. Mean-reverting human behaviors : One of the main challenges in M2H interfaces is that, although users have the smart devices, they minimally “follow” the suggested course of action and, eventually, the devices end up serving as “shelfware.” 122 David Rose states that machines cater to human drives; he cites six such drives: omniscience (the need to know all), telepathy (human-to-human connections), safekeeping (protection from harm), immortality (longer life), teleportation (hassle-free travel), and expression (the desire to create and express). Machines serve human drives through one or more of their features (see figure 19). These features also determine the machine’s position in the enchantment hierarchy (see figure 20). The enduring association between the machine and its user is a function of the machine’s position in the enchantment hierarchy, starting from the most basic level of “connection” and going all the way up to “storyification.” 123
: One of the main challenges in M2H interfaces is that, although users have the smart devices, they minimally “follow” the suggested course of action and, eventually, the devices end up serving as “shelfware.” David Rose states that machines cater to human drives; he cites six such drives: omniscience (the need to know all), telepathy (human-to-human connections), safekeeping (protection from harm), immortality (longer life), teleportation (hassle-free travel), and expression (the desire to create and express). Machines serve human drives through one or more of their features (see figure 19). These features also determine the machine’s position in the enchantment hierarchy (see figure 20). The enduring association between the machine and its user is a function of the machine’s position in the enchantment hierarchy, starting from the most basic level of “connection” and going all the way up to “storyification.” Inertia to technology-driven decision making in organizational entities: Decision makers have decades of experience running successful businesses wherein they have primarily relied on professional judgment. They typically encounter resistance to newer developments such as predictive and prescriptive analytics.124 Executives are skeptical of the accuracy and efficacy of conclusions drawn out of statistical analyses, since they view augmented intelligence tools as “black boxes” in which they do not understand how the outcome has been churned.125
To manage these augmented behavior changes in organizations, decision makers could give the new technologies a fair chance to contribute in their decision-making process by setting aside their biases. At the same time, data scientists and developers could focus on two objectives: continuously improving the statistical tools and the algorithms to bring the machine’s decision-making ability closer to reality, and making it easier for business users to comprehend the results through means such as easy-to-use visualization tools. In the current state of affairs, augmented behavior has the potential to grow, with an increasing number of successful use cases over time.
The Information Value Loop can serve as the cornerstone of an organization’s approach to IoT solution development for potential use cases. To transform ideas and concepts discussed earlier in the report into the concrete building blocks of a solution, we posit an end-to-end IoT technology architecture to guide IoT solution development. This architecture links strategy decisions to implementation activities. It can serve as a playbook for establishing the vision for an IoT solution and for converting that vision into tangible reality. The Information Value Loop informs and is present in each phase of this development, whereby ideas are made progressively more specific, and tactical decisions remain consistent with the overall strategic goals. The process of turning ideas into IoT solutions is shown in figure 22.
Our architecture for guiding the development and deployment of IoT systems consists of the following views:
Business. This view defines the vision for an IoT system and covers aspects such as return on investment, value proposition, customer satisfaction, and maintenance costs. Functional. The linchpin of the reference architecture, this view spans modules that cater to high-level information flow through the system. It contains the functional layers for data creation, processing, and presentation. Usage. This view shows how the reference model realizes key capabilities desired in a usage scenario. It may include the detailed use case description, user journey, and requirements. Implementation. A technical representation of usage scenario deployment, this view incorporates the technologies and system components required to implement the functions prescribed by the usage and functional viewpoints. Specifications. Finally, this view captures the complete IoT stack to be deployed. It includes detailed technical specifications for the build-out of the solution, and translates these blueprints into the individual components needed to design, build, and implement the components and interconnections shown in the functional and implementation views.
In the business view, the Information Value Loop stages are utilized to examine the flow of information which guides strategic decisions for the use case at hand. These decisions further help define the overall IoT strategy. An example of how value can be realized using IoT in health monitoring is shown in figure 23.
Prior to the IoT, the patient could wear a heart monitor, but the monitor’s data would usually be communicated to the external world using written records that had to be carried each time. This represented a blockage at the "communicate" step (see arrow "A").
With the introduction of the IoT, data can now be communicated between a patient and the physician using network connections. However, there is still a bottleneck associated with the ability of the smart systems to interface with existing electronic health record (EHR) systems in order to aggregate data. Alleviating this bottleneck is key to IoT applications in the health care industry.
In the “Meet Isabel’ scenario of figure 23, the bottleneck associated with data aggregation and use can be addressed by the “integration” layer wherein standards for sensor management, data transfer, storage, and aggregation come together in an integral fashion. In the earlier part of this report, we discuss “standards” as they relate to specific technologies that fall under the integration layer described further in the functional view.
The functional view categorizes the components of an IoT system across the five value loop stages and five functional layers—sensors, network, integration, augmented intelligence, and augmented behavior. It serves as a guide to the functional considerations and technology choices of an IoT solution (see figure 24).
As discussed earlier in the report, sensors create the data that are sent downstream to subsequent layers of the architecture. Network is the connectivity layer that communicates data from the sensors and connects them to the Internet. The integration layer manages the sensor and network elements, and aggregates data from various sources for analysis. The augmented intelligence layer processes data into actionable insights. Finally, augmented behavior encapsulates the actions or changes in human or machine behavior resulting from these insights. The augmented behavior layer includes an edge computing sub-layer defined by local analysis (near the source of data) and action without the need for human intervention. Aligned with these layers and the value loop stages are standards for sensor management and data management and use, as well as security considerations including end-point protection, network security, intrusion prevention, and privacy and data protection.
The usage view sets up the technical solution by describing the user’s journey through all the steps of the use case being implemented. This view would include the key actors, that may be users and/or machines, and the activities involved. The usage view also describes the use case from the point of view of user needs and system capabilities. Figure 25 illustrates a typical IoT use in a brick-and-mortar store.
The implementation view delves deeper into specific technology choices and the vendor solutions that are used to deploy those choices. It leverages the high-level component view from the functional architecture to frame the specific system implementation.
Our IoT reference architecture describes parameters and benchmark criteria that can be used to identify the best mix of product solutions for an IoT implementation across different layers. Figure 26 shows a representative implementation view for the retail use case example described earlier.
The specifications view captures the final translation of the various viewpoints described above as part of the IoT Reference Architecture into ground-level deployment. It crystalizes the functional requirements and specific technology choices identified earlier into detailed specification definitions that describe how all the selected components must be linked to work together. A sample specifications view is shown in figure 27.
Together, all the myriad viewpoints that comprise the Deloitte IoT Reference Architecture form an end-to-end blueprint for realizing an IoT system from strategy through implementation.
The Internet of Things is an ecosystem of ever-increasing complexity, and the vocabulary of its language is dynamic. As we stated at the outset, our intent in presenting this primer is not to answer every question that a reader may have about the IoT. No single resource could ever hope to achieve that end about anything as elaborate as the IoT. Rather, in developing this report, our objective was to provide a useful top-down reference to assist readers as they explore IoT-driven solutions. In using this primer, the reader should come away with a better understanding of what the IoT is as well as the elements that comprise its constituent parts within a strategic framework.
At this relatively nascent stage, the IoT ecosystem is fragmented and disorganized. Over time, the IoT ecosystem should undergo a streamlining and organizing process and a “knitting together” of its individual pieces. Because the IoT will play an increasingly important role in how we live and run our businesses, Deloitte is undertaking an IoT-focused eminence campaign. This primer will serve as a foundational resource for the campaign that will include thoughtware examining the IoT both from industry- and issue-specific perspectives.
Deloitte’s Internet of Things practice enables organizations to identify where the IoT can potentially create value in their industry and develop strategies to capture that value, utilizing IoT for operational benefit.​
To learn more about Deloitte’s IoT practice, visit http://www2.deloitte.com/us/en/pages/technology-media-and-telecommunications/topics/the-internet-of-things.html.
Read more of our research and thought leadership on the IoT at http://dupress.com/collection/internet-of-things/.
Actuator: a device that complements a sensor in a sensing system. An actuator converts an electrical signal into action, often by converting the signal to non-electrical energy, such as motion. A simple example of an actuator is an electric motor that converts electric energy into mechanical energy.
Analytics: the systematic analysis of often-confusing and conflicting data in search of insight that may inform better decisions.
Application program interfaces (API): a set of software commands, functions, and protocols that programmers can use to develop software that can run on a certain operating system or website. On the one hand, APIs make it easier for programmers to develop software; on the other, they ensure that users experience the same user interface when using software built on the same API.
Artificial intelligence: the theory and development of computer systems able to perform tasks that normally require human intelligence. The field of artificial intelligence has produced a number of cognitive technologies such as computer vision, natural-language processing, speech recognition, etc.
Batch processing: the execution of a series of computer programs without the need for human intervention. Traditional analytics software generally works on batch-oriented processing wherein data are aggregated in batches and then processed. This approach, however, does not deliver the low latency required for near-real-time analysis applications.
Big data: a term popularly used to describe large data sets that cannot be handled efficiently by traditional data management systems. In addition to the large volume, the concept of big data also refers to the variety of data sets—i.e., structured and unstructured as well as the velocity or the rate at which the data are incoming.
Cloud computing: an infrastructure of shared resources (such as servers, networks, and software applications and services) that allow users to scale up their data management and processing abilities while keeping the costs low. A cloud vendor invests in and maintains the cloud infrastructure; a user pays for only the resources and applications he wishes to use.
Cognitive technologies: a set of technologies able to perform tasks that only humans used to be able to do. Examples of cognitive technologies include computer vision, natural-language processing, and speech recognition.
Communication protocol: a set of rules that provide a common language for devices to communicate. Different communication protocols are used for device-to-device communication; broadly, they vary in the format in which data packets are transferred. One example is the familiar Hypertext Transfer Protocol (HTTP).
Complex event processing (CEP): an analytics tool that enables processing and analysis of data on a real-time or a near-real-time basis, driving timely decision making and action.
CEP is relevant for the IoT in its ability to recognize patterns in massive data sets at low latency rates. A CEP tool identifies patterns by using a variety of techniques such as filtering, aggregation, and correlation to trigger automated action or flag the need for human intervention.
Computer vision: a type of cognitive technology that refers to the ability of computers to identify objects, scenes, and activities in images. Computer-vision technology uses sequences of imaging-processing operations and other techniques to decompose the task of analyzing images into manageable pieces. Certain techniques, for example, allow for detecting the edges and textures of objects in an image. Classification models may be used to determine if the features identified in an image are likely to represent a kind of object already known to the system.
Data rates: the speed at which data are transferred by a network. Sometimes termed “bandwidth,” data rates are typically measured in bits transferred per second. Network technologies that are currently available can deliver data rates of up to 1 gigabit per second.
Descriptive analytics: a type of analytics that provides insights into past business events and performance. In a fundamental sense, descriptive analytics helps answer the question “What has happened?” Descriptive analytics tools augment human intelligence by allowing us to work effectively with much larger or more complex data sets than we would ordinarily be able to without such tools.
Extraction, Transformation, Loading (ETL) tools: a set of data aggregation tools that aggregate, process, and store data in a format that can be used for analytics applications. Extraction refers to acquiring data from multiple sources and formats and then validating to ensure that only data that meet a specific criterion are included. Transformation includes activities such as splitting, merging, sorting, and transforming the data into a desired format; for example, names can be split into first and last names, addresses can be merged into city and state format, etc. Loading refers to the process of loading the data into a database that can be used for analytics applications.
Hadoop: an open-source tool that is useful for processing large data sets. Hadoop is a part of the Apache Software Foundation and is based on the Java programming language. Hadoop enables parallel processing of large data across clusters of computers in which each computer offers local aggregation and storage.
In-memory processing: the process of storing data in random access memory instead of hard disks; this enables quicker data querying, retrieval, and visualizations.
Internet Protocol (IP): an open network protocol that provides unique addresses to various devices connected to the Internet. There are two versions of IP: IP version 4 (IPv4) and IPv6.
Internet transit prices: the price charged by an Internet service provider (ISP) to transfer data on a network. Since no single ISP can cover the worldwide network, the ISPs rely on each other to transfer data using network interconnections through gateways.
IP version 4 (IPv4): an older version of the Internet Protocol (IP); IPv6 is a most recent version. IPv4 offers an addressing space of about 6 billion addresses, out of which 4 billion addresses have been used already. IPv4 allows a group of co-located sensors to be identified geographically but not individually, thus restricting the value that can be generated through the scope of data collected from individual devices that are co-located.
IP version 6 (IPv6): a recent version of the Internet Protocol (IP) that succeeds IPv4. IPv6 has superior scalability and identifiability features compared to IPv4: the IPv6 address space supports approximately 3.4x1038 unique addresses compared to 6 billion addresses under IPv4.
Latency: the time delay in transfer of data from one point in a network to another. Low-latency networks allow for near-real-time data communications.
Local area network (LAN): a network that extends to a geographic range of at least 100 meters, such as within a house, office, etc. Devices could connect to wired or wireless LAN technologies. Examples of wired LAN technologies include Ethernet, and fiber optics. Wi-Fi is an example of a wireless LAN technology.
Machine learning: the ability of computer systems to improve their performance by exposure to data, without the need to follow explicitly programmed instructions. At its core, machine learning is the process of automatically discovering patterns in data. Once discovered, the pattern can be used to make predictions. For instance, presented with a database of information about credit-card transactions—such as date, time, merchant, merchant location, price, and whether the transaction was legitimate or fraudulent—a machine-learning system recognizes patterns that are predictive of fraud. The more transaction data it processes, the better its predictions are expected to become.
Machine-to-human (M2H) interfaces: a set of technologies that enable machines to interact with human beings. Some common examples of M2H interfaces include wearables, home automation devices, and autonomous vehicles. Based on the data collected and algorithmic calculations, mJust a few years ago, many people expected the internet of things (IoT) network of interconnected machines, sensors, and other devices to send all its data to the cloud for storage and processing. Today, however, edge computing architecture can place processing and storage closer to the physical sources of data generation. A growing number of IoT solutions now benefit from a combination of edge and cloud computing, which can help to alleviate latency, increase scalability, and enhance access to information to enable better, faster decision-making, among other advantages.
As the amount of data generated by sensors grows tremendously, enterprises are increasingly focused on the amount of time it takes data to move from a connected device to the cloud and then back to the device. In a cloud-only IoT architecture, information typically travels hundreds or even thousands of miles, so if quick, data-based decision-making is vital to an IoT solution’s efficacy, that information can lose value in milliseconds. In such cases, edge computing can dramatically decrease latency and improve response time. According to one estimate, as much as 55 percent of IoT data could soon be processed at or near the source.
Reducing latency is just one considerable benefit of adding edge capabilities to IoT architecture. Others can include more effective bandwidth use resulting from localized data processing; improved network connectivity and security; increased autonomous data processing and storage on everything from vehicles to medical devices; and enhanced data privacy, normalization, and filtering capabilities.
This balance between cloud and edge architecture can dramatically improve the aggregation and transmission of data across a wide range of operations relying on IoT solutions.
Smart factories. Many manufacturers have multiple plants in different locations, each typically with unique characteristics and functional requirements. The more spread out an operation, the more difficult it may be to maintain centralized data analysis capabilities in the cloud or at a corporate data center. While the cloud will continue to play an important role in smart manufacturing—monitoring systems and processes across large or even global portfolios, for example—an integrated edge-cloud architecture can provide the kind of speedy and nearly unimpeded connectivity necessary to support smarter operations on the factory floor.
Smart buildings. IoT-connected devices are transforming some offices, retail stores, hospitals, and other buildings into cost-efficient, responsive environments that can deliver better experiences to their occupants, support digital collaboration, and enable owners to conserve space, energy, water, and other resources. For example, edge computing can transmit occupancy data from strategically placed sensors to a cloud-hosted service that performs specialized analytics. The results can be sent back via the gateway or edge server to alter the schedules of a building’s lighting, ventilation systems, and other connected equipment to improve energy efficiency and lower costs.
Despite the many benefits, adding edge computing in a cloud-based IoT environment can also pose operational and systems design complexities. Some widely distributed sensors or gateways may be scattered and difficult to physically reach or both when placed in offices, plants, and campuses; on pipelines; and in remote field sites, among other locales. An organization may have thousands of devices and hundreds of associated gateways and edge nodes with firmware and operating systems requiring backups, software patches, and other updates. Monitoring these disparate devices and addressing potential problems can require an enormous amount of automation and field service.
In addition, while the cloud offers on-demand scalability and can be readily configurable, automated, and resilient, providing these capabilities at the edge may be costly, requiring significant investment in additional hardware and software and much complex work to enable an increased number of devices and edge nodes.
Extending the cloud and the data center to the edge with multiple endpoints can also increase the surface area for cyberattacks. Insecure nodes and devices can be weak links that leave the entire network vulnerable, so maintaining the physical and cybersecurity position of all edge computing assets is critical.
IoT devices and the data they can provide are changing how enterprises interact with the world as well as how they gather and process massive quantities of business-critical information. While no single solution will suit every organization, a balanced approach to cloud and edge computing will likely play an increasingly prominent role in IoT architecture in the years ahead.Many manufacturers face a range of material, resource and quality constraints that impact productivity and revenues on a daily basis. Since many large production floors can span literal miles, one without IoT enabled technology tends to lack complete visibility into each element of the production cycle, making the factory floor ecosystem rife with inefficiencies. Managers often find it difficult to locate parts in real time as they’re distributed throughout the factory floor, employees wait idly while maintenance is performed on a malfunctioning machine, and overall quality potentially suffers as a result.
This was the norm until the manufacturing industry discovered the power of IoT and began its transition to the smart factory. Leveraging smart technology with IoT capabilities, smart factories enable increased visibility, optimized production and improved quality while minimizing unplanned downtime. In fact, a recent study by Deloitte and Manufacturers Alliance for Productivity and Innovation (MAPI), which evaluated the impact of smart factories on key business metrics such as manufacturing productivity, found that smart factory initiatives could be the key to manufacturing competitiveness in the future.
Until recently, IoT collected data wasn’t actionable for many businesses. The volume of data produced by the manufacturing segment is so large that it’s been difficult for any company to keep the number of physical servers necessary to collect and store this data. Additionally, combing through data for actionable business insights is time consuming. If the investment is made to analyze IoT data, by the time a company receives data-driven insights, they’re typically outdated. Cloud has drastically increased the value of IoT, allowing organizations to process more information than before, at a much lower cost. While IoT sensors have collected data for years, businesses can now see the value of what they're collecting.
Recently, we worked with a large aerospace manufacturer with a widespread and complicated operation, making it a challenge to locate various parts on the shop floor in real-time. Previously, the manufacturer used a schedule that was only updated once or twice per day, which would create delays when there were production changes. IoT technology, on the other hand, enables the data analysis for every part and every piece of data at every moment throughout the cycle, allowing for the utmost flexibility and agility in resource management.
Through IoT enabled technologies, we placed antennas strategically within the factory as well as on machines that could read each part. Then we designed a cloud-based dynamic scheduling system that provided much more visibility into where specific parts were located during its journey.
Now, if parts are delayed, the team is notified in real time in order to create a new expedited order or move forward with another project first. IoT also provides predictive maintenance on the factory floor – monitoring the health of machines and proactively scheduling maintenance ahead of any issues, based on historic data.
Combining IoT technology and real-time data with data in the cloud, Deloitte, in working with AWS, enabled dynamic scheduling of the production facility to automate materials movement. The result for the client has been a significant improvement in overall factory performance.
If your organization is looking to implement a smart factory and apply IoT with cloud for greater visibility into operations, dynamic scheduling and predictive analytics, I suggest a three-step approach to adoption:
Think big: When it comes to making IT decisions, lean into technology purchasing choices that can evolve as your business grows. Don’t let the technology capabilities you have today constrain your plans for growth because technology and business models are constantly evolving, and you have more options than ever before. Start small: You don’t have to apply all technology changes to your business operations overnight. Test innovations on small areas of the business first (for instance, extracting data insights via cloud from the existing IoT sensors on your equipment instead of installing new ones) for a proof of value. Scale fast: Once you’ve proven that the technology you’ve tested is improving operations, scale it quickly. If you’re attending AWS re:Invent 2019, you can learn more about our approach and how we’ve helped companies with manufacturing operations find real business efficiencies with IoT and cloud by visiting our session on Monday, December 2nd at 11:30 a.m. PT.Over the last 25 years, four fundamental forces representing computing concepts and movements have gained momentum. Together, they helped integrate hardware, software, and the physical environment in a way that is intuitive and accessible to a do-it-yourself audience. These forces are:
Objective: To design a system that will monitor the temperature of my home environment and trigger a text message to my phone when the temperature crosses a certain threshold.
Raspberry Pi 3: A credit-card sized computer that has an HDMI port to connect to monitor and a USB port to connect to keyboard/mouse
Node-RED: A visual programming tool for wiring hardware devices, APIs, and online services to facilitate the Internet of Things
Sensors attached to a Raspberry PI 3 continuously monitor the temperature in the surrounding environment; when a predetermined threshold is met, an alert is sent through the IoT platform to the user’s smartphone.
The sensor continuously monitors the environment: Install the operating system on the Pi and connect the sensors IoT platform connects devices and your application: Use the IoT Platform to a) register the Pi b) connect to the Node-RED server-side application
Raspberry Pi with sensor attached The sensor sends data to IoT platform: Write the client-side program (using JavaScript in Node-RED) to process the temperature signals and send it to the IoT platform
Sensor in steady state The application connects to other cloud services as needed: Register the smartphone with the cloud-based communication platform and use those credentials in server-side application to enable sending a text The application sends signals to the user: Start receiving temperature signals from the Pi; this triggers the application to send a text message when the threshold is crossed
Open-source software movement: Remember the battle in the late '90s against the open-source software movement when Linux was called the “malignant cancer?” We’ve come a long way since then. In this project, the same Linux is the operating system on the minicomputer. Linux Foundation 1 estimates the total development cost of its collaborative projects alone is $5 billion. There are many such foundations. Node-RED is part of the JS Foundation, which supports open source projects in the JavaScript ecosystem. And JavaScript itself is developed on an open standard.
Remember the battle in the late '90s against the open-source software movement when Linux was called the “malignant cancer?” We’ve come a long way since then. In this project, the same Linux is the operating system on the minicomputer. Linux Foundation estimates the total development cost of its collaborative projects alone is $5 billion. There are many such foundations. Node-RED is part of the JS Foundation, which supports open source projects in the JavaScript ecosystem. And JavaScript itself is developed on an open standard. Cloud computing: In the early 2000s, Salesforce 2 pioneered the concept of enterprise app delivery via the Internet. Remember the “no software” days? Since then, almost anything tech is delivered “as a service.” Thanks to the cloud delivery model, a cloud-based communication platform, and the entire IoT platform are represented in this project. Worldwide public IT cloud service revenue 3 in 2018 is predicted to be $127 billion.
In the early 2000s, Salesforce pioneered the concept of enterprise app delivery via the Internet. Remember the “no software” days? Since then, almost anything tech is delivered “as a service.” Thanks to the cloud delivery model, a cloud-based communication platform, and the entire IoT platform are represented in this project. Worldwide public IT cloud service revenue in 2018 is predicted to be $127 billion. Maker Movement: In 2005, 4 with the launch of MAKE Magazine, the tech-influenced DIY community has come to be identified as the Maker Movement 5 . Recently I attended a Maker Faire, called the “greatest show and tell on earth," 6 and sat on a 3D printed chair! Affordable, intuitive tools and hardware have fueled the rise of the Maker Movement and enabled DIYers like me to tackle our own technology projects. Pi 7 and Arduino 8 are available for under $50 and frequently used in DIY projects. Industry stats on the movement estimate 9 that makers fuel about $29 billion into the economy each year.
In 2005, with the launch of Magazine, the tech-influenced DIY community has come to be identified as the Maker Movement . Recently I attended a Maker Faire, called the “greatest show and tell on earth," and sat on a 3D printed chair! Affordable, intuitive tools and hardware have fueled the rise of the Maker Movement and enabled DIYers like me to tackle our own technology projects. Pi and Arduino are available for under $50 and frequently used in DIY projects. Industry stats on the movement estimate that makers fuel about $29 billion into the economy each year. Low-code development platforms: A name coined in 2014, these platforms10 represent rapid application delivery with minimal coding, setup, and deployment. To create my project app, the amount of code I had to write in JavaScript was minimal, thanks to Node-RED, a primary example of this trend. Forrester11 estimates that the total market for low-code development platforms will grow to $15.5 billion by 2020.
According to Deloitte, the Internet of Things is taking off in both consumer-focused and B2B industries, and our Tech Trends research has identified the move from sensing to doing. There are multiple platforms of choice and robust offerings from several technology leaders and specialized providers. GE predicts12 investment in the Industrial Internet of Things is expected to top $60 trillion during the next 15 years. The possibilities in the universe of connected things are only beginning to be realized; the real potential lies in making data actionable and uncovering valuable insights.
An iota of that investment is more than enough to start your own prototypes. As you start your next IOT project, may the force(s) be with you!Insert Custom CSS fragment. Do not delete! This box/component contains code needed on this page. This message will not be visible when page is activated.The Internet of Things (IoT) has the potential to offer business value that goes beyond operational cost savings. Providers in the IoT ecosystem have a largely unexplored opportunity to develop compelling IoT solutions that explore how the ability to collect and analyze disparate data, in real-time and across time, might transform the business. These developments will play out within and across enterprises, offering opportunities for sustained value creation and even disruption for those who can imagine possibilities beyond the incremental.
Throughout this paper, we offer strategies—to both enterprise adopters and IoT providers—to unlock the business value of connected devices. For providers, we offer six actionable strategies to create solutions that improve enterprise adopters' business performance, not just in the short term but sustained over time. For enterprise executives, we offer a framework to think about where business value resides and where opportunities might exist for IoT solutions. Learn how IoT solutions can improve enterprise adopters' fundamental business values, not just savings and risk management, but revenue growth and innovation.Since then we realized that some CRE companies may not possess the requisite talent required to process this data. Professionals with the skills required to aggregate, analyze, and manage the data are scarce and the data sets are enormous. How then can these companies crunch the data and generate adequate returns on their investment in IoT technology?
AI could be a potential solution. CRE companies can harness the predictive capability of AI technologies such as machine learning to generate insights and power decision-making. Machine-learning technology “can automatically identify patterns and detect anomalies in the data that smart sensors and devices generate—information such as temperature, pressure, humidity, air quality, vibration, and sound.”2 CRE companies can use AI in this way to drive operational efficiency and tenant satisfaction. For instance, Google’s AI-based predictive tool uses sensor information to forecast pressure and temperature at its data centers. The company has been able to optimize power consumption and reduce cooling costs by 40 percent.
A combination of sensor data and machine-learning solutions may also help improve real-time threat detection and response. As an example, the city of Las Vegas is using AI technology to detect and automate responses to cyber threats.3 Other AI technologies such as speech recognition and computer vision can extract insights from sensor data, which typically require human intervention.
Given the benefits of AI-powered IoT systems, many vendors are now evolving building management systems (BMS) to incorporate AI.5 According to the International Data Corp., AI will support “all effective” IoT efforts by 2019.6 It is also believed that IoT data will have “limited value” without the use of AI technology.7
In summary, CRE executives that are implementing IoT technology should consider AI-powered IoT systems. Owners of existing smart buildings should supplement their buildings with AI technology to mine the data.Although many organizations are investing in technology, they need to adapt their way of thinking quickly in order to avoid key challenges and the risk of getting left behind. Older stadiums are starting to show their age and fall behind in terms of infrastructure and technology. As the price of tickets rise and the at-home experience improves, many teams are seeing their game attendance steadily decline. Teams are gathering data on their players and fans from multiple sources, but these data sources are often not being integrated.
Currently, many teams are implementing IoT capabilities into their stadiums and organizations, but the solutions are often independent and don’t work together, preventing organizations from realizing the full potential of IoT. Unused current assets, limited wearable application, siloed fan experiences, and self-contained operational technology (OT) and IT systems contribute to organizations not being able to fully leverage IoT. Teams and organizations need to recognize the prevalence and real power that IoT can have when it’s integrated and considered on a comprehensive, holistic level.Whilst the Internet of Things has helped to revolutionize the way that people interact with technology, and has become an integrated part of our lives, there still exist serious threats that emerge from these technologies. As the IoT revolution is still in full swing, this article looks at the background of these developments and ensures that security by design/default principles is at the forefront of our minds.
Technological change is the only constant within today’s business world. In both the public and private sector, there is huge potential for integrated data collection, analysis and communication software. The Internet of Things (IoT) provides the means to create value through a new information value cycle – enabling business activities through sensor data collection and analysis, deriving insights and thereafter making decisions and taking action – a circular, additive process. However, there are inherent risks associated with the development of pervasive, smart technologies. This article examines what exactly IoT and cybersecurity threats are, and presents several examples of cybersecurity threats, highlighting the vulnerability of today’s IoT ecosystem. IoT extends beyond mere physical hardware; in effect, it is an integrated approach to, and process by which, data is ‘used’. The increased vulnerability to cybersecurity threats may be linked to three IoT features – ‘smart’ devices, increased connectivity, and a lack of security by design/default. As we move into the future and embrace new and innovative IoT capabilities, attention must be paid to the inherent risks of such an action.
IoT, a term first coined by Kevin Ashton in 1999, is not something that can be easily defined. Any definition will be inherently vague, in order to provide inclusiveness, and not limit the scope of IoT. Deloitte provides a definition of IoT in referring to it as “as suite of technologies and applications that equip devices and locations generate all kinds of information – and to connect those devices and locations for instant data analysis and, ideally, “smart” action.” This description suffices for a number of reasons. Firstly, it refers to the coupling of technology and physical devices. This coupling is important as it means that consideration should not just be given to modern IoT devices such as smart phones, but also to devices that have been IoT-enabled. Secondly, it refers to the “smart” characteristic of IoT devices, and their ability to analyze data. Within a single device, there is the potential to both connect with other devices, thus gathering, and to use the hardware and software capabilities of the device to process. It must be noted that processing in this sense does not only constitute the analysis of the collected data, but also the storage, transfer and modification.
The scale of IoT device prevalence must also be considered when evaluating cybersecurity threats. According to industry reports, the number of IoT-connected devices in 2016 was 8 billion. That figure is expected to rise to 31 billion by 2020. A rising number of IoT enabled devices implies that significantly more, valuable data will be collected and generated, and also that the potential cyber-attack surface will be greatly expanded. The very nature of smart and connected IoT devices seems to be inherently opposed to the primary principles of cybersecurity, such as security by design/default, lifecycle support, testing for scale, 1:1 user access and authentication, or systems isolation.
In order to explain how the Internet of Things (IoT) has developed in such a way that we are now vulnerable to cyber threats, one must first understand what a cybersecurity threat is. Tim Stevens defines cybersecurity in terms of both an offensive and defensive purpose. Cybersecurity protects the members and critical infrastructure of a society, and is the means by which a nation can pursue policies to bring to account malicious actors who exist on the global stage. Kevin Quigley et al. refer to cybersecurity threats as “uncertain risks.” The authors further elaborate that these risks result from the lack of scientific or technical bases for decision making, whereby a risk-modelling framework is unable to anticipate or elucidate risk events. The clear takeaway is that the key components of a cybersecurity threat are both the known and unknown elements – malicious actors use known methods to breach networks and compromise data, whilst 0-day exploits and software bugs may create system vulnerabilities unknown to developers. By its very nature, technological change causes uncertainty. Currently, companies do not know the extent of the additional benefits of IoT and associated revenue streams, nor are possible security breaches, technical difficulties or future regulatory challenges fully understood. One of the important things to remember when examining IoT and cybersecurity threats is that the identified risks are not new. However, the connectivity and ‘smart’ characteristics of IoT have allowed the number of malicious attacks or attempts to subvert systems to increase. Due to the speed of IoT development, basic principles of security may be overlooked, or deemed to be not of sufficient criticality to warrant investment and implementation.
The rapid development of IoT capabilities has meant that both governmentally driven regulations and controls, as well as ‘Security by Design/Default’, are lagging behind. Responsibility for such controls lies both in the public, and private sector, as both governments and businesses have a vested interest in leveraging IoT capabilities, but will do so to different ends. There exists the need to balance the focus upon restricting IoT advancement as it pertains to protecting individuals and reducing risk, while allowing growth and free development. A dilemma exists whereby regulators and developers are both uncertain of what the other is doing, as both are working in an uncertain environment; regulators cannot act without understanding the technology, and developers cannot work with uncertain regulations. However, without cooperative action, IoT will continue to develop in a way which increases vulnerability to cyber threats. The following paragraphs detail three cyber threats which are directly influenced by the development of IoT devices/principles.But it was not all unicorns and rainbows at RIMS. The glaring potential downside risks of IoT were just as present at the conference, giving pause to risk management stewards and conceivably impacting their ability to sleep soundly.
One presenter regaled the audience with a tale of a visit to his dentist, where the receptionist had a smart speaker (which serves as an IoT hub) on her desk. She was clearly not alone in using such a device at the office or when working from home but was most certainly unaware that each time she discussed a patient’s information the device may have been “listening in,” making personally identifiable data potentially accessible to hackers.
Such possible breaches may not appear to be much of a threat on the surface. However, when these Internet-connected devices are assembled into a botnet, the consequences can be ruinous on a significant scale. Thus, many at RIMS expressed alarm not about attacks on individual sensors, but rather that they will be co-opted to execute wider-reaching assaults. From smart microwaves, refrigerators, and lightbulbs to sensors entrenched in smart city infrastructure, the systemic peril was the bigger picture issue worrying risk managers, given the alarming implications for widespread damage and liabilities.
In one such attack in 2016, a Mirai botnet (Japanese malware) exploited insecure IoT devices to scan the Web for open Telnet ports and launched a distributed denial of service (DDoS) attack, essentially knocking out large segments of the Internet in the US.2 Alarmingly, the Mirai botnet has since been updated and gained increased effectiveness.3When it comes to designing an IoT ecosystem, choosing the underlying connectivity solution responsible for the data transfer between sensors and applications is essential. With more and more connected devices, the amount of data generated increases accordingly, which in turn means that a staggering amount of data needs to be transferred to the relevant backend.
By making this transfer possible, the connectivity layer acts as the crucial enabler of any IoT solution, which makes selecting a fitting connectivity solution so important. Nowadays, decision makers are facing a multitude of options and there is no universal best option to be found. Instead, different use cases demand different solutions, each of which brings their own particular advantages and challenges with them.
In our Point of View “The Future of Connectivity in IoT Deployments” we take a closer look at these connectivity solutions and what they entail. Starting by presenting a market overview of current technologies and expected trends, we then delve into a more detailed examination of specific use cases. Additionally, this Point of View also provides an outlook on the future by highlighting long-term implications of upcoming technologies (in particular 5G) and overall business implications.
In order to identify and deploy the right connectivity solution, organizations have to identify and assess their own needs first, as different use cases have wildly differing requirements. In this particular Point of View, we examine the following specific use cases and their implications for choosing a connectivity solution:
Precision Farming - A use case focused on increasing efficiency and reliability in farming through sensors in the soil.
Wearables - A use case considering health tracking with wearables such as smartwaches or sleeptrackers.
Connected Car: Smart Traffic Management - A use case studying the communication between vehicles and their surroundings, especially other vehicles and roadside infrastructure.
Connected Medical Devices - A use case highlighting the use of connected medical devices at patients’ homes.
As the Point of View illuminates, each of these use cases imply specific needs which need to be considered when choosing the correct connectivity solution. Without an appropriate connectivity solution acting as an enabling base layer, a successful wide-scale deployment becomes impossible.
However, when deployed successfully, IoT applications can have a marked impact on businesses in a wide range of industries. With the market of IoT applications and connectivity solutions being as dynamic as it is, this requires an ecosystem-oriented mindset, as with one single application numerous specialized parties come together. In this context, connectivity is just one aspect out of many for a comprehensive IoT solution - but it is without doubt an essential one.This article is a precursor to a more in-depth analysis of Security by Design/Default principles for IoT device producers by proving an overview of the current requirements for security within the expanding IoT industry. The aim is provide some food for thought before delving deeper into the specifics of IoT regulation and legislative control.
As discussed in the blog post Connectivity and Vulnerability: An Examination of Cybersecurity Threats resulting from IoT Development, IoT devices and capabilities will continue to play a significant part in future business capabilities. In addition, due to the complexity of these devices and their capabilities, threats from malicious actors, as well as intrinsic vulnerabilities will exist. The logical approach to ensuring that IoT devices are kept as secure as possible rests upon the premise that security prioritization begins during development and production phases. Security is a particularly difficult measure to implement retroactively, requiring improvements to both software and hardware.
To paraphrase Tim Stevens, risk arises from both known and unknown elements; the onus of protection regarding known risks rests most strongly upon the producers of IoT devices to ensure that they are implementing a satisfactory degree of security in their products, in order to mitigate future unknown risks. However, the conflict between the rapid development of IoT, and legislative regulation, is yet to be resolved to any satisfactory degree.
In September of 2018, The Washington Post reported that a Bill (SB-327) was awaiting the signature of Gov. Jerry Brown (D) of California which would require IoT device manufacturers to implement basic device security measures. At this time, the Bill has been signed and will come into power as of January 1, 2020.The Bill is seen in both a positive and negative light however. The Bill itself states that:
(a) A manufacturer of a connected device shall equip the device with a reasonable security feature or features that are all of the following:
(3) Designed to protect the device and any information contained therein from unauthorized access, destruction, use, modification, or disclosure.
(b) Subject to all of the requirements of subdivision (a), if a connected device is equipped with a means for authentication outside a local area network, it shall be deemed a reasonable security feature under subdivision (a) if either of the following requirements are met:
(2) The device contains a security feature that requires a user to generate a new means of authentication before access is granted to the device for the first time.
The positive aspects of the Bill are that finally, steps are being taken to ensure that there is a legal basis for a minimum standard of protection required for all IoT devices which are manufactured. This will serve to protect those devices which are currently produced without adhering to industry ‘best practices’, and create significant risk for the users of the devices.
The negative takeaway is that the wording of the Bill is rather vague, and seems to leave the onus of determining what exactly can be considered “appropriate”. Additionally, there is no information which sets out clearly defined requirements for what constitutes a ‘security feature’.
It is quite possible that in the near future, there will be a security feature requirements catalogue and certification process for IoT devices. However, this will serve to increase the workload for innovative device manufacturers, and the complexity of the IoT environment. In an International Electrotechnical Commission Whitepaper of 2016 entitled IoT 2020: Smart and secure IoT platform, the problem of governmental control over IoT regulation was already noted. The problem was, that “government bodies strive for regulations that provide a proper balance between supporting helpful innovation and protecting consumers” and that the search for this balance was “causing significant confusion in the marketplace and adding to the complexities of designing, building, deploying and operating both homo- and heterogeneous systems within and across geopolitical boundaries.”
The problem mentioned above is significant when considering the fact that a huge range of business opportunities are arising from the continued, somewhat unhindered (or overly regulated) development of IoT technologies. An excess of regulation stymies development, which restricts market growth, and results in a negative economic effect. Uncertainty between IoT manufacturers and regulators can lead to an environment wherein regulators are forced to play ‘catch-up’ in order to regulate new developments in IoT technology, and manufacturers slow their research and development efforts due to concerns which arise from the unknown of when and how their projects will be impacted by newly implemented regulatory requirements.
As Deloitte, future developments within the IoT industry will require us to adapt service offerings and to cater our approach to the specific needs of our clients. As part of our offerings, we seek to share our experiences and knowledge in order to build awareness. We look forward to delving further into this topic in the next Blog Post and discovering more opportunities together.Machines and other infrastructure components often have a long service life that extends far beyond the tax depreciation period. This is especially true for buildings and facilities for energy supply. These “Legacy Devices” have so far been largely excluded from the Internet of Things, although applications such as predictive maintenance are of great importance, especially in old age. The reason is that digital technologies were not yet available at the time of production and changes to the control systems would often be expensive or would require a new approval of the system. However, the rapid development of sensor technology and electronics has led to high performance and low cost of IoT edge devices. Current gadgets are both cheap and capable of executing complex algorithms for signal processing and pattern recognition in real-time. It is now possible to equip existing Things with a digital heartbeat via minimally invasive sensor technology. We call this Artificial Intelligence of Things (AIoT). In this publication, we describe the idea and basics and show application examples.
Aging technical systems, commonly referred to as “Legacy Devices”, are an integral part of our daily lives. Who does not know the picture of an elevator from the seventies that tries to close its doors in an endless loop? The malfunction is simply caused by dirt on the reflector that triggers the door sensor. House inhabitants only shake their heads and nobody informs property management.
Elevators, finned radiators, kitchen appliances, and even the humans themselves share their fate as "Legacy Devices". This generally refers to "devices" that have no own digital identity on their own. The automatic acquisition and evaluation of data and the corresponding actions or recommendations are therefore not possible, sometimes with fatal consequences.The Internet of Things—sensors and actuators connected by networks to computing systems—has received enormous attention over the past five years. A new McKinsey Global Institute report, The Internet of Things: Mapping the value beyond the hype, attempts to determine exactly how IoT technology can create real economic value.
Our central finding is that the hype may actually understate the full potential—but that capturing it will require an understanding of where real value can be created and a successful effort to address a set of systems issues, including interoperability.
To get a broader view of the IoT’s potential benefits and challenges across the global economy, we analyzed more than 150 use cases, ranging from people whose devices monitor health and wellness to manufacturers that utilize sensors to optimize the maintenance of equipment and protect the safety of workers. Our bottom-up analysis for the applications we size estimates that the IoT has a total potential economic impact of $3.9 trillion to $11.1 trillion a year by 2025. At the top end, that level of value—including the consumer surplus—would be equivalent to about 11 percent of the world economy (exhibit).
Exhibit We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Achieving this kind of impact would require certain conditions to be in place, notably overcoming the technical, organizational, and regulatory hurdles. In particular, companies that use IoT technology will play a critical role in developing the right systems and processes to maximize its value. Among our findings:
Interoperability between IoT systems is critical. Of the total potential economic value the IoT enables, interoperability is required for 40 percent on average and for nearly 60 percent in some settings.
Currently, most IoT data are not used. For example, on an oil rig that has 30,000 sensors, only 1 percent of the data are examined. That’s because this information is used mostly to detect and control anomalies—not for optimization and prediction, which provide the greatest value.
Business-to-business applications will probably capture more value—nearly 70 percent of it—than consumer uses, although consumer applications, such as fitness monitors and self-driving cars, attract the most attention and can create significant value, too.
The IoT has a large potential in developing economies. Still, we estimate that it will have a higher overall value impact in advanced economies because of the higher value per use. However, developing economies could generate nearly 40 percent of the IoT’s value, and nearly half in some settings.
Customers will capture most of the benefits. We estimate that IoT users (businesses, other organizations, and consumers) could capture 90 percent of the value that IoT applications generate. For example, in 2025 remote monitoring could create as much as $1.1 trillion a year in value by improving the health of chronic-disease patients.
A dynamic industry is evolving around IoT technology. As in other technology waves, both incumbents and new players have opportunities. Digitization blurs the lines between technology companies and other types of businesses; makers of industrial machinery, for example, are creating new business models by using IoT links and data to offer their products as a service.
00:00 Audio Getting the most out of the Internet of Things MGI’s Michael Chui discusses how businesses could unlock trillions of dollars in value during the next decade.
The digitization of machines, vehicles, and other elements of the physical world is a powerful idea. Even at this early stage, the IoT is starting to have a real impact by changing how goods are made and distributed, how products are serviced and refined, and how doctors and patients manage health and wellness. But capturing the full potential of IoT applications will require innovation in technologies and business models, as well as investment in new capabilities and talent. With policy actions to encourage interoperability, ensure security, and protect privacy and property rights, the Internet of Things can begin to reach its full potential—especially if leaders truly embrace data-driven decision making.A midstream company was struggling with asset management lifecycle challenges as its aging infrastructure created competing investment priorities. They wanted to refocus their program on leveraging data to improve information management, predictive asset management, asset risk management, and asset management planning.
Discover how we refreshed multiple dimensions of the program using the Internet of Things (IoT) and data-driven approaches.Manufacturing history is a study in evolution, as industry has quickly adopted and adapted to new technologies, from power generation and electrification to automation and the digital age. That’s why the way that cars and other products are manufactured today looks very different than it did when Eli Whitney first developed a simple production line based on interchangeable parts used in the manufacturing of muskets.
In many ways, manufacturing has been part of the Internet of Things (IoT) throughout its entire history. Many companies have been embedding sensor-based technology in their devices for decades without fully realizing their potential. Manufacturing was one of the first adopters of robots and automated processes—many of these machines signaled distress with a sensor providing notification and addressing the problem before the machine stopped working, thereby avoiding downtime.
Today, thanks to the power of IoT, new data processing technologies, and availability of analytical forecasting models, the entire manufacturing value chain, from concept to completion and beyond, can now take advantage of this sensor technology.
For a modern example, some of today’s most sophisticated fighter jets are built almost completely out of outsourced parts. With a digital supply chain supported by advanced predictive analytics coordinating three principal partners, nine countries, 40,000 individual parts, and thousands of suppliers, a major manufacturer of these jets predicts it will soon be able to build one jet per day, a process that used to take months or years.
As this example illustrates, IoT and analytics are innovating manufacturing, improving interoperability across a large set of assets and linking machines, products, computers, people, and analytical resources into one ecosystem.
At the simplest level, IoT and analytics are creating two important buckets of value in manufacturing: growing the business and operating the existing business more efficiently.Financial services have long trafficked in the intangible, from counterparty risk and online bill payment to things that used to be tangible but increasingly are not any longer, such as stock certificates and even money itself.
So all the talk about IoT—a suite of technologies and applications that provide information about, well, things—might not seem directly relevant to the way financial services institutions do business.
But, according to the Deloitte Center for Financial Services research, there are near- and long-term opportunities for the financial services industry to see the benefits from IoT. Read this report for an overview of where IoT is working well, bottlenecks companies could encounter when leveraging IoT data, and potential use cases for future adoption.
Or explore the below infographic, which was created at the BAI Retail Delivery Conference where the Deloitte Center for Financial Services hosted a sponsored session on IoT in financial services. The graphic includes an overview of the findings from the research study and ideas generated from small group discussions on the application of IoT in retail banking through the lens of lending, branch, wealth management, and payments.IoT platforms are emerging that make IoT development and deployment much easier. But just as important is their ability to enhance IoT platform security. With IoT, devices are both smart and connected—gathering and sharing data without the need for human intervention. This enables information to be collected and shared on a massive scale with unprecedented levels of speed, efficiency, and detail.
This also makes it a target for bad actors looking for any little weakness. IoT greatly expands the universe of potential weaknesses—in a particular device, device-to-device communications, or the broader internet. Even a single breach point may be enough to compromise an entire network.
IoT provides a bridge between digital and physical, making it possible for hackers to wreak havoc in the physical world—whether it’s taking control of your vehicle or causing a nuclear power plant to melt down. The World Economic Forum noted, “hacking the location data on a car is merely an invasion of privacy, whereas hacking the control system of a car would be a threat to a life.”1Deloitte's turnkey IoT framework and technology bundles were developed to meet market demand for predictive maintenance and asset monitoring, asset performance management, and asset tracking capabilities, to help deliver significant, fast returns on IoT investment.
Drawing on the industry, functional, and digital experience within Deloitte and our alliance network, we provide a single pre-configured package that includes:
These turnkey IoT solutions are pretested, fully integrated, and shown in production to lower risk and shorten the path to value from months to weeks.
Our turnkey IoT approach can help clients realize the benefits of IoT faster, achieving relatively quick returns in specific high-impact areas of their business while accelerating digital adoption and modernizing operations in general. Clients can accomplish this by replacing legacy systems entirely or by adding new technology for gathering and analyzing data from existing sensors and controllers.The Consumer Electronics Show (CES) is an annual industry extravaganza and it took place, as usual, in Las Vegas earlier this month. This is where all kinds of firms showcase their latest and greatest consumer tech offerings to the world, with the focus typically on one or two big themes. This year was no different.
Much of the excitement at this year’s event was around the Internet of Things, or IoT, as the cognoscenti refer to it.1 The Internet of Things includes anything and everything that is connected to the Internet and able to communicate and share information with other “smart” devices. These may include home appliances, fitness and health monitors, home security systems, light bulbs, audio systems, temperature control equipment, etc.
In keeping with that theme, a number of firms displayed a staggering array of gadgets at this year’s CES, ranging from smart cooking pots and toothbrushes to wearable technologies like watches and clothing.
To be sure, the IoT is not really a new concept. The technology industry has been talking about this for a while now, with some people equating the IoT with the industrial revolution. They claim a profound transformation lies ahead in ways humans and machines interact with each other.2
Estimates of the size of the IoT market vary. For instance, Gartner expects it to include nearly 26 billion devices, with a “global economic value-add” of $1.9 trillion by 2020.3 Others are more optimistic: The International Data Corporation (IDC), for one, estimates that the universe of things connected to the Internet will generate nearly $9 trillion in annual sales by 2020.4
One may wonder whether this is just hype or an inevitable evolution in how people, objects and networks will interact in the near future. Some recent advances suggest this is for real. We already have products that use sensing and communication technologies in a range of consumer sectors, such as self-driving cars and geospatial sensing on mobile phones. We are also seeing applications in business, with supply chain management being a focal area.
An obvious and critical challenge that the IoT industry is likely to face is in the area of security and privacy. With the explosion of devices, cybersecurity takes on a whole new dimension – not just for institutions but also for consumers. Digital vulnerabilities are likely to expand exponentially.
The question for us in the financial services industry is how we should respond to this growing phenomenon. What does the IoT mean for how we communicate and interact with customers? Contrarians may argue we are in the business of providing services, not “things,” so we needn’t pay much attention to this. In my opinion, that might be a short-sighted view.
We are already seeing this concept applied in insurance through telematics (monitoring driver behavior for car insurance). Other potential applications in insurance are life, health and homeowners insurance and worker’s compensation in the commercial arena.
Some applications that come to mind are ATMs, information kiosks in bank branches and credit/debit cards that may use sensing technology to monitor and take action on the consumers’ behalf. Another big potential may be the connection of financial services (such as checking, credit card, or investment accounts) to some of the common household devices.
For instance, imagine a personal health monitor that is also connected to your investment account. At the sign of any serious health hazard (say a heart attack), the investment account could automatically rebalance to limit your downside exposure, or transfer your holdings to more liquid securities, in anticipation of future cash needs. This may sound a bit far-fetched now, but is not completely out of the realm of possibilities.
Other applications may be possible in the middle- and back-office functions at banks, insurance firms and investment management shops that could potentially benefit from the IoT technologies.
Again, such innovations also come with new risks. The deluge of new data is likely to complicate data management for financial services firm. And of course, cybersecurity may become an even greater challenge.
We cannot know all the answers here and now, but my takeaway from this year’s CES is that the financial services industry ought to be proactively thinking about how to deploy the IoT technologies in the way it serves customers.
1Kim Peterson, “’Internet of Things’ all the rage at the Consumer Electronics Show,” CBS Moneywatch, January 7, 2014.
2Steve Johnson, “Internet of Things promises profound transformation, could rival Industrial Revolution," Mercury News, January 8, 2014.
3Peter Middleton, Peter Kjeldsen and Jim Tully, “Forecast: The Internet of Things, Worldwide, 2013,” Gartner, November 18, 2013.
4IDC, “The Internet of Things is Poised to Change Everything, says IDC,” Press Release, October 3, 2013.
As used in this document, “Deloitte” means Deloitte & Touche LLP, a subsidiary of Deloitte LLP. Please see www.deloitte.com/us/about for a detailed description of the legal structure of Deloitte LLP and its subsidiaries. Certain services may not be available to attest clients under the rules and regulations of public accounting.A global telecoms company knew that the Internet of Things (IoT) is taking off in a big way. But since many ‘smart’ products only worked with their associated apps, it’s difficult to build a true ‘smart’ ecosystem.
Our client asked us to do just that—transform the way consumers interact with IoT. Together, we built a new IoT business from the ground up, including technical design and execution for the new platform, onboarding a network of partners and users, and scaling the talent and capabilities to make the new business a success.Can financial services, which deals mostly with the intangible, benefit from Internet of Things technology? Absolutely—and not only from more and better data about clients' physical assets. IoT applications aim to transform finance along with every other sector.
Financial services have long trafficked in the intangible, from counterparty risk and online bill payment to things that used to be tangible but increasingly are not any longer, such as stock certificates and even money itself. So all the talk about the Internet of Things (IoT)—a suite of technologies and applications that provide information about, well, things—might not seem directly relevant to the way financial services institutions (FSIs) do business.
But the IoT may be as broadly transformational to the financial services industry as the Internet itself, and leaders should make an effort to recognize the opportunities and challenges it presents for the financial sector as well as for industries with which FSIs work closely.
Notwithstanding the inevitable hype, many industries see great promise in IoT applications: Analysts and technology providers forecast added economic value of anywhere from $300 billion to $15 trillion by this decade’s end.1 Few analysts seem to expect anything but a transformative effect on just about every dimension of economic activity by 2020. The IoT—based on the concept of physical objects being able to utilize the Internet backbone to communicate data about their condition, position, or other attributes—is likely going to matter a great deal. (For an overview, see Deloitte University Press’s “Internet of Things” collection of articles.2) And FSIs can be active participants in this transformation.
Indeed, FSI leaders can easily imagine the potential benefits accruing from having more comprehensive, real-time data about their own or their clients’ physical assets. Some use cases have already proven themselves: Applications such as auto insurance telematics and “smart” commercial real estate building-management systems offer clear IoT examples of new products or changed processes. Our aim in this report is to go a step further by exploring the IoT’s potential impacts on the financial services industry when those effects are hazier. We also aim to help FSI professionals such as claims administrators, portfolio managers, loan officers, and leasing agents understand how IoT applications may change their jobs in the coming years.
Many analysts view the IoT narrowly, defining it as little more than an extension of related technology concepts, such as machine-to-machine (M2M) communication or big data. But the IoT, and its applications’ potential value, goes far beyond mere data communication or analysis. For the purposes of this report, we will define the IoT as technology that connects objects (including people) to a network (such as the Internet) in order to provide access to information about that object’s condition, position, or movement. Kevin Ashton, generally credited with coining the term “Internet of Things” in 1999, envisioned computers having “their own means of gathering information, so they can see, hear, and smell the world for themselves.”3 Many IoT systems take this vision a step further, either by visualizing that information for decision makers or by providing it directly to computers to enable action in the physical world.
For the financial services industry, how does the flow of IoT-generated information create value for companies and consumers? Many firms are already using sensor data to improve operational performance, customer experience, and product pricing. Perhaps the most mature example involves the development of usage-based insurance, in which sensors in automobiles or, increasingly, smartphone apps automatically provide insurance carriers with information on vehicles’ driving history and therefore their drivers’ performance.4 Using telematics to increase the accuracy of underwriting automobile collision policies, as well as the use of gamification strategies based on those data to change and incent lower-risk driver behavior, has been shown to be quite successful in the still-early stages of deployment.5
Another example is in commercial real estate, where sensors within commercial buildings of all types can help better manage energy usage, environmental comfort, and security.6 For example, motion detectors can control lighting and temperature usage, while smoke and heat sensors can detect the presence of fire and not only set off alarms but also communicate with elevator control systems to prevent usage—a much more effective deterrent than traditional take-the-stairs-during-a-fire signs. Mall operators are currently experimenting with IoT-like applications, such as using cellphone Wi-Fi data to track and analyze foot-traffic flow around and within the mall, that suggest ways to increase certain properties’ attractiveness and thus drive increased rental income and investment activity.7
These examples highlight something that Ashton declared as a premise underlying the IoT concept: For the technology to make a direct impact, a business’s value chain must have a thing that can be measured and enabled to communicate. But for most financial services businesses, the IoT’s impacts could be characterized as having a “derivative effect”: While the IoT is fundamentally about gathering, processing, and creating value from information about tangible physical objects, many financial transactions are based on information from intangible sources that may ultimately have roots in the physical world but that are one level removed from it. No tech startup has yet figured out how to strap a sensor to a company’s profit-to-earnings ratio. But many, even most, pieces of information have roots in the physical world—for instance, a logistics firm’s stock price may depend on the number of packages shipped, while wheat futures may change based on rainfall levels.
As discussed above, FSIs are already using IoT technology to measure and analyze those elements of their business that are directly tied to data about tangible thing—driving habits, health, and so on. Therefore, we see the IoT’s near-term potential in financial services as largely defined by how these existing “tangible” applications may spread. To identify possibilities, one approach would be to consider deployments of sensors of all types and analyze which of these might yield information that could be useful—even tangentially—to the various businesses within the financial services industry. In a sense, since sensors are the IoT’s most physical element, we can use them as a stand-in to measure IoT applications as a whole.
In a recent report, Gartner forecast that, on a worldwide basis, “endpoints of the Internet of Things will grow at a 32.5 percent CAGR from 2013 to 2020, reaching an installed base of 25.0 billion units.”8 Covering more than 200 different categories of sensors, across consumer, business, and vertical-specific categories, the forecast suggests a broad expansion of deployments between now and the decade’s end. Undoubtedly, deployment of 25 billion new endpoints should create considerable business opportunities for companies of all types.
In aiming to assess the scope of the IoT’s nearterm impact on financial services, we used the Gartner forecast as a starting point and took the following steps to generate the numbers used in this section of the report:
Reviewed the more than 200 types of sensors in the forecast and assessed their resulting information’s potential value to financial institutions
Interviewed senior practitioners within Deloitte to gather their views and input on potential use cases
Categorized the detailed list of sensor types into a small number of broad use-case categories with broad appeal to FSIs (See exhibit 1 of the appendix)
Created potential use cases by financial services sector for each use case (See exhibit 2 of the appendix)
Our analysis is meant to be illustrative rather than exhaustive, with the goal of exploring both the IoT’s possibilities and limitations for FSIs between now and 2020.
Whole categories of sensors will likely have little or no direct impact on the financial services industry—just consider education (for example, lab equipment or smart boards) and entertainment (for example, smart TVs or gaming consoles). But as a starting point, our analysis (see sidebar for details) suggests that perhaps as many as one-quarter of sensors deployed in 2013 could be of use to FSIs, rising to one-third in 2015 and then to about 50 percent by 2020. In other words, one could reasonably assume that by the end of the decade, companies will have deployed several billion sensors that could provide data of interest to financial firms of one kind or another.
How might companies use these data, and how could the information be further exploited? Our analysis suggests that sensor deployments may find traction within the industry in more than a dozen different applications (see exhibit 2 of the appendix). Several categories are interesting to consider as further enhancements to existing opportunities. For example, analysts expect deployment of automotive sensors to continue to grow, providing insurers with better data to drive usage-based insurance.9,10 Building-management sensor deployments will likely similarly increase.11
On the consumer side, a significant number of sensors are forecast to be deployed in the home to control utility consumption, provide home security and flood and fire detection, and monitor the dwelling’s overall condition. Google’s acquisition of Nest suggests the potential for combining home automation and analytics into the “conscious home.”12 These technologies could benefit FSIs as well: Lenders could better understand a home’s condition and thus its value during the mortgage origination process (for appraisals and underwriting), and insurers could improve risk management and provide more accurate pricing for homeowner insurance, as they do today for auto coverage.
In commercial applications, we believe that FSIs might benefit from various sensors that monitor the activity and condition of retail industrial and agricultural businesses, such as connected field devices in manufacturing or agricultural sensors that monitor livestock. Both capital market firms and commercial lenders could use the data these sensors generate to support investing or lending activities. Sensors attached to goods in transit—from manufacturing plant to retail outlet—could offer opportunities to banks’ cash management and trade services businesses, better matching flows of payments and goods between seller and buyer.
Apart from augmenting how FSIs provide services, companies can deploy IoT technology to change how they do work internally—a broad category of sensors that addresses the “quantified self.” In the same way that automotive telematics provide input to insurers as well as feedback to drivers, personal sensors may provide information to firms across multiple sectors. Even sensors that simply provide information on location and movement of individuals have been shown to provide rich insights into how employees work, interact, and share ideas.13
Taken together, the analysis we conducted suggests that growth in sensor deployments for FSI examples such as these is certainly robust, ranging from just over 20 percent to 100 percent annually on a compounded basis, depending on the sector (see figure 1).
But gross numbers and growth rates for sensor deployments tell only part of the story. To truly begin to discern the industry potential for the application of IoT-generated data, we should also consider those uses that have not yet become common. To do so, it is useful to consider the value that companies might derive from such usage, as well as bottlenecks that hinder growth in that usage, using a framework known as the Information Value Loop.
The suite of technologies that enables the Internet of Things promises to turn most any object into a source of information about that object. This creates both a new way to differentiate products and services and a new source of value that can be managed in its own right. Realizing the IoT’s full potential motivates a framework that captures the series and sequence of activities by which organizations create value from information: the Information Value Loop.
For information to complete the loop and create value, it passes through the loop’s stages, each enabled by specific technologies. An act is monitored by a sensor that creates information, that information passes through a network so that it can be communicated, and standards—be they technical, legal, regulatory, or social—allow that information to be aggregated across time and space. Augmented intelligence is a generic term meant to capture all manner of analytical support, collectively used to analyze information. The loop is completed via augmented behavior technologies that either enable automated autonomous action or shape human decisions in a manner leading to improved action.
The amount of value created by information passing through the loop is a function of the value drivers identified in the middle. Falling into three generic categories—magnitude, risk, and time—the specific drivers listed are not exhaustive but only illustrative. Different applications will benefit from an emphasis on different drivers.
Using the Value Loop to understand how the IoT uses information to create value, we can see the largest barriers to wider future adoption: the scale and scope of available data. To illustrate the scale problem, one can see how, for most given applications, sensor deployments can inevitably fall short in covering the entire market. Take, for example, the safety issues inherent in cars having improperly inflated tires. Automakers have begun making tire-pressure monitoring sensors standard equipment on vehicles they sell in the developed world, but most cars aren’t new—the average automobile even in the United States today is 11 years old.14 The Gartner forecast we have used predicts about 3.5 billion automotive sensors deployed across many different categories by 2020, when the number of passenger cars in use worldwide could be as much as 1 billion.15 Clearly, then, a significant number of vehicles may still lack the ability to provide the kind of comprehensive safety data of which insurers could make use, even by the end of this decade. The lack of relevant data limits even the “tangible” uses of IoT technology that FSIs already use from achieving their full potential.
For future uses that seek to use the IoT to shed light on “intangible” measures, the data problem is even more pronounced. Here the scope of sensor coverage remains a key issue. As discussed above, monitoring retail business performance in real time may allow analysts to truly understand foot-traffic patterns and compare this information to sales figures to determine which retailer is more effective at converting shopper volume to sales per square foot, which would then influence buy/sell recommendations. Such a real-time capability would likely require an array of different sensor types, including beacons (devices that connect to a mobile phone or tablet to determine positioning and deliver proximity-based content, such as coupons), smart cash registers, RFID tag readers, parking lot sensors, and smart mobile signature devices for home delivery. However, forecasts estimate that the lion’s share of sensor deployments will be beacons that measure only one data parameter: location (see figure 2).
In a similar vein, manufacturer activity may be monitored by devices that observe plant activity of various kinds, industrial controllers and smart robots on the assembly line, smart asset tagging to prevent loss of tools and equipment, and RFID tag readers for finished-goods inventory. Here, most sensors are projected to be connected field devices that monitor general plant activity—again, a valuable indicative input to existing data sets, but currently insufficient to yield the kind of in-depth comparative intelligence that might someday transform the way that lenders, traders, or analysts assess risk or make stock picks. In summary, firms may benefit as these data flows start to come online, but the transformative effect resulting from a more comprehensive picture of business activity may remain somewhat elusive over the next five years.
In the shorter term, sensor data coming online will likely create new information asymmetries that traders and portfolio managers can exploit. Indeed, firms have a vested interest in protecting the status quo of information asymmetry that drives value in the capital markets and, therefore, may resist the kind of radical transparency that might someday emerge from this new source of data.
FSIs will also confront challenges associated with deriving value based on the data’s reliability and accuracy. Not all IoT-generated data will be useful, and so companies will likely need to gain experience with some of these new data types (especially those associated with the “quantified self ”) in order to discern which are predictive in nature, and update their analytical models accordingly.
Especially for the applications imagined for capital markets and investment management firms, then, IoT-generated value will likely accrue much more slowly, since many processes within these sectors are based on the availability of comprehensive and timely market data. Referring back to the value drivers within the Information Value Loop, frequency, timeliness, and latency are therefore an issue, as firms often depend on continuous, realtime data flows, particularly as relating to the equity markets.
Keeping in mind that IoT applications in financial services may increasingly shift from common uses with tangible measures to uses with intangible measures, the question is what path IoT technology will take from here to there.
The answer can again be found in the Information Value Loop. One of the implications associated with the IoT is that a product’s information content is now as valuable as its performance.16 The flow of information around the Value Loop creates value for customers that companies can then capture. Analyzing this flow of information can help companies locate specific strategic and technical challenges facing them in an IoT-enabled world. But information does not flow evenly around the loop: A bottleneck will exist at one stage of technology, which limits the flow and thus the value. Alleviating this bottleneck can increase the flow of information, creating value for customers, and the company that controls the bottleneck is in a place to capture the bulk of value created.17
The uneven progression of sensor deployments highlights the fact that for many emerging applications, the bottleneck is at the create stage of the Value Loop. Until some minimum critical mass of sensors is in the market, more complex uses beyond the few existing tangible examples will be impossible.
Even then, FSIs must clear other hurdles before they can use IoT technology to model “intangible” financials. One hurdle is the availability of these data to FSIs. For example, manufacturers or agribusinesses should benefit from closer monitoring of operations, but they will likely struggle to see the upside of releasing or selling such strategic information to the marketplace, since such data may reveal specific strategies or competitive advantages that companies would prefer not to expose to competitors. Firms—especially commercial lenders—may someday require the release of such information as a condition for granting credit, but these requirements may adversely impact client experience, as customers may perceive those companies that decide to be on this trend’s leading edge as being more difficult to do business with.18 So the next bottleneck blocking the way of more complex IoT applications is in the communicate stage, as companies or individuals may be unwilling to share their data with a financial institution.
Even if the bottlenecks associated with the creation and communication of data were to someday disappear, many FSIs will find aggregating and analyzing the output to be a challenge. IoT-generated data streams will require them to augment their data-management and analytical capabilities. Banks and insurance companies in particular already struggle with the vast pools of data within their legacy systems, and without exercising more discipline toward the specific data they want to capture, the potential flood of fresh information may overwhelm them.
Regulators, aiming to protect investor interests and market transparency, will have their say, and consumers and corporations uncomfortable with the notion of being “watched” will demand limits on the collection and use of sensor-based data. In this new world, clients may be unable to adequately discern the risks of transparency, and one might anticipate that regulators will look for increasing disclosure to protect the interests of clients and markets, as well as monitoring the handling and use of personally identifiable information as a result.19
So what exactly will the future hold if these current applications are able to reach sufficient scope and scale? By introducing enough data about the world, the IoT can help drive the creation of models that approximate the underlying physical drivers of even intangible financial measures. That said, given the accelerating pace of technological development, predictions about how things might evolve in the next 5–10 years are difficult to make. To help gain some insight into future scenarios, we engaged with a group of academics, analysts, and entrepreneurs with expertise in financial services and technology using a crowdsourced model to imagine how IoT technologies might generate new examples over a longer time horizon (see “About the project” for more details).
The insights in this section on future IoT scenarios are based in part on a crowdsourced simulation exercise conducted by Wikistrat on behalf of the Deloitte Center for Financial Services. The project, fielded during July 2015, involved more than 50 analysts across 20 countries. These analysts had varied backgrounds, including technology entrepreneurs; business and technology leaders within the financial services industry; academics with doctorates in economics, business, and technology; analysts in government and research centers; and cybersecurity consultants.
The project was designed to explore the IoT’s long-term potential in financial services. Wikistrat tasked analysts with developing a series of use cases within six specific industry sectors, and with forecasting and describing the opportunities and challenges that IoT technology presents (see exhibit 3 of the appendix for a full list of the scenarios).
Using an online tool, analysts worked collaboratively to develop 44 use-case examples using a wiki-based template designed to identify IoT-related trends and issues, potential opportunities, and risks and challenges.
They then provided a quantitative assessment of the probability that each use case will emerge and its overall impact or importance to the industry.
Wikistrat and the Deloitte Center for Financial Services then reviewed all cases and probability assessments to select 10 use cases for further development.
At a final workshop, participants reviewed and enriched the short list of 10 cases. Enrichment activities included clarification of use cases, provisioning of additional data points, reinforcing potential value for FSIs, and identification of cross-cutting themes and issues.
The sheer number of ideas our workshop generated in a short period suggests that opportunities to capitalize on new information flows may be limited only by our collective imagination.
A few of the workshop’s more interesting use cases provide a glimpse into a future of new opportunities and threats for incumbents, emerging technology–based financial services companies, and regulators alike. Some overall themes emerged from this exercise. In brief, these include:
The emergence of what the panel called “radical transparency” may undermine advantages that come today from information asymmetry. This is particularly true in investment and lending businesses, in which equity analysts, loan officers, and others make decisions based on their unique perspectives.
Data associated with individual (and corporate) preferences and behaviors will likely be at the center of new opportunities and disruptions to the incumbents’ business models.
Risks of various types can emerge along with the opportunities. Protecting data privacy and security should be of paramount importance, especially for financial institutions. But unintended consequences may emerge from automated processing of huge volumes of near real-time data flows. Fraudsters could seek to intercept this information to manipulate markets, or operational disruptions could occur if automated decisions are made based on faulty data or inaccurate analysis.
The ability to access IoT-generated data will likely be a challenge for many firms, which may result in the emergence of a new class of service providers, offering data “subscription” services in the manner of credit bureaus or market data providers. Again, whether it makes sense for the owners of these data to offer this intelligence for public consumption will be driven by many factors, such as whether or not these data provide a competitive advantage to the owners within their own businesses.
The project also yielded some broader implications for the industry at the sector level. These are presented in turn below.
The analysts imagined that IoT applications might help banks improve underwriting processes and reach new markets. They foresaw that physical, performance, and behavioral data generated from biometric and positional sensors for individuals, and shipping and manufacturing control sensors for businesses, could provide new opportunities for credit underwriting, especially for those underserved customer segments lacking a credit history. The challenges here involved developing an understanding of which kinds of data are best predictive of creditworthiness, as well as the potential risk of new forms of redlining based on so-called “pattern of life” (POL) analyses.
Given that banks finance the lease or purchase of many physical items, our Wikistrat panel found opportunities for banks to tap into data from sensors monitoring these goods’ condition to offer customized solutions. For example, lenders could partner with electronics and “white goods” manufacturers to proactively make credit offers to individuals if their purchased items begin to show noticeable wear or face imminent failure. Leasing companies, too, could monitor the condition of leased assets in order to determine a more precise residual value of the asset at lease expiration, or determine with greater accuracy any discounts or penalties for preferred or unacceptable use.
Analysts considered IoT-enabled opportunities to further automate trading and investing activities, driven by continued acceleration in algorithmic trading and the enhancement of this approach through the application of IoT sensor data. The group considered the possibility that, with the removal of the human element in combination with more comprehensive real-time data flows, firms could develop analytics that might better evaluate suspected market bubbles. Others were less sure: While efficiencies would certainly be gained, intelligent agents might be unable to account for shifts in consumer demand or geopolitical events, and thus faulty conclusions could in turn actually create a bubble. There was consensus, however, on the need for firms on both the buy and sell sides to help improve their capacity and capability to gather, store, and analyze huge amounts of real-time, IoT-generated data.
Taking it a step further, crowdfunding and micro-investing opportunities could emerge based on based on analysis of investor behavior. New capital pools could therefore emerge, potentially with new and different systems of rewards. The Wikistrat report suggested that this could significantly shift the way venture capital is sought.
The longer-term impact of the adoption of automotive sensors emerged as one of the more interesting scenarios for insurance carriers. Already, the industry is grappling with the strategic implications of self-driving cars, suggesting a shift from automobile casualty insurance, where the driver is at fault, to product liability insurance, where the manufacturer may be held liable.20 Insurers may gain better information on product-design defects to more accurately price coverage but face the potential evaporation of significant amounts of premium income as accident rates drop and traditional coverages fade away.
A more interesting implication concerns augmented behavior: Usage-based insurance itself may lead to policyholders demanding more on-demand coverage to reduce their costs. For example, in personal life and injury insurance, all manner of risks are covered under a single policy, but with the development of more fine-grained data about personal behaviors, firms could fine-tune coverages to potentially add or eliminate certain risks. In essence, insurance coverages could be unbundled and “decommoditized” to create differentiation from other products in the marketplace. This would make underwriting and pricing a more complex undertaking, but could yield improved customer satisfaction.
On the commercial side, deployment of sensors on shipping containers and transport vehicles may provide insurers with the opportunity to enhance shipping insurance coverage. The ability to better detect and model risks due to theft or damage could move the pricing of these products from an actuarial exercise to one that better assesses risks and losses in real time, while at the same time enabling insurers to more accurately determine responsible parties. In essence, IoT technology could go a long way toward eliminating “proxies” in the risk-assessment process much more broadly than the initial forays seen in telematics today.
The Wikistrat analysts identified ways that investment managers could benefit from modeling the “enthusiastic crowd.” Firms could utilize information from a client’s IoT “ecosystem” to tailor investment decisions and asset allocation based on behaviors, preferences, and location. For example, a more intimate understanding of a client’s interests and purchasing patterns could enhance wealth management. Investment offerings could be tailored based on these data, leading to the extension of concepts similar to socially responsible investing. This analytical approach could also potentially provide a more accurate modeling of investor risk tolerance as well, a part of new-account onboarding that firms have traditionally given lip service through execution of a simple survey. In the new, IoT-enabled world, companies could develop algorithms relying on inputs of POL-based behavioral data to provide a more accurate picture of a new client’s true risk tolerance than a response on a questionnaire.
The analysts also explored the possibilities associated with automating portfolio management. Assuming that firms can address existing constraints around data availability, they could combine real-time data flows from a variety of sensors with cognitive technologies and M2M communication to automate fund management far beyond what is seen today, as with index funds. This could lead to increased differentiation between types of investment management firms, funds, and pricing strategies. Active managers may be forced to specialize in a particular strategy or sector, while automated managers leverage an ability to synthesize huge amounts of data, combined with high-frequency trading technologies, to act faster than any human can today.
The emergence of real-time bidding markets in commercial real estate was another scenario the panel of specialists envisioned. Already, tech startups have emerged to create more transparency in the process of finding and leasing commercial space.21 With IoT technology, firms could combine data from sensors used to manage building energy and security with activity sensors that monitor the level of human interaction within common areas, on elevators, and in the surrounding neighborhood. In this way, analysts could value properties even more accurately. These data flows, if exposed to a public marketplace, could in turn create a kind of trading market, reducing friction in the leasing or buying processes as well as giving investors greater transparency as to property values.
Design and construction of commercial and residential properties could benefit from behavioral analysis as well as the monitoring of construction equipment and materials, some panelists believed. Developers could take advantage of the increasing interest in combined “live/work/play” developments by analyzing foot traffic and other POL indicators to fine-tune their building plans. And engineering and construction firms might be better able to manage projects’ safety and efficiency based on wider deployment of connected construction vehicles and smart asset tags.
Finally, the analysts envisioned “quantified self ” concepts as a way to potentially reduce risk and improve performance. For example, companies might better manage conduct risk by monitoring FSI employees’ stress levels, patterns of movement, and other factors as a way of predicting the potential for internal fraud. Multi-factor authentication in both virtual and real environments could better flag identity theft. For example, retailers could authenticate online chip-enabled payment-card transactions by matching the presence of the card to other physical objects (such as a mobile phone, or even wearables) that are known typically to be within close proximity to the payment device.
Portfolio managers could also improve their performance by understanding how they react during times of stress. Clearly, employees may resist being monitored so closely, but for those in positions of particular importance, such data gathering, kept private and secure, may become a requirement of employment.
Firms should begin planning for this new source of data. As recently as 2012, slightly less than 15 percent of FSIs—and less than 10 percent of insurance carriers—were implementing or planning to implement IoT or M2M-based solutions or applications.22 Firms should start exploring potential impacts and opportunities related to the deployment of IoT technologies, and begin strategizing on how to capitalize on these developments, using the Information Value Loop as a guide. Developing strategic partnerships with IoT innovators across the spectrum, including related technologies such as cognitive computing, will aid understanding of where the market may be headed.
Early experimentation, building off of existing deployments, will help firms with a test-and-learn approach. Certainly, insurance carriers and firms in the commercial real estate industry have a leg up here, but banks may be able to capitalize on the connections between mobile payments, wearables, and sensing devices. Beyond that, firms could start with the assumption that every single object in the day-to-day lives of both customers and employees will soon be able to share data. From that starting point, take an art-of-the-possible approach by identifying the potential opportunities these new data streams could create for them. Indeed, they could consider going beyond test-and-learn, and instead take an approach that embraces the notion of “learn fast, fail fast.”
On a more tactical level, however, firms will need to pay attention to the operational side of the opportunities they may identify. The avalanche of IoT-generated data will dwarf firms’ current data volumes, threatening to overwhelm already-inadequate strategies and technologies in place to manage and capitalize on these data. Accommodating this increased data flow will not come cheap: Both data management and analytical capabilities will require a quantum leap forward. And firms may need to rely on new information brokers to manage and allow centralized access to these data if they are to be of any benefit.
Even though, for most FSIs, the presence of a physical thing is absent from the products they offer and the operations they maintain, the industry is increasingly informationcentric at its core, and has plenty of hard-won experience in information management.
Firms that get ahead of this trend will likely be at an information advantage, where faster, better, and cheaper insight can create opportunities for improved customer experience and operational performance. In many ways, the opportunity for FSIs can be to decommoditize products and services that are differentiated based on their command of these data flows. Regardless of which of the scenarios imagined above emerge, the stark reality is that an increasingly large percentage of the physical world will be connected to computing power of one kind or another, and we’re only at the beginning of what could be a vastly different world from what we see today. Reflecting back on Kevin Ashton’s vision that computers may someday be able to see, hear, and smell the world for themselves, it could be argued that financial services has a built-in advantage.
Deloitte’s Internet of Things practice enables organizations to identify where the IoT can potentially create value in their industry and develop strategies to capture that value, utilizing IoT for operational benefit.​
To learn more about Deloitte’s IoT practice, visit http://www2.deloitte.com/us/en/pages/technology-media-and-telecommunications/topics/the-internet-of-things.html.
Read more of our research and thought leadership on the IoT at http://dupress.com/collection/internet-of-things/.For nearly half a century, technology has underpinned critical business and logistics operations on which FedEx customers depend. Almost a decade ago, we committed to an expansive technology renewal initiative based on an ongoing vision for cloud and everything-as-a-service. We began a journey to simplify and modernize our monolithic legacy systems by creating a collection of orchestrated microservices.
We’re wrapping up the primary phase of the IT renewal initiative, and it’s nothing less than a complete refactoring of legacy software applications that typically have long development, testing, and deployment cycles. Our new service-oriented, cloud-based model is more value-driven. The technology team manages software functions as interoperable microservices that can be used across multiple platforms. They are smaller, incremental, and modular, with iterative delivery cycles that enable us to rapidly adapt to ever-changing business circumstances and help us remain in alignment with our customers as they adopt API- and service-driven architectures and workflows.
As the internet of things (IoT), advanced analytics and blockchain emerged, we were able to leverage them to sustainably develop innovative new products and services for our customers. We’ve been able to position ourselves ahead of the curve on these and other emerging technologies. For example, we developed and are testing small, embeddable IoT sensors—each about the size of a pack of gum—that provide drop-in connectivity using Bluetooth Low Energy (BLE) wireless networks. This allows us to dramatically expand the amount of shipment data we collect beyond date, time, and location stamps to include temperature, speed, and a host of other measurements. The application of real-time analytics to the sensor-collected data improves visibility into the transportation network, automatically predicts the flow of shipments, and optimizes delivery routes by dynamically routing shipments to bypass network clog points.
When IoT and analytics are combined with blockchain, they have the potential to improve existing chain-of-custody systems and processes. Embedded IoT sensors can automatically transmit data to a blockchain ledger as a shipment moves from point of supply to point of demand, enabling carriers, regulators, and customers to track the provenance of goods, combat illegal and counterfeit products, and simplify the cross-border shipping process. Ultimately, we expect the impact of these technologies to extend beyond product shipments to the end-to-end life cycle of a product as it moves through the supply chain.
To stay ahead of the innovation curve, we must be responsive, which requires an agile framework that allows us to rapidly and iteratively adapt, deploy, and pivot when the market demands it. For instance, our experiments with sensor-based logistics stretch back more than a decade with the launch of our SenseAware device. Initially, we deployed sensors that relied on cell phone networks, migrating to BLE network technology when it proved more efficient. Large and expensive, the original sensors had to be reclaimed and reused. As IoT capabilities matured and became more cost-effective, we were able to roll out smaller, less expensive sensors at scale.
We also embrace risk-taking innovation when the potential reward outweighs the risk. For example, we calculated that the cost of experimenting with blockchain—and potentially concluding that it wasn’t useful—would be a fraction of the cost of not making an early blockchain move at all. Our willingness to take an early risk paid off. As a charter member of the Blockchain Research Institute and current standards chair of the Blockchain in Transport Alliance, we have access to invaluable contacts and resources in the blockchain industry.
We know this is a continuous journey—we can’t ever stop transforming. New competitors are agile and technologically savvy, so we plan to continue to evolve our analytics capabilities and to integrate AI into the logistics network. And there are a few more legacy systems whose long tentacles haven’t been fully pried out yet. But because we can’t predict the next innovation or market force, we haven’t locked ourselves into processes, investments, or technologies that aren’t adaptable to future unknowns. I don’t always know what’s coming next, but with an adaptable set of services and the ability to be agile and iterative, I know we’ll be much faster at delivering value.By Amry Junaideen, Risk & Financial Advisory Life Sciences and Health Care leader, Deloitte & Touche LLP
Remember six degrees of separation? This is the idea that every person on the planet is no more than six social connections away from each other. If each person on the planet knows at least 44 others, the number of potential contacts tops seven billion in just six steps (44 to the sixth power).1
Similarly, the Internet of Things (IoT) can connect people, their devices, and their data to clinicians, health systems, pharmaceutical companies, researchers, medical device manufacturers, and other stakeholders via the internet. While this emerging era of interconnectivity could be a huge step forward, it also creates a substantially larger attack surface for cyber-attacks.
I recently moderated a webinar that looked at some of the potential risks created by this cyber-everywhere environment. We also discussed strategies life sciences and health care companies can use to identify and safeguard their digital crown jewels. During the presentation, my colleague John Lu explained that cyber is evolving into a living, learning, interconnected system where all players in the health ecosystem are beginning to work collectively toward a common objective of seamlessly trading information back and forth.
Just a few years from now, as many as 20 billion devices could be connected to the internet (personally, I think this estimate might be a bit low).2 In health care, the information generated by connected devices could generate meaningful data that might help improve medical devices and pharmaceuticals, our level of understanding, and the health of consumers. A digitally enabled pacemaker, for example, could transmit a patient’s data to a physician’s office, which might be integrated with a health system. The data generated by the device might also be collected by the manufacturer, and at some point, that information could become part of a database tapped by researchers or other stakeholders.
In 2017, hackers gained control over an internet-connected fish tank in a Las Vegas casino and used it as a backdoor to enter the casino’s high-roller database.3 Internet-connected sensors regulated water temperature, food, and the cleanliness of the tank. The unprotected device allowed the hackers to access the casino’s database and transmit information to a device in a foreign country. While this might seem like an Oceans 11 plot, it is not. It illustrates that any unsecured internet-connected device could be an unlocked door for someone with criminal intent. This is even more critical as the costs associated with cyberattacks continue to escalate.
The cost of a cyberattack in life sciences and health care can be particularly devastating—especially in markets where revenues are flat or declining—and costs can add up quickly. Across all industries, the average cost of a security breach is about $3.9 million. This assumes an average of 26,000 records per breach multiplied by the average cost of each record, which is about $150. The costs are dramatically higher in health care and life sciences where the average cost of a breach tops $6.5 million.4 That’s 65 percent higher than other industries. This is because patient records contain quite a bit of valuable information that can be exploited.
As I noted in a My Take last May, electronic health records (EHRs) can contain a wealth of exploitable information—everything from demographic information to work history to financial information. This information can be worth substantially more on the black market than financial records and other types of data.5
Additionally, the cost of a breach can be felt for years in terms of fewer patients, lost revenue, and recovery costs. Moreover, in a heavily regulated sector like health care, the costs to respond to questions can be dramatic.
Life sciences and health care organizations have historically viewed cybersecurity as an issue relevant only to the IT department. But as data becomes increasingly interconnected, cyber should be considered a first-order enterprise risk. Moreover, the cyber landscape appears to be evolving more quickly than cyber defenses. During the webinar, we discussed the following topics life sciences and health care professionals should consider when evaluating their cyber strategies:
Define your most valuable digital assets: Organizations need to identify and prioritize their most valuable data that would likely disrupt the business if stolen. This can include patient data, applications, and systems. For hospital systems and health plans, this might be patient/member data. In life sciences, it could be intellectual property.
Organizations need to identify and prioritize their most valuable data that would likely disrupt the business if stolen. This can include patient data, applications, and systems. For hospital systems and health plans, this might be patient/member data. In life sciences, it could be intellectual property. Keep up with cyber-related regulations: Several federal government agencies have taken a renewed interest in cyber and have engaged the assistance of medical device manufacturers and other stakeholders within the health care community. For example, in October 2018, one agency released a revised draft guidance on premarket considerations for medical device cybersecurity. 6 The guidance refines expectations related to the cybersecurity considerations a manufacturer should adhere to during the design and development of a medical device.
Several federal government agencies have taken a renewed interest in cyber and have engaged the assistance of medical device manufacturers and other stakeholders within the health care community. For example, in October 2018, one agency released a revised draft guidance on premarket considerations for medical device cybersecurity. The guidance refines expectations related to the cybersecurity considerations a manufacturer should adhere to during the design and development of a medical device. Build threat intelligence and analytics capabilities: Stakeholders should understand potential threats and develop plans for responding. Consider penetration testing when designing devices or implementing new IT systems. The idea is to try to hack a device or system before it becomes connected to the internet to make sure it is resilient.
Stakeholders should understand potential threats and develop plans for responding. Consider penetration testing when designing devices or implementing new IT systems. The idea is to try to hack a device or system before it becomes connected to the internet to make sure it is resilient. Minimize internal threats: Health care is an industry where people inside the organization pose a bigger threat than outsiders. Nearly 60 percent of cyber-related incidents in the health sector involve someone from inside the organization. According to our research, Communicating the value of cybersecurity to boards and leadership, organizations identified hosting regular cyber threat simulations as a top practice for educating employees.
The internet is making the world a much smaller place by connecting all of us (and our devices and data) in fewer than six steps. While the benefits of a cyber-everywhere environment are enormous, cyber risk is now one of the biggest threats our health care and life sciences clients face. Once stakeholders understand the potential risks in this digital world, they can be better positioned to safeguard their data, their customers, and consumers.
3. Is your fish tank listening? A roadmap to dipping your toes in the IoT waters, TechTarget, November 10, 2017
6. Statement on FDA’s efforts to strengthen the agency’s medical device cybersecurity program, October 1, 2018Help clients understand the strategic context and full economic picture before embarking on an IoT journeyAfter years of hype, anticipation, and steady uptake, the Internet of Things (IoT) seems poised to cross over into mainstream business use. The number of businesses that use the IoT technologies has increased from 13 percent in 2014 to about 25 percent today. And the worldwide number of IoT-connected devices is projected to increase to 43 billion by 2023, an almost threefold increase from 2018.
This level of uptake is both a result and an impetus of the developing technologies that underpin the IoT. For one, technological advancement means that IoT technology will become easier to implement, opening the door for a wider variety of companies to benefit from IoT applications. Indeed, although large enterprises began to invest their sizable resources in IoT technologies years ago, the beneficiaries of this latest wave of IoT maturity will be small and medium-size enterprises. While they may not have the means to execute bespoke implementations, they can still invest in easy-to-use IoT solutions.
As frequent investors in midsize companies, private equity (PE) funds should re-evaluate the IoT as a sector that can help create significant value. To that end, this article will serve as an overview of the growing market for the IoT, the technology’s major applications, and the elements within the IoT technology stack. These insights can then be translated into business benefits for PE funds interested in becoming involved with the IoT as investors, owners, and partners.
Sidebar Varied growth within the IoT depending on underlying technology Because IoT technologies are at different levels of novelty, they are projected to grow at different rates. Wide-area IoT networks extend over large geographic areas, in which connected objects typically communicate at a low data volume. The number of associated devices is projected to grow at 30 percent per year from 2016 to 2022. Wide-area IoT is expected to benefit from the rollout of 5G technology, which will rapidly increase bandwidth and improve network performance. In addition, emerging low-cost alternatives to cellular technologies will facilitate the growth of new wide-area IoT networks. Short-range IoT networks cover small areas. They are primarily found in applications for Industry 4.0 and smart homes and are projected to grow at 20 percent per year from 2016 to 2022. Smartphones, a mature product category, are projected to grow at 3 percent per year. The advent of 5G connectivity might elevate growth rates because of demand for new equipment. Personal computers and tablets, another mature category, is stable at 0 percent annual growth. Although tablets still see some uptake in enterprise settings, personal computers are already in decline as a category.
Advanced principal technologies and a proliferation of devices have helped fuel the growth of IoT technologies. In fact, investments in IoT technology are projected to grow at 13.6 percent per year through 2022 (see sidebar “Varied growth within the IoT depending on underlying technology”). Further growth in the coming years will be possible thanks to new sensors, more computing power, and reliable mobile connectivity.
Sensor technology—embedded in IoT devices—will continue to become cheaper, more advanced, and more widely available. In turn, this availability and cost-effectiveness will make new sensor applications possible, including large-scale monitoring and detection. Meanwhile, computing power has increased about 100 times in the past 15 years. Applications such as real-time analytics and artificial intelligence can thus shift activity from local devices toward cloud and edge computing solutions. In addition, improved mobile connectivity with the advent of 5G will allow new applications for experiences such as augmented and virtual reality.
Finally, the IoT market will grow because existing IT devices will need to be linked to the IoT. Growth in traditional connected IT devices is admittedly moderate—about 2 percent per year. However, the installed base of more than five billion smartphones, two billion personal computers, and one billion tablets indicates a massive market for device integration.
Sidebar IoT solutions at two private equity–owned companies Two companies had recent successes improving their business operations with IoT tools. One pest-control company deployed a fully automatic solution that uses cellular connectivity to continuously monitor and control pest activity. This solution’s features made it more effective for customers than conventional pest-control services and was highly profitable for the provider. Ultimately, the IoT tool replaced the standard physical and manual pest-control tools, avoided the use of pesticides, and generated data and documents required for regulatory compliance. Similarly, a specialty-chemical company used a suite of IoT solutions to improve its manufacturing and supply chain performance. The company was able to track overall equipment effectiveness online, eliminating bottlenecks in its operations, which led to significantly improved output. These companies’ results are typical. Implementing IoT solutions often generates efficiency gains of 20–30 percent by improving performance in areas such as delivery time and pricing for tailored opportunities. In addition, these solutions can help position private equity owned companies for their next phase of growth and new investors.
The IoT already numbers more than 200 known applications in enterprise settings, but IoT adoption isn’t limited to large companies. And early adopters have moved beyond pilots to scale IoT solutions across their businesses. Indeed, IoT technologies have already given rise to a number of landmark applications in sectors as diverse as Industry 4.0, smart cities, smart homes, connected cars, and e-health. Furthermore, advances in the technologies that contribute to the IoT mean that all affected sectors can now access functionality that did not exist five years earlier. For instance, B2B companies have started using Industry 4.0 technologies to maintain direct connections to their products in the field. This constant monitoring makes predictive maintenance possible and improves efficiency and equipment uptime (see sidebar “IoT solutions at two private equity–owned companies”).
The IoT technology stack has advanced over the past five years—in the meantime, each layer holds significant market growth opportunities. Device-enablement platforms have an especially strategic advantage of enabling related IoT growth while still in their own growth phase.
Smart devices—the foundational layer of the IoT technology stack and the most mature product category—are dominated by large manufacturers and specialist suppliers and enjoy healthy market growth (Exhibit 1).
Exhibit 1 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
The connectivity layer of the IoT technology stack is most tightly bound to mobile-network operators that offer standard cellular connectivity. A small number of well-financed start-ups have targeted this layer of the stack and have made progress in subsegments such as low-power wide-area connectivity. Connectivity technology occupies a still-growing market that’s strongly influenced by international standardization in this technology layer.
In the third layer of the stack is cloud computing (which facilitates central processing and storage of data) and enablement platforms (which facilitate access to devices, data across devices, and connectivity standards). Complementary analytics and computational tools have emerged to interpret, visualize, and produce insights from device data. Together, these platforms have proliferated and developed over the past five years and now simplify device integration and application implementation—a favorable growth outlook for key players.
The final and top layer, business applications, will continue to be highly fragmented, with many disparate solutions and established companies coexisting with significant start-up activity. Because of its relatively early life, the largest IoT financial opportunities will likely come from this layer of the stack. However, cloud computing and device-enablement platforms will also be technologically and financially important.
Cloud platforms, the hardware and operating environments of web-based data centers, developed quickly over the past half-decade and now grow at a CAGR of 18 percent. During that time, large technology providers contributed their data-storage capacity and computing power as crucial fuel for the growth of IoT applications, which helped create numerous sophisticated functionalities for security and analytics. These functionalities were aided by strategic, technical partnerships between providers of specialized services that further augmented the value of cloud computing. For instance, a provider of cloud infrastructure might partner with a supplier of analytics solutions. In that vein, advances such as mobile edge computing (which reduces network congestion and improves application performance) can make IoT solutions easier to implement and use.
Sidebar Applications of device-enablement platforms Device-enablement platforms make many uses of the IoT technologies possible. This role has made them a lynchpin of the technology stack. Some of the most important IoT applications of device-enablement platforms, which are now worth €2.1 billion in revenues, include the following: Device connectivity, or basic data connections through a platform, plus troubleshooting for all IoT devices Remote monitoring for real-time status monitoring Remote control for IoT devices Incident management allowing for automatic reset and repair procedures for malfunctioning equipment However, device-enablement platforms are also still heavily used for traditional IT equipment, even though the offerings for the IT market and IoT market tend to come from different companies. The most significant capabilities of device-enablement platforms for IT, a €8.3 billion revenue market, include the following: Unified support plays a role in troubleshooting IT equipment, access management, and file transfers.
Remote access allows users to access and directly control IT equipment, including local data and software tools. In small- or home-office and small and medium-size enterprise settings, users generally use standard platforms; meanwhile large enterprise customers might use proprietary solutions and customized versions of standard platforms.
IT management involves monitoring and error detection, patch management, over-the-air updates, and data backup.
Augmented reality field support is training, instruction, and direct online support for field professionals (such as repair technicians and machine operators).
Device-enablement platforms—connecting devices, cloud providers, and applications for optimal processing in IoT settings—are a notable source of growth and value. In a nutshell, device-enablement platforms improve financial performance across cost, revenue, and operating efficiency, especially for midmarket companies (see sidebar “Applications of device-enablement platforms”). These platforms’ ease of implementation helps midmarket companies take advantage of IoT opportunities, even as these companies have fewer resources for bespoke solutions compared with major enterprises.
Our research indicates that as device-enablement platforms become more important, in part due to uptake among small-to-medium-sized enterprises and small- and home-office users, their corresponding revenue pools will continue to grow at an average CAGR of 24 percent, 48 percent for the IoT use cases (Exhibit 2).
Exhibit 2 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
The majority of the device-enablement value pool is based in the Americas, where it was worth €5.5 billion in 2018. Device enablement’s importance to the IoT and its global revenue growth also means that both technological and business opportunities will be almost geography-agnostic and grow at similar rates. And although enterprise customers will remain the largest customer segment, device-enablement platforms will see fast uptake among small and mid-sized customers.
The growing market for IoT technology reflects some of the ways in which maturing technologies have begun to fulfill the promises of the IoT. PE funds should evaluate opportunities to leverage IoT in their portfolio companies and look for emerging investment opportunities in both the IoT market and in sectors that can reap outsized benefits from these technologies.​Companies often see Internet of Things (IoT) projects stall or fail despite increased spending on these initiatives. However, improvements in areas such as security, data management, and performance could help companies better manage their investments.
While enterprise spending on Internet of Things (IoT) technology is growing briskly, many projects have struggled. The good news: Steadily improving technology is helping to overcome some of the barriers to IoT adoption. The five vectors of progress laid out here aim to help business and technology leaders time their investments effectively.
In the last two years, vendors have brought to market numerous solutions designed to protect IoT devices from attack at both the hardware and network levels 1
Major IoT platform providers now boast dozens of partnerships and integrations with providers of IoT component technologies
Low-power wide-area networks are providing low-cost connectivity for IoT devices in nearly 100 countries 2
Launches of hardware and software products that support “edge computing”—analyzing data close to where it is generated rather than in the cloud—are up more than 30 percent so far in 2018 compared to all of 20173
Enterprises are investing big money in Internet of Things technology. One three-year projection foresees companies spending nearly $15 billion on IT consulting and systems integration services to build and implement IoT solutions.4 As this market develops, it is becoming increasingly specialized. Each of the major market segments—enterprise/industrial, consumer, and services/public sector—presents distinct opportunities to create value through diverse applications. (See table 1.)
Learn More ​Explore the Signals for Strategists collection ​Subscribe to receive updates on Internet of Things
The IoT is advancing along a bumpy road, however, with technical challenges keeping many initiatives from achieving their goals.5 In a 2017 survey, more than 1,800 IT and business decision-makers in the United States, United Kingdom, and India reported that close to three-fourths of their IoT projects were failing.6
The reasons are various. Multiple enterprise surveys identify security as a top IoT deployment challenge.7 Other challenges include implementation complexity and costs8 and lack of talent with necessary skills.9 Going to the heart of the value of the IoT, some enterprises are finding it hard to manage, analyze, and derive benefit from IoT-generated data,10 and they struggle to process it in real time to gain actionable insights.11 Fortunately, progress in IoT technology is helping to overcome these obstacles.
We see further adoption of IoT technology propelled in part by progress along five vectors, each of which addresses an important challenge. These progress vectors are not all applicable to every industry or application type. But collectively they will likely continue to help drive adoption of IoT solutions and create new possibilities for business and technology leaders.
New device hardware is helping to overcome the technical challenges of securing IoT devices, while machine learning is helping to secure the networks that connect them. Earlier generations of IoT devices often lacked the necessary computing and battery power to run traditional cybersecurity applications and protocols, leaving them vulnerable to attack.12 But recently, microprocessor manufacturers have introduced low-power hardware products that embed security features—such as providing trusted identities to certify devices on networks—directly into IoT devices.
Securing IoT networks has also been a challenge in part because existing security tools designed for corporate IT networks were poorly suited for recognizing threats in networks of IoT devices. But cybersecurity solutions tailored for IoT networks are becoming widely available. Some use machine learning to recognize IoT devices’ unique network activity and behaviors to spot anomalies and potentially compromised devices; the city of Las Vegas, for instance, is using machine learning-based threat detection to monitor its smart city infrastructure for possible intrusions.13
Things are getting easier for companies looking to develop and deploy IoT solutions, thanks to the introduction of IoT platforms: software that makes it easier to integrate IoT hardware, networks, and applications.14 Providers are mitigating the complexity of building solutions by preintegrating third-party technologies through vendor partnerships.
Over the last two years, leading IoT platform providers have launched and expanded their partner ecosystems and now boast dozens of major vendor partners each. To illustrate how preintegrated components can accelerate the development of IoT applications, several platform providers report helping clients get proofs of concept and pilots up and running in a matter of weeks through their partner ecosystems.15 IoT platforms are already a common element of enterprise IoT deployments: In a recent survey, 57 percent of IT decision-makers said their companies already used them for their IoT projects; another 35 percent said they planned to.16
In addition to IoT platforms—which provide “horizontal” capabilities that can make it easier to build a wide variety of applications—“vertical” IoT solutions continue to arrive on the market.17 These offerings preintegrate sensors, devices, analytics, and other components to create complete solutions. Manufacturers have taken advantage of such turnkey IoT solutions, but they are spreading to more industries. One luxury clothing retailer deployed a platform with preintegrated software, sensors, in-store analytics, and RFID tags from different vendors to gain insights on shopper behaviors and real-time inventory visibility.18 (To learn more about the turnkey IoT trend, see Turnkey IoT: Bundled solutions promise to reduce complexity and accelerate ROI19.)
Low-power wide-area networks (LPWANs) are proliferating worldwide, providing connectivity at low cost and with low power requirements, a crucial advance for a major class of IoT application that relies on battery-powered sensors and spans large geographical areas.
Major telecom players have launched more than 40 LPWANs.20 Smaller LPWAN specialists are also expanding their proprietary networks globally; networks based on the LoRaWAN standard now cover 100 countries around the world.21
Batteries powering LPWAN sensors can last for years, with the networks providing connectivity for IoT devices for as little as $3 per year.22 In comparison, cellular connectivity for IoT devices can cost at least a few dollars per month.23 Rapidly falling LPWAN module prices can also help reduce implementation costs; some are already less expensive than traditional cellular modules.24 ABI Research predicts that LPWANs will connect more than 4 billion IoT devices by 2025, making it the fastest-growing IoT connectivity option.25 (To learn more about how low-power wide-area networks enable IoT adoption, see Internet of Things: Dedicated networks and edge analytics will broaden adoption26.)
The growth of these LPWAN networks is helping drive adoption of IoT-based devices for applications such as condition-based monitoring and optimization of capital assets in smart cities, smart utilities, and smart agriculture projects. One industrial equipment maker is using LPWAN technology to remotely monitor connected boilers, for instance, which would have been too costly with other connectivity options.27 And an Asian water utility firm is using LPWANs to connect smart water meters, gaining better access to meters located underground and in basements than cellular options could deliver.28
AI technologies such as machine learning and computer vision are increasingly being used to analyze IoT-generated data and automate operational decision-making. Nearly every major IoT platform vendor has now augmented its offerings with AI capabilities.
The rich insights and self-learning that AI can provide enhances the value and utility of the IoT in applications such as process optimization, predictive maintenance, dynamic routing and scheduling, and security. For instance, machine learning can reveal hidden patterns in airplane engine performance to make predictive maintenance feasible.29 Seeing new patterns in changing data can be crucial in applications that monitor and respond to changing conditions such as weather in agricultural settings, vital signs in health care, and operating parameters in industrial settings. (To learn more about the convergence of IoT and AI technologies, see Intelligent IoT: Bringing the power of AI to the Internet of Things30.)
Analysis of data generated from IoT devices is increasingly occurring not in the cloud but at the network “edge,” physically close to where the data is generated—on local servers, micro data centers, or even on the device generating the data. New hardware and software product launches related to edge computing and the IoT have increased more than 30 percent so far in 2018 compared to the entire year of 2017.31
Analyzing data at the edge sidesteps the latency associated with transmitting data between the sensors that generate it and the cloud-based applications that analyze it. Lower latency makes it possible to generate real-time alerts and insights that can improve operational safety and performance in industrial, enterprise, and smart city settings, among others. For instance, performing analytics in micro data centers positioned near its plant, a major chemicals manufacturer gained real-time visibility into plant operations, enhancing fire safety and equipment uptime.32 Analyzing data at the edge can also help reduce data transmission and storage costs. A major European rail operator pre-processes data on smart sensors before sending it to the cloud for predictive railway maintenance to save on data transmission costs.33
Additionally, AI technology is increasingly making its way onto edge devices. Major cloud providers have been tailoring their AI solutions for on-device deployments, while manufacturers are embedding AI capabilities directly into smaller, low-power chips designed specifically for smart sensors, cameras, and other IoT devices. Deploying AI at the edge may help avoid running afoul of data privacy regulations and reduce dependency on unreliable network connectivity in remote areas.
Gartner predicts that the majority of industrial IoT data analysis will happen at the edge by 2022, up from less than 10 percent last year.34 (To learn more about how edge computing empowers IoT applications, see Internet of Things: Dedicated network and edge analytics will broaden adoption.35)
The five vectors of progress described above are increasing IoT technology’s value in many industries: reducing risk in health care36 and banking,37 improving operational costs and uptime in mining38 and energy,39 enhancing service delivery in utilities40 and retail,41 and more. This progress is making it easier in some instances for executives to make a sound business case for investing in an IoT solution. As barriers to adoption of IoT technology in the enterprise continue to fall, business and technology leaders would do well to keep an eye on these vectors of progress.Leads the firm’s global work in digital manufacturing and collaboration with the World Economic Forum on technology adoption
April 16, 2018 Pilot purgatory sounds like a hectic aviator schedule, but with the Internet of Things, it signals pilot programs traveling at a snail’s pace – if at all.
While most businesses with pilots believe in IoT’s economic potential, a McKinsey survey in May 2017 found that less than 30 percent of pilots are starting to scale. Eighty-four percent of companies were stuck in pilot mode for over a year and 28 percent for over two years.
Pilots that scale successfully possess common success factors (see figure above). Here are seven based on our research and observations:
Secure CEO support. IoT projects that scale positively have a CEO leading the push. Support from the CEO shepherds a project past the bumpy spots and defends it throughout the organization. Start simple, execute relentlessly. Sustaining momentum requires wins. Be wary, though, of declaring victory too early. Pick a simple use case and follow through relentlessly until you capture value. Successes help land support of frontline employees and expose vulnerabilities around the need for process reengineering, talent, culture and alignment, and go to market. Ponder outcome vs. technology. Rather than becoming enamored by technology, ask more nuanced questions around the business model before choosing a pilot: Value proposition: What is the offering? What user needs does it address? Why is it better? How does it create customer value?
Delivery model: What is the go-to-market model? What parts of the value chain and functions must change? Which ecosystem partners must unite to deliver this?
Economic element: It is easier to see the link to value for operational use cases (e.g., smart factory-related) than it is for companies seeking to drive revenue growth through IoT offerings. Our research shows most value created becomes consumer surplus, leaving a portion for a provider ecosystem to capture. Companies must ask: What portion of this value will the customer share? How many people in the value chain will lay claim to this? What portion of this value flows to the bottom line? What are direct and indirect ways to monetize this? During the pilot stage, testing the business model and the technical viability will improve confidence in delivering value. Focus on people. Companies that scale IoT enlist employees with an entrepreneurial bent and who embrace change. They help set a transformation’s pace and tone. Also required: cross-functional collaboration among those with deep process knowledge, analytical acumen, and digital and IT experience. “Business-building leadership” assists in translating technology to business outcomes and commercial opportunities. Recruiting and retaining this talent is hard, especially in bureaucracies. Treat data as a transformational asset. Properly used data creates a sustainable business advantage and innovative business models. But consider the data sources. One company couldn’t perform analytics on its equipment because it didn’t own the data. Bring clarity around your technology stack. With today’s plethora of IoT platforms, picking the right one proves hard. Ask a set of clear questions around five areas – applications, data management, infrastructure needs, security and edge process/control – to select the right platform. Build an ecosystem of tech providers, not a logo collection. Few website logos reflect meaningful relationships. One company invested $1 million in a test plant after a handshake between its CEO and technology provider. The result: a science experiment that could not scale. Meaningful relationships require a clear value proposition for each party, skin in the game, common objectives, and successes in delivering joint value.
IoT trials get stuck in purgatory for many reasons. This starter list reflects what we see as emerging success criteria.What makes the Internet of Things (IoT) different from the traditional Internet? People, for starters. The IoT doesn’t rely on human intervention to function. With the IoT, sensors collect, communicate, analyze, and act on information, offering new ways for technology, media and telecommunications businesses to create value—whether that’s creating entirely new businesses and revenue streams or delivering a more efficient experience for consumers.
But this also creates new opportunities for all that information to be compromised. Not only is more data being shared through the IoT, among many more participants, but more sensitive data is being shared. As a result, the risks are exponentially greater.
Take the smart home as an illustrative example. Imagine a garage door opener with the added functionality to deactivate the home alarm upon entry. This is a convenient feature for a homeowner entering their home in a hurry. However, now the entire alarm system could potentially be deactivated when only the garage door opener is compromised. The broad range of connectable home devices—TVs, home thermostats, door locks, home alarms, smart home hubs, garage door openers, to name a few—creates a myriad of connection points for hackers to gain entry into IoT ecosystems, access customer information, or even penetrate manufacturers’ back-end systems.
Many technology, media and telecom companies are already grappling with these cyber risk challenges. What are they finding? In this issue of Flashpoints, we’ll take a closer look at some of the more notable developments in the battle to combat cyber risks and take advantage of new opportunities as the IoT expands its reach:NEW YORK, Oct. 24, 2019 — With the number of connected Internet of Things (IoT) devices anticipated to swell beyond 41 billion by 2025 according to a forecast from IDC estimates and the number of cyber attacks on such devices growing exponentially by the day, organizations should put security at the forefront of their priorities around IoT solutions. In an effort to help organizations shore up their security postures, Deloitte offers five tips to address IoT security in the products that organizations deploy in their environments and encourages manufacturers that make connected products to take a secure-by-design approach.
From cameras to toothbrushes, thermostats to hospital infusion pumps, connected devices are actively being targeted by cyber adversaries determined to compromise corporate and individual privacy, construct botnets, place malicious software and steal intellectual property.
The risk of compromise to a connected device is too great to ignore and often too late to reactively respond to. Organizations should adopt a proactive, secure-by-design approach while strategically and intentionally working to monitor and patch outdated legacy equipment, software and infrastructure.
—Sean Peasley, partner, Deloitte & Touche LLP, and IoT security leader for Deloitte cyber risk services.
California is leading the charge with a new Internet of Things Security Law taking effect on Jan. 1, 2020, requiring all IoT devices sold to be equipped with reasonable security measures. Consequently, organizations should prepare and protect their companies, customers and communities. The benefits of IoT connectivity far outweigh the investment in cyber measures to ensure the integrity of the devices, networks and programs.
Take note of every endpoint added: The expanse of IoT increases with every endpoint added into a network. This adds more vulnerabilities and has become a more popular and destructive cyber attack. While the adversarial landscape is always changing, Deloitte advises organizations to bring as much of their endpoint footprint under their security management in order to better secure the attack surface. Industry analysts predict that spending on IoT endpoint security solutions will be more than $630 million in 2021. Once these devices are managed, integration of security tools can be a more effective security focus for the organization. As with most domains within cybersecurity, security professionals realize that in order to meet the complex security challenges of their organizations, they should formulate a sound security strategy and constantly evolve by making continuous improvements to best mitigate their risks.
Align operational technology, IT and security: In addition to IoT, enterprises are managing multiple digital transformation initiatives simultaneously. Yet, according to the “Deloitte Future of Cyber” study, less than 10% of cyber budgets are allocated to these efforts. For companies to be successful with IoT initiatives, they need a new approach. One that helps them understand enterprise and cyber risks; develop a plan to prioritize and mitigate those risks; and then operationalize these efforts by obtaining alignment across key stakeholders: operational technology, IT and cybersecurity. Peasley adds, “IoT spans operational environments as much as it includes wearables, connected cars and products. Organizations should proactively plan for how to identify, track, patch and remediate around how it all could impact their organizations and ecosystems.”
Know the players in your ecosystem: Since the interconnectivity of third-party hardware, software or services may be the source of a security breach, it’s imperative to consider how a covered device interacts with such third parties. Ideally, contracts with third, fourth, and fifth parties should address security updates and concerns. Organizations should establish a third-party risk management program to evaluate the cyber risks of their third parties and supply chain partners.
Employ AI and ML to detect anomalies that humans can’t: You can’t prevent what you don’t know about. Artificial intelligence for IT operations (AIOps) has grown from an emerging category to an IT necessity. AIOps platforms are uniquely suited to establish a baseline for normal behavior and detecting subtle deviations, anomalies and trends. This is significant as IoT turns much of the physical world into robots powered by AI. Organizations should take both a secure by design (DevSecOps) approach in tandem with an AIOps approach to both prevent and identify cyber attacks.
Conduct vulnerability assessments on devices: As cyberattacks continue to grow, organizations should have confirmation that their connected devices — and the environment in which they’re deployed — have been designed, built and implemented with security in mind. Whether through basic testing or a bug bounty program, testing can provide assurance around the security posture of an organization’s devices.
Deloitte’s Cybersphere is a state-of-the-art destination to help organizations explore their most pressing cyber challenges. The Cybersphere features a 24/7 threat monitoring and reconnaissance “Watch Floor,” and labs designed for cyber teams to increase capabilities and confidence as they face ever-evolving cyber threats. It also features a Cyber IoT Studio where organizations can test the security of their connected devices on their networks to help identify whether their most critical assets are secure.
Technical testing services for IoT devices — from autonomous cars and connected medical devices, to industrial control systems, building automation and smart cities.
A center of excellence that provides leading practices for device security testing and certification readiness methods.
Diverse IoT ecosystems to architect and test heterogeneous technologies for a multitude of industry-specific, use-cases with the latest security and control solutions for on-premise and cloud integrations.
Deloitte provides industry-leading audit, consulting, tax and advisory services to many of the world’s most admired brands, including nearly 90% of the Fortune 500® and more than 5,000 private and middle market companies. Our people work across the industry sectors that drive and shape today’s marketplace — delivering measurable and lasting results that help reinforce public trust in our capital markets, inspire clients to see challenges as opportunities to transform and thrive, and help lead the way toward a stronger economy and a healthy society. Deloitte is proud to be part of the largest global professional services network serving our clients in the markets that are most important to them. Our network of member firms spans more than 150 countries and territories. Learn how Deloitte’s more than 312,000 people worldwide make an impact that matters at www.deloitte.com.Regulations should do more than tell companies what they can’t do—rules should help guide corporate players through minefields of uncertainty. It’s a lot of responsibility, especially when it comes to still-developing IoT technology that holds great promise—and real risks.
Imagine Pandora sitting and staring at her box. In a few moments, she will open its bronze lid and release fear, death, and plague into the world . . . but right now she is wracked with uncertainty. What’s inside? The box might contain untold riches to help her new kingdom—but Zeus warned her never to open it. Should she open it and risk punishment, or leave it shut and possibly leave valuable resources untapped?1
In many ways, the story of technological change and regulation is Pandora’s story—technology can be understood only through the lens of risk and uncertainty. Technological change by its very nature causes uncertainty: How could this new technology be used? How might it improve people’s lives? How may it harm those same lives? With the Internet of Things (IoT) at the peak of its hype cycle, these questions are swirling more than ever.2 The challenge is the risk that accompanies all of this uncertainty. Like Pandora, companies looking to implement IoT solutions are facing a box that may contain significant new revenues—and, quite possibly, technical difficulties, future regulatory challenges, or security breaches. Do they risk opening the IoT box and facing these uncertain regulatory issues, or do they leave it closed and risk missing out on the potentially most transformative technology since the Internet?
One key to making an informed decision and ameliorating risk is to reduce uncertainty—in particular, uncertainty about future regulation that may affect IoT practices. For regulators too, pressure is mounting to protect consumers even while IoT technology itself is still developing.3 But with the often-blunt instrument of regulation, this could become a catch-22 of inaction: Regulators take no action because they are uncertain about the technology, so companies take no action because of uncertainty about regulation, slowing technological adoption . . . and further slowing the action of regulators (see figure 1).
But it takes only a shift in perspective to break this catch-22. Consider that government’s relationship with IoT technology goes beyond regulation—agencies are also consumers and developers of IoT infrastructure and applications. In these two roles, government can influence the development of IoT technology, guiding it toward safe, secure, and responsible uses—and saving regulation for indisputably necessary areas such as critical infrastructure or health systems (see figure 2).
To illustrate exactly how governments at all levels can help to guide the IoT’s development—protecting citizens while still encouraging technological growth—this article makes use of a body of industry-specific use cases. The goal: to reduce overall uncertainty, allowing policymakers to understand this complex issue and businesses to see where government action is likely, thereby reducing the risk of their investments in IoT technology.
The first step to reducing the uncertainty and risk around the IoT is to get a better picture of what it is, and how government agencies may need to interact with it. The IoT is the architecture and suite of technologies needed to create, communicate, aggregate, analyze, and act upon digital information in the physical world (see figure 3).
With such a broad definition, the applications and impacts of connected technology on the public sector can cover an equally wide spectrum. Utility providers have created mesh networks of smart meters capable of hosting other communications.4 Automakers and tech companies are investing in autonomous vehicles that may require new public infrastructure.5 Customer advocacy groups are calling on government to create strenuous security and privacy standards for new connected devices.6 Even with this bewildering mix of uses, roles, and industries, agencies’ interactions with IoT technology can be grouped into three categories:7
Government as IoT end user. To the extent that reporters and academics have addressed the government’s relationship to the IoT, articles (including our Anticipate, sense, and respond 8 ) have focused on the question of how government can harness connected technology to better provide services. These address how schools, public utilities, law enforcement, and other government functions can take advantage of the new technologies to break traditional trade-offs and find innovative ways to serve the public. In the interest of space, we will address less commonly discussed roles of government.
Government as infrastructure provider. The investigation of what government policies or regulation may be necessary for effective use of IoT technology begins with understanding connected infrastructure. Just as governments are responsible for building and maintaining their countries’ highways for vehicles, they may be called upon to provide the infrastructure for the IoT. However, with so many different types of communications mechanisms and protocols within the IoT stack, it is unclear at this point exactly what is required to create foundational infrastructure for IoT.
Government as regulator. New technologies necessarily bring with them new uncertainties about their use. These uncertainties represent a risk to the public, which governments at all levels are responsible for ameliorating. Complicating this issue is that, at the emergence of a new technology, the full array of its eventual possible uses cannot be known. Therefore, it can be quite difficult to forecast the potential dangers that such technologies pose to the public.
Already from these three roles, we can see a tension forming in governments’ goals with relation to new technology. As an infrastructure provider, governments seek to support and incentivize further technological development to create new value and new public goods. On the other hand, governments have a duty to protect the public from the risks of both the known and unknown uses of those new technologies. Striking the right balance between these goals, and then crafting appropriate policies to achieve them, is the chief challenge facing officials dealing with emerging technologies.
The first step in order to strike that balance is to understand what the IoT needs in order to reach its full potential. To do so, we’ll look at some industry-specific case studies that reveal the key bottlenecks impeding the IoT from creating new value.
The IoT is fundamentally about bringing the benefits of information to the physical world. Therefore, for the technology to create value for customers, companies, or society at large, the information created by sensors needs to reach those individuals or machines that can take informed action on it. In other words, information must be able to complete the Information Value Loop. In this sense, the race to create IoT solutions is really a race to alleviate a series of bottlenecks that restrict or stop that flow of information. Understanding where and how these bottlenecks are restricting the flow of information, then, can help companies and government alike understand what is holding back the development and implementation of IoT technology as a whole.
Through an extensive IoT research campaign, Deloitte has built up a large collection of use cases, with IoT examples in every industry.9 In analyzing these use cases, we found that once companies began generating data with IoT technology, the most common bottlenecks arose in the communication, aggregation, and analysis of that data.10 By looking at each of these bottlenecks, we can begin to sketch out where government action is needed and where it may be counterproductive. (See figure 4.)
At least as far back as the Industrial Revolution, there has been a clear role for governments to coordinate, if not directly provide, the basic infrastructure needed for economic development.11 When infrastructure meant highways, bridges, canals, and airways, the government’s role was rather clear: In situations where private industry could not or would not act, the public sector would provide the physical roads, ramps, and rails over which the traffic of commerce could move.12 Same with power lines and gas connections, and with telephone lines and submarine communications cables: The government has an interest in linking citizens, even in rural areas that companies might find unprofitable to service.
But when it comes to the Internet of Things, government’s role is less clear—as are its possible actions as an infrastructure provider. After all, with IoT technology, it is information—not trucks, planes, or rail cars—that creates value.
No question, though, that government does play a key role. While you may not be able to see it, information still travels via public-sector infrastructure much as cars traverse highways. For example, every smartphone is able to deliver driving directions only because of the multibillion-dollar government investment in GPS satellites13—not to mention the electromagnetic spectrum, a finite resource that government regulates to carefully share among competing public, private, and even military uses. With the number of IoT-connected devices expected to increase by 3 to 30 times over the next 15 years, the strain on existing spectrum allocations is enormous.14 So it is perhaps unsurprising that governments around the world are taking steps to open up more spectrum to wireless uses. Whether allocating previously unused spectrum to IoT applications or repurposing spectrum from older uses, governments are working to provide the raw materials that connected technology needs to grow.15
Perhaps most interestingly, where paving highways and laying track cost taxpayers millions, allocation of spectrum is technically free—save for the time it takes to do the work. In fact, the potential IoT-based advances mean that governments can in some cases actually generate significant revenue from reallocating portions of spectrum. Recently, both US and Canadian telecom regulators were able to raise billions of dollars from spectrum auctions, with the 2015 Canadian sale raising more than $2 billion and the US auction a year earlier generating a record $44.9 billion.16 In exercising its role as IoT infrastructure provider, a government may be able to efficiently allocate scarce wireless resources and, in the process, create benefits for both companies and taxpayers.
For connected technology to create real value, it should be able to sense not just one particular piece of data but data from multiple sensors and sources. In reality, this means that different devices from different manufacturers often must be able to seamlessly communicate and share data. To do so requires common standards for data format and communications protocols. At first glance, this represents a great opportunity for government to intervene in its role as regulator to create one common standard and accelerate the IoT’s growth.
However, government action on standards may be superfluous or even counterproductive. Industry is not insensitive to the need for standards and has formed a number of competing groups aimed at designing the standards of the future.17 While none of these standards has yet won out, that is more a function of the continuing development of the technology and market, rather than intransigence of the groups.
In fact, with many of the underlying standards in place for communication protocols, such as 4G and Wi-Fi, and device addressing, such as IPv6, the situation resembles the early days of mobile operating-system competition.18 In that arena, it was not government regulation but, rather, a dominant player creating a superior platform that created the de facto standard. Industry leaders produced winning mobile OS platforms that unified many elements of a fragmented technology landscape to produce industry standards.19
A similar process may be under way with IoT technology, leading both government and industry leaders to conclude that government regulation of IoT standards would be a mistake.20 While there may be a role for agencies to play in setting out IoT guidelines for specific critical industries—such as ensuring interoperability of electronic health data—full regulation of IoT standards may actually slow innovation rather than accelerating it.21
This is not to say that there is no role for government in its capacity as a regulator. The IoT’s expanding implementation means more and more data being generated about things and people. Companies aim to combine and analyze all of this data to create new insights and provide services to consumers. The catch: In the process, IoT technology may expose individuals’ privacy in new ways. Research shows that it can take as few as four data points from mobile communications to individually identify an individual.22 In analyzing data such as purchasing history or speed patterns of your connected car, an IoT system can unintentionally reveal sensitive private information such as attendance at a particular church or movements of a competitor’s sales force. Apart from obvious security concerns from such data attracting criminals and identity thieves, breaches may leave users justifiably uneasy.23
In the interest of building confidence in connected technology, there is an undeniable need for government to regulate the IoT from the perspective of consumer protection, especially as it relates to security and privacy. The difficulties will sound familiar to anyone involved in government regulation of technology: IoT applications are fast proliferating—with new technologies, processes, and uses emerging almost daily—while traditional regulatory processes are often measured and slow, with publishing a new rule in under three months usually possible only in an “emergency.”24 This is to say nothing of the legislative gridlock that can stall for years the authority to even make those new rules in the first place.25
Even beyond the general difficulties in regulating fast-moving technologies, privacy presents special challenges. As digital information moves rapidly around the globe, it can encounter many different regulatory regimes. Sure, companies can aim to comply with each nation’s privacy rules, but these different rule sets are often built upon entirely different legal conceptions of privacy, resulting in at times contradictory rules, making compliance with all rules impossible.26 If the IoT is to reach its potential, it will almost certainly involve collecting and transmitting data across national borders. Decades and centuries of transnational trade have firmly established regulation across borders, but data is both different and intangible, and nations’ underlying differences on the core concepts of privacy make such regulation highly unlikely for IoT technology. Issues with transnational fragmentation await resolution in a way that both protects consumers globally yet allows connected technology to thrive.27
In this way, we have returned to Pandora’s box—the fundamental issue of regulating new technology. Governments should step in to protect consumers in some way, despite uncertainty about rapidly changing technology. Similarly, companies working to develop IoT applications face uncertainty around potentially impactful regulations. That said, however new and expansive IoT technology might be, these uncertainties shouldn’t dramatically hold up development of either applications or regulations. For one thing, as we have seen, only a few areas actually demand regulatory intervention. Second, the consumer privacy and security issues raised by connected technology are not new. While the mobile nature of IoT technology may cause these issues to pop up in new and unexpected places, governments and companies are well equipped to deal with security and privacy issues once identified. In the United States, agencies such as the Consumer Protection Bureau and legislation like the Fair Credit Reporting Act are empowered to act to protect consumers from IoT-based security and privacy challenges, even if the pace of new IoT developments may require these familiar actors to pick up some new tools.
If regulation’s ultimate purpose is to encourage companies and others to take into account externalities such as security and privacy, there can be a number of effective tools that can accomplish this.28 Two untapped tools for governments at every level are their actions in other roles relating to IoT technology—namely, user and infrastructure provider—which, again, offer more certain and stable starting points than trying to hit the moving target of regulating a rapidly changing new technology. Agencies can use their activities as IoT users and infrastructure providers to help guide and shape the development of connected technology.
Set a good example: government as an IoT user. First and foremost, governments exist to provide services to citizens. Given the IoT’s tremendous power to increase efficiency and provide new services, it is no surprise that much of the discussion center on how agencies can use connected technology to better serve citizens. Hardik Bhatt, CIO of the state of Illinois, summarizes: “The first and very active role of government is government as a customer.”29 It is exactly by being large-scale consumers of connected services and technology that agencies can influence IoT development through buying power, not regulations. By setting responsible requirements and buying secure, privacy-respecting solutions, government can, as Bhatt describes, “start being the role model of how the Internet of Things technology can be used.”30
The impact of a public-sector role can go beyond the economic impact of the dollars that agencies spend to set up IoT solutions. It can extend to the heart of the technology itself. Humans can be both incredibly creative and also incredibly lazy, and programmers are no exception. As a result, once a programmer finds a successful solution to a certain problem, others tend to copy that code and paste it into new applications, skipping the usual rounds of testing. The jumbled result, dubbed “spaghetti code,” can introduce unintended bugs and flaws,31 and with fast-moving technologies, this problem has the potential to quickly spread security holes. While spaghetti code is a problem in every industry, government’s open, public-service nature may put it in a unique position to help the situation: By creating good, solid code and making it publicly available, an agency can be the source or seed for other organizations using connected technology more responsibly.
Reduce function creep: government as infrastructure provider. There’s no question that function creep—a product being used in unanticipated ways—can be an incredibly powerful tool for innovation, such as when a teacher noticed that a wallpaper cleaning putty made a good toy, giving birth to Play-Doh. But function creep can introduce critical security and privacy flaws into new technologies,32 exacerbated by a lack of purpose-built tools, forcing developers to plug in close-enough hardware and software. Government can play a strong role in limiting function creep—and thereby reducing the likelihood of security and privacy vulnerabilities—by making available stable infrastructure for connected technology.
Enable transparency: government as both user and infrastructure provider. The IoT-based distributed denial-of-service attack that shut down Internet access to millions of people on October 21, 2016, highlights a key vulnerability of connected technology. Many people whose devices were compromised by the Mirai malware that launched the attack were unaware that their devices’ security might be substandard; in fact, many did not even know their devices had been compromised.33
Whether dealing with security or privacy, transparency is a critical virtue. In the United States, for example, privacy is governed largely by contracts and user agreements, an arrangement that is untenable if companies conceal their usage of consumer data. Similarly, both governments and companies are powerless to begin to plug IoT cyber vulnerabilities unless they are aware of the basic state of their hardware and software. And when that hardware and software is compromised, each party needs to be able to share information about the attacks and signatures with each other.
In its dual role as IoT user and infrastructure provider, government can help to lay the foundation for this needed transparency.34 Transparency is a critical unsolved challenge in IoT technology, since there’s no practical way to adequately inform consumers about all the uses of their data stemming from potentially hundreds of small devices. Agencies can serve as a model of transparency by finding new ways to solve this challenge, clearly and concisely communicating to users what data is collected and how it will be used.
Similarly, as infrastructure providers, governments can begin to create stakeholder groups and information-sharing venues that can allow for the transparency necessary to combat cyber threats. Here companies can share information on attacks and threats, preemptively benefiting from shared information and concerns—better for everyone than regulators requiring them to reveal data losses. Finally, given the continued threat posed by botnets such as Mirai, governments should consider establishing a security rating system or evaluation organization for new hardware and software products. A public-private working relationship on the model of Underwriters Laboratory may be an effective model for quickly and efficiently establishing the baseline of transparency required for IoT security.35
These same principles can have a double impact at reducing uncertainty: Not only do they help governments act amid uncertainty around connected technology—they can help companies understand how regulators are likely to respond to IoT-related issues. These seemingly small actions can give companies the confidence to innovate and drive the technology further, while protecting citizens’ rights and personal information.
In this way, the IoT resembles Pandora’s box less than it does Schrödinger’s box:36 You can never know ahead of time whether the cat is alive or dead—if the technology will be a boon or a hazard—so you need to plan for both eventualities and try to build in as much certainty as possible. Of course, unknowns are inevitable and not necessarily fatal—after all, uncertainty around the state of the electron did not stop Erwin Schrödinger and others from building modern electronics; in fact, chances are that the touchscreen of the laptop or phone on which you are reading this article harnesses exactly those quantum effects.37 And for government, the key to ameliorating uncertainty, encouraging corporate innovation, and protecting citizens is to consider IoT technology as both user and regulator.The number of cyberattacks, data breaches and overall business disruption caused by unsecured IoT/IIoT devices are increasing because many companies don’t know the depth and breadth of the risk exposures they face when leveraging IoT devices and other emerging technologies.
IoT and IIoT are a set of business and technology innovations that offers many compelling benefits, but they also present significant cybersecurity risks and a greatly expanded attack surface. Mitigating these risks by understanding IoT/IIoT platform security can help organizations realize greater potential and benefits of these innovations.
The following top risks were outlined by leaders from Deloitte Risk & Financial Advisory’s cyber practice and Dragos in a recent Deloitte Dbriefs webcast, The Internet of Things and cybersecurity: A secure-by-design approach:
Not having a security and privacy program Lack of ownership/governance to drive security and privacy Security not being incorporated into the design of products and ecosystems Insufficient security awareness and training for engineers and architects Lack of IoT/IIoT and product security and privacy resources Insufficient monitoring of devices and systems to detect security events Lack of post-market/ implementation security and privacy risk management Lack of visibility of products or not having a full product inventory Identifying and treating risks of fielded and legacy products Inexperienced/immature incident response processes
Security needs to become embedded into the DNA of operational programs to enable organizations to have great products and have peace of mind. Today all sorts of products are becoming a part of cyber: from ovens to instant cookers, 3D printers to cars. Organizations need to consider what can actually go wrong with what is really out there and look at those challenges as a priority.
—Sean Peasley, a partner in Risk & Financial Advisory and the Consumer & Industrial Products leader and Internet of Things (IoT) Security leader in Cyber Risk Services at Deloitte & Touche LLP
Organizations need to think through this. There are a lot of requirements and they need to figure out a strategy. When looking at product security requirements, I see this as a challenging aspect as organizations get a handle around what they are manufacturing. There are organizations for example in industries such as health care, medical devices, and power and utilities that are starting to ask questions of their suppliers as they consider security before they deploy devices into their customer ecosystem. Where I see a lot of organizations struggle is in understanding system misconfiguration or not having the architecture they thought they did in order to make sure their manufacturing environment is reliable.
More than 4,200 professionals across industries and positions participated in and responded to poll questions during the Deloitte Dbriefs webcast, “The Internet of Things and cybersecurity: A secure-by-design approach” held May 30, 2019. Answer rates differed by question.
A majority (81 percent) of respondents indicated that information security is accountable for the securing of connected products in their organization. The information security team is still primarily where boards look to drive their cyber agenda but as the 2019 Future of Cyber survey indicates, cyber is becoming everyone’s responsibility. It is critical to understand that if you are the plant manager you likely have the responsibility to the safety and liability of the operation. But the challenge is that everyone does have a role to play. Ultimately, the CEO is going to be held accountable.
How confident are respondents that their organizations’ connected products, devices, or other "things" are secure today? Not very. More than half of respondents (51 percent) were somewhat confident, while 23 percent were uncertain or somewhat not confident, with only 18 percent feeling very confident in their organizations’ ability to secure connected products and devices. This may be as a result of there being an overall lack of standardization across industries for security and awareness of cyber risks and connected devices.
A positive revelation in the poll results was when 41 percent of respondents indicated that they look to industry and professional organizations for guidance in driving security-by-design within their organizations. Another 28 percent said that they look first to regulatory bodies and agencies that set the standards; and 22 percent indicated their leading practices were developed internally for providing that guidance in driving security-by-design.
According to Peasley and Lee, it is a favorable strategy for organizations to understand leading practices and standards of peer organizations first, and then look to the regulatory bodies that are starting to shape standards and regulations and help inform the standards and regulations that are to come.
These results conflict with another question regarding whether their product teams use a defined set of product cybersecurity requirements as input for requirements selection. Twenty-eight percent use an industry defined framework, and 41 percent indicated a custom framework, while 30 percent of respondents indicated “No” that they didn’t use a defined set of requirements. The results of this question indicate there is still much work to do across the industry to influence and inform on standards for cybersecurity.​Enterprises are increasingly complementing their cloud-based IoT solutions with edge computing to accelerate the pace of data analysis and make better decisions, faster.
Just a few years ago, many expected all the Internet of Things (IoT) to move to the cloud—and much of the consumer-connected IoT indeed lives there—but one of the key basics of designing and building enterprise-scale IoT solutions is to make a balanced use of edge and cloud computing.1 Most IoT solutions now require a mix of cloud and edge computing. Compared to cloud-only solutions, blended solutions that incorporate edge can alleviate latency, increase scalability, and enhance access to information so that better, faster decisions can be made, and enterprises can become more agile as a result.
Learn more Read more from the Internet of Things collection Explore the Emerging technologies collection Subscribe to receive related content from Deloitte Insights
That being said, complexity introduced by edge computing should justify the objectives at hand, which include scale, speed, and resiliency. A choice that goes too far in one direction typically introduces substantial operational complexities and expenses. Ultimately, the enterprise should take into consideration a full range of factors that reflect its own particular objectives in designing and building an IoT solution in the first place.
In this article, we discuss when and how enterprises can optimally make use of both the edge and the cloud in their IoT solutions. We explain the roles edge and cloud computing play, why the edge may be needed, and how to approach selecting a solution. We also explain some of the complexities with edge computing and provide some use cases.
What is edge computing Edge computing is a distributed architecture functionality, such as processing and storage, that is located closer to—even on—the very source of the data. Examples include cameras with on-device vision processing and wearable medical devices that send data to a mobile phone via Bluetooth. Given these qualities, making a balanced use of both edge and cloud computing is now often considered a key requirement of designing and building enterprise-scale IoT solutions. The key representative functionality often used at the edge can be seen in figure 1.
We have experienced a veritable explosion of cloud adoption in the past decade—the IT functionality of many modern companies exists exclusively, or in large part, in the cloud.2 Among the many benefits of the cloud infrastructure are cost effectiveness, scale, self-service automation, interoperability with traditional back-office systems, and centralized functionality.3
At the same time, the amount of sensor-generated data has grown strongly too, and this trend is expected to continue in the years ahead.4 Because data can become essentially valueless after it is generated, often within milliseconds, the speed at which organizations can convert data into insight and then into action is generally considered mission critical. Therefore, having the smallest possible latency between data generation and the decision or action can be critical to preserve an organization’s agility. However, as the speed of data transmission is inviolably bounded by the speed of light, it is only by reducing the distance that data must travel that the latency challenge can be mitigated or avoided altogether. In a cloud-only world the data ends up traveling hundreds or even thousands of miles, so where latency is critical to a solution, edge computing can become key.
According to one estimate, as much as 55 percent of IoT data could soon be processed near the source, either on the device or through edge computing. Indeed, scale plays a big role in this likely shift—growing data demands will likely put the focus on latency, and decreased latency could dramatically improve the response time, thereby saving both time and money.5
Latency is just one of the many reasons to drive the addition of edge functionality to an IoT solution. A fuller list of the potential benefits of edge computing is given in figure 3.
In bringing edge and cloud computing to life, an understanding of real-world cases can go a long way. Constant technology evolution, such as the eventual availability of 5G, often affects the cost/latency/balance equation. As such, it is pertinent to consider current conditions in making decisions rather than simply defaulting to previous choices. Being mindful of all drivers while designing an IoT solution is important, as multiple drivers may apply in a given situation.
The IoT can have a dramatic effect on an organization’s ability to be more agile. Given below are some ways in which the edge and cloud help aggregate and transmit data on behalf of enterprises connected by the IoT.
Enterprises are quickly moving toward an event-driven architecture and real-time automated digital processes.10 But when you consider that many manufacturers have multiple plants across geographies—each typically with unique characteristics and functional requirements— the challenge to maintain an exclusively centralized data-analysis capability in the cloud or at a corporate data center becomes apparent.
To be sure, cloud computing offers a number of benefits and it most certainly has a role in smart manufacturing. With data in the cloud, a centralized operations facility can monitor systems and processes across a large, possibly global, portfolio. It is also possible to undertake comparative analysis across the full portfolio that can determine potential for optimizations.
Still, we envision that an integrated edge–cloud architecture would provide the kind of speedy and nearly unimpeded connectivity that smart factories require.
Figure 4 illustrates how the edge and cloud typically work with sensors and devices on a manufacturing floor.
The device layer represents individual pieces of equipment that are connected to local operational technology and IoT capabilities for immediate interactions. At this layer, machine learning (ML) scoring or inferencing is done that is based on ML models trained in the cloud. Significant amounts of raw device data are also stored here.
represents individual pieces of equipment that are connected to local operational technology and IoT capabilities for immediate interactions. At this layer, machine learning (ML) scoring or inferencing is done that is based on ML models trained in the cloud. Significant amounts of raw device data are also stored here. While the device layer provides visibility and control of individual pieces of equipment, the plant apps layer provides visibility and control across all connected pieces of equipment in a plant. The edge connectivity layer provides the necessary connectivity between the individual pieces of equipment and the plant apps.
provides visibility and control across all connected pieces of equipment in a plant. The provides the necessary connectivity between the individual pieces of equipment and the plant apps. The enterprise layer, which is cloud-hosted, provides primarily visibility, and some control, across multiple plants—a portfolio view. Enterprise analysis and ML algorithms are developed in this layer to predict and provide actionable intelligence—the ML models trained and re-trained here make use of data from across the whole portfolio of plant equipment and are then “pushed” to the edge and eventually to the IoT software at each piece of equipment, making operations smarter with the information.
The rise of smart, connected IoT devices and ubiquitous connectivity has created an opportunity to transform buildings—whether they are offices, retail stores, factories, or hospitals—into cost-efficient, responsive environments for delivering exceptional experiences to their occupants.11 Smart buildings are digitally connected structures that combine optimized building and operational automation with intelligent space management to enhance the user experience, increase productivity, reduce costs, and mitigate physical and cybersecurity risks. Smart, digital buildings span industries and uses, but all of them can provide the same basic capabilities: They connect humans; they provide better control of facilities and operations; they support ways to collaborate digitally; and they enable owners to conserve resources, including space, energy, water, and employees. Each of these four capabilities can form the basis for creating a smart building strategy that can deliver measurable benefits. Figure 5 illustrates some of the different types of sensors and applications that can be utilized in a smart building.
For example, 75–80 percent of a building’s life cycle costs are related to building operations. All existing commercial and large residential buildings have some form of building automation (or management) system which controls such things as HVAC. In order to introduce smart building features, such as smart lighting with embedded occupancy sensors, and have these interact with the main system, at minimum a gateway is required with some additional capability that would usually come with an edge server.
The edge capability would provide data (occupancy data, for instance) from strategically placed sensors to a cloud-hosted service that performs some specialized analytics. The outcomes from these analytics can be sent back, via the gateway or edge server, to alter the schedules of equipment connected to the main system in order to optimize operations. This configuration is also necessary to obtain a portfoliowide view of building operations and conditions. Edge computing and cloud enable smarter management of resources.
While edge computing offers solid benefits, it can also introduce operational and design complexities. Edge processing is highly distributed and often includes far-flung and/or difficult-to-access locations, including sensors/actuators and gateways in offices, plants, at campuses, on pipelines, and in various remote field sites. Any given organization can have thousands of devices and hundreds of associated gateways. All these edge nodes have firmware, operating systems, some form of virtualization and containers, and software installed, some of which are provided by manufacturers and some by solution providers. These need to be properly managed and maintained by the owner/manager of these edge nodes, mandating an enormous degree of automation (such as for backups, patching, updates, and monitoring).
The number of potential problems is enormous, and troubleshooting can be very challenging and complex in a highly distributed model. In many cases, field service technicians are required to be regularly onsite to address issues that occur as a result of upgrades or even general maintenance. These drivers also tend toward the need for a widespread “software defined everything” approach, as software upgrades are more easily and conveniently achieved than hardware upgrades.
Despite its challenges, cloud computing obviates concerns with many key IT issues, providing a degree of self-service and automation. Edge processing requires common data center operations (provisioning, updating, change management, and monitoring) in addition to the other higher-level functions (device management, updating machine-learning models, etc.) to be undertaken and replicated to all of the edge nodes and clusters. This is a heavy undertaking, requiring the enterprise to shift the focus from business needs to some extent.
Policies and practices used in traditional data centers are often not readily applicable to edge deployments, which are distributed across multiple locations and considerably more dynamic than traditional data centers. Undertaking the operational management of such a system is a complex challenge.
While the cloud offers on-demand scalability and is readily configurable, automated, and resilient, providing for these capabilities at the edge can be costly and complex. Accommodating the expansion of an existing edge deployment to allow for an increased number of devices and edge nodes can involve significant investment in additional hardware and software, and much complex work.
Extending the cloud and the data center to the edge with multiple nodes and devices exponentially increases the surface area for cyberattacks. Insecure endpoints, such as devices and edge nodes, can be used as entry points to valuable assets within an enterprise network and for other nefarious purposes, such as distributed denial-of-service attacks. Maintaining the physical and cybersecurity position of all assets in the edge is a complex and critical challenge.
Including unnecessary complexity in a solution can be costly, risky, and wasteful, so whether to add edge processing to an IoT solution is a decision best taken with care and based on a risk/reward assessment. To that end, figure 6 offers some guidelines that may help.
In many IoT use cases, the edge is simply a necessary or mandatory part of the solution, given the already existing operational technology. Adding a cloud-hosted component of an IoT solution requires some degree of edge-computing presence, even if primarily a gateway. Similarly, the desire to add smart capabilities to existing building management system infrastructure and provide for a cloud-based real estate portfolio view necessitates use of some edge-processing capability.
IoT scaling challenges with use of only edge or only cloud Designing a large IoT solution that does essentially nothing at the edge and sends all data for action to the cloud often presents scaling challenges in terms of bandwidth usage, possibly necessitating upgrades to networking infrastructure. Additionally, as the solution scales, exclusive use of the cloud could require reconfiguring ingestion engines and load balancing through manual intervention. The complexities of an exclusively edge-based distributed architecture (especially one that may involve distributed processing) are no less, and they increase with scale. Systems and application management are highly complex, and tools needed for these have yet to mature. In many cases, edge deployments do not adequately consider expandability, complicating the support of more devices and more data.
The first step is to assess whether edge computing is needed at all. It may well be that the best solution is a purely cloud solution. The next step is to determine the capabilities needed at the edge, and followed by determining the most appropriate deployment model, given that edge processing can be on devices, gateways, edge servers, possibly in multiple tiers, or micro data centers. There can be large variations in compute capabilities, responsiveness, and placement.
In some cases, preconfigured solutions, packaged into a single, integrated product, can offer simplicity, but at the possible expense of flexibility. The capability provided by the flexibility of self-constructing from best-of-breed components is attractive, though it comes at the expense of software/product development and stabilization, which lengthens the time taken to deliver a solution and brings a number of inherent risks.
Paying attention to the changes in the edge compute landscape is important, as is conducting a proof of concept with the relevant deployment design in order to finalize the best fit choice for the use case involved.
There is another variable worth noting—the edge-computing vendor landscape. It is undergoing rapid change. Most IoT infrastructure or platform vendors recognize that edge computing is an important part of many IoT solutions and delivery hardware, such as gateways or servers, with some data processing, analytics, and local storage capabilities. These hardware vendors tend to rely on others for device management, protocol handling, and conversion, in addition to other capabilities. Significant consolidation is likely to occur in this space as vendors seek to offer end-to-end solutions.12
IoT devices and the data they can provide are changing the world and how we interact. Much of the connected-consumer IoT world resides primarily on the cloud largely because of its copious benefits. However, in most cases an IoT solution will involve some mix of the edge and the cloud. Bringing it to the edge can alleviate latency, boost scalability, and increase access to information so that better, faster decisions can be made, and organizations can become more agile as a result.
While deciding on the right balance of edge and cloud functionality in an IoT solution, it is helpful to keep in mind that edge computing has various configurations, and all can bring their own benefits, but they also can present unique challenges. Substantial operational complexities and expenses can emerge in in no time, so enterprises should take into consideration a full range of factors while designing and building any given IoT solution.
Even then, an IoT solution should be only as simple as it needs to be, and no simpler. Conversely, it should be only as complex as it needs to be, and no more complex. These seemingly straightforward, yet essential, points can make a difference in the success of a solution.
Clearly, there is no single correct answer in the cloud vs. edge assessment in an IoT context. Every situation is unique. What is clear, however, is that a balance between cloud and edge computing will likely make up tomorrow’s IoT architecture.The IoT is getting smarter. Companies are incorporating artificial intelligence—in particular, machine learning—into their Internet of Things applications and seeing capabilities grow, including improving operational efficiency and helping avoid unplanned downtime. The key: finding insights in data.
With a wave of investment, a raft of new products, and a rising tide of enterprise deployments, artificial intelligence is making a splash in the Internet of Things (IoT). Companies crafting an IoT strategy, evaluating a potential new IoT project, or seeking to get more value from an existing IoT deployment may want to explore a role for AI.
Venture capital funding of AI-focused IoT start-ups is growing fast: In the first eight months of 2017, this group of start-ups raised $705 million 1
Acquisitions of AI-focused IoT start-ups are on the rise: 21 in the first eight months of 2017 and 24 in 2016, up from 11 in 2015 2
Vendors of IoT platforms—including Amazon, 3 GE, 4 IBM, 5 Microsoft, 6 Oracle, 7 PTC, 8 and Salesforce 9 —are integrating AI capabilities
GE, IBM, Microsoft, Oracle, PTC, and Salesforce —are integrating AI capabilities Large organizations across industries are already leveraging or exploring the power of AI with IoT to deliver new offerings and operate more efficiently 10
Gartner predicts that by 2022, more than 80 percent of enterprise IoT projects will include an AI component, up from only 10 percent today11
Artificial intelligence is playing a growing role in IoT applications and deployments,12 a shift apparent in the behavior of companies operating in this area. Venture capital investments in IoT start-ups that are using AI are up sharply. Companies have acquired dozens of firms working at the intersection of AI and IoT in the last two years. And major vendors of IoT platform software are now offering integrated AI capabilities such as machine learning-based analytics.
AI is playing a starring role in IoT because of its ability to quickly wring insights from data. Machine learning, an AI technology, brings the ability to automatically identify patterns and detect anomalies in the data that smart sensors and devices generate—information such as temperature, pressure, humidity, air quality, vibration, and sound. Companies are finding that machine learning can have significant advantages over traditional business intelligence tools for analyzing IoT data, including being able to make operational predictions up to 20 times earlier and with greater accuracy than threshold-based monitoring systems.13 And other AI technologies such as speech recognition and computer vision can help extract insight from data that used to require human review.
The powerful combination of AI and IoT technology is helping companies avoid unplanned downtime, increase operating efficiency, enable new products and services, and enhance risk management.
In a number of sectors, unplanned downtime resulting from equipment breakdown can cause heavy losses. For instance, according to one study, such losses average $38 million annually for offshore oil and gas operators.14 Another source estimated that for industrial manufacturing in total, unplanned downtime costs $50 billion per year, with equipment failure being the cause for 42 percent of the outages.15
Predictive maintence—using analytics to predict equipment failure ahead of time in order to schedule orderly maintenance procedures—can mitigate the damaging economics of unplanned downtime. In manufacturing, for instance, Deloitte finds that predictive maintenance can reduce the time required to plan maintenance by 20–50 percent, increase equipment uptime and availability by 10–20 percent, and reduce overall maintenance costs by 5–10 percent.16
Because AI technologies—particularly machine learning—can help identify patterns and anomalies and make predictions based on large sets of data, they are proving to be particularly useful in implementing predictive maintenance. Leading South Korean oil refiner SK Innovation, for example, expects to save “billions of won” by using machine learning to predict failure of connected compressors.17 Similarly, Italian train operator Trenitalia expects to avoid unplanned downtime and save 8–10 percent on its €1.3 billion annual maintenance costs.18 Meanwhile, French power utility EDF Group has already saved over $1 million with machine learning-driven early warning on equipment failure.19
AI-powered IoT can do more than help avoid unplanned downtime. It can also help improve operational efficiency. This is due in part to the power of machine learning to generate fast and precise predictions and deep insights—and to AI technologies’ ability to automate a growing variety of tasks.
For example, for Hershey, managing the weight of their products during the production process is critical: Every 1 percent improvement in weight precision can mean more than $500,000 in savings for a 14,000-gallon batch of product such as Twizzlers.20 The company used IoT and machine learning to significantly reduce weight variability during production. Data is captured and analyzed by the second, and weight variability can be predicted by machine learning models, enabling 240 process adjustments per day, compared to just 12 per day before the ML-powered IoT solution was installed.21
AI-based prediction is also helping Google cut 40 percent of data center cooling costs. The solution, trained on data from sensors in the facility, predicts temperature and pressure over the next hour to guide actions for limiting power consumption.22
Machine learning produced insights that persuaded one shipping fleet operator to take a counter intuitive action that saved them big money. Data collected from ship-board sensors was used to identify the correlation between the amount of money spent on cleaning the ships’ hulls and fuel efficiency. The analysis showed that by cleaning their ships hulls twice a year rather than every two years—and thereby quadrupling their cleaning budget—they would end up saving $400,000 due to greater fuel efficiency.23
IoT technology coupled with AI can form the foundation of improved and eventually entirely new products and services as well. For instance, for GE’s drone and robot-based industrial inspection services, the company is looking to AI to automate both navigation of inspection devices and identification of defects from the data captured by them. This could result in safer, more precise, and up to 25 percent cheaper inspections for the client.24 In health care, Thomas Jefferson University Hospital in Philadelphia seeks to improve patient experience with natural language processing that will enable patients to control room environment and request various information with voice commands.25
Meanwhile, Rolls-Royce aims to soon introduce a new offering featuring IoT-enabled airplane engine maintenance services. The company plans to use machine learning to help it spot patterns and identify operational insights that will be sold to airlines.26 And automotive manufacturer Navistar is looking to machine learning analysis of real-time connected vehicle data to enable a new revenue stream, in vehicle health diagnostics and predictive maintenance services. According to Navistar technology partner Cloudera, these services have helped cut downtime for nearly 300,000 vehicles by up to 40 percent.27
A number of applications pairing IoT with AI are helping organizations better understand and predict a variety of risks as well as automate for rapid response, enabling them to better manage worker safety, financial loss, and cyber threats.
For instance, Fujitsu has piloted the use of machine learning to analyze data from connected wearable devices to estimate its factory workers’ potentially threatening heat stress accumulated over time.28 Banks in India and North America have begun evaluating AI-enabled real-time identification of suspicious activities from connected surveillance cameras at ATMs.29 Vehicle insurer Progressive is using machine learning analysis of data from connected cars to accurately price its usage-based insurance premiums and thus better manage underwriting risk.30 And the city of Las Vegas has turned to a machine learning solution to secure its smart city initiatives, aimed at automatically detecting and responding to threats in real time.31
For enterprises across industries, AI has the potential to boost the value created by IoT deployments, enabling better offerings and operations to give a competitive edge in business performance.
Executives contemplating new IoT-based projects should be aware that machine learning for predictive capabilities is now integrated with most major horizontal (in other words, general-purpose) and industrial IoT platforms, such as Microsoft Azure IoT,32 IBM Watson IoT,33 Amazon AWS IoT,34 GE Predix,35 and PTC ThingWorx.36
A growing number of turnkey, bundled, or vertical IoT solutions take advantage of AI technologies such as machine learning.37 For instance, for connected-car use cases, BMW’s CarData platform gives access to data shared by vehicle owners and AI capabilities from IBM Watson IoT.38 In consumer products and retail, a number of replenishment automation and optimization solutions use machine learning to predict demand and optimize inventory levels.39 Providers of telematics solutions for the auto insurance industry are integrating machine learning to create more accurate risk models and predict claims behavior.40
It may be possible to use AI technology to wring more value from IoT deployments that were not designed with the use of AI in mind.41 For instance, a Hungarian oil and gas company applied machine learning to sensor data that was already being collected during diesel fuel production. The analysis allowed the company to more accurately predict the fuel’s sulfur content and helped identify process improvements that are now saving the company more than $600,000 per year.42 The major horizontal and industrial IoT platforms—which enterprises may already be using—are offering new AI-based capabilities that might help boost the value of existing deployments.
It may soon become rare to find an IoT implementation that does not make some use of AI. The International Data Corp. predicts that by 2019, AI will support “all effective” IoT efforts and without AI, data from the deployments will have “limited value.”43 A growing number of IoT vendors are offering at least basic AI support. Vanguard companies across industries are already reaping the benefits of AI in their IoT deployments. If your company has plans for implementing IoT-based solutions, those plans should probably include AI as well.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.Each week watch Deloitte Consulting Chief Futurist Robert Schmid, aka “Mr. IoT,” interview guest specialists across the burgeoning IoT space about the technologies you want to know more about.Nowadays, Agile methodologies have well and truly arrived in most organizations. The complexity of digital opportunities and the unpredictability of customers and competitors are both on the rise, making it impossible to predict what businesses will need in the future. That is why Agile is such a decisive factor to enhance organization’s responsiveness towards volatility. Strategy management has to evolve as well, which is where Agile concepts come into play. More...Andy is a principal in Deloitte Consulting LLP and leads the Internet of Things practice. He has worked in the high-tech industry for 25 years, advising clients on the strategic use of technology to optimize their businesses. Andy specializes in advising executives on the practical applications of emerging technologies, effective management of IT organizations, and execution of complex, transformational, technology-enabled projects.The increasing number of Internet of Things devices demands for a central approach of managing complex systems with a large number of services and things. This management of IoT devices and services, management of workflows and capabilities as well as automated reactions to incidents and events, are key aspects provided by ServiceNow.
The goal of implementing ServiceNow as an IoT solution is to take a long-term view and to enable your business with the necessary tools to manage the complexity of IoT systems, things, and related services. Having a robot broadcasting data sets the basis for starting a process, which is simplified by ServiceNow as implemented in our PoC: the data is analyzed and appropriate actions are derived from the analysis, which are accomplished by technicians with necessary skills and proximity. All done without unnecessary, time consuming, time-lagging, manual work.
As a tool for Asset & Configuration Management, Service & Issue Management, and Discovery & Orchestration, ServiceNow offers reduction of downtimes, automation of (production) processes, and increase in up-times and utilization for predictive maintenance - in particular service requests and automation in the cloud. The whole end-to-end process is scalable and can be applied from one machinery to a globally distributed network of plants.
Automation is simply necessary for the next step in the IoT implementation efficiency and Deloitte ServiceNow team has the tools to help you transform your business into a highly automated and efficient one. We support you from the first idea of bringing IoT and automation into your organization to the management and continuous improvement of your IoT and ServiceNow solution.As airports become more digitally connected, the Internet of Things (IoT) can open up a world of opportunities. Much more than merely improving efficiency, IoT can transform the traveler experience and generate new revenue.
Digital technology seems to connect everything today. So it is perhaps no surprise that airports—the infrastructure that helps billions of travelers connect across the globe each year—are themselves becoming more digitally connected. The connected, or smart, airport brings together a variety of technologies through the Internet of Things (IoT), with the goal of strategically differentiating an airport, including via improved traveler experience, and tapping into monetary benefits through greater efficiencies and new revenue streams. Achieving this end goal requires significant collaboration between stakeholders, and airports should carefully craft implementation strategies that aim for incremental quick wins over “big bang” transformations.
While awareness of IoT across the aviation ecosystem is high, its knowledge of how to harness and maximize IoT’s capabilities within an organization is much lower. In our survey of the industry, only 12 percent of airport representatives reported that their organizations are very prepared to benefit from IoT applications, and another 10 percent felt that they were not even exploring IoT yet. So if they want to create the connected, smart airport, the logical starting point is by beginning with the basics of what IoT is.
Methodology of this study Funded by the Airport Cooperative Research Program of the Transportation Research Board of the National Academies of Sciences, Engineering and Medicine, researchers from Deloitte and Texas A&M Transportation Institute produced a primer on smart airports and IoT.1 In the context of this report, the term “airport” is not limited solely to airport operators, but refers to the complex network of stakeholder interactions that goes into getting aircraft safely in the air and travelers and cargo comfortably to their destinations. The report drew on a variety of research methods including: Literature review. The research team reviewed existing academic, business, and technical literature on IoT’s background, concepts, technological architecture, and value propositions. The team also reviewed lessons learned from IoT applications outside an airport environment.
The research team reviewed existing academic, business, and technical literature on IoT’s background, concepts, technological architecture, and value propositions. The team also reviewed lessons learned from IoT applications outside an airport environment. Stakeholder interviews. The team conducted 18 interviews with industry stakeholders representing IoT experts, airports, airlines, aviation industry associations, federal agencies, vendors, and intelligent transportation system/transportation providers.
The team conducted 18 interviews with industry stakeholders representing IoT experts, airports, airlines, aviation industry associations, federal agencies, vendors, and intelligent transportation system/transportation providers. A stakeholder survey. The team conducted an online survey of 103 industry stakeholders representing airports, airlines, airline vendors, aviation industry consultancies, IoT suppliers, and other consulting organizations.
The team conducted an online survey of 103 industry stakeholders representing airports, airlines, airline vendors, aviation industry consultancies, IoT suppliers, and other consulting organizations. Case studies. The research team conducted 11 case studies, eight in an airport environment and three in other industries.
IoT is not a technology itself but rather a technology architecture—that is, IoT is more than the sum of its component parts. IoT is a way of bringing together different enabling technologies in a specific way to do something new. But how exactly do enabling technologies come together to form an architecture? IoT’s architecture is explained conceptually using the information value loop (figure 1). However, perhaps the best way to understand how these technologies come together to create value is through an example from an airport:
The airport needs to locate its nonmotorized ground service equipment to maintain it more regularly. GPS tags affixed to the equipment function as sensors to create a thread of digital information about the location of a specific piece of the equipment. A network of radios communicates that information back to a central server. The server aggregates the location of one cart with the location, type, and maintenance schedule for all of the other carts. All this data is analyzed together to create a plan for which carts need to be retrieved today and undergo maintenance. With that information in hand, workers act, bringing in the right pieces of equipment for maintenance on time.2
When workers use the information created by IoT to take a new action, the digital information has created value in the real world—in this case, allowing for proper maintenance and greater uptime for ground service equipment. Because IoT is an architecture, what is important is not the specific technologies involved but rather the flow of information through the steps of the information value loop. Since that information can be about anything, the exact amount and type of value created by IoT are limited only by the business problems airports need to solve.
We see three principal classes of benefits from IoT, and, in selecting the IoT capability or set of capabilities that are “right” for them, airports should consider their goal(s) for IoT implementation:
IoT is already in use in airports in many different ways, such as in traveler information systems, traveler traffic monitoring, baggage systems, and facilities management. Most of these uses focus on increasing efficiency. Other uses of IoT, such as enhancing security effectiveness, can improve both efficiency (maintaining throughput with fewer machines or staff) and differentiation (shorter and faster lines for a better traveler experience). Finally, still other use cases can directly generate new revenue such as the use of geofencing to gather fees from rideshares. As a result, these three categories help us understand what IoT can achieve at an airport.
The majority of current airport uses of IoT focus on operational efficiency. For example, an airport representative shared that one airport has “a new online inspection system that uses a tool provided to maintenance grounds crew and connected to the Internet with GPS functionality. The purpose of this tool is to digitally connect maintenance crew inspection findings to a map of the airport grounds.”3
Another airport is planning a smart bathroom pilot test. The airport will install IoT sensors on various bathroom assets, including faucets, toilets, lighting, soap dispensers, air fresheners, toilet paper dispensers, and other equipment, in one of its busiest bathrooms. These sensors will transmit data to facilities management to alert it in real time of various shortages and breakdowns. As part of this pilot, the bathroom will have a people counter and a customer input button to capture perceptions of bathroom cleanliness, which will enable facilities management to gauge perceptions of cleanliness against actual use. This may enable greater efficiency for maintenance staff while also providing a better traveling experience.
The long-term horizon for IoT applications supporting efficiency at airports may include autonomous vehicles, tenders, and baggage carts. If integrated with other data sources such as schedules, push-back times, and gate numbers, this data could fully automate a tarmac where robots and autonomous vehicles deliver baggage, fuel planes, clear debris, and perform other tasks—all faster and to closer tolerances than human workers. The result would be that airports could conduct surface operations more efficiently, allowing more flights in and out of the same physical ramps and taxiways. While something like the fully automated tarmac is still years away, the technology needed for such uses is already in action on roadways today.4
While gains in efficiency can be significant, airports that use IoT can also provide a more differentiated product or better customer experience than nonsmart airports. However, differentiation can be much broader, especially for airports where the greatest competition comes not from other airports but from other modes of travel. For example, limiting greenhouse emissions, reducing noise levels over neighboring areas, or even responsibly maintaining an airport’s open space can all be differentiators that make the airport an attractive brand as well as an integral part of the community. In fact, smart products used as part of IoT can even gather information about customer preferences, providing a deeper understanding of what does and does not differentiate travel options.
Differentiation is often a watchword for advertising or customer experience, but it is actually much more. Differentiation is fundamentally about how an airport provides distinctive value to important stakeholders—stakeholders that include groups that range from airlines to travelers to retail tenants to local communities. Differentiation can underpin and support the brand of an airport. IoT applications that support differentiation can come in many different varieties, aimed at traveler satisfaction or even environmental causes. For example, Heathrow Airport set the goal of reducing nitrogen dioxide emissions to help improve local air quality. The airport realized that a major—and avoidable—source of ground-level nitrogen dioxide emissions is aircraft parked at the gate that use auxiliary power units (APUs) instead of plugging into the power grid. As a result, Heathrow Airport deployed an IoT solution to help improve air quality. Microphones positioned around the apron pick up the telltale sound of APUs running. These data are cross-referenced against schedules and other data to determine whether an aircraft is running its APU instead of using the power grid. The airport can then share this data with airlines and remind aircraft to plug in and switch off the APU—not just saving money for the airline but also improving local air quality for all.5
IoT can also create new sources of revenue. This can come from creating new products or services to attract new customers or by using IoT to sell more to existing customers. While IoT solutions aiming to generate new revenue are often the largest and most complex, they can also build upon existing solutions that generate efficiency gains to help ease implementation. Our interviews with subject matter experts indicate that airport stakeholders do see the value in such uses and may pursue them in the future. Use cases being investigated include variable rates for advertising and off-airport transit recommendations personalized to an individual traveler. However, because these revenue-generating use cases may involve the greatest number of stakeholders, they are often the hardest to pursue.
That said, just because use cases that create new revenue are hard to create does not mean that they have to be technologically advanced. One airport used Wi-Fi access points as sensors to measure the location and dwell time of people as they moved through the terminals. Armed with this data, the airport was able to put signs and advertising in places most likely to be seen by the right people. So while earlier, very few sales were made to landing travelers, this airport was able to place signs for the products those travelers may want to buy before departing the airport where they would be likely to see them. The result was increased sales to a previously untapped group for retailers, and through them, increasing the airport operator’s landside revenue.6
Industries generally have a typical development progression with IoT. The expected benefit of an IoT application varies with the scope, and therefore difficulty, of the project. As a result, most industries begin by pursuing small-scope IoT projects aimed at efficiency since these can often be managed entirely within an organization. Therefore, in most industries, IoT applications aimed at efficiency are the most common, followed by differentiation and then new revenue.
In one recent survey, 34 percent of companies—the top response—said they anticipated gains in efficiency from IoT technology.7 On the other hand, only 6 percent—by far the lowest response—anticipated realizing new revenue thanks to IoT technology. Another survey of companies already using IoT found similar results: 52 percent used IoT to improve efficiency versus 40 percent that used customer-facing IoT applications for differentiation and generating new revenue.8
Overall, airports follow these trends in IoT adoption as well. In our survey, 76 percent of respondents using IoT indicated they used it for efficiency/optimization, compared with 58 percent for customer experience/differentiation and only 35 percent for new revenue.
However, while many airports may follow the typical IoT development trends (moving from efficiency to differentiation to new revenue), unique forces in the aviation industry also open other pathways to IoT adoption. The aviation industry has traditionally set a very high standard for traveler experience, with leading airports designing truly tailored experiences that reflect not only the bespoke expectations of their global travelers, but the uniqueness of the local region as well. Therefore, while IoT applications that improve traveler experience at an airport may be more difficult to implement than those dealing only with internal efficiency, airports may find it easier to begin with differentiation and move to internal efficiency. As aviation entrepreneur and indoor mapping expert Jack Loop puts it:
"Very often, [airports] begin with the consumer-facing side. Consumer-facing projects need to meet a higher bar of usability, so it is actually easier to take a slick consumer-facing project and use it internally than it is to take a purely functional internal tool and bring it up to consumer-facing standard.9"
So while past IoT developments may have focused on efficiency, as airports develop future IoT solutions, they may tend to skew more toward differentiating the airport by improving traveler experience. These sentiments were echoed by other interviewees from airlines and airports, who indicated that future IoT plans were largely focused on improving customer experience.
As we saw, airports can use IoT to improve efficiency, differentiate their strategy, and generate new revenue. These benefits of IoT can be applied to any aspect of airport operations. Since airport operations are typically split into two, air side and land side, we will explore how IoT can impact both below.
IoT can be applied at every stage of a traveler’s journey from arrival curb to gate (figure 2). For example, IoT way-finding applications could be relevant at the parking and arrival stage and the check-in stage. Figure 3 maps common IoT solutions to each stage as well as the airport stakeholders involved in the implementation.
Much like a traveler’s journey, operations at an airport can also be seen through the lens of an aircraft’s journey from arrival to departure (figure 4), and IoT implementations can similarly be mapped across each stage and the stakeholders involved for each stage (figure 5).
With so many technological options, IoT can quickly overwhelm even the most tech-savvy managers. However, a structured planning process can help airport leaders navigate all the options and gain confidence that the end result will support the airport’s business goals.
Determine the technical and organizational maturity needed to successfully implement the chosen solution
The process begins with selecting a potential IoT project. This can be done with either a top-down approach or a bottom-up approach.
Based on the goals in their strategic plan, airports should select the right set of IoT capabilities. Different goals for an IoT solution can often call for radically different technology and organization to support them. As a result, the overall strategic goal for IoT drives the infrastructure requirements needed for a successful IoT implementation.
Airports can also identify promising IoT opportunities by examining the existing IoT solutions— or, if there are no true IoT solutions, the existing sources of data—currently operating in their airport, and then identifying areas where these solutions can be extended across or beyond the airport to further meet the airport’s strategic goals. This exercise also shows where other stakeholders may have data or expertise that can help an airport achieve its goals.
The result should resemble a matrix of IoT applications, stakeholders, and the impacted stages of traveler or operations journey, as depicted in Figures 2, 3, 4, and 5. As in the top-down approach, this assessment of the infrastructure requirements for an IoT solution can help the airport gauge the feasibility of a project. However, the map created by the bottom-up approach has an additional benefit: It can help identify other stakeholders who may be able to provide some of the capabilities needed—in effect accelerating an airport’s IoT project adoption by tapping into existing tools or infrastructure.
Whether using the top-down or bottom-up approach, airports assess their overall digital maturity versus the desired end state of a successful IoT implementation.
The data (size and complexity), communications, and infrastructure required for the potential solution(s) versus what the airport already possesses;
Stakeholder groups that can achieve benefits from the potential solution versus the security/privacy procedures that must be in place to secure their cooperation or use.
Assessing potential IoT solutions against these qualifiers can confirm (or disprove) the overall fit of that solution for the defined needs of the airport before moving to implementation. More importantly, the gaps between required and current capabilities in each of these criteria can guide the first steps to developing an implementation road map as airports pursue digital maturity (figure 6).
Even with all the right tools and information, implementing IoT solutions can be a significant undertaking filled with new challenges for even the most digitally mature organizations. We look at some of the broad challenge areas below.
Safety, security, and privacy. In the aviation industry, safety is an inviolate standard. No new technology, no matter how efficient or cost-saving, can be introduced if it compromises safety. When physical objects are connected digitally, the compromise of digital data can have real-world consequences. Therefore, as IoT gains in adoption, safety, cybersecurity, and data privacy are all increasingly linked.
In the aviation industry, safety is an inviolate standard. No new technology, no matter how efficient or cost-saving, can be introduced if it compromises safety. When physical objects are connected digitally, the compromise of digital data can have real-world consequences. Therefore, as IoT gains in adoption, safety, cybersecurity, and data privacy are all increasingly linked. Technology and infrastructure. Large IoT implementations involve numerous, disparate systems and devices, which all need to connect and operate together. Very few out-of-the-box IoT solutions for airports are currently on the market. This can make it hard to figure out what is needed to support an IoT ecosystem.
Large IoT implementations involve numerous, disparate systems and devices, which all need to connect and operate together. Very few out-of-the-box IoT solutions for airports are currently on the market. This can make it hard to figure out what is needed to support an IoT ecosystem. Talent. As IoT gains wider adoption, the roles and responsibilities of airport employees may change as they have more interaction with technology. To keep up with this trend, airports should prioritize addressing talent and skill gaps by implementing training programs for existing employees, expanding hiring for new technical roles, and changing the way leaders manage and organize work groups.
As IoT gains wider adoption, the roles and responsibilities of airport employees may change as they have more interaction with technology. To keep up with this trend, airports should prioritize addressing talent and skill gaps by implementing training programs for existing employees, expanding hiring for new technical roles, and changing the way leaders manage and organize work groups. A compelling business case. In every industry, concerns about return on investment (ROI) are among the top barriers to implementing IoT. Both upfront and continuing costs can vary widely, depending on the specific IoT application. Since IoT has few test cases, the ROI for any IoT investment is not fully certain, with the result that cost can quickly become a deterrent. However, careful consideration of the factors that drive costs and ROI in IoT can help leaders narrow down options and structure their decision-making.
In every industry, concerns about return on investment (ROI) are among the top barriers to implementing IoT. Both upfront and continuing costs can vary widely, depending on the specific IoT application. Since IoT has few test cases, the ROI for any IoT investment is not fully certain, with the result that cost can quickly become a deterrent. However, careful consideration of the factors that drive costs and ROI in IoT can help leaders narrow down options and structure their decision-making. Funding and financing. Even with a solid business case that promises a clear and acceptable ROI, airports can struggle to find the upfront funding needed to begin a project. Given the thin margins of many airport operators, finding extra dollars to finance an IoT project can induce fear in any airport executive. Taking a structured approach to understanding funding and financing options by asking question about the goal, timeline, and stakeholders involved in a project can help reduce uncertainty and encourage adoption of IoT.
Every IoT solution is unique and, therefore, the funding needs of each solution are likely to be unique as well. But there are a few variables common to every project that can help airports think through which types of funding or financing may be most applicable (see Figure 7 for one example):
What is the goal of IoT solution? How will success toward that goal be measured? Size of investment. What is the upfront investment required for IoT? What are the recurring costs?
What is the upfront investment required for IoT? What are the recurring costs? Timing of return. When can an airport expect a return from an IoT solution?
When can an airport expect a return from an IoT solution? Where costs and benefits accrue. Do benefits from IoT help one segment of the organization while the costs must be borne by another?
Overall, barriers to implementing IoT solutions can seem overwhelming. However, with the right team, a thoughtful plan, and supportive buy-in, airports can use IoT to create a better, more profitable operation.
Regardless of the technology or application involved, IoT can have the biggest impact on airports when the technology is incorporated into the core business model. For example, IoT might be used to facilitate a seamless door-to-door experience for air travelers: A single platform that can order and pay for rides on rail or taxi, handle travel documents, and order additional services could open up entirely new business opportunities for airport operators currently dependent on retail sales and parking receipts and greater customer interaction for airlines and other stakeholders. This mobility-as-a-service approach is exactly the type of IoT-based new business model that could deliver a new future to airports. Other opportunities may include biometric check-in, variable services or prices based on wait times, and individualized boarding processes.
However, only time—and the detailed picture that IoT data can create—will tell what the future holds.10The connected vehicle has been the most visible and familiar example of Internet of Things technology. But as cars become increasingly software-driven, the real IoT developments in the auto industry are behind the scenes, as automakers and software providers both lay claim to the driver’s seat.
Our cars have been connected for years, in ways that by now seem routine: They seamlessly link to our smartphones, register real-time traffic alerts, stream our Spotify playlists, and offer emergency roadside assistance at the touch of a button. Indeed, automakers began linking vehicles to information streams back in the early days of the Internet. When it comes to connecting drivers and technology, the auto industry has a longer and richer track record than any other sector.1
True, automakers have yet to turn the “connected car” into a significant revenue generator or a key driver of vehicle sales: Despite two decades of TV ads promoting advances in in-vehicle connected services, drivers have resisted paying extra for those features, either not understanding the new technologies or simply seeing little value in the services offered.2 But this—and a great deal more—is about to change.
Indeed, the auto industry is on the brink of a revolution, and the driving force is the suite of technologies known as the Internet of Things (IoT). With IoT applications—grounded in advances in everything from sensors to artificial intelligence to big-data analysis—all manner of objects, from wristwatches to road signs, can be not only connected but also “smart.” And both industry insiders and everyday drivers will soon see a fundamentally different world of mobility.3
Analysts differ in their estimates, but all agree that the prospects are staggering. Gartner predicts that by 2020, more than 250 million vehicles will be connected globally, with the number of installed connectivity units in vehicles worldwide increasing by 67 percent and consumer spend on in-vehicle connectivity doubling. Deloitte’s consumer research suggests that drivers of the next generation want their cars to act as smartphones on wheels, like to remain connected and productive while on the go, consider fully connected vehicles among the most beneficial futuristic technologies, and are ready to pay a sizeable amount for a vehicle that meets all their technology needs and wants.4 We expect the impacts on the industry to be transformational, not incremental.
As ever, new opportunities bring fresh challenges. As IoT technologies and services transform the automobile, the ecosystem is witnessing a steady influx of new players and the continued evolution of the roles of key stakeholders and the balance of power among them. Of particular interest is the evolving relationship between automakers and software providers. Each has a viable claim on the driver’s seat in the rapidly changing auto-industry ecosystem, even as each new generation of services promises to throw into question just how long whoever might have their hands on the wheel can keep them there.
The connected car has evolved in distinct stages, or phases, over the last few decades that show advances in both technology and the ecosystem in which that technology functions. At each stage, not only are new features and services added to the growing connected car product portfolio, but also new ecosystem players as well as, in many cases, new business models and supporting technologies. That’s why the best way to fully perceive the complexity of the playing field is to use the past as prologue, tracking the evolution of the connected car from its earliest stages to where it is today and where it’s going. Figure 1 outlines these phases of evolution.
Since as far back as the mid-1960s, automakers have looked for ways to enhance the driving experience with information. General Motors’ Driver Aid, Information and Routing (DAIR) initiative sought to provide everything from directions to current road conditions and accident reports.5 Far ahead of its time, DAIR never got out of the R&D stage, mostly because the technology of the day simply wasn’t up to the task. Punch cards provided information for turn-by-turn directions; radio relay stations and magnetic sensors buried in roads communicated additional data. For such a system to be useful, it would have required ubiquitous availability—in other words, deployment on roads across the country or, at least, a substantial geographical scale—at the time, cost-prohibitive and commercially unworkable, which is why we classify DAIR as Phase 0, a connected car before connections truly existed.
Conceptually, however, we can think about this effort in terms of how the information creates value and therefore assess DAIR in those terms. The Information Value Loop describes the stages through which information must pass to create value, the technologies required to push information around the loop, and the characteristics of the data that drive value (see inset on page 5).
By connecting the vehicle with in-road sensors, DAIR created and communicated information, analyzing it to provide an augmented response—action—in the form of navigation and traffic information. In closed test environments, the value was visible as information completed the trip around the value loop. At commercial scale, however, the cost of putting the expensive sensor technology in place across large stretches of road created too tight a bottleneck for DAIR to be feasible. It did not help that, for a single-company initiative, there was no larger ecosystem in place to spread the costs around. Even for the GM of the 1960s, DAIR was too great a dare.
The suite of technologies that enables the Internet of Things promises to turn most any object into a source of information about that object. This creates both a new way to differentiate products and services and a new source of value that can be managed in its own right. Realizing the IoT’s full potential motivates a framework that captures the series and sequence of activities by which organizations create value from information: the Information Value Loop.
For information to complete the loop and create value, it passes through the loop’s stages, each enabled by specific technologies. An act is monitored by a sensor that creates information, that information passes through a network so that it can be communicated, and standards—be they technical, legal, regulatory, or social—allow that information to be aggregated across time and space. Augmented intelligence is a generic term meant to capture all manner of analytical support, collectively used to analyze information. The loop is completed via augmented behavior technologies that either enable automated autonomous action or shape human decisions in a manner leading to improved action.
Getting information around the Value Loop allows an organization to create value; how much value is created is a function of the value drivers, which capture the characteristics of the information that makes its way around the value loop. The drivers of information value can be captured and sorted into the three categories: magnitude, risk, and time.
When GPS technologies were opened up to civilian use in 1996, GM announced OnStar in collaboration with EDS and Hughes Electronics.6 As originally introduced, every connected car would have a digital communication module (DCM), essentially a phone embedded in the vehicle, responsible for communicating information wirelessly to a telematics service provider (TSP) or the automaker itself. In a breakthrough we categorize as Phase 1, this connected the car to information and services from the outside world to enable a safer and easier driving experience.
OnStar’s success is clear in terms of its ability to effectively push the right kinds of information around the Value Loop. For example, safety services leverage sensors embedded in the vehicle—aggregating information that the car creates and communicates associated with safety-related events and emergency situations. Navigation services use GPS technology to ascertain the auto’s location. Analysis of the information enables the provider to use augmented-behavior technologies to act on the customer’s behalf—from dispatching emergency services to the site of a crashed vehicle to providing live concierge services over the in-vehicle phone.7 The timeliness, reliability, and accuracy of information are the most critical value drivers, due to the importance of rapid response in emergency situations and the legal implications of safety failures.8
The automotive ecosystem was becoming more than just the car and its maker. Unlike the closed DAIR ecosystem, OnStar’s ecosystem brought in two new players: the hardware providers and Tier 2 chip providers that supplied the DCM devices and the TSPs that provided the core services. The new hardware providers, operating similarly to existing Tier 1 providers, fit within existing power structures. The TSPs, however, represented an important shift: Automakers’ introduction of embedded safety services expanded their business models beyond product manufacturing and retail into service provision, touch-points across the customer lifecycle, and the ability to collect recurring revenues. The communicate stage was an important bottleneck that TSPs were key to relieving. As a result, TSPs possessed two critical pieces of value in the partnership: the customer data related to the services provided and the actual interactions with customers themselves.9
After a century of carmakers’ unquestioned industry dominance, other players were staking a claim to ownership of the overall relationship with the customer. But the potential power struggle had to take a back seat to the fundamental problem of consumer adoption: Notwithstanding industry hype, consumers were slow to comprehend the new services being offered and the benefits of such connectivity; the high prices of these services proved a particularly big speed bump.10
Even just the two data points provided by DAIR and OnStar illustrate a trend: Communication-based technologies often require an expanded ecosystem to function effectively and affordably, appeal to customers, and offer opportunities to generate value. But while enlarging an ecosystem enables a given value loop to create more value, it poses additional challenges for the players involved when it comes to capturing that value.11 The continued evolution of the connected car has played out according to these same rules.
By the mid-2000s, the near-ubiquity of mobile phones and the rapid rise of smartphones prompted the introduction of “infotainment” applications within the vehicle.12 These applications were built on a driver’s “brought-in” phone (using a phone’s cellular connection to stream data to the vehicle via Bluetooth) rather than embedded hardware (as with DAIR or OnStar). The connected capabilities within the car aimed to duplicate entertainment and features a driver could get elsewhere (at home or on their phone) rather than providing a wholly new stream of features—and new kinds of value. Even so, this signaled a new phase: a shift from creating value through technology to creating value through information, and expansion of connectivity to better integrate with the customer’s out-of-vehicle life.13
Infotainment services introduced two new categories of players to the ecosystem—software providers and third-party content and app providers—and consequently set off an important shift in the power equation in the industry, even as players within these categories proliferated and the Silicon Valley giants began to make their presence felt.14 Blackberry’s QNX, Google, and Apple all released proprietary software platforms in an effort to establish themselves in this market.
As access to content has increasingly shaped customers’ in-vehicle experience, who owns the customer’s experience—a key question in this phase—has grown more important.15 In other words, in the case of infotainment, value is captured by those who can aggregate—and thus control—the data that drivers create and communicate. With software providers taking on that role, automakers saw their own ability to capture value from data beginning to diminish.
The entry of the big Silicon Valley firms created something of a dilemma for the carmakers: The mass appeal and cross-industry possibilities of Google’s Android Auto and Apple’s CarPlay were offset by the fact that, in such a partnership, both players are competing to completely own the customer experience and customer data. No surprise that automakers—which consider the customers their own and want to retain control over the center stack—find this precedent troubling.16 Automakers fear that, should they lose control of the customer to software providers, cars could become commodity devices secondary to the software they run. Some carmakers have chosen to instead build or retain their own proprietary platforms,17 or to limit the data they share with their technology partners.18 Others are exploring innovative ways to bridge this gap and collaborate with software providers. Together with another major automaker, Toyota has opted for an open platform with BlackBerry’s QNX that can support not only a larger number of apps19 but also greater freedom for user-interface customization.20
On the whole, the infotainment era renewed interest and adoption in the connected car. However, monetization of services continued to be an issue—as customers grew accustomed to accessing music and other entertainment on demand, often for free, they resisted paying extra for those services in their cars.21
For several years, players debated whether to create systems around embedded or brought-in technology and services, and that debate drove the scope of the connected-car ecosystem and the struggles over value capture. The last couple of years, however, have seen the development of a “hybrid model” that combines the two—and opens the door to the introduction of a host of applications and opportunities for value capture.22 High-tech innovation from outside the automotive world is bleeding into it, making the current period one of intense activity and excitement, with many new entrants, startups, VC investments, and M&A movements. It is no surprise, though, that this is further muddying the ecosystem’s waters. At the heart of these hybrid solutions are multiple sensors embedded not only in the vehicle itself but in all manner of smart devices across the IoT landscape—from wearables and Dedicated Short-Range Communications devices to smart-home gadgets to infrastructure—that can communicate with and share data with the vehicle through what is being called V2X integration.23
The breadth of devices and sensors available create a tremendous scale of data based on a wide scope of detected events, and that in itself is responsible for much of the value being seen in this phase. An IoT system can communicate the generated data to a common platform, where it may then be aggregated with data originating from other sources, including third-party content and social media, and analyzed, generating a response that is then delivered through the vehicle or other designated output device. This triangulation of data coming from these myriad devices is where the greatest value lies: firstly, in making sense of the data to paint a complete picture of both the customer’s behavior and the surrounding context to generate insights, and secondly, to even enable this aggregation in the first place in a way that is interoperable across devices and provides a comprehensive and cohesive customer experience.24
A platform that can aggregate and analyze all this data represents a complex undertaking, as it involves cooperation and collaboration between multiple stakeholders from multiple industry sectors. The aggregate and analyze stages are the real bottlenecks for this phase of connectivity, and this is what positions software providers at the center of value creation in this ecosystem, since they, and they alone, hold the wherewithal to deliver such a platform.
It should be noted that with great power comes great responsibility. The increasing scale and scope of data from the vehicle and connected devices represents a tremendous revenue opportunity for the players that own and control this information, but it raises the stakes for these same players in ensuring that the data remains secure. Car hacking has grown as a concern over the last few years, with several digital-security studies revealing the dangers of vehicle security breaches: Protected personal information could be stolen; hackers could potentially even seize remote control of a vehicle, with dangerous consequences.25 In light of such possibilities, the players that own and operate on the data expose themselves to significant legal liability, an additional consideration that they will have to take into account as they look to establish their positions in this space.
The notion of adding vehicles to the ever-widening ecosystem of interconnected devices heralds a significant shift: the treatment of the vehicle as just another connected device—albeit a powerful and multi-functional one—in a significantly expanded ecosystem. The implications for the balance of power between automakers and software-platform providers are still unfolding: Indeed, software providers may gradually supplant carmakers as the center of the ecosystem and the owner of customer data and experience.26
Naturally, automakers hope to retain control over the automotive ecosystem; they continue to make big IoT investments and work to stake a claim beyond the car. One automaker has launched a series of 25 “experiments” worldwide that showcase V2X connectivity, from testing out electric bikes and urban-mobility options to data-driven health care and insurance, as well as car-sharing, 3D printing, and biomimicry.27 Mercedes-Benz also co-hosted Hack with the Best, a hackathon to develop new IoT and wearable concepts for the company’s vehicles.28
Who will ultimately sit in the driver’s seat remains unclear; for now, at least, there are several pairs of hands on the wheel.
The same cultural, ecosystem, and technological changes that affect automakers’ competitive position affect manufacturing considerations and processes as well. Indeed, when it comes to manufacturing, many foresee the auto industry’s recent challenges persisting for the foreseeable future:
Customers opting out of owning. For many customer segments, behavior has changed dramatically with the rise of car-sharing and alternative travel methods, making car ownership less appealing. “Total cost of ownership” has also increased, pushing customers to choose less expensive new cars or opt for used vehicles instead. This has directly impacted carmakers’ profitability, and this trend is expected to continue; for the companies, customer satisfaction and loyalty, along with the ability to convert prospects, are increasingly important.
Faster design cycles. Interaction between people and devices has increased massively over the last 10 to 15 years, and the connected car comes with tremendous business potential. But beyond market share, the implications of connectivity extend to development. Rapid advances in technology have forced a continuous reduction in the time it takes to bring a new product to market: While mobile-device makers typically issue annual updates, the automotive development cycle is far longer—about six to seven years, with a market lifecycle of seven to fifteen years. In other words, cars take longer to develop and last far longer than the software, smartphones, and other connected technology with which they need to work, meaning that automakers face the additional challenge of ensuring upgrades can be accommodated, so connected cars don’t become obsolete long before consumers are ready to replace them.
Building in upgradability. With the shorter lifecycles of electronic software and hardware, consumers increasingly expect that their cars will seamlessly accommodate the latest gadgets and automatically update them whenever needed. Today, the technology exists to update a vehicle’s features by delivering a software upgrade over the air, but this system requires the vehicle to have processing and memory capabilities that can accommodate for scaling, to prevent the vehicle from becoming obsolete. Given the rate of technology development, this can pose a real challenge. With these challenges in mind, carmakers are exploring new ways to reduce overall product costs, shorten time to market, build in greater flexibility, and distinguish their vehicles in an era in which software is fast becoming as key a differentiator as body design and fuel economy. Indeed, several automakers have begun redesigning the product-development process by focusing on standard components and technology. The ratio of standard components will increase, reducing the product-development process per car (for example, time to market) and decreasing production costs. Automakers are also working to increase production flexibility and more efficiently leverage production capacities. Virtual car development, integrated production planning, data integration, and extensive data analysis will also further streamline the process.
Carmakers can also leverage the data generated by the connected car and apply increasingly sophisticated analytics capabilities to guide their internal decision processes, from better understanding and predicting customer preferences to driving design, testing, flexible production planning, and quality assurance. The automotive industry already has a long history of leveraging cutting-edge, cross-industry technologies in design and production, from digital technology to augmented reality to 3D printing. Smart infrastructure and wearables integration are the next step.
Automakers will continue to face many of the same challenges they always have: managing complexity and quality, improving flexibility and process optimization, conserving resources, and ensuring profitable growth. And while connectivity and mobility will change automotive business models—perhaps dramatically—they can also support many traditional functions and help improve companies’ overall competitiveness.
The key is settling on the right strategy. In this case, as always, it is better to be the leader than the follower.
Even as V2X ramps up and an increasing number of well-resourced and well-positioned players vie for dominance, the automotive industry is already looking ahead to the next phase and beyond: the autonomous or self-driving car. Automakers and software providers alike are pouring in R&D investments into self-driving technologies,29 and prototype self-driving vehicles are already on the road. As technology obviates human drivers, new interior designs for automobiles will create space and opportunity for passengers to enjoy greater productivity and personalization of experiences, while passenger data create ever-expanding sources of potential value. In addition, self-driving vehicles may encourage a further shift away from vehicles as owned assets—a self-driving Uber model, so to speak. Many observers look ahead to a not-too-distant future where shared vehicles operate autonomously, rarely crash, and provide true multi-modal transport options.30
Some foresee enormous benefits from this transformation: Morgan Stanley expects “full automation” by 2022, creating $1.3 trillion in value in the United States alone.31 The benefits will be accrued by businesses across a gamut of sectors even outside of automotive: cities, governments, and municipalities; customers themselves; and society at large.32
Self-driving cars require multiple connected technologies to work: GPS technologies to support navigation and routing; sensors including radar, lidar, high-powered cameras, sonar, and lasers that create and communicate a continuous, three-dimensional, omnidirectional view of a vehicle’s surroundings; sophisticated software that analyzes this information, including artificial intelligence that allows for self-learning capabilities; and technologies that translate the information collected and processed into action, including accelerating, braking, and steering.33
Google’s Self-Driving Car project, which the company expects to be commercial by 2020,34 exemplifies all of these capabilities. Google began by retrofitting a Toyota Prius with driverless technology and has moved on to its own designed prototype vehicles, with neither steering wheel nor pedals. The car is driven by sensors that can detect objects and steer around them: Google Chauffeur artificial-intelligence software processes the sensed information, predicts how these objects might behave, and makes decisions on how the car should respond.35 The car’s self-learning capabilities allow it to identify, respond to, and learn from new situations.
The vehicle’s functioning is based on its ability to respond instantly to stimuli and make decisions that drive the right response: that is, the timeliness, accuracy, and frequency of communication and processing of the information. At the same time, with little direct human control over the vehicle, security of the data communicated will be a critical value driver. And as connectivity expands and the vehicle is increasingly integrated into a broader ecosystem of other devices and infrastructure, still other capabilities will likely arise, such as smart traffic routing of self-driving vehicles, aimed at improving roadway efficiency.
The scope of the technologies involved appears to imply, as it has in the past, an expansion of the ecosystem needed to enable this Value Loop and a consequent further shift in the balance of power among the relevant players. However, the potential impacts on the automotive business model in this case indicate a more fundamental and widespread transformation of the industry itself. In one scenario, the power lies firmly with the software-platform providers, and the vehicle is just a conduit that acts on the information it is given—and is only as powerful as its operating system. In this way, it becomes little different than a smartphone or smart thermostat, chosen less for its own merits than for its operating system and its compatibility and interoperability with other connected devices that run on the same platform. Here, the majority of value is captured by players in the ecosystem that have the ability to use information generated by the vehicle and its surroundings—but none more so than the software providers that aggregate all of that data.
Many analysts predict significant impacts, not all positive for automakers: Barclays forecasts that shared driverless cars entering the market could cut total U.S. auto sales by 40 percent, meaning that automakers “would need to shrink dramatically to survive.”36 Automakers must make very deliberate choices today about the role they would play and how they would work within this ecosystem, if they are to survive in such a future. GM believes that it has designers, engineers, and scientists who “are working at the cutting edge, and we’re confident GM will be very successful.”37 Essentially, this creates a vision of OEMs not as carmakers but as tech companies that solve mobility problems.38 In other words, rather than lose their longstanding positions to software providers, automakers are themselves making a brave push into the software space, to ensure they can maintain more control over their vehicles—and customers—and capture IoT value as well. If you can’t beat them, join them? Only time will tell who will win this particular power struggle—the tech giants trying to be carmakers or the automotive giants trying to be tech companies.
Remember when a customer simply wrote a check and drove her new SUV off the lot? Those days are numbered, as connected cars suggest ongoing customer relationships. Considering that increased connectivity is, in turn, powered by increasingly sophisticated software technologies, automakers may look to software revenue models for ways to monetize. For example, software-as-a-service can enable pay-per-use models for in-vehicle services; licensing can allow for tiered services based on a customer’s selected level of service; ad-supported content can subsidize delivery of in-vehicle services; and other software-industry concepts can be leveraged to drive in-vehicle service adoption.
Similarly, several of the other challenges the automotive sector faces now bear closer resemblance to those faced by software providers: Vehicle security and customer privacy may go hand-in-hand with developments in software and mobile-device security; the regulatory environment may more closely resemble the software industry; data and intellectual-property ownership may reside primarily in the hands of the software providers; technical governance and integration may reside with the software players as well; and so on. It may not be a stretch, in fact, to reclassify the automotive industry of the future as a software-driven mobility industry.
The Internet of Things enables transformational change, and there is no question that the automotive sector is changing extremely rapidly. IoT-related technologies will draw the map for the industry to follow, and the connected car will play a major role on the roads and in the economy of the future.
The power struggle between automakers and software developers is a symptom of the ongoing transformation, like birth pangs as the industry reinvents itself. We are moving from an age of products to an age of services and experiences, from hardware to software, from functionality to information as the key object of value creation, and from industry silos to intricately connected ecosystems and value loops. It is no surprise that carmakers find themselves navigating new terrain within an ever-expanding ecosystem of players, all of which are trying to capture value, and where players that control the aggregation and analysis of this information—the software providers—steadily gain ground.
As automakers consider their place in this changing industry, they can consider several approaches to strengthening their position:
Align on a vision of the role that the business will play in the ecosystem, understanding and accepting the transformational impacts this may have on the business and on the “old ways of thinking.”
Develop a clear mapping of where data originates—and, consequently, who owns it—for each of the services delivered, to better understand where value can be captured.
Develop a roadmap for shifting to a more service-oriented approach as an entire organization, not just in the connected-vehicle divisions, to enable ongoing interaction with customers throughout the entire lifecycle.
Accept new capabilities that need to either be built internally or acquired externally. Seek greater involvement in—and ownership of—in-vehicle software-platform development.
Consider ways to address manufacturing/lifecycle challenges by working closely with technology providers to more closely integrate development processes and software-driven feature rollouts and updates.
Identify and build strategic partnerships with key players across the ecosystem, including with emerging smart-device manufacturers, and work across the value chain to build a broader, more holistic brand experience enabled through connected technologies.
The road ahead for the industry is open and lined with opportunity. It’s time to shift into high gear.
Deloitte’s Internet of Things practice enables organizations to identify where the IoT can potentially create value in their industry and develop strategies to capture that value, utilizing IoT for operational benefit.​
To learn more about Deloitte’s IoT practice, visit http://www2.deloitte.com/us/en/pages/technology-media-and-telecommunications/topics/the-internet-of-things.html.
Read more of our research and thought leadership on the IoT at http://dupress.com/collection/internet-of-things/.Inputs devices and sensors: Devices and sensors begin the IoT cycle by gathering and sharing modality-specific data. IoT platform: To communicate with each other, the devices are integrated on an IoT platform that provides the infrastructure and standards/protocols for seamless connectivity. Artificial intelligence: Sophisticated machine-learning loops that interpret the data, derive insights, and determine responses have long replaced linear if-this-then-that logic. Actionable feedback loops: The AI engine activates automatic responses (e.g., through an effector arm) and/or synthesizes insights for human interpretation or future machine learning. User interfaces: Finally, users interact with the devices and consume the information and insights generated by the IoT ecosystem.
In-home automation is an example of how these five components are brought to life. Smart home devices (e.g., smart light bulbs, thermostats, locks, refrigerators, garage doors) are connected to a home automation platform. This allows an AI engine to combine data from multiple devices and drive actionable feedback loops. For example, when the AI engine recognizes that the garage door has been left open, it might use motion-sensor data and geofencing (smart phone GPS location) to determine that (a) the home is vacant and (b) that nobody is likely to return in the immediate future based on prior patterns. The system determines the best course of action is to shut the garage door for security and send an update memo to the home owner.
Similarly, the digital health ecosystem abounds with opportunities to advance care and improve the health experience. Real-world data generated by the health IoT is becoming increasingly abundant and accessible. A recent Deloitte survey found that consumers are becoming more interested in technology such as wearables and mobile apps, for health purposes. Specifically, 60 percent of respondents said they are willing to share data gathered from wearable devices with their doctors.1 Health-related IoT ecosystems have the potential to generate profound insights and enhance patient care—even within the home.
Consider patients who are living with diabetes. A health IoT ecosystem might enable more precise glucose control, which could help improve short- and long-term health outcomes. The input and output devices for this particular ecosystem (a digital glucose monitor, an automatic insulin pump, a smart watch, and a smart pill box) connect through an AI-enabled diabetes management platform. On its own, the continuous glucose monitor could make insulin dosage recommendations. But the digital ecosystem becomes even more powerful when data—including patient activity levels and smart pill uses—is added (e.g., heightened stress, changes in physical activity or forgetting to take medication). By tapping into historic activity patterns, the system could further refine the recommendations. For example, by prompting the user to decrease his insulin dosage on Saturday mornings when he plays basketball with neighbors. With the patient’s verbal confirmation, the adjusted insulin dose would be administered. An ecosystem like this—in which real-time data feeds are processed and combined with predictive models—enables truly personalized health interventions when properly integrated, optimized, and monitored.
Health care organizations that want to take advantage of IoT and virtual health will likely need to work through some key steps to realize this digital health ecosystem vision:
Inputs and platforms: Integrating multiple inputs onto a single platform, or compatibility across multiple platforms, can be challenging. Many companies have a proprietary strategy for delivering IoT, which means users are restricted to a list of devices that are compatible with the platform they choose. Health care organizations that want to build an IoT platform should first consider the standards through which the devices can be accessed and how the devices will communicate and interact with other components of the ecosystem. More specifically, these organizations will likely need to determine whether the platform is capable of supporting data from multiple existing and future inputs. Organizations should consider the extent to which the platform is customized in-house vs. relies on standard configurations by the platform vendor. In health care, there are few clear IoT standards and protocols. 2 Although some partnerships are being formed to develop standards, work still needs to be done to foster true interoperability and increase industry adoption. 3
Integrating multiple inputs onto a single platform, or compatibility across multiple platforms, can be challenging. Many companies have a proprietary strategy for delivering IoT, which means users are restricted to a list of devices that are compatible with the platform they choose. Health care organizations that want to build an IoT platform should first consider the standards through which the devices can be accessed and how the devices will communicate and interact with other components of the ecosystem. More specifically, these organizations will likely need to determine whether the platform is capable of supporting data from multiple existing and future inputs. Organizations should consider the extent to which the platform is customized in-house vs. relies on standard configurations by the platform vendor. In health care, there are few clear IoT standards and protocols. Although some partnerships are being formed to develop standards, work still needs to be done to foster true interoperability and increase industry adoption. AI and data management: Data is the backbone of the IoT ecosystem. Without data, AI cannot perform analytics and generate actionable feedback loops. Data security is paramount when handling PII/PHI (personally identifiable information and personal health information). Data that circulates between distributed devices and end-users is especially vulnerable to security breaches and unauthorized access. Developers should take proper measures around encryption, access control, and traceability, and overall compliance with HIPAA requirements (for example not all consumer electronics are HIPAA compliant!). Organizations should ensure that data security and integrity is ensured throughout acquisition, processing, storage, transfer, and use. 4 Similarly, special attention should be placed on any AI engine’s ability to meet pertinent standards and requirements (which can vary with geography and the regulatory regime under which the solution falls).
Data is the backbone of the IoT ecosystem. Without data, AI cannot perform analytics and generate actionable feedback loops. Data security is paramount when handling PII/PHI (personally identifiable information and personal health information). Data that circulates between distributed devices and end-users is especially vulnerable to security breaches and unauthorized access. Developers should take proper measures around encryption, access control, and traceability, and overall compliance with HIPAA requirements (for example not all consumer electronics are HIPAA compliant!). Organizations should ensure that data security and integrity is ensured throughout acquisition, processing, storage, transfer, and use. Similarly, special attention should be placed on any AI engine’s ability to meet pertinent standards and requirements (which can vary with geography and the regulatory regime under which the solution falls). User interfaces: Particularly in health care, simplicity and user-friendliness are paramount to promote adoption and prevent possibly severe health implications. Challenges include limited IT literacy among users, which can lead to difficulties related to installing, configuring, or integrating the devices.5 Organizations that want to build IoT devices should consider developing a friendly, easy-to-comprehend user interface and user experience (UI/UX) that will help address this common adoption barrier. When building the user interface, health care organizations should pay close attention to accessibility (e.g., for elderly or disabled patients), expandability (the ability to add other devices and functionalities), and engagement (capabilities like gamification and nudging that use behavioral economics to improve well-being). Deloitte and the Perelman School of Medicine at the University of Pennsylvania recently published the results of their STEP UP study, which highlights that gamification combined with wearable fitness trackers can lead to sustained results (more steps).
Health care organizations should build IoT into their broader virtual health strategy, specifically geared toward patient engagement and care management objectives. To achieve IoT’s potential, health care organizations should consider the following seven questions:
Where is IoT likely to have the biggest impact on the quadruple aim (i.e., enhance the patient experience, improve the health of populations, reduce costs, and enhance the caregiver experience)? In which ways can IoT solutions radically re-imagine patient engagement and care management? How can organizations manage implementation to maintain patient safety and improve the patient experience during the transition?What additional inputs might need to be combined with the existing digital/virtual health infrastructure to integrate IoT into care management plans, thereby creating an ecosystem powered by multiple devices What additional inputs might need to be combined with the existing digital/virtual health infrastructure to integrate IoT into care management plans, thereby creating an ecosystem powered by multiple devices? How should the organization source its IoT platform? What existing platforms and solutions can accelerate the journey to implementation? How can the organization address physician resistance to technology adoption in the clinical setting and generate insights that physicians will trust? To further enable IoT adoption, how can the organization align its consumer and physician-engagement strategy with user-friendly interfaces? How can an IoT platform reduce total cost of care, become self-funding, and free up resources for investment in other critical capabilities?
Most health care organizations are in the early stages of developing a health IoT ecosystem. As they embark on the journey toward the future of health, they should acknowledge that the true strength of IoT resides in creating an ecosystem that brings together multiple devices to create insights and outputs that improve health.Think about this: There are now more than a half a billion types of medical devices manufactured around the world.1 Through the Internet of Things (IoT), a growing number of these devices are collecting, analyzing, and transmitting health data or images to the cloud or to internal servers. Over the next decade, as many as 50 billion medical devices will connect to clinicians, health systems, patients, and to each other.2
Last month, our UK Centre for Health Solutions released a report that examined connected medical devices and their potential to transform health care. Within the next five years, medical technology companies anticipate that 68 percent of their devices will be connected through IoT, up from 48 percent now, according to an online a survey Deloitte conducted with 237 companies. Within five years, 44 percent of respondents predicted that all of their devices will be connected, according to our research.
Devices that diagnose, monitor, and help treat patients touch every part of health care. The connected-medical-device market is expected to more than triple, from $15 billion in 2017 to $52 billion by 2022, according to the research firm MarketsandMarkets.
Our research identifies eight challenges that medtech companies should consider addressing as they transition from being suppliers of innovative products to insightful partners in health care.
Developing an in-depth understanding of end users: As the idea of value-based care gains more traction in health care, stakeholders will likely push medical technology companies to demonstrate the value of their products.
Solution: Manufacturers of connected medical devices should forge closer ties to health system leaders, clinicians, and to patients who rely on their products. They should build new business models and scenarios that demonstrate how their devices can improve patient outcomes and create value to stakeholders. Nearly 40 percent of medtech companies are, to a large extent, taking a value-based approach to their pricing, according to the results of the survey.
Building funding, business, and operational models: Only about half of surveyed medtech companies say they are implementing new business models to a large extent, while just 10 percent of respondents said they are not adding any new models.
Solution: The fee-for-service payment model does not reward health systems or clinicians for their ability to prevent illnesses or to avoid long-term costs. We are probably still years away from having a value-based health care system that effectively rewards innovation, but the industry is working toward it. We recently worked with the Advanced Medical Technology Association (AdvaMed) to launch a strategic value initiative—a framework that assesses the value of medical technologies that can be adopted by medtech companies, health systems, health plans, and other industry stakeholders. Innovation will likely require different business models, and progress will depend on medtech companies developing new ways to take on risks and rewards.
Improving interoperability: If health care stakeholders are to take full advantage of connected medical devices, interoperability could be critical. Interoperability can be a significant barrier to creating a patient-centered, digitally-enabled health care ecosystem. There are privacy and security challenges associated with the exchange of health information, and there is no single standard for electronic health records (EHR) systems. There is also little incentive for the private sector to move toward a more interoperable system.
Solution: Open platforms, based on open-data standards, could allow health plans, health care providers, and technology vendors to come together to make data more available to each other. Stakeholders should work toward developing a unified platform through which clinical data can be shared. They also will likely need to develop a consensus for interoperability standards.
Maintaining cybersecurity: Nearly 70 percent of medical device manufacturers say an attack on their medical devices is likely, but just 17 percent of those companies are taking significant steps to thwart cyberattacks, according to research from the Ponemon Institute.
Solution: Our survey results indicate that most medtech companies are working to maintain the security of their connected devices. More than 80 percent of respondents said they were “reasonably well prepared” (44 percent) or “very well prepared” (37 percent) to protect their devices. Just 14 percent of respondents indicated that they were “not very well prepared,” or “not at all prepared” to protect their devices from a cyberattack. Medical device manufacturers should consider adopting a “security-by-design” approach where a device is built from the ground up to be secure, rather than having security features added after it has been delivered and deployed. Navigating regulatory change: A variety of security issues related to connected medical devices has prompted new regulations and guidelines that medtech companies need to navigate.
Solution: Survey results indicate that medtech companies are prepared to comply with regulatory changes. Forty-three percent of respondents said they were “reasonably well prepared,” while 39 percent said they were “very well prepared.” Medtech companies should build strategies to engage with regulators on their innovation models. They should also consider involving clinicians and patients when designing products. The US Food and Drug Administration’s (FDA) initiatives to develop a more collaborative approach to innovation could provide a path for regulators outside of the US to follow.
Attracting digital talent: There is some concern among stakeholders that they might lack the skills needed to deploy connected devices, which could hinder market growth. To stay competitive, medtech companies should build a tech-savvy workforce.
Solution: Nearly 80 percent of surveyed medtech companies said they are prepared to build digital capabilities within their companies. Resourceful recruitment and retention strategies could include collaborations and partnerships with a diverse range of existing and emerging players (e.g., academia, engineering companies, technology firms, and innovative new start-ups).
Maintaining trust in a digital age: The success of connected medical devices can hinge on the willingness of patients to share their health data. This is probably less likely to happen if patients aren’t sure how their data will be used. As more devices become connected, medtech should be vigilant in protecting patient data. In a My Take a year ago, I wrote why medtech companies need to make sure patient data are secure.
Solution: Medtech companies should earn the trust of providers and patients by developing strong privacy and security arrangements through the use of data encryption and authentication mechanisms. They should also give patients control over their own data (including the right to keep it from being shared), and allow the patient to see who is using data and for what purposes. Nearly 70 percent of surveyed medtech companies agree that patients will eventually own their health data. Embedded blockchain-like technology could offer a real-time mechanism for tracking how data are processed.
Improving the adoption of medical technology: More than 70 percent of medtech companies said health care systems and clinicians are not yet prepared to use data generated from connected medical devices. According to our recent surveys of US health care consumers and physicians, half of consumers use technology to track their health information and 53 percent said they shared this information with their doctor. However, only nine percent of providers have implemented technology for remote monitoring and/or integration of data from wearables, and just 27 percent intend to add this capability within the next couple of years.
Solution: Medtech companies should provide health care stakeholders with robust and reliable evidence that the data generated by their devices can reduce costs, improve efficiencies, and lead to better patient outcomes. They also should demonstrate that the devices are intuitive and easy to use, and, when necessary, offer training and support to staff.
As connected medical devices become more sophisticated and mainstream, we can move closer to having an interconnected health care system. Along with allowing clinicians to change how and where medical care is provided, connected medical devices have the potential to gather, analyze, and share data that could help improve our understanding of patients and their diseases.In our sixth Internet of Things Newsflash we cover recent news and updates from the international IoT space. Both HPE and Microsoft provided Edge computing news while the IIC announced a new testbed and Telefónica and ASTI Mobile Robotics made their cooperation public. Additionally, a NelsonHall study examined the current state of IoT projects and a survey by Plataine/ SME.org highlighted current digital factory trends.
HPE to invest $4 billion in intelligent edge – Hewlett Packard Enterprise (HPE) announced a four year plan for investing $4 billion in intelligent Edge technologies and services built on data insights. As part of the announcement Antonio Neri, HPE’s president and CEO, stressed the importance of data in today’s business and provided an outlook for edge-to-cloud architecture.
Microsoft makes Azure IoT Edge generally available – Microsoft announced that Azure IoT Edge is now generally available (GA) globally for their enterprise customers. In addition, IoT Edge is now open sourced and available on Microsoft’s recent acquisition GitHub.
IIC announces Smart Printing Factory testbed with Fujifilm – The Industrial Internet Consortium (IIC) announced the Smart Printing Factory (SPF) Testbed led by Fujifilm and supported by Fujitsu, IBM, Real-Time Innovations and Toshiba. This testbed and its Smart Printing Factory Platform are intended to automate print production as well as provide predictive maintenance for factory-based printing equipment.
Telefónica and ASTI Mobile Robotics team up – The two companies signed a collaboration agreement focusing on industrial IoT as part of the “Logistics 4.0” field. The collaboration consists of both a technological and a commercial component, which means that Telefónica and ASTI Mobile Robotics intend to develop both new products in the field of LTE networks as well as new business together.
NelsonHall study “IoT Services: Continued Focus on Use Cases” – The new NelsonHall study examined the current state of implemented IoT projects across organizations. The report found that most organizations are focusing on incremental adjustments rather than transforming entire business models. Improving operations and enhancing existing offerings have been identified as main goals of current IoT projects.
Digital manufacturing survey by Plataine and SME.org – The joint survey conducted by IIoT solution provider Plataine and SME.org questioned 400 C-level members of the manufacturing industry and illuminates current trends in Industry 4.0 and the digital factory environment.Deloitte Consulting Chief Futurist Robert Schmid, AKA “Mr. IoT,” interviews guest specialists across the burgeoning IoT space. They’re taking deep dives into the world of connected technologies and in particular the human impact these technologies have on how we live and work.
Guests include current and former luminaries of the digital world, including Deloitte leaders and practitioners who have worked on IoT projects, clients who have implemented IoT, and collaborators from our alliance network. Topics have covered Industry 4.0, smart buildings, smart cities, connected home and medical devices, digital supply networks, industrial IoT, AR, AI and machine learning, virtual assistants, standards, and more.
Check back each week for new episodes. You can also view episodes of Coffee with Mr. IoT as a video series on YouTube.During the rise of the Internet, communication services treated their network providers as little more than “dumb pipes,” providing bandwidth. The IoT revolution, requiring a dramatic increase in strong, secure communication links, offers providers an opportunity to not only play a larger role but to create new value.
The Internet of Things (IoT) has become increasingly visible thanks to the rise of intelligent thermostats, interactive fitness trackers, and the promise of autonomous vehicles. Such technologies are compelling because they make the things around us smarter and more interactive. In the words of one commentator, we need no longer settle for dumb tools but can instead look forward to “enchanted objects.”1
The sensor technologies that make things “smart” are only part of the IoT, however. Connecting all these devices is what turns isolated pockets of technology into a network that generates and pools data in ways that lead to valuable insights.
Thanks to the central role of communications in many IoT deployments, how companies create value is often a function of the interaction between sensor technology and the network layer. Linking new and legacy sensors within an IoT ecosystem often means that companies seeking to realize value from the IoT need to work closely with their communication services providers (CSPs).
In the words of one commentator, we need no longer settle for dumb tools but can instead look forward to “enchanted objects.”
Such collaboration is unlikely to come easily to either party. Consumers of communications services can easily overlook the challenges associated with creating the sort of connectivity required to realize the full benefit of IoT technology. With “Internet” in its name, the IoT connotes that the advancing legions of smart devices need simply plug into the existing infrastructure: Just give everything an email address and we’re good to go. In this scenario, CSPs aren’t indispensable partners—they’re mere vendors.
Providers of network services can be expected to have their own biases to overcome. The rise of the Internet separated communications services from the communications network they ride over. There was a tendency among CSPs to resist the claim that they provided little more than “dumb pipes,” a term that belied the industry’s technological sophistication. Yet the economics of the asset intensity implied by building out near-ubiquitous, high-bandwidth, reliable, and secure wireline and wireless networks rewarded the large-scale deployment of relatively undifferentiated services. Shifting to a more nearly bespoke set of solutions means going against a grain that runs deep.
To help companies and CSPs think more carefully about how they work together and overcome any legacy of benign mutual neglect, we are well served to consider how sensor technology and network systems relate within different IoT deployments, the nature of the value created, and what that means for the collaboration required.
The rise of smart, connected things—from wearable activity trackers to connected cars to the electrical grid—allows companies to compete not only on the functionality and performance of their products or services but also on the information created by the use of these products or services.2 Where supply chains determine functionality and performance, the value created by information is captured by the Information Value Loop (see inset).
The suite of technologies that enables the Internet of Things promises to turn almost any object into a source of information about that object. This creates both a new way to differentiate products and services and a new source of value that can be managed in its own right.
Creating value in the form of products and services gave rise to the notion of a “value chain”—the series and sequence of activities by which an organization transforms inputs into outputs. Similarly, realizing the IoT’s full potential motivates a framework that captures the series and sequence of activities by which organizations create value from information: the Information Value Loop.
Note first that the value loop is a loop: an action—the state or behavior of things in the real world—gives rise to information, which is then manipulated in order to inform future action. For information to complete the loop and create value, it passes through the stages of the loop, each stage enabled by specific technologies. An act is monitored by a sensor that creates information. That information passed through a network so that it can be communicated, and standards—be they technical, legal, regulatory, or social—allow that information to aggregated across time and space. Augmented intelligence is a generic term meant to capture all manner of analytical support, which collectively are used to analyze information. The loop is completed via augmented behavior technologies that either enable automated autonomous action or shape human decision in a manner that leads to improved action.
Getting information around the Value Loop allows an organization to create value; how much value is created is a function of the value drivers, which capture the characteristics of the information that makes its way around the value loop. The drivers of information value can be captured and sorted into the three categories: magnitude, risk, and time.
The value loop begins with creating and communicating information in entirely new contexts. Sensor technology enables actions in the world to give rise to data—the create stage. Networks, often provided and managed by CSPs, link create and communicate, liberating data and enabling the rest of the value loop. It is at the interface between the two that the opportunity for new forms of collaboration arises.
When the Internet emerged, most online services connected people, and there was a relatively high tolerance for low or variable quality because people are good at coping with latency, errors, and/or failure. Unlike people, even smart machines are poorly equipped to deal with these same communication issues. In other words, dumb pipes are sufficient when connecting people; smarter pipes become more important when connecting things.
More demanding still, some companies are deploying a much larger number of sensors—connecting tens of billions of things rather than “merely” hundreds of millions of people—and many companies are placing those sensors in harsh environments or mission-critical situations that put new stresses on how these devices need to communicate. Consequently, there is no one-size-fits-all combination of sensors and network connectivity. What is being connected (that is, the nature of the sensors) and how it is connected (that is, the nature of the network) have a real impact on how value is created. At first principles, the differences turn in many cases on a choice between new and legacy sensors, and between “best efforts” and managed communication.
In weighing how to incorporate IoT technology and applications, few companies today are starting from scratch. Many industrial activities, for instance, have long had sensors generating data, at central plants and remote locations, at customers’ homes and main assembly lines. These sensors, often installed decades ago, typically have limited communication or autonomous operation capabilities—they rely on human operators for activation and data collection-much less the capacity for analysis and action. So the first key decision is whether to augment existing sensors or to replace those sensors with smart, connected devices.
As with many technologies, prices of IoT-enabled sensors are falling. In commercial applications, replacing existing sensors nevertheless can be expensive. More daunting, wholesale replacement can require rethinking a business process. This combination of cost, asset life cycle, and inertia means that many solutions will rely on existing sensors augmented with either communication capabilities or additional sensors. (As a company rolls out new business assets, those can be outfitted with new sensor networks.)
In contrast, consumer applications often require new smart sensors—either as standalone additions to an existing asset or to be embedded in a replacement asset. Current standalone examples include smart thermostats and security systems. Sensors are also being embedded in cars, domestic appliances, and consumer electronics. These solutions’ functionality—and business models—are still in flux, leaving similarly undetermined the relationship between the capabilities of the sensors and the networks they require. In other words, consumer-facing businesses don’t know yet what IoT-enabled products customers will buy in the coming years, or exactly how those products will function, so it is next to impossible to determine ahead of time what communication networks will be necessary.
In a best-efforts communication network, the customer essentially gets what is available. There are no guarantees on data speed, responsiveness, availability, error rates, or other performance attributes. For some services, such as downloading or streaming content, this can prove bothersome: Almost everyone has experienced delays while the viewing software waits for the missing bitstream to arrive, or been forced to reboot when an Internet-based application freezes. To compensate, many customers end up buying more bandwidth—capacity and speed—than they actually need and hope that in most circumstances this will enable a reasonable service level.
Currently, almost all wireless connections provide a best-efforts approach to communications3—in other words, the availability, data transfer rate, packet loss rates, and latency are subject to the vagaries of contention for capacity between users, interference, and radio propagation.
In contrast, a managed-communications solution shifts to the CSP the burden of ensuring a reliable bitstream, opening the door to customer applications that demand reliable real-time or near-real-time connectivity over wide distances or other similarly demanding constraints. The International Telecommunications Union identifies three dimensions of managed services:4
Grade of Service (GoS) : This defines the physical connection’s availability and performance and measures attributes such as coverage, capacity, and the probability of a network outage.
: This defines the physical connection’s availability and performance and measures attributes such as coverage, capacity, and the probability of a network outage. Quality of Service (QoS) : This defines the traffic flow’s performance and allows an application to specify its needs according to attributes such as latency, jitter, dropped packet performance, error rates, and guaranteed throughput (bit rate).
: This defines the traffic flow’s performance and allows an application to specify its needs according to attributes such as latency, jitter, dropped packet performance, error rates, and guaranteed throughput (bit rate). Quality of Experience (QoE): This relates to users’ experience of using a service and is beyond the scope of this article. It is a subjective assessment of the end user’s experience with the service and thus brings in the communications network, the terminals, ease of use, and so on.
When connecting sensors to networks—that is, when linking the create and communicate stages of the value loop—lost information and transmission delays can generate a variety of undesirable outcomes, especially when IoT-generated data are driving the operations of heavy equipment or public utilities. Closer collaboration between network users and network service providers can help avoid such difficulties because the technologies enabling each IoT deployment can be configured to address the specific GoS and QoS performance levels required. (QoE tends to take center stage when we get to analyze and act.)
On the downside, managed solutions can be comparatively expensive to construct and operate—certainly more so than ad-hoc best-efforts wireless systems—but they can solve legacy issues such as requesting sensor data, managing the relationship between multiple sensor data streams, and understanding whether a sensor has failed or is just unable to communicate.5 The communications network can take responsibility for managing the collection cycle (a pull approach), providing time and device stamping of sensor information, and ensuring device functionality and security.
Mapping the options for sensors (legacy versus new) and communications networks (best-efforts versus managed) reveals four categories of IoT deployments, each defined by the primary dimension of value most affected by the relationship between the company deploying an IoT solution and its CSP (see figure 1). Locating a given IoT deployment and its associated value loop provides a roadmap for assessing the viability and advisability of evolving current solutions to potentially more valuable—even if more demanding—configurations.
By examining each quadrant through the lens of a specific use case, we can begin to understand the value that each combination can create, as well as the implications for collaboration between a company and its CSP.
The current IoT emphasis on cost savings and IP-based solutions, with a heavy reliance on wireless communications (typically a best-efforts network), has resulted in very few examples of customization, which relies on managed communications. Among those that have come closest so far are some industrial point solutions such as German automation manufacturer KUKA’s connected robots, part of a 1,444-node network linking around 60,000 devices.6 One such deployment is in the new Jeep Wrangler production facility in Toledo, OH, where 259 robots are connected through 33 control points and are able to produce 830 car bodies for eight different vehicles every day.7 The connections between these industrial robots have traditionally been hardwired local area connections.8 Since each of these solutions has been contained inside a single facility, requiring a full private network, the companies have not engaged CSPs. This self-contained approach is representative of highly customized solutions. IoT systems that require high security, uninterrupted connections, and the latest technology are typically deployed in circumscribed environments running proprietary protocols over a hardwired network.
As quality improves and prices fall, more companies will likely find customized solutions, implemented in collaboration with a CSP, increasingly attractive.
Such a “closed shop” is unlikely to persist indefinitely, as two forces drive more companies to engage CSPs even when developing customized solutions. First, as firms implement IoT solutions in a wider variety of contexts, the performance benefits of customized sensor/network combinations will become clear, as will the flaws of many work-arounds based on existing best-efforts infrastructure. Early IoT solutions aimed to solve point problems, such as how to make a machine more productive or autonomous; the next step is using the IoT to make a system, with multiple machines, work in concert, and this requires managed communications. Second, the communications technologies required today for customized solutions are likely to follow in the footsteps of previous telecom technologies: falling costs and increasing modularization.9
As quality improves and prices fall, more companies will likely find customized solutions, implemented in collaboration with a CSP, increasingly attractive. Consequently it makes sense to explore the other three categories of IoT communication deployment not only in terms of how firms are currently using the technology but also in terms of how companies might migrate their current approaches to this more demanding, but more rewarding, configuration.
Furthermore, since few companies will have the luxury of starting over with their IoT strategies, unencumbered by legacy systems or budget constraints. So, in addition to describing how a company and CSP collaborate in the other three quadrants, we will explore how applications starting in each quadrant can make the migration to customized solutions, with an emphasis on how each application’s starting point affects its path forward.
Unsurprisingly, cost reduction characterizes many companies’ current priorities for IoT deployments, which in many cases consist of comparatively rudimentary sensors linked by a basic Wi-Fi network.10 Especially with large, established organizations—particularly those with huge investments in existing machinery—we see numerous situations in which equipment is already instrumented but executives have not yet moved to integrate the resulting data into an automated workflow: the value loop’s communications, aggregation, analysis, and action stages.
Consider the mining industry, where most large mine vehicles have been fitted with sensors since before anyone spoke of an Internet of Things. Caterpillar’s Vital Information Management System,11 for instance, collects data on more than 250 attributes such as payload, engine RPM, brake condition and use, structural stress, and replaceable-part condition (for example, air filters) from the massive haul trucks. This information is used to assess the truck’s health, increase vehicle uptime, maximize route and payload efficiency, and even provide data on the condition of the haulage road the mining truck is using. Initially, this system was designed to enable data download from the vehicle; now Caterpillar can link it to a system such as MineStar12 that allows fleet management and vehicle health monitoring over a radio link—usually 802.11 b/g, a best-efforts Wi-Fi connection.13
The bottleneck in the create phase is the cost and complexity of measuring new vehicle attributes and fundamentally changing vehicle sensors. Since a large mine haulage truck typically costs between $500,000 and $5 million and lasts perhaps 20 years, operators will likely opt, for now, only to augment existing sensor capabilities. But this will necessarily limit the potential value from IoT solutions.
As companies look to exploit IoT capabilities more fully, one way forward is to migrate to more carefully managed networks: With long-lived assets—such as haul trucks, with sensors built into the engine—it is easier to upgrade the network than the sensors. For example, some mine haulage companies are beginning to deploy autonomous vehicles by retrofitting14 additional sensor systems (collision-avoidance sensors and positioning systems) and networking them through a managed communications system. The companies’ CSP partners add significant value and control two bottlenecks: the deployment of managed networks and the ability to manage legacy sensors more effectively to improve asset performance and lower operating costs.
There are already mining applications emerging for which companies are deploying localized managed communications. For example, in many underground situations, companies deploy a wired and wireless data network for telemetry, monitoring, and limited remote operations. But these private networks, while built to a high standard and with extensive redundancy built in, cannot truly offer fully managed communications. As mining moves to more automated solutions, with a shift from simply improving the performance and safety of manned machines (for example, having an operator manage a machine by remote control) to machines working in harmony to create an autonomous mining system, communications networks will require total control, to ensure the system’s safety and efficiency. As with other firms and industries with IoT deployments in the cost quadrant, mine haulage companies moving toward customization demands both upgrading to new sensors and working with CSPs to implement a managed communications system.
Some companies, working with last-generation sensors installed years ago, have moved to convert their existing connections into IoT functionality by dramatically upgrading the communication links between their sensors, working with CSPs to improve and control communications.
For example, in managing its wind turbines, GE tapped its existing range of sensors, including lasers that measure the wind heading for the turbine and sensors in the turbine linked to others at the wind-farm level, at the storage system, and in the distribution grid.15 Using its highly developed communication system to meet demand, the wind farm analyzes information to optimize power production, operations and maintenance costs, and flexibility. The system analyzes tens of thousands of data points every second to integrate hundreds of megawatts into the grid. The GE system has six interconnections that communicate with each other: turbine to turbine, farm to farm, farm to grid, turbine to remote operations center, turbine to battery, and turbine to tech.16 Through these communications—achieved using reliable fiber and wireless IP communications—the system is able to optimize power output and management for grid operators. These solutions are largely focused on improving the generating capabilities of an individual wind farm.
The next step for GE, and for other companies with legacy sensors and managed communications, is moving to wide-area managed communications and broader sensor networks. Since wind power is less reliable and predictable than traditional fossil-fuel generation, power grids that aim to integrate it often struggle to match supply with demand. Grid operators’ technical challenges can result in voltage and frequency management issues: In essence, a grid runs in a situation where demand and supply are exactly balanced; if demand begins to exceed supply, the frequency of the grid will fall, and power-plant operators have a series of approaches to resolve this situation.
Managed wide-area communications will clearly help deal with wind power’s unpredictability, but very low latency can enable wind power to play a more significant role in frequency management. The bottom line: As wind power becomes a more significant component of power generation, wide-area managed-control networks will likely be necessary to effectively integrate this new power source.
So in the case of mining operations, the shift to managed communications offers significant benefits; the key tradeoff appears to be deploying a local private network or purchasing managed communications from a CSP. In the wind-turbine situation, the choices are the same, but the wide-area nature of the communications means that a CSP solution likely makes more sense.
Consumer-oriented IoT devices are a recent development, so naturally the sensors at the heart of their functions are more nearly up to date. But since at least some customers will use these appliances across networks managed by different CSPs, the devices’ connections can’t be as heavily managed as sensors that operate solely within the orbit of a single provider.
An example is the Fitbit fitness band, the latest iteration being the Surge,17 which measures exercise activities, heart rate, steps, and route information (for example, distance, pace, gain). Usually, it connects via Bluetooth to the user’s smartphone and thence to the Internet, updating the user’s Fitbit account every 20 minutes or less. This limited communications does not impede the device’s functionality in its current role: primarily, recording exercise data.
However, those limitations may hamper efforts to integrate the device into a personal health-and-fitness ecosystem. Today Fitbit can be integrated with other analytics and sensors systems, but this relies on the user to create the integration and offers limited increased functionality. For example, a user can manually link her Fitbit to a Weight Watchers, MyFitnessPal, or Endomondo application,18 or to other IoT devices such as a Withings body analyzer (measuring weight, BMI, fat mass, and air quality). While part of a sophisticated ecosystem of analysis, a Fitbit band is nevertheless hamstrung by best-efforts communication.
With more sophisticated communication links, a Fitbit would be able to interact with other sensors and actuators. In a gym workout situation, it could pass a user’s heart rate, exercise levels, and body temperature to smart climate-control systems to modulate the air-conditioning system in real time. Similarly, if multiple gym users are wearing the same technology, their sensors could interact in real time to allow for direct competition or to create overlays of historical data with information from the sensor—for example, overlaying the user’s current workout with a historical performance: How does my time compare to Jesse Owens’? Finally, the Fitbit could interact with the exercise machine for more sophisticated workouts. Thus it is likely that at least some companies will shift some consumer applications from best-efforts communications to managed situations, allowing for much more complex interactions between devices and for consumer devices to take on more critical functions.
Even so, making such a shift requires careful consideration: for many consumer applications, a shift from best-efforts to high-powered, top-security managed communications would be both impractical and overkill. The basic functionality envisioned for a smart refrigerator or thermostat is not materially compromised by the momentary hiccups and delays of a Bluetooth or Wi-Fi connection, and no hacker would bother attacking such a small target. Also key: Consumer-device manufacturers sell highly standardized products to a global market, with no control over which networks consumers may use for their new IoT devices, making managing those communications problematic at best. Some consumer-facing companies will be able to make the move to the customization quadrant; many will not.
Obviously, companies constitute only half of the partnership that can get them to the customization stage, with managed communications to link and draw value from new IoT sensors. CSPs—soon to be tasked with connecting millions of new devices and users, carrying both sensor data and sensitive information19—will play an important role, one that both requires more from them than in the past and offers far greater opportunity to create value.
In the IoT world, CSPs’ biggest challenge is to shift from an environment in which they charge based on volume of traffic and connections to one in which they charge based on level of performance. These firms, long relegated to a back-office function, will have to take unaccustomed risks to create networks in which they can guarantee that a particular data communication will take place—every time—with the latency, speed, and error rate that the customer has demanded. This represents a major shift, since today, even in managed networks, CSPs either set the bar low on performance guarantees or make only limited, aggregated performance promises.
CSPs also face a major technological challenge, the one that makes high-level IoT applications function: the actual work of collecting and processing information from multiple sensors and devices—and standardizing it, even as technologies continue to evolve. In order to do this, CSPs will need to implement their QoS capabilities in a standardized way that makes it easier for sensors and applications to take advantage of them. This means driving customer loyalty and differentiating their services based on performance, rather than aiming to lock customers into a proprietary interface.
In general, IoT devices generate limited volumes of data traffic, so the capacity of the pipeline is far less important than for, say, streaming video—in the IoT, the relationship between traffic flows is where the value lies. In a model where carriers charge for traffic, the revenue uplift from handling IoT-based data will be less than those carriers might hope, especially as data prices continue to fall. Thus, charging for QoS performance and delivering on performance guarantees creates a mechanism by which CSPs are able to grow revenues and sustain investment in their networks. Indeed, the importance of carriers correctly pricing managed services is key—too often, they charge too little to cover the enormous costs of serving clients and prioritize attracting new customers over asking premium prices for premium services.
For convenience and cost , standards are key, so CSPs should implement QoS in a standardized form that smoothly links applications and services.
and , standards are key, so CSPs should implement QoS in a standardized form that smoothly links applications and services. For companies implementing a control -based solution, CSPs need to consider managed services and IoT applications as a way to link the communications network to end-user applications, not just a form of short-term differentiation.
-based solution, CSPs need to consider managed services and IoT applications as a way to link the communications network to end-user applications, not just a form of short-term differentiation. When defining a customization-based solution, CSPs need to understand the benefits of an industrial IoT solution moving to a managed wide-area communications system and, then work with IT services, device providers, and customers to deliver on the plan.
We have seen that close connections and structured, predictable relationships between an IoT system’s sensors and actuators can allow companies to expand processes’ efficiency and capabilities. Take, for example, security. In an IoT ecosystem, security is not a single problem or a single solution—rather, it must be included at each layer of the stack from physical to application layer. The strongest passwords and credentials for an application are useless if hackers can intercept the data as they travel across a network. Researchers have also recently succeeded in wirelessly stealing many decryption keys based only on the emissions from a computer’s processor, meaning that devices now too must be designed to strict security standards.20 To do so, CSPs and their partners at every level must collaborate closely to ensure proper functionality.
However, the challenges for users can be substantial—in particular, the cost and complexity of partnering with CSPs to engineer managed communications networks, especially on a wide-area basis. Without the capabilities of a managed network, companies will find their IoT applications’ value generation limited to processes that are not dependent on instant communication and near-total accuracy.
For many IoT deployments, both the key driver of value creation and the main determinant of value capture lie at the intersection of create and communicate. These stages draw upon sensor technologies and communications networks, respectively. The degree of collaboration with its CSP that a company considers will be a function of the way in which it hopes to create value now and in the future.
When cost is paramount, a traditional working relationship can be entirely adequate. CSPs can focus on economies of scale; IoT deployments can exploit well-understood, standardized solutions. Convenience-driven solutions in the consumer sector are largely similar, with the possible exception of a greater willingness by companies to accept lower performance from their CSPs than in commercial applications, in the interest of greater innovation. Exploiting such opportunities requires not so much deep collaboration as sufficient insight into a CSP’s technology roadmap so that new functionality can be exploited as quickly as possible.
When control is central, companies should at least be open to collaborating more closely, leaning on cutting-edge CSP solutions to compensate for legacy and retrofit sensor technology. Such solutions often create knock-on problems around, for example, security, and CSPs can be well positioned to address such issues.21 In the early days of such deployments, the CSP may well be relieving the bottleneck to value creation, and so close collaboration might also be key to value capture. However, the CSP should not charge too much for its capabilities, since doing so could create financial incentives for companies to create private networks or stronger standalone capabilities.
Today we have examples in which closed private networks can deliver better results with a similar level of automation: For example, KUKA claims that its factory produces a Jeep Wrangler in 13.57 man-hours, 1.5 fewer than any other Jeep plant. But just imagine what efficiencies could be achieved with wider-area communications enabled by a CSP that link information from point of sale of the vehicle through the entire supply chain. In the case of GE wind turbines, we see how wider-area managed communications can simplify the task of frequency control; in the case of mining, a wide-area (CSP-provided) solution would allow vehicles to easily move from mine to mine and potentially lower the overall communications costs for many mines. And more examples, both successes and failures, will come forward as more companies expand their IoT deployments.
Whatever the challenges, the opportunities are there for CSPs and companies seeking to capture the full potential of the IoT to become closely aligned partners. It is by deploying managed communications at reasonable price premiums in ways that work today while opening a path to tomorrow that CSPs and companies relying upon them to deploy IoT solutions can move beyond the dumb pipe, creating an IoT that is smart at every level.
Deloitte’s Internet of Things practice enables organizations to identify where the IoT can potentially create value in their induastry and develop strategies to capture that value, utilizing IoT for operational benefit.​
To learn more about Deloitte’s IoT practice, visit http://www2.deloitte.com/us/en/pages/technology-media-and-telecommunications/topics/the-internet-of-things.html.
Read more of our research and thought leadership on the IoT at http://dupress.com/collection/internet-of-things/.The third part of the IoT Newsflash series illuminates the possibilities of IoT in the healthcare industry and thereby provides an overview over the most recent publications of renowned research institutes.
The adoption of the Internet of Things is speeding up across all industries. Therefore, the third IoT Newsflash picks and covers insights and use cases from the healthcare industry.
Here, the impact of IoT solutions comprises not only the improvement of the patient’s experience, but also even the improvement of the health of populations and a reduction of the per capita cost of healthcare. Ranging from strategy topics to concrete market insights for a determined device renowned researchers sum up the evolvement of the so called medtech within their most recent studies:
Deloitte’s study Devices And Diseases: How The IoT Is Transforming Medtech enlightens how IoT technology opens the door to business models in which the devices themselves are not the most valuable piece of the puzzle. In other words, the value provided by the technology can be expanded by embedding it in a more inclusive ecosystem. Providing a framework called the “Information Value Loop”, the study provides recommendations and guiding principles that allow well-established health care players to navigate the turbulent waters of the fast-changing, IoT enhanced medtech market.
In a more detailed and less abstract way, Gartner’s Market Insight(2018) on wearables in healthcare ecosystems predicts a gain of momentum in 2018. Wearables sales topped 155 million units in the past two years. Jumping on this bandwagon, 40 % of large health systems will shift form digital health pilot programs to full-scale rollouts in 2020, compared to 5 % in 2017. Giving concrete best practices, the study concludes, that AI and voice technology will be the most important drivers for accessibility and ease of use of wearables. Furthermore, B2B channel development and the increased acceptance of patient-generated data from wearables in healthcare communities boosts and interconnects the medtech market.
Forrester’s study Virtual Care Enables the Digital Health Imperative (2018) outlines, that virtual care is about to disrupt today’s outpatient visit. A variety of healthcare players is already increasing its investments in new virtual care solutions, realizing that healthcare delivery is shifting from the hospital to home. Another key takeaway of the study is that healthcare organizations, which have consistently failed to deliver high-quality patient care will have to consider crucially the upcoming virtual care solutions. These virtual care solutions are hosted by a multitude of new and established vendors. The following figure gives a broad overview over the relevant players focusing of the different virtual care solutions provided.Even if your devices and products look the same as they did before they got smart and connected, they’re fundamentally different—now they’re members of a larger community of products, processes, and stakeholders. Making objects capable of filling those new roles is a serious design challenge.
Product connectivity has been part of our daily lives for decades. An automated door is connected because a pressure sensor detected the presence of foot traffic and instructed the door to open accordingly—an example of an open-loop connected system. A thermostat is connected because a sensor detected that room temperature was above or below a set point, thereby instructing a furnace to turn on or off depending on the temperature—an example of a closed-loop connected system.1 In the pre-IoT days, these systems were connected in that they performed limited functions based on what a sensor detected. But they did not typically communicate with other parts of a larger ecosystem, and thus companies had trouble collecting data about usage, customer behavior, and performance.
The Internet of Things (IoT) has ushered in an age of connectivity, one that enables objects to function in new, expanded ways. IoT technology allows objects to communicate with each other continuously, forming large, interconnected systems capable of creating, communicating, aggregating, analyzing, and acting on data.2 This, in turn, opens up a world of opportunity for connected objects that can better serve customers’ individual needs3 and gather data to drive the development of more tailored services.4 Developers can use data gathered via IoT-enabled devices for a range of applications, from consumer goods that make a home more efficient to industrial systems that can enhance asset management.5
The casual observer may see nothing different about a product once it becomes “smart.” But that product is fundamentally different: It is now a member of a larger community of products, processes, and stakeholders, expected to do more and fill more roles than ever before.6 IoT technology transforms the product and everything within it.
As connectivity expands a product’s role and functionality, it only makes sense that its original design might prove limiting. And new smart products need to incorporate IoT technology from the beginning. So product design is a way not only to fashion smart products but also to create an effective connected system. An industrial sensor must generate a much broader range of data than pre-IoT models and, then, be able to securely communicate that information. A fitness tracker needs to incorporate sufficient memory and sensors to collect useful data as well as a reliable connection to a smartphone or computer—all while looking and feeling attractive to shoppers.
This article examines four significant ways in which IoT technology has transformed the nature of products and, by extension, product design. We will also identify the accompanying organizational transformations—in terms of people, process, and technology—that are crucial to successful product design in the IoT age.
The Information Value Loop The Internet of Things is a technology architecture. It is a specific way of stitching together a suite of new and existing technologies to turn almost any object into a source of information about that object. This creates both a new way to differentiate products and services and a new source of value that can be managed in its own right. At the same time, it creates challenges for product designers as they seek to create useful—and usable—objects that can accommodate the added complexity that goes along with connectivity. In order to understand the full nature of those design challenges, we must first understand exactly how IoT technology enables those new products and services. Since the value in connected products comes from their information about the world, modeling the flow of information through the system is a good way to illustrate the architecture. Deloitte’s Information Value Loop illustrates how IoT technology links together enabling technologies to create new value for companies and customers (see figure 1). Note first that the Value Loop is a loop: An action—the state or behavior of things in the real world—generates information, which then gets manipulated in order to inform future action. For information to complete the loop and create value, it passes through the loop’s stages, each enabled by specific technologies. A sensor creates information and is communicated within a network, and standards—technical, legal, regulatory, or social—allow the data to be aggregated across time and space. Analytical support is collectively used to analyze information. The loop is completed via augmented behavior technologies that either enable automated autonomous action or shape human decisions in a manner that leads to improved action. The amount of value created by information passing through the loop is a function of the value drivers identified in the middle. Falling into three general categories: magnitude—how much data is needed; risk—how reliable and accurate must that data be; and time—how quickly the data is needed. These value drivers may offer a good starting point for product designers as they begin to unravel what customers truly need in an IoT product, and what may be extraneous features.
Even in the world before IoT connectivity, a product designer had many things to consider: who would be using the product, how, when, and why—and, perhaps, how it might look in a TV ad or on a store shelf. The object’s desired lifespan and any risks associated with its use could also shift design requirements.
IoT connectivity adds to the process an additional layer of complexity and, thus, challenge. Connectivity reshapes the challenges and complexity of product design; the interconnectedness that defines the technology imposes new requirements. We can begin to categorize the impact of IoT technology on products—and product design—into four main transformations:
With IoT enablement of a physical product, embedded sensors are able to capture and transmit data about that product over a network. The system then analyzes the data and, based on that analysis, takes action. The information the product generates is as important as the physical product itself. In that sense, there is a marriage of the physical and digital worlds: Each component is equally essential to the function, and value proposition, of the connected object.
While this union of the digital and physical brings with it a host of user benefits—including more efficient products tailored to the user’s behavior and demonstrated preferences7—it significantly complicates the design process. Connectivity means the product must be able not only to create and communicate information but to act on it autonomously—in turn creating and communicating new information that enable it to learn and adjust.8 Incorporating these capabilities seamlessly into a physical object such that the object can reliably interact with a digital network while still remaining user-friendly—or outwardly relatively simple—is critical to designing a smart object.9
Indeed, the importance of user-friendliness and simplicity cannot be overstated. Even while making an object smart, the designer cannot lose sight of the customer, her mindset, and how she will use the product. One particular concern that derives from the convergence of the physical and digital may be some customers’ wariness of smart objects; IoT-enabled objects can inspire strong psychological reactions in users, who may fear or overcomplicate a high-tech object that is, practically speaking, no more difficult to use than an unconnected object.10 Even the need to learn a few extra steps or deviate from current habits may deter users from purchasing a connected product, much less signing up for the IoT-based system of which the object is a component.11 Thus, keeping the product simple to use—even while its capabilities expand—is a crucial aspect of design. An IoT-enabled thermostat must still function as a traditional device; a smartphone must still serve as an easy-to-use cell phone no matter how many new features developers add; a connected car must drive normally even if the owner elects not to subscribe to all the available navigation and entertainment options.
In the world of connectivity, no product is an island. An IoT-enabled object will necessarily stay connected to a network to facilitate the communication of data. Indeed, that ability to stay connected and communicate data regularly—if not constantly—constitutes much of a smart product’s value proposition. At one level, connectivity invokes purely technical issues for the product designer: choice of network, power-consumption considerations, and interoperability. Designers creating an IoT-enabled object will thus need to account for the need to stay connected.
At a higher level, when a product becomes a part of a larger IoT ecosystem, the components that make connectivity possible are as much a part of the user experience as the physical object itself—and must be as secure and reliable. For all of the value it adds, connectivity significantly adds to the ways that a product experience can fail. If the components in a connected product that communicate information fail, it does not matter that the rest of the device might function perfectly.
And the stakes are higher: Many consumers find malfunctions in IoT-enabled objects particularly disconcerting; they may appreciate the benefits of physical-digital convergence, but they expect connected products to function as reliably as previous versions,12 especially since connectivity implies new susceptibility to outside interference. Individuals may be relatively tolerant of periodic failures in now-familiar web browsers, voice-over IP, or apps—for which periodic service interruptions can seem contextually appropriate—but they tend to apply their same high expectations about the reliability of previously unconnected objects to their newly IoT-enabled counterparts.13
Beyond its impact on customers’ mindset, expectations of always-on connectivity mean that the implications of failures or compromises in connectivity are dramatically more far-reaching and can have more serious consequences than unconnected counterparts.14 With a connected medical device monitoring patients’ vital signs and informing decision making of remotely located health care professionals, a failure in connectivity could place lives at risk. A connected piece of factory machinery may serve as the linchpin of an automated manufacturing process, and a dropped connection might shut down the entire factory.15 A smart lock that loses its connection may refuse to unlock, leaving a homeowner unable to open his front door.
When a product is connected and expected to be always on, product designers must prepare for the consequences of malfunction and connectivity loss. They must do so across multiple dimensions—not only the object itself but its components and, potentially, even the entities with which it interacts. Designers cannot break down the design process and treat each component separately. Rather, they must understand each component’s actions, interactions, and even security and legal implications as a part of the larger whole.16
If the constant connectivity of an IoT system makes it difficult to separate a product’s physical makeup from its digital components, it also introduces wider interactions that complicate design even further. For example, consider just the communications protocols needed to establish the always-on connectivity that IoT technology demands. The manufacturers of a connected product may assemble the hardware and even write some software code. However, in nearly every case they will use an established communications protocol owned by another company or foundation. In many cases, this can mean using third-party signals to take advantage of that protocol.17 As connectivity is central to the function of an IoT-enabled product, this means that most connected products are dependent upon external groups simply to work as designed.
But this external dependency extends far beyond just communication protocols. Even core customer interactions may be mediated by external elements. With typical products—say, a traditional lightbulb—the interaction between customer and company typically ends at the sales counter. A connected lightbulb, by contrast, may be a part of a larger web of interactions between manufacturer, distributor, third-party developers, and customer.18 These new interactions are integral to the function of the product—indeed, the whole value proposition of an IoT-enabled lightbulb in the first place.
This increases the level of contact the company must have with the customer, as well as all the other stakeholders in the system. This, in turn, ups the ante considerably for the manufacturer: Not only must its designers create a product that can interface with digital systems created by many others outside its direct control—they must design a product and process capable of sustaining continuous, ongoing customer-to-company engagement. In this way, the object changes from simply a product into a product and a service—or, increasingly, multiple services.19
The Amazon Echo, for example, is an audio device with a speaker and set of microphones—in other words, a traditional home entertainment gadget. Echo’s value lies in its connected web service and software platform, which, using voice recognition and artificial intelligence capabilities, act as a virtual assistant that engages digital services and other smart home devices upon command. (Devices expected to launch in late 2016, aim for similar functionality.20) Thus, a user can play music, control a connected thermostat, or summon a car via Uber.21 These external connections are core to Echo’s function and value: If the connection to Uber and other services is dropped, the device ceases to “function.” This enhancement of a physical product with diverse—and expanding—digital capabilities is just one such example of how consumers will shift to engage with smart objects and, also, how designers should account for multiple demands and stakeholders. In this case, the value shifts from the physical object to its operating system—and its ability to interact with other connected systems.
Nor are these issues limited to the world of consumer products. Consider Flowserve, which manufactures valves and other fittings for hydraulic lines. Where customer interactions once ended with valve sales, Flowserve now offers sensor-enabled valves along with as-a-service valve status monitoring.22 As with the consumer-oriented Echo, this shift relies on a host of external interactions beyond the physical valve.
With all of these external connections being critical to a connected product’s functionality, its boundaries extend beyond the physical plastic case or steel valve to encompass communications protocols, APIs, and other components that may not be under designers’ direct control. Regardless, designers may need to consider—or at least take into account—these services as they develop products.
In the pre-connected world, a manufacturer designed a product and released it. Based on market conditions, user feedback, and competitive forces, the manufacturer could subsequently design and release updated versions of that product, or discontinue it altogether.23 In the connected world, that sense of control and predictability changes: Now, not only can a manufacturer potentially change the core function of its product at any time via an update—third-party partners can do the same thing to key components, such as apps.24 The forces of change and product evolution are faster, more complex, and further outside the hands of the manufacturer.
For their part, designers are now tasked with designing an object that can not only adapt to unforeseen updates that can change the function completely but can also accommodate mismatched life cycles. This challenge is particularly acute for IoT-enabled objects. While a traditional product’s components may have differing life cycles—particularly in the case of objects with electronic components—the manufacturer has some level of control and predictability, along with component lifespans of at least several years.25 With connected objects, component lifespans can vary much more widely. Take, for example, the connected car. Individuals typically keep newly purchased vehicles for at least five or six years—the average car on an American road is nearly a dozen years old26—but digital developers push updates every few months, or even more frequently.27 Automakers should therefore take into account the full spectrum of life cycles as they consider the design of a connected car, from its durable frame to its ability to accommodate regular technology updates. Designers must even anticipate technological developments that won’t arrive for several years—and, when they do get here, may alter various car features and functions considerably beyond the initial intended use.28
With digital product update cycles becoming ever more compressed, this problem will likely only intensify.29 Many manufacturers no longer have the luxury of time and predictability in attempting to sort out the complex ecosystems in which their products exist. Evaluation and adaptation of design must be a continuous process.30
Across each of these transformations, a common theme emerges: Connected products are part of complex and ever-changing ecosystems that extend well beyond the product itself. Designing IoT-enabled products, therefore, challenges organizations to think beyond the object to understand exactly how those complex ecosystems work. It requires them to adapt—and to develop new capabilities to keep up with the pace of change.
The issue of “designing for the IoT” moves beyond the contours of product design to touch on organizational design. To effectively design a connected product, the organization should first consider how it will handle the transformations that IoT technology imposes on product design. These new requirements can, in turn, result in a shift in design mindset, responsibilities, and design and management workflows.31
To accommodate these shifts, the organization needs to evolve, which can manifest in three broad ways: people, process, and technology. It is important to note that the changes occurring throughout the organization need not be exclusive to just one of these pillars—particularly with a comprehensive technology such as the IoT. Rather, evolutions can span all three, and each can bleed into the other.
As designers begin to think about developing a connected, smart object—or adding intelligence to a previously unconnected product—they will need to develop new skills to enable them to do so. These can include programming capabilities32 or app design—or at least, the ability to consider the need for those features in a product, and the means to find an expert resource to bring those features to life. To this end, organizations will need to develop networks of reliable experts, either within the organization or via external specialists.
IT and product design skills don’t always overlap, and a traditional consumer products company looking to incorporate IoT technology for the first time may need to bring in a wider range of digital skills such as programmers, engineers specializing in artificial intelligence, and other related skill sets.33 On the other hand, a software company looking to launch its first connected object may need industrial designers, materials scientists, or human-factor specialists to deal with the physical aspects of the new product. Always helpful: individuals who can visualize the design in big-picture terms and understand how the components fit together holistically.
As these skill sets and talent needs come to life within an organization, it will then be important to consider how these experts and specialties will work together, and how their design processes will evolve to accommodate new IoT-specific design requirements.
In a connected environment, designers’ concerns hardly stop at the object itself. They should consider the data that usage of the object generates—the lifeblood of an IoT system. The product’s objective is no longer purely physical, and the information it generates helps shape a new value proposition—and can even result in new, ongoing data-based service offerings.34 Reorienting the design process to focus on that data output as a key design objective may also mean working cross-functionally with teams that understand once-arcane principles—for example, data analytics. These teams can thus provide insights as to what data characteristics—frequency, scale, scope, and others—are most important to consider. This can enable design teams to create products capable of creating and communicating the right data effectively and efficiently.35
Sharing and thinking collaboratively and cross-functionally can require shifts that go beyond individual skills to the organization itself. Indeed, management may need to institute processes to enable broader communication across teams, backgrounds, and even geographies.36 This can also impact leadership: Senior executives may need to reconsider how they manage cross-functional teams, think beyond their own areas of expertise, and create a culture that prioritizes innovative product design.37 These changes in team organization, design considerations, and necessary skill sets can encourage designers to incorporate and update venerated design philosophies to accommodate the new demands of IoT technology. (See sidebar, “Applying design philosophies to the IoT.”)
Applying design philosophies to the IoT There are nearly as many design philosophies as there are designers. No single philosophy is intrinsically more valid than any other; the decision to use any particular philosophy depends on the context, and sometimes a design calls for more than one approach. Several philosophies are particularly salient to IoT design: Systems thinking. To bring order to complexity, designers may turn to a design philosophy called systems thinking, which allows engineers and designers to understand the boundaries between different parts of a product, even when those parts can be separated by thousands of miles and owned by different organizations. Systems thinking focuses on looking at the object as part of a larger ecosystem rather than discrete and independent.38 For this reason, systems thinking is well suited to deal with complex ecosystems such as an IoT-enabled system. Design thinking. If systems thinking is fundamentally about understanding the complex ecosystem in which a product operates, design thinking takes this concept a step further, urging designers to picture that system but place a human at its center.39 In doing so, designers can assess the needs, wants, and dislikes of their product’s likely user and meet those needs not only with the product itself but with everything around it: how it is made, packaged, and sold, and all of the other connections that support it. Lean startup. Based on the concept of “fail fast, succeed sooner,” lean startup focuses on rapid iteration—or agile approaches—to better meet customers’ needs.40 In his eponymous book, Eric Ries describes how designers should Build-Measure-Learn quickly and repeatedly in order to meet ever-changing customer needs with the smallest amount of overhead.41 Indeed, one of the principles of lean startup is to produce an optimized design quickly, with minimal waste. No matter which design philosophy best suits the organization, the transformative challenges of IoT technology guide the approach. These design philosophies are like parallel roads to the same city: The exact paths may be different, but the ultimate destination is the same. In IoT product design, that destination means realizing that organizational change is required to meet the complex, changing demands of connected products.
Manufacturers that have traditionally focused on developing purely physical objects—or objects that may be connected in only limited ways—may need to develop or acquire new capabilities to incorporate IoT technology into designs. They can do so on multiple fronts.
First, organizations will need to have the technological resources and capabilities to enable the design of objects containing IoT hardware—such as sensors and other physical components for connectivity—and capable of running the requisite software.
Beyond the object itself, companies should consider how they will manage the resulting information flows: how they will aggregate, analyze, and act on any data these smart objects generate on an ongoing basis as they move from selling simple products to selling products and services.42 Furthermore, because of that potentially valuable user data, products and solutions may at some point need to connect to or communicate with other systems within the organization, such as customer accounts or order management systems, to enable more tailored services or customer behavior-based pricing structures.43 In the case of connected machinery, companies may need to aggregate data with that of other machines to better enable capabilities such as predictive maintenance44—or to inform future designs of the same object.45 Thus, designs may need to be integrated and interoperable with other core IT systems, increasing both design complexity and technological capabilities necessary for not only design and production but ongoing function as well.
Companies can also use these information flows to realize new opportunities, such as continuous improvement of products. Product development does not stop once a product transitions from R&D into manufacturing, and engineering teams have traditionally used reliability testing combined with analysis of field failures to identify design weaknesses that need to be addressed in future releases. Adding connectivity to a product gives designers the opportunity to monitor product performance and failures in real time in their actual environment. By incorporating the ability to monitor critical performance and environmental metrics such as temperature, battery condition, and wireless signal strength, designers can correlate specific conditions with specific failures. The company can then use that data to issue a firmware update to fix the problem in the field, or to construct a targeted set of lab tests that duplicate the conditions that caused the failure. Connectivity gives designers a window into how, what, why, and where failures occur and makes sustaining a product easier—if they have the appropriate technological and organizational capabilities in place to act on the information.
The rapid rate of change in IoT technology and the potential to realize design benefits—such as continuous improvement—suggest that organizations may need additional technological capabilities to push regular software updates to objects as well receive data from them. This is yet another factor for which designers should account as they grapple with multiple life cycles within just one product.
In changing the nature of products, IoT technology unavoidably guides their design. If an organization wants to meet the new challenges imposed by these transformations and successfully design connected products, it should rise to the challenge. As companies focus on readying themselves to design and develop IoT-enabled objects, they can consider the following actions:
Build a talent pool capable of addressing digital and physical issues, such as artificial intelligence, app design, programming, and big data analytics. By combining two disciplines—the digital and the physical—designers can reorient their thinking to account for new, IoT-specific requirements. This may involve upending the design process to start from the premise of the desired information outcome rather than the desired physical form.
Coach designers to know their limitations and recognize when they should engage experts outside their traditional teams. Knowing the possibilities—but also where help is needed—will be important for changing designers’ mindset so they feel comfortable looking to experts with unfamiliar skill sets.46
Encourage cross-functional collaboration to ensure that designers and engineers can share expertise and focus on solving the design challenge together. Rather than continuing to focus on functional specialization—a tenet of traditional design—organizations can promote the creation of design teams with representatives from each function.47 This may help design teams cope with unexpected changes internally and much more rapidly and effectively.48
Train managers to lead cross-functional teams and encourage collaboration. Organizations can consider rotational programs in which leaders and other high-potential employees can gain experience in multiple areas crucial to IoT product design, providing the skills to more effectively manage diverse teams and projects.
Stress simplicity through a digital design approach, even as the object necessarily grows more complex. Designers and engineers should consider expanding their thinking to incorporate a digital approach, including CX/UX approaches used in website and app design. They can include regular testing throughout the design process to help ensure that connected objects, while expanding functionality, retain simple interfaces that make them easy to use.
Bring IT into the picture early and often. In keeping with the more collaborative, cross-functional model of effective IoT product design, including IT experts on the design team can provide much-needed expertise about incorporating often-complex technologies. As Eric Libow, ‎the CTO of Internet of Things Lab Services and Support at IBM, explains, “we recommend that companies considering IoT start with a use case for a line of business but involve the IT group from the start, because you almost always want to use or interface with at least some legacy systems.”49
Develop a plan for accommodating future technological advancements in current designs. To account for future developments, engineers may incorporate modularity in some components, enabling service providers to swap outdated hardware for updated options capable of accommodating next-generation software as it becomes available. Thus, objects meant to have long lifespans—such as automobiles, appliances, grids, buildings, and industrial machinery—can assimilate new technologies with shorter life cycles.
As companies adapt existing products—and create new ones—for a connected world, no single solution or approach is correct in all situations. And since IoT technology is still in a nascent stage of development, the future of connected objects will get only more interdependent and complex, and organizations should consider and prepare for the changes that smart connectivity can bring to their products and their designs.The second Deloitte IoT Newsflash covers relevant news affecting the IoT market, covering Google and their purchase of Xively, the “Charter of Trust”, Qualcomm Wireless Edge Services for IoT as well as Bosch and their new IoT campus in Berlin.
Google announced in February that it will buy Xively from LogMeIn for $50 million. Xively is a tool that enables device designers to build connectivity into the design process while providing a cloud-mobile connection between the end user app and the connected device. With this purchase, Google Cloud adds an established IoT platform to their portfolio and underlines the importance of the IoT market for their business.
Siemens, IBM, Daimler and Deutsche Telekom signed the „Charter of Trust” for more security in IoT infrastructure
Eight companies, part of them are Siemens, Daimler, IBM or Deutsche Telekom signed a „Charter of Trust“ at the Munich Security Conference. The goal of this charter is to define and set binding rules and standards for more cybersecurity along the value chain as well as to build trust in new technical developments.
Qualcomm, one of the biggest multinational semiconductor and telecommunications equipment companies announced wireless edge services. These are software services that are designed to meet the requirements of Industrial IoT customers to provision, connect and manage long life-cycles intelligent wireless devices through their cloud platforms.
Bosch, the Engineering and Electronics Company, is opening its global IoT campus in Berlin. From the start, more than 250 employees from different domains will work at this new site.Like companies, government agencies are striving to deliver quality services in increasingly complex environments. And the public sector is also looking at ways to apply Internet of Things technology to find new value for citizens, aiming to enhance capabilities, streamline processes, and engage partners.
Long before the advent of today’s wrist wearables, Hollywood’s James Bond was using his watch to measure radioactivity and receive messages from headquarters.1 And before any company began prototyping connected cars, he careened through a high-speed chase where he controlled his car from the backseat via mobile phone—augmented by sensors that triggered fixes for safety issues such as flat tires and a video feed that alerted him to obstacles.2 Previously the domain of fantasy, such devices are becoming reality and even mainstream: Smart watches help verify identity and pay for goods, alarm clocks know the current traffic, and smart glasses provide instant access to expert advice.
What were once imaginative toys for a tech-savvy spy may soon be a new class of tools for public servants more generally. As governments work to deliver quality services in increasingly complex environments, devices that have already begun to make life easier and more efficient for companies and consumers can also help create greater public value.
“This wave of technology has more chance of reimagining whole swathes of the world than anything we've seen before.” —Tim O’Reilly, quoted in Chris Witeck, “The Internet of Things (IoT): The best is yet to come,”
However, strategic application of the Internet of Things (IoT)—the suite of embedded sensors and wirelessly connected devices—is still nascent in government. In fact, a recent Brookings Institution report found that not a single federal agency mentioned the IoT in its strategic plan.3 The diverse nature of public sector missions and the citizens they serve frequently complicates attempts to implement new technology. Yet if public sector organizations do not start analyzing the implications of the IoT today, they risk being left behind, making it more difficult to effectively regulate or efficiently deliver services in this shifting reality.
This report aims to help government leaders navigate this emerging reality by providing an overview of how new IoT capabilities can create value, illustrating their impact on three traditional public sector domains (education, public safety, and utilities), and discussing a few considerations as agencies plan for adoption of this technology.
The definition of a “computer” is changing again. The continued evolution toward cheaper processors and faster networks has enabled a shift from desktop workstations to mobile phones and, now, to everyday objects, inspiring the term “Internet of Things.” Almost any device can be Internet-enabled, linking it to additional computing power and analytic capabilities that make it “smart.” The aggregation of outputs from sensors, beacons, machines, and other IoT devices offers far more value than just a better or “smart” product; by connecting these devices and environments, we can understand more about their use, the world, and ourselves—often in real time. As more complex and mature systems take advantage of this connectivity to tap into new capabilities, organizations must think about how these technologies combine to create value in new and different ways.
Many current IoT applications, however, simply enhance existing products and processes rather than rethinking them, creating limited value. Just as the first televised news shows featured an anchor reading the events of the day from a typed paper in his hand—treating television as “radio with pictures”—early IoT applications have considered only how these devices can improve current performance. Ultimately, the IoT represents a new way of working, where—as Kevin Ashton, who coined “Internet of Things,” describes—machines and other devices supplant humans as the primary means of collecting, processing, and interpreting information.4 This breaks many of the constraints that have traditionally defined fundamental business processes—from timing to availability of information—and asks organizations to think differently about how they create value.
Just as the first news shows treated television as “radio with pictures,” many early IoT applications have considered only how these devices can improve current performance.
Doing so may require a fresh approach to information collection and analysis—not simply “Big Data 2.0.” Today, only 8 percent of companies are capturing and analyzing IoT data in a timely way, and 86 percent say that faster and more flexible analytics would increase the value of their IoT investments.5 The current model of mass collection and exploratory analysis is likely unsustainable; instead of collecting all possible information for future analysis, we need to streamline information collection and develop focused rules to make insights actionable now. As Steven Fritzinger, public sector alliance manager for NetApp data management, explains, “Once sensors and networks are cheap, the temptation is going to be to put them everywhere . . . [but] it is going to be much more important to think about the problem.”6
The CheckLight Sports Impact Indicator developed by hardware start-up MC10 provides an example of how tightly focused data collection can create insights and change behaviors. MC10 worked to develop a better way to test whether an athlete may have taken a dangerous hit to the head—and make it easier for coaches to decide whether to pull athletes off the field to check for concussions. CheckLight uses an accelerometer and gyroscope worn on an athlete’s head to collect a few basic data points, and then uses algorithms to detect and determine an impact’s severity. The results are shown through a light at the base of the athlete’s head. A moderate impact triggers a yellow light; a severe impact triggers a red light. When tested with a football team in which coaches would bench players sustaining a red-light impact, MC10 found that the disincentive of sitting out plays changed athlete behavior: Players improved their tackling form, and head impacts decreased over the course of the season.7
Organizations have the same opportunity to improve outcomes using technologies that provide immediate feedback and drive better decision making—but doing so can require that they orchestrate a complex system of sensors, processors, and actuators. The Information Value Loop (see sidebar, “The Information Value Loop—an overview”) offers a blueprint for how the technologies at play in the IoT fit together to generate value. The value loop shifts the focus from what we connect to what we enable, accelerating the relationship between data and action—and enabling governments to more efficiently and effectively drive public value.
Government agencies thinking about how to construct the Information Value Loop should consider five key capabilities: data creation, communication, aggregation, analysis, and action.
Create: Sensors collect data on the physical environment—for example, measuring things such as air temperature, location, or device status.
Communicate: Networks enable devices to share this information with other devices or a centralized platform.
Analyze: Analytical tools help detect patterns that signal a need for action, or anomalies that require further investigation.
Organizations can accelerate the value they get from IoT data by extending this loop (adding capabilities they do not yet have) or addressing bottlenecks (improving existing capabilities).
“If the Internet of Things has to do with home automation or automation of the car [or] controlling devices like security systems through the Internet . . . what does [it] have to do with any of the service-providing departments of government?”8
Just like this respondent in a 2014 GovLoop survey, many people may wonder what the IoT has to do with government.9 Admittedly, it may be difficult to see the immediate relevance of sport sensors or connected appliances, but deriving value from information collection and analysis is central to many government missions. The IoT can increase value by both collecting better information about how effectively public servants, programs, and policies are addressing mission challenges, as well as helping government deliver services based on real-time and situation-specific conditions.
Early government activity has coalesced around a few main areas, including “smart cities” focused on improving citizen services and federal agencies focused on scaling measurement capabilities. Local experiments include “smart parking” that helps commuters find spots (and streamlines city enforcement), and “smart waste” such as Big Belly Solar—Internet-connected trash bins that communicate their status to help optimize collection routes. New York City is even transforming public pay phones into Internet-connected pylons with the potential to someday broadcast emergency messages or provide places where New Yorkers can provide civic feedback on various topics.10 At a federal level, agencies are more focused on scaling measurement capabilities: The Department of Defense uses RFID chips to monitor its supply chain more accurately,11 the US Geological Survey employs sensors to remotely monitor the bacterial levels of rivers and lakes,12 and the General Services Administration has begun using sensors to measure and verify the energy efficiency of “green” buildings.13
As in industry’s early IoT-enabled work, many of these government applications focus on optimizing current operations rather than identifying how faster, more precise, and more reliable information might generate new possibilities for service delivery. To fully reap the IoT’s potential benefits, public sector organizations will need to rethink how they do business—identifying new models for service and adopting the technology and the corresponding organizational structure(s) to support them. We explore the implications for a few classic public-sector domains and posit three ways in which these new tools might redefine work:
Of the 1,025 hours the average American student spends in the classroom each year, more than 300 are likely lost to interruptions. In fact, an estimated one of every five minutes is consumed by “anticipated interruptions”: transitions, materials distribution, and starting or ending class.14 Each minute a teacher spends managing large group procedures takes away from time he or she could spend on student interventions—such as differentiating instruction or developing students’ socio-emotional skills—to help close an achievement gap between rich and poor students that has grown more than 50 percent since the late 1980s.15
How the IoT can help. Connected devices offer the potential to relieve teachers of some of the administrative burden in taking roll or distributing materials, allowing more time to focus on students’ learning needs.
As students take their seats in a connected classroom, attendance could be logged automatically by a wearable “smartband” such as the RFID bands that many theme parks already use to check in to rooms, rides, and even find lost children.16 A beacon might push a warm-up exercise directly to students’ tablets or smart desks. And when it comes to keeping students on task, teachers could send a “haptic” vibration—similar to silent notifications on mobile devices—to a student’s wearable or tablet, redirecting her attention or behavior in a way that limits public embarrassment and reduces direct confrontation.
Teachers, freed from managing many classroom procedures, could focus more fully on students—and perhaps focus more incisively too. Pattern-recognition software or data analytics applied to these new inputs might add to a teacher’s contextual understanding, mapping the record of behavioral incidents against student stress levels, classroom temperature, or even the teacher’s own actions. And IoT technologies could help translate these insights in real time—much like MIT Media Lab’s MindRider, a bicycle helmet that picks up on 10 types of brain waves that signal activities like concentration or stress and produces a corresponding light to make drivers more aware of panic-inducing behavior.17 In the classroom, using similar devices to identify which students are expending higher amounts of cognitive energy on an exercise could help teachers dedicate attention to students who need it the most—not just those who ask for help the loudest. Educators with years of experience often develop an intuitive understanding of such complex behavioral dynamics, but a connected classroom could provide insights even to the teacher just starting out.
Implications. Schools and districts looking to take advantage of these capabilities will need more than new technology—they must start by building a culture of digital literacy that can support greater creation and communication of data, to use the terms from the Information Value Loop. Creating these data requires that teachers use technology as a consistent part of instruction, and schools should empower teachers to decide which devices best fit their specific needs. This approach is a significant change from today’s centralized technology budget and procurement process originally designed around computer labs, but districts that embrace opportunities for decentralized technology procurement—such as Idaho’s cash-poor but forward-thinking West Ada district—have found that it presents an opportunity to encourage bottom-up experimentation and scale what works.18 Perhaps counterintuitively, schools and districts should pair this move toward decentralized applications with investments in shared platforms. By providing common information security, data standards, and system monitoring, these platforms enable effective integration into school records and information management systems—and ultimately help communicate and aggregate IoT data.
Emergency response today suffers from information gaps and asymmetries, driven by how quickly and how well those affected are able to alert authorities. As a result, responders are often delayed; for example, in 2011, only 15 percent of Los Angeles 911 dispatchers successfully alerted Los Angeles Fire Department response units within the targeted 60-second timeframe.19 Waiting for adequate information delays the response, yet responding too early risks endangering underinformed responders or committing unnecessary resources.
How the IoT can help. IoT applications can more quickly aggregate and analyze information about an event, helping responders better identify incidents, decide how to respond, and communicate decisions (and critical actions) to those involved.
Environmental sensors, for example, can register and report early indicators of an emergency or crime; already, devices such as ShotSpotter can detect the sound of a gunshot and pinpoint its location to within 10 feet. By automatically alerting police dispatch, the device can speed reaction time, as well as reduce reliance on witnesses to report crime, helping to detect crimes that might never have been reported. When police started using ShotSpotter in Camden, NJ, they found that 38 percent of gunshots in one neighborhood were not being reported.20 Beyond detecting gunshots, data points from other sensors, cameras, and even databases can be aggregated to reveal incident patterns; much as PredPol or Palantir are used today to “hot spot” where crimes are most likely to occur, similar algorithms working on data from distributed sensors might be able to report that crimes are likely occurring. And these environment-generated alerts can be quickly directed to multiple parties, as PulsePoint, a San Francisco-based nonprofit that uses location-aware apps today to crowdsource CPR skills, does—alerting CPR-trained citizens who are within walking distance of reported incidents and allowing “citizen superheroes” to step in until professional first responders arrive.21
Connected devices can also improve officers’ performance when responding to an incident. Connected firearms, for example, can track when and where an officer removes a weapon from its holster and discharges it. In the moment, pulling or firing the weapon could dispatch additional support; over time, the record could inform coaching and development discussions. Other wearables might augment these discussions, providing similar insight into officers’ behaviors. Sensors that monitor officers’ stress levels, heart rate, or voice volume could alert supervisors or fellow responders to elevated tension or other anomalies that might endanger an officer or bystanders, allowing quick intervention and, later, coaching and training on handling future situations. This has particularly powerful implications, as local public safety organizations increasingly play a role in crowd control or longer incident response.
Beyond enhanced alerts and officer performance, IoT applications can aggregate real-time information to provide greater situational awareness. As more cities incorporate smart infrastructure, for example, iPavement—a Wi-Fi- and Bluetooth-enabled paving material that can be embedded in sidewalks—could send out crime alerts or emergency messages to mobile phones located within a certain distance.22 Or indoor beacons, such as those being deployed in Next Generation 9-1-1 systems,23 could help direct responders to an exact floor and room. Emergency systems could also integrate this precise location data with local video and social media to give responders context well before they arrive at the scene: Local video from nearby cameras might be streamed directly to the dashboard of the responders’ vehicle, and even mapped to streaming social media posts coming from the same area. For example, the police department of one major US city is already experimenting with combining video and social media with facial-recognition or social-network analysis software to help officers better investigate crimes and identify suspects.24 While today this analysis occurs after the incident, IoT applications can provide real-time insight, moving from a model of prosecution to one of prevention—from analysis to action, the final stage of the value loop.
Implications. We rely on public safety officers to act as human sensors, naturally aggregating multiple sources of data to assess a situation. Moving forward, machine sensors will enable public-safety organizations to collect a wider array of real-time data, but effectively aggregating and analyzing this data will require new processes. Where many current processes rely on centralized analysis, for example, organizations may glean greater value by empowering offers to make decisions at a local level based on IoT-generated data. And where current systems assume that information moves in one direction, the advent of localized communications via beacons or Bluetooth can allow dispatchers to engage citizens in the area to help—reframing public safety as a shared responsibility.
Moreover, as public safety networks aggregate information from new sources—transit, utilities, or telecommunications—governments should advocate for and implement common data standards to ensure interoperability. Greater volume of and access to information can eliminate distance and accelerate response, but may ultimately require a more elegant understanding of how to properly bridge dissimilar types of data.
The United Nations’ 2030 Water Resources Group observes that, if current trends continue, the demand for water will exceed supply by 40 percent in 2030.25 Already, in the United States, California is facing an extended drought and recently implemented water rationing, and the Ogallala aquifer that feeds the Plains States’ agricultural communities is at historic lows. However, scaling solutions is difficult in a highly localized and fragmented system of more than 155,000 different US water-supply corporations. Little venture capital or corporate research and development is focused on the water challenge,26 leaving it to government organizations to close the gap between water supply and demand—a task estimated to require $50 to 60 billion in annual investment over the next 20 years.27
How the IoT can help. IoT technology can provide greater comprehension of the complex challenges surrounding water security, enabling governments to better define priorities for water supply, consumer demand, and governance. Like other issues driven by multiple and diverse factors, improving outcomes for water management will require contributions from an ecosystem of partners, many of whom are not even aware of the role they play in water conservation. IoT applications can also help agencies better coordinate response among this set of players by capturing the specific impacts of each policy, not only through predictive models but also through real-time measurement that enables “lean startup”-style A/B testing.
Increasing water supply is often the first option considered as water inventories drop, and traditionally, companies have invested heavily in finding new sources of water—just as Midland, TX, recently spent $197 million to tap into a new source 67 miles away.28 As new sources dry up, however, utilities might instead focus on improving the yield for delivery; more than 40 percent of the infrastructure is over four decades old, and water-supply systems lose 16 percent on average during delivery.29 One of the challenges the IoT could solve is determining exactly where to repair to improve yield—and whether the volume saved for that area will offset the capital cost of repair. Sensors can provide a more precise understanding of water flows and help prioritize improvements, even at the level of individual homeowners not typically engaged with the state of water infrastructure. Stopping or slowing in-home leaks, which can waste up to 10,000 gallons a year, can further boost the yield on sanitized water: Products such as LeakSmart, for example, combine a simple sensor and actuator to detect when a pipe has burst and shut off the water.30
Conserving water by lowering demand can also be a powerful way to extend limited water supplies. Boston provides an early example: When demand outstripped supply in the early 1980s, the city was able to avoid $500 million in capital infrastructure costs through a conservation campaign that led to a 43 percent reduction in water consumption.31 IoT applications promise to make conservation campaigns even easier and more effective by tracking progress and offering—or even automating—new ways to conserve. Simply giving consumers more insight into when or where they use water and how they compare to neighbors can encourage conservation, as the Municipal Water Department in East Bay (California) recently demonstrated. Partnering with WaterSmart, the department saved 5 percent in water consumption by giving 10,000 customers access to a Web portal that showed how each stacked up against families of comparable size, as well as by providing ideas for improving water conservation.32 An IoT system might further support conservation efforts by helping users understand where and how they use water most, and applying rules or reminders to domains such as showers, appliances, or pools. This real-time monitoring might even reinterpret the local “water tower” as a way to create a public display of progress—much like the Southern California Edison energy company distributed “energy joules” that glow different colors to help customers and businesses see the current demand on the grid.33
The greatest savings in water consumption can come from automating agricultural and municipal use: More than 70 percent of water consumption today is for agricultural use,34 and 60 percent of the remainder goes to urban landscape maintenance.35 In both instances, agribusiness companies often irrigate regardless of current conditions, risking overwatering rather than drought.36 Sensors with advanced algorithms can help address both problems, aggregating measurements of soil moisture, heat, humidity, and slope to analyze how much water plants need. One startup, Hydropoint, has partnered with several landscape companies to install these systems for urban parks, golf courses, and corporate campuses. Hydropoint’s system has cut the Los Angeles suburb Santa Clarita’s irrigation costs by more than 25 percent and is projected to save the city approximately 180 million gallons of water annually.37
Implications. By creating greater insight into both supply and demand, IoT applications can help government and utilities work together to improve governance of the water ecosystem. However, information alone does not make the water system more efficient: Localities may need to build behavioral and technical foundations to allow people to act on information. For example, knowing how customers respond to various scenarios can shape tailored prompts and change behavior around water use. Similarly, servo valves can automatically take action to shut off pipes once a rupture or leak has been detected.
Further, IoT-generated information and action can not only directly save scarce resources but also feed better planning and policy—including enabling decision making based on empirical data as opposed to political pressures. And if government officials and water companies can improve operations, they likely can boost profit margins and free additional capital to invest in additional innovation.
The three examples above are predicated on the collection, analysis, and use of large volumes of data, introducing a complex and controversial set of issues: the privacy and security of citizen data. The proliferation of data created by IoT applications will almost certainly continue to generate concern over how government systems and employees handle that data. Early IoT applications have already sparked national debate and Senate hearings on privacy: One such hearing, a 2015 US Senate Committee on Commerce, Science, and Transportation hearing entitled “The connected world: Examining the Internet of Things,” addressed “how to strike the appropriate balance between encouraging IoT innovation and protecting privacy and data security.”38 Driving public acceptance of government application of IoT technology will likely mean proactively framing the discussion of “privacy” around concepts of “value, security, and trust.”
Deliver value to citizens. Our society is accustomed to exchanging data for valuable services. From Facebook to fitness trackers, users continue to grant companies access to their data if they feel they are realizing value in return.39 This seems to hold true for government applications as well: US Customs and Border Protection’s optional Global Entry program, which provides participants an expedited customs experience, has 1.8 million members and receives 50,000 new applications every month, despite requiring sensitive personal information—beyond that required for a passport—to enroll, including fingerprints.40
Make security a priority. Given their intrinsic responsibility to protect the public interest, public sector organizations are uniquely positioned to help develop a secure IoT; where private companies must balance profit incentives, government’s core mission is naturally aligned with safety and security. Gilad Meiri of Neura, a platform designed to integrate the management of IoT devices, agrees: “The market is not asking for security and privacy. Start-ups are focused on acquiring customers over designing for security.”41 To fill this gap, governments should lead, incentivize, and often own the development of airtight solutions that can advance security in both public and private sector applications. As Kerry O’Connor, chief innovation officer for the city of Austin, notes, “This is not a commodity we’re acquiring. This is something we need to design and work iteratively.”42 One potential approach to security that has gained recent popularity—championed by thinkers such as Marc Goodman, author of Future Crimes—is the idea of addressing security in the same way as public health, focusing on educating the public, tracking symptoms, and isolating outbreaks quickly.43 This model looks to improve resiliency by shifting focus from “who’s getting in to what’s getting out.”44
Build trust through transparency. Government organizations, perhaps even more so than industry, have a responsibility to their users, and should offer transparency—for example, being clear on what data are requested, how the data are being used, and who will see the data. A director of policy for one mobile cybersecurity company frames this in terms of “surprise minimization”: the idea that “a user should never be surprised by what an organization is doing with his or her data.”45 Transparency helps users feel they have control over their inputs, and it should also give them a choice over their outputs, which generally makes people more likely to use a service. In fact, in a 2014 study, 80 percent of users said they would be willing to provide personal information to a “trusted brand.”46 Government organizations can look to a few current initiatives for practical ways to build in these concepts while implementing new IoT applications (figure 3).
One thing is certain: Government agencies that adopt a wait-and-see attitude toward the IoT are unlikely to develop the expertise or engender the trust needed to effectively and efficiently deliver services in this new reality and to reassure citizens concerned about how this new technology will affect them.
On an organizational level, public sector leaders ready to start tapping into the potential of IoT technology can begin by identifying specific, pressing mission challenges, and then analyze how more or better information, real-time analysis, or automated actions might help address them. By solving for concrete problems, governments can more effectively identify the technical, organizational, and talent changes necessary to realize new benefits—and scale what works.
At the US federal level, additional changes may include organizations such as the Office of Management and Budget or the General Services Administration working across agencies to avoid creating the siloed or incompatible systems endemic to previous technology transformations. And organizations such as the National Institute of Standards and Technology and the National Information Exchange Model may work with industry to create standards and ensure interoperability, particularly important given that data integration is foundational to the IoT’s value proposition.
Beyond the tactical changes for organizations and broader government policy, governments can be particularly sensitive to the potential social implications of IoT applications. As the data from IoT devices offer new insights, they may also usher in new social complexities. For example, the ubiquity of these data can lead to the potential to discriminate by using algorithms to automatically categorize, make decisions, or treat people differently—without an appreciation for the social, economic, or racial factors at play.47 Understanding such social risks up front is key to the design of effective public IoT applications.
Ultimately, the IoT is not simply a cool new technology but an inflection point in how we do work, structure businesses, and govern the resulting economy and society. David Bray, 2015 Eisenhower Fellow and CIO of the Federal Communications Commission, recognizes the public sector’s crucial role in this transition: “empowering consumers to make choices, encouraging new [IoT] partnerships across private sector and public sector organizations, and exploring new ways to increase [IoT] privacy and resiliency by design [that] will encourage a future with more beneficial opportunities for us all.”48 Government agencies need to be active players to understand and shape this future—and should start today.
Deloitte’s Internet of Things practice enables organizations to identify where the IoT can potentially create value in their industry and develop strategies to capture that value, utilizing the IoT for operational benefit.​
To learn more about Deloitte’s IoT practice, visit http://www2.deloitte.com/us/en/pages/technology-media-and-telecommunications/topics/the-internet-of-things.html.
Read more of our research and thought leadership on the IoT at http://dupress.com/collection/internet-of-things.As the business impact of the COVID-19 crisis mounts, leaders in every industry are moving urgently to protect employees and build resilience. Governments are mobilizing to safeguard citizens and manage the economic fallout. Immediate action is critical, but leaders must also embrace a new agenda—one aimed squarely at what comes next.Tools, game consoles, kitchen appliances—many of the devices we use for work or pleasure already communicate with each other via the Internet. But the Internet of Things (IoT) has only just begun. According to a McKinsey market analysis, around €23 billion will be generated in Germany in 2020 with the intelligent networking of machines and devices. In 2015, annual IoT sales in Germany were still under €10 billion, meaning the potential will more than double within five years. The most important fields of application are the digitalization of production (Industry 4.0) with a potential of just under €9 billion and networked vehicles at around €4 billion.
But even the networked home promises growth. The United States is a prime example. Here, the number of smart homes increased from 17 million in 2015 to an estimated 29 million in 2017. The merging of the virtual and the real world should make life easier for people, save time and money, and ensure more security.
More and more everyday objects which to date have relied on manual control are expected to become “smart” in the future. Estimates from McKinsey expect that by 2020 consumers in Western Europe will spend more than €12 billion annually on smart devices and applications and thus on the Consumer IoT.
The Consumer Electronics Show in Las Vegas held at the start of the year once again showcased numerous IoT innovations ranging from the intelligent hairbrush that draws conclusions on the condition of the hair from brush noises, right up to the athletic shirt that measures the heart rate, records routes jogged with the built-in GPS, and transmits the data to the associated app. Just a gadget? Mere niche products? Maybe. But one thing is already clear: in the years to come, networking is going to gain more momentum with drastic consequences for the entire consumer industry.
The Internet of Things has the potential to fundamentally change business models and value chains in companies. Over the long term, it is no longer going to be just about intelligent fridges or fitness armbands; practically every product can be connected in an economical way with the Internet. Why not, for instance, equip a school backpack with an IoT sensor that measures location (via GPS) and movement (via an acceleration sensor)? This way, parents can track in real time where their child is and where he/she is going. The sensor would also signal falls and other accidents. Technically speaking, this kind of product has been feasible for a long time; the costs for such a sensor are around €10.
Consumer goods companies have no reason to fear the changes on the horizon. On the contrary, the Internet of Things offers them immense opportunities (exhibit):
Exhibit We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Manufacturers of consumer goods usually have little direct contact with customers, apart from user involvement in product development (embedded customer) and product tests. After the sale, if at all, manufacturers often learn only through customer service how their product stands up in daily life.
What are the most common complaints or questions from customers? Which feature is used most? The situation is different with smart products. Here, manufacturers are moving closer to the users, are maintaining contact throughout the entire product life cycle, and are collecting application data on an ongoing basis. How long is the school backpack worn each day? How often is it put down and picked up? The needs of users can be understood and met much better on the basis of the information gathered. But in return, manufacturers have to invest considerably more in the rapport with the end customers. And, ultimately, their greater proximity to the consumers will also fundamentally change their relation to retail trade.
Smart products create more value because manufacturers can generate recurring sales beyond the one-time selling price. One feature for the intelligent school backpack, which is available at an additional charge, is an alarm feature. If the child unexpectedly starts moving more than one kilometer away from the kindergarten or school, the parents are informed immediately. There is a €5 charge every time the alarm goes off. Other features can be added monthly, such as having the sensor automatically open the front door when the child comes home.
Successful manufacturers manage to establish an emotional bond between the customer and the product. This boosts customer loyalty and the recommendation rate. Networked products provide many ways to retain customers: updates allow features to be renewed regularly or expanded by additional ones making the entire customer journey a special experience.
So, the advantages for manufacturers and consumers are immense. Only companies that understand what the market wants and what it doesn’t want will enjoy long-term success with the consumer IoT.
Right now, many customers are still skeptical about the Internet of Things. There are a number of reasons why the consumer IoT has some catching up to do compared to other segments. The main reason is that many of the products offered to date offer no real added value for the majority of consumers. Even though manufacturers are tripping over themselves to network everything under the sun, they are launching some questionable products like the sock gadget that recognizes if you fall asleep in front of the TV and stops the show by way of a signal. Products that solve more pressing customer problems are more likely to be a success.
Many consumers are also hesitant to buy smart devices because they are worried that in doing so they will limit their choices. Today every device has its own specific applications, which don’t run on other devices. A fitness tracker only works with the smartphone app of the manufacturer, and the smart light bulb usually cannot be connected with the intelligent socket of another manufacturer. Here, a consistent separation of hardware and software would significantly improve market conditions. However, this would presuppose industry-wide partnerships and a consistent implementation of technical standards.
A third reason for the ongoing skepticism is that many important questions on data privacy and data security remain unanswered in the eyes of the customers. What is going to happen with my data? Where is it going to be stored? Who does the data belong to? Who has access to it? What is the company doing to prevent access from unauthorized third parties? And it is not just the personal privacy of customers that is at risk. Security breaches can also lead to smart devices being seized and used for digital attacks.
While the consumer IoT promises attractive growth potential, many traditional consumer goods and brand name manufacturers lack the know-how and necessary capabilities to develop a convincing IoT product and to market it quickly. Four success factors have emerged in practice:
Implementing IoT products is demanding and in terms of technology sometimes very complex. Without a closed system of partners, the task is hardly manageable (see sidebar, “Without partners nothing happens”). The partners can be technology or even content partners who deliver corresponding data and contents. Digital pioneers like Facebook, Amazon, or Google have built up entire ecosystems around their platforms with a pool of hundreds of thousands of specialized developers. For its Android ecosystem, Google benefits from 5.9 million mobile developers who target Android, many more than the 25,000 developers Google has in total internally across all their platforms and products, not just Android. Even in traditional industries these kinds of ecosystems are being established. One example for this is the map service, HERE, which a consortium consisting of three German automobile manufacturers bought as a joint asset en route to autonomous driving.
As important as partners are, manufacturers of consumer goods will not be able to avoid setting up their own software and big data capabilities—and far beyond the existing levels at that. They should resolutely follow their goal of transforming themselves into a technology company. In the process, digital capabilities should be set up not just in individual divisions. The whole organization has to understand what the Internet of Things is capable of today and which work methods and capabilities are necessary to use it effectively.
Digital networking should not necessarily be used for the most lucrative product in the portfolio, but, rather, for a niche product, that is ideally geared to technology buffs but also to a fault-tolerant target group. Nevertheless, the goal has to be to thrill the customers with a really revolutionary product. By building on the first customers’ experiences, more and more products can be equipped with IoT applications.
Cooperation is the key characteristic of a dynamic operating model. Cross-functional teams which involve external partners, suppliers, and, above all, customers develop products and services which meet the market demands as quickly as the digital world requires. In the process, innovative approaches like hackathons should be used.
In these events, which originate from the IT sector, employees sit down together in a room to advance new ideas in time-limited sessions or to tweak unclear product ideas by building prototypes. Part of dynamic product development involves having the courage to take risks. Employees need to know that it is ok for ideas to fail, that it is important to try out new things and when successful to consistently push on. And by the way, this applies not only to development, but also to all divisions. In short, when it comes to the production of traditional brand name items, more Silicon Valley is needed in the future.The Internet of Things connects people, places, and products and, in so doing, it offers opportunities of value creation and capture for a full panoply of stakeholders. Organizations, however, should be careful in focusing on IoT initiatives that solve real business problems and create real business value―not just connecting stuff for the sake of connecting stuff.
Learn More ​Subscribe to receive updates on Emerging Technologies ​Subscribe to receive Internet of Things content
Today, it seems easy to imagine a world in which a manufacturing enterprise enjoys complete visibility and monitoring of inventory as it enters the factory, gets processed, and leaves the factory floor. Or a world where it is possible to remotely track and optimize production asset effectiveness—through introduction, maintenance, and retirement—and even detect system failures as they occur to maximize uptime. Or still, another world in which products are given sensor capabilities to detect usage patterns and, on that basis, inspire still more products and revenue streams.
It is easy to imagine these and other such worlds because it is in fact the world of smart connectivity within which we live today—thanks to the capabilities offered by the Internet of Things (IoT).
In 1991, long before anyone ever used the term “Internet of Things,” Mark Weiser, chief scientist at Xerox, imagined a world of “ubiquitous computing” in which all objects could sense, communicate, analyze, and act with respect to other objects and people.1 But it was only in 1999 that the term “Internet of Things” was coined by Kevin Ashton, a technologist specializing in sensors and radio-frequency identification (RFID) tags.2 Over the years since then, we have witnessed various IoT applications evolve from concept to fruition across the full range of industries and use cases.3
This primer provides an overview of the IoT—its market space, key drivers, underlying challenges, potential solutions, and the business value it creates. The piece is intended to help readers understand at a high level why they should proceed in considering the technology's current and potential business applications and associated benefits and outcomes.
There are several definitions of the IoT in technical literature and popular media. Our definition encompasses the key elements as follows:
The IoT is a suite of technologies and applications that equip devices and locations to generate all kinds of information—and to connect those devices and locations for instant data analysis and, ideally, “smart” action. Conceptually, the IoT implies physical objects being able to utilize the Internet backbone to communicate data about their condition, position, or other attributes.4
The IoT focuses on the aggregation and use of information from several sources. Information, however, creates value only when it is utilized for modifying future action in beneficial ways. Ideally, this modified action gives rise to new information, allowing the learning process to continue. Information, then, can create value not in a linear value chain of process steps but, rather, in a never-ending process. One way of capturing this process is as an Information Value Cycle (IVC) with discrete but connected stages (figure 1).
For information to complete the cycle and create value, it passes through the cycle’s stages, each enabled by specific technologies.5 It starts with everyday business activities that generate data. This data is captured by sensors (attached to devices), creating information as a result, along an array of dimensions from vibration to humidity to movement, and beyond. Such information is communicated via a network, aggregated, and analyzed, leading to insights. These insights—sometimes called “augmented intelligence”—may then either enable automated action or shape human decisions (“augmented behavior”) in a manner leading to improved, more competitive business operations, thereby completing the cycle.6
When one thinks at a very high level, IoT market segments can be generally divided into three broad categories: enterprise/industrial, consumer, and services/public sector. Each of these segments is marked by distinct characteristics and market opportunities (table 1).
The enterprise/industrial segment involves relatively complex and rich data sets and far fewer devices relative to the consumer segment. The enterprise/industrial segment tends to also be driven by manufacturing operations and product development within a relatively private cloud environment. In contrast, the consumer segment is typically rooted in customer experience and a more public cloud environment. The services/public sector segment is generally something of a hybrid between the other two segments in terms of richness and complexity of data, number of devices, and a bias toward a particular cloud environment, although it tends to bear a closer resemblance to the consumer segment in terms of experience-driven use cases.
The fastest growing IoT segment appears to be enterprise/industrial, projected to capture slightly more than half of global IoT spending by 2020. A particularly strong driver of growth in IoT spending within the enterprise/industrial segment is digital supply network (DSN) applications. While there is a host of DSN use cases that is driving IoT spending within the enterprise/industrial segment, four seem to stand out in particular:
Condition-based monitoring/predictive maintenance : Monitoring and continuously evaluating key performance parameters of capital assets and, in the process, leveraging advanced analytics to predict failures before they occur
: Monitoring and continuously evaluating key performance parameters of capital assets and, in the process, leveraging advanced analytics to predict failures before they occur Asset tracking: Tracking location and movement of assets and/or materials using location-based sensors, enabling real-time reporting and optimization of system performance
Tracking location and movement of assets and/or materials using location-based sensors, enabling real-time reporting and optimization of system performance Dynamic routing and scheduling : Enhancing the productivity of both individual units and broad networks using deep and broad insights derived from aspects such as visibility on conditions and performance in real time
: Enhancing the productivity of both individual units and broad networks using deep and broad insights derived from aspects such as visibility on conditions and performance in real time Asset and process optimization: Evaluating and monitoring operational data and ambient conditions of critical assets and processes in real time to optimize performance and safety
Manufacturing is a substantial driver of spending within the enterprise/industrial IoT space as well as overall IoT spending.7 This may be attributed to Industry 4.0 and the ensuing wave of digital transformations that will likely drive significant demand for IoT capabilities across a broad spectrum of services within manufacturing. Other key sectors driving enterprise/industrial IoT include oil & gas, power & utilities, life sciences/health care, and transportation.
The IoT is a complex ecosystem—there are different approaches to its market sizing. One of the common ways of describing the market is in terms of connected devices. In 2016, the number of IoT-connected devices was estimated at 18 billion units and is expected to grow at approximately 15 percent CAGR to reach about 31 billion units by 2020.8 Other estimates place the projected number of connected devices at somewhat less than this figure.
Alternatively and without regard to the end-use segment, the IoT market can be characterized in terms of four categories of products―device hardware, systems integration, network connectivity, and platforms/applications/cloud solutions.9 These four categories taken together (which comprise the global IoT market) had an estimated market value of $0.4 trillion in 2015, and is forecasted to expand at approximately 20 percent CAGR to reach around $1.1 trillion by 2020 (figure 2).10 As mentioned, the enterprise/industrial sector is expected to account for by far the largest share of this global IoT market by 2020 at about 50–60 percent of total spending.11
Device hardware: Components used in machines and devices such as sensors and circuits to collect information
Components used in machines and devices such as sensors and circuits to collect information Systems integration: Hardware and software to integrate different proprietary systems with each other and with open systems in order to increase interoperability
Hardware and software to integrate different proprietary systems with each other and with open systems in order to increase interoperability Network connectivity: A host of established network technologies (such as Wi-Fi and Bluetooth) and emerging technologies (such as 5G and Low-Power, Wide-Area [LPWA]) for connectivity among different IoT devices 12
A host of established network technologies (such as Wi-Fi and Bluetooth) and emerging technologies (such as 5G and Low-Power, Wide-Area [LPWA]) for connectivity among different IoT devices Platforms/applications/cloud solutions: Software solutions to facilitate integration of the other three elements in order to provide a secure user interface and drive on-ground applications; includes data aggregation, visualization, and security; analytics; and action management
Among these four major categories, platforms/applications/cloud solutions account for the largest share (40–45 percent over the forecast period). However, the fastest growing segment is systems integration, which is expected to grow at 52 percent CAGR from 2015 to 2020, tripling its share of global IoT spending from 5 percent to 15 percent.13
The growth of the IoT over the last few years can be attributed to a number of beneficial factors, some of which are discussed below:
Bandwidth, data storage, and computing prices declining: Costs associated with transferring, storing, and analyzing data have declined precipitously over the last two decades (figure 3).14
Growing analytics applications driving the use of augmented intelligence: IoT applications are increasingly driven by both decreasing storage costs (figure 3) and volumes of big data (figures 4)—coupled with growth in advanced analytics tools, proprietary as well as open-source, such as the R package (figure 5). We are witnessing applications of augmented intelligence for not just analyzing past business performance but also making predictions about customer demand, supply chain optimization, machine performance, etc.15
Expanding use of augmented behavior from simple automation to complex decision-making: Improved functionality at lower prices (figure 6) is driving higher penetration of industrial robots (figure 7). For situations where a user needs to take the action, machines are increasingly being developed with basic behavioral science principles in mind, allowing them to influence human behaviors in positive and effective ways.16
Sector-specific undercurrents also driving demand: Beyond industry-agnostic technical drivers of the IoT reside sector-specific demand conditions. In manufacturing, for example, a broad digital transformation seems to be taking place under the banner of Industry 4.0 that undergirds the deployment of advanced analytics IoT capabilities. Within the power and utilities sector, a desire to “reach beyond the meter” in optimizing network performance, among other factors, appears to be driving IoT investments. The call for integrated smart city initiatives is likely driving public sector IoT spending. The explosion of health-related data and unyielding demand for health care delivery options “anytime, anywhere” seem to be driving IoT solutions within life sciences and health care. Other examples of sector-specific IoT demand drivers abound.
While we discussed above some key factors that seem to be driving the growth of the IoT, we should be mindful of some of the issues hindering IoT applications, and their corresponding potential solutions. Table 2 offers a set of some of the technical challenges that confront continued IoT development.
Beyond the scope of these technical challenges seem to reside some very real challenges of cultural resistance to the adoption of the smart solutions that IoT offers. Some of this resistance stems from the workforce itself, perhaps slow in accepting a “new way of doing things.” Some of this resistance seems to also stem from a reluctance on the part of organizations that don’t yet understand or are otherwise unable to articulate the IoT value proposition. And, still others believe in the IoT value proposition, but misapply it in ways that merely pursue connectivity for its own sake, without a real plan to address real business problems. We will speak more on this shortly.
The IoT is transforming business models, given its applicability for a wide range of applications in different industries and geographies. A sampling of the current and emerging IoT-related applications is described in table 3 by industry.
The IoT is emerging as an important digital transformation technology irrespective of the industry, business function, or geography. Costs associated with data collection, transfer, processing, storage, and computing have together come down to a point where they can drive significant mainstream IoT applications. With fast-evolving and expanding applications, the IoT seems to be shaping into an increasingly complex ecosystem that offers opportunities of value creation and capture for different stakeholders, including individuals, societies, companies, consortia, and governments. As such, the IoT is increasingly influencing the way we run businesses and live our lives. Additionally, the IoT is also expected to drive and support a number of related yet different technologies such as augmented/virtual reality, automation, and robotics.
All of this said, however, organizations should bear in mind that “connectivity” in and of itself is not a strategy that necessarily provides real business value. Unfortunately, many IoT initiatives end up being “shiny” solutions in search of a problem, concepts that have popular appeal but don’t deliver real-world value. And organizations should be focusing on IoT initiatives that create real business value―not just connecting stuff for the sake of connecting stuff.
Indeed, the real power of the IoT likely resides in harnessing its incredible potential in solving real problems and, in so doing, creating real business value. From asset monitoring and predictive maintenance to fleet management and logistics to smart supply chains to smart mobility and well beyond, the IoT—when used strategically—can help solve some of the most nettlesome challenges that organizations of all kinds face today. As IoT applications are evolving with each passing day, companies may wish to think through their current and future strategic positioning and build product and service offerings accordingly.
And toward that end, companies can adopt a commonsense approach in implementing IoT solutions successfully. First, companies should think big. Push the envelope in developing an ambitious and forward-looking IoT vision that cuts across organizational silos. Second, companies should actually start small. Target the most promising opportunity areas, launch small and swiftly, and go for the rapid wins. Third, companies should scale fast. Once an IoT initiative is proven successful, companies should scale up quickly to maximize benefits. Finally, companies should consider turnkey solutions that may help to jump-start the process—solutions that are geared toward a particular industry or business application in line with the organization’s objectives.
There is no magic formula when it comes to successful IoT implementation. But companies that know what they want to achieve in relying on the IoT—and approach it with a vision that is grounded in real-world issues—may very well have a leg up in achieving strategic objectives.
The next few years will likely be marked with increasing applications of the IoT in different industries. In developing this primer, our objective was to help organizations review the market potential and assess current and potential applications, think through different opportunities for value creation and capture, and address key challenges to adoption. Additionally, as the IoT supports different technologies such as robotics, augmented reality, and automation, this primer should serve as reference material for several other technologies that we will discuss in individual primers.
For more information, including IoT-related industry perspective and use cases, please refer to the Internet of Things collections page on Deloitte Insights.A large US-based airline deployed an Internet of Things proof of concept to provide customers with security wait times. After the initial phase ended, only 1.4 percent of the IoT-interested airline’s target customers had used the technology, and there was no clear path to scale across the organization; it was stuck in “loT pilot purgatory”—a state of ambiguity without a clearly defined strategy to scale.
Here’s the kicker: They’re not alone. Seventy-four percent of IoT pilot programs fail to scale, according to Cisco,1 and those that aren’t immediately abandoned enter IoT pilot purgatory.Smart, connected objects offer tremendous opportunities for value creation and capture, but can also create tremendous risk, demanding new strategies for value protection. A single vulnerable device can leave an entire ecosystem open to attack, with potential disruptions ranging from individual privacy breaches to massive breakdowns of public systems.
A defining element of the Internet of Things (IoT) is that objects are not merely smart—equipped with sensors and processing power—but also connected: able to share the information they generate. What separates the IoT from the traditional Internet is the removal of people. The Internet is powered by humans inputting data: search terms, e-retail browsing, looking up a friend’s social media page. Based upon the answers, they make decisions about how to act: whether to visit the site, buy the sweater, or “like” a friend’s photo.
With the IoT, the role of humans diminishes, to the point that in many cases they are removed from the equation: Machines input, communicate, analyze, and act upon the information. Using sensor detection, machines can create information about individuals’ behavior, analyze it, and take action—ideally in the form of streamlined, tailored products and services or, in the case of businesses, greater efficiencies. This newfound capability is why the IoT enables enterprises and individuals alike to create value in new ways, at a faster velocity than we’ve ever seen (see the sidebar “The Information Value Loop”).
There is a dark side, however: As data are created and transmitted, this represents a new opportunity for that information to be compromised. More data, and more sensitive data, available across a broad network means the risks are higher and that data breaches could pose significant dangers to individuals and enterprises alike. Thanks to the IoT, data security risks will very likely go beyond embarrassing privacy leaks to, potentially, the hacking of important public systems. According to the World Economic Forum, “Hacking the location data on a car is merely an invasion of privacy, whereas hacking the control system of a car would be a threat to a life.”1 Consequently, in addition to new ways to create and capture value through information, the rise of the IoT creates a new need to protect this information-based value.
Secure: In the spirit of “prevention” being worth more than a “cure,” effective risk management begins by preventing system breaches or compromises. The forms that effective prevention takes include controls of many layers, types, and approaches, because the potential attacks are quite effective at exploiting weaknesses never imagined by their creators. We lock our doors because thieves might enter through them. Similarly, we physically “harden” sensors on power plants to protect them from accidental or deliberate assaults, and install software firewalls to keep out hackers.
In the spirit of “prevention” being worth more than a “cure,” effective risk management begins by preventing system breaches or compromises. The forms that effective prevention takes include controls of many layers, types, and approaches, because the potential attacks are quite effective at exploiting weaknesses never imagined by their creators. We lock our doors because thieves might enter through them. Similarly, we physically “harden” sensors on power plants to protect them from accidental or deliberate assaults, and install software firewalls to keep out hackers. Vigilant: Making a system secure is not a once-and-for-all proposition. Both hardware and software degrade over time due simply to age. Worse, the nature and intensity of attacks can change in ways that render previously effective security measures obsolete. And, of course, no level of security is perfect: Best efforts still leave any system vulnerable. Consequently, security must be complemented by vigilance—monitoring to determine whether a system is still secure or has been compromised.
Making a system secure is not a once-and-for-all proposition. Both hardware and software degrade over time due simply to age. Worse, the nature and intensity of attacks can change in ways that render previously effective security measures obsolete. And, of course, no level of security is perfect: Best efforts still leave any system vulnerable. Consequently, security must be complemented by vigilance—monitoring to determine whether a system is still secure or has been compromised. Resilient: When a breach occurs, limiting the damage and reestablishing normal operations are much more easily and effectively done when there are processes in place to quickly neutralize threats, prevent further spread, and recover.
This framework has proved valuable in creating effective risk management systems for IoT deployments. In this article, we will illustrate how to apply it in a newly connected age.
The suite of technologies that enables the IoT promises to turn most any object into a source of information about that object. This creates both a new way to differentiate products and services and a new source of value that can be managed in its own right.
Creating value in the form of products and services gave rise to the notion of a “value chain”: the series and sequence of activities by which an organization transforms inputs into outputs. Similarly, realizing the IoT’s full potential motivates a framework that captures the series and sequence of activities by which organizations create value from information: The Information Value Loop (figure 1).
Note first that the value loop is a loop: An action—the state or behavior of things in the real world—gives rise to information, which is then manipulated in order to inform future action. For information to complete the loop and create value, it passes through the stages of the loop, each stage enabled by specific technologies. An act is monitored by a sensor that creates information. That information passes through a network so that it can be communicated, and standards—be they technical, legal, security, regulatory, or social—allow that information to be aggregated across time and space. Augmented intelligence is a generic term meant to capture all manner of analytical support, which collectively is used to analyze the information. The loop is completed via augmented behavior technologies that either enable automated autonomous action or shape human decisions in a manner that leads to improved action.
An exhaustive itemization and review of the risks arising from all possible IoT deployments is not practical, nor perhaps even possible. The complex and rapidly changing ecosystems and technologies at play demand instead a structured approach to identifying risks and appropriate responses (figure 2). By focusing on some of the defining features of many IoT deployments, we can begin to see how the reinforcing principles of security, vigilance, and resilience can help companies protect the value they create.
Securing data is, of course, critical at every stage of the value loop. In some cases, the security challenges and remedies are very similar to those with which many companies are already quite familiar. For example, a company implementing a supply chain solution within its own factory or warehouse has created a new value loop, but the data being generated and transmitted are conceptually no different than the email or sensitive documents transmitted over the office Wi-Fi network. Similarly, most companies are already grappling with the collection, storage, and retrieval of vast quantities of data. Addressing these challenges effectively is critical, but, as they relate to the IoT, the differences are of degree rather than kind.
There are, however, elements of IoT deployments that give rise to risks that are, for many companies, entirely new. Specifically, what makes the IoT so powerful is the ability to create and communicate data—the first two stages of the value loop. These stages are enabled through sensor technology and, typically, wireless communications networks, and each is vulnerable to security breaches.
For example, sensors are susceptible to counterfeiting (fake products embedded with malware or malicious code); data exfiltration (extracting sensitive data from a device via hacking); identity spoofing (an unauthorized source gaining access to a device using the correct credentials); and malicious modification of components (replacement of components with parts modified to generate incorrect results or allow unauthorized access). Any or all of these compromises would leave the sensors vulnerable. Communication networks can be hacked, allowing data to be intercepted or their flow disrupted through denial-of-service attacks. The following three sources of risk are especially relevant to IoT deployments and can be addressed through the application of specific security countermeasures.
A common feature of many IoT deployments is the creation of an ecosystem that can include many different organizations or other stakeholders. Both upstream and downstream supply chain partners generate data, which extend even to the end-use customer. A large part of the value of IoT deployments stems from an ability to aggregate these data, yet the sensor technologies that various players in an ecosystem use can often be very different. Data are generated in different formats, and sensors connect to different networks via different communication protocols.
The lack of a single, generally accepted standard governing the functioning of IoT-enabled devices is therefore frequently a barrier to the interoperability required to realize the IoT deployments that many envision. The need for such standardization is evident in some device manufacturers’ willingness to join one of the standard-setting bodies devoted to establishing interoperability standards and providing open source software that enables manufacturers to certify their products.2 Unfortunately, even where standards have been adopted, different companies in the same supply chain may well adhere to different standards.
Consequently, companies can find themselves falling back on ad hoc solutions to create the interoperability that a given IoT solution needs. Unfortunately, it can be difficult to invest the time and money required to harden and test these solutions at the same level as formally developed standards, and so they are potentially more vulnerable to attack. Companies therefore face a sometimes-painful trade-off between creating interoperability and adequate security.
In the short run, the commonsense advice is simply to “test and invest” in order to create sufficiently secure case-by-case solutions. The IoT is unlikely to be a short-lived strategic priority, however, and it will therefore often be in a company’s long-term interest to set an active and deliberate standards strategy. This can take the form of promoting the adoption of a single standard within a supply chain; it might mean getting involved in the standard-setting process itself, with an eye to helping shape cyber security standards and promoting their widespread adoption. The temptation to delegate standard setting to others can be strong, but, with so much at stake, it is a temptation worth resisting.
Large, established organizations looking to implement IoT solutions that have already deployed sensors on a significant scale, such as industrial control systems (ICS), often consider adapting existing sensors to the IoT. This can be much more economical than developing new purpose-built technologies and then replacing existing components.
Unfortunately, many of the systems already in place—think of water or gas meters—use sensors with minimal security protocols because they were not designed to be connected to a more generally accessible network. Relying on such devices can only amplify the already-endemic risk associated with any value loop. For example, a manufacturing plant might use sensors to track its equipment’s performance and health, with all of those sensors feeding data to a secure central system. With IoT functionality, information moves in all directions, and the back-end system now aggregates and analyzes all the data. But with so many more points of communication, the older security programs’ simple, shared-system accounts and passwords are no longer adequate: If a malicious actor were able to break into such a system account, he or she could steal sensitive instrumentation data from anywhere in the system or launch a denial-of-service attack, devastating plant operations.
Eventually, however, retrofitting may cease to be a viable option from a security standpoint. Given the rapid pace of innovation, many devices will likely become physically incapable of being upgraded to prevent against the latest threats, rendering them outdated and vulnerable to threats.
Every new device added to an IoT ecosystem adds a new attack surface or opportunity for malicious attack, and each hand-off is a new opportunity for a security breach. This risk can be exacerbated by the lack of sufficient interoperability, which warrants an emphasis on increased security.
Awareness and accurate assessment of the risks arising from retrofitting are crucial to effectively managing them. Whenever possible, companies should err on the side of replacing legacy devices with wholly new purpose-built hardware rather than retrofitting. Failing that, developing purpose-built add-ons that are outfitted with appropriate security measures may be the next best route.
In light of the rapidly evolving technologies that enable many IoT deployments, there is an understandable desire to experiment and keep investment levels low. There is a real danger of overcommitting to technologies and even business models that subsequent innovation renders obsolete. When waiting is not an option but commitment entails material risk, it can make sense to extend the functionality of existing protocols and tools beyond their original design parameters. This allows companies to experiment and then commit as proven designs emerge.
Unfortunately, many of the technologies and protocols that developers are repurposing for the IoT can lack the high degree of native security controls that these new applications might warrant.3 Everything from short messaging service (SMS) to the Internet itself is used in ways that go beyond its original intent, often with negative implications for security. The Heartbleed OpenSSL vulnerability, for example, allowed third parties to steal information normally protected by the SSL/TLS encryption, affecting many IoT devices.4 Estimates suggest that fully eradicating Heartbleed from IoT products may take years, if not decades.5 Similarly, identity management—the authentication and authorization of devices for machine-to-machine communication—is often accomplished by relying on user names, passwords, and basic machine certificates. These continue to be points of compromise, and it is possible that new solutions for machine-level authentication need to be created to more effectively secure the vast array of IoT devices that are being predicted.
As with retrofitting, the practice of extending functionality enlists off-the-shelf communication protocols in ways not originally intended for secure machine-to-machine connections. Thus, to shore up vulnerabilities, companies would do well to take a similar approach to that of retrofitting: by hardening current solutions; designing new, bespoke, IoT-specific solutions; or adding a bespoke security element to protocols repurposed for the IoT.
Developing a security strategy for safeguarding an IoT ecosystem isn’t enough; as the technology evolves, so too will the threats it faces. Therefore, remaining vigilant to new or unexpected challenges is crucial to maintaining security. Two aspects of the IoT that are new to many companies create challenges that warrant an especially attentive, watchful response.
As the technologies upon which the IoT relies improve, so too will the scale and scope of data collected, as well as the frequency with which they are collected. Smaller, cheaper, smarter, lower-power sensors and near-ubiquitous high-bandwidth wireless networks make it possible to know much more about many more things far more often. We can know not just where data are but also their velocity, direction, operational status, and a host of other characteristics.
When it comes to people, the scope of data collection is still more remarkable. The smartphone is already a widely deployed sensor that can reveal all manner of personal behaviors. To that we can add wearables of all sorts, gleaning still further insights into people based on what their things—home, car, and so on—do.
More information creates more possibilities to create value: This is the promise of the IoT. On the other hand, it also creates new liabilities. The quantity and variety of information companies find themselves collecting can make it difficult for companies to know if their data have been breached—a situation exacerbated by the fact that much of companies’ data may be held by third parties, making them even more difficult to safeguard. When dealing with such tremendous volumes of data, it is only too easy for relatively small, virtually unnoticeable thefts to pile up until they amount to a veritable fortune. Worse, the loss of a small amount of data can translate into a threat to an entire system and irreparable tarnishing of an organizational brand. Under such circumstances, the need for heightened vigilance is especially acute.
Companies can address this threat by developing a deep understanding of the data they possess and combining that with analytics to measure against a set “normal.” By establishing a baseline of what “normal” looks like, they can more readily and reliably identify possible abnormalities, triggering further investigation.
The volume and complexity of the data in an IoT deployment are often a reflection and consequence of the variety and complexity of the stakeholders in the ecosystem that enables that deployment. IoT applications—particularly those employed at the enterprise level—can rely on the closely coordinated actions of multiple players, from vendors along the supply chain to clients, transport agencies, the showroom, and end-use customers.
As discussed before, every new device added to an IoT ecosystem adds a new attack surface or opportunity for malicious attack, and each hand-off is a new opportunity for a security breach. This risk can be exacerbated by the lack of sufficient interoperability, which warrants an emphasis on increased security. In addition, a complex ecosystem can diffuse responsibility for monitoring the flow of data around the value loop. This can be especially acute as ecosystems grow and change over time, and originally established responsibilities become less relevant.
As manufacturers extend IoT-enabled processes and systems beyond their own organizations to encompass these additional parties, information flows across multiple external devices and databases, each under the control of third-party organizations. These third parties, however, may not recognize that their secure, vigilant, and resilient strategies—or lack thereof—have implications for the systems of every other stakeholder: The chain is only as strong as its weakest link.
The complex nature of IoT ecosystems may lead enterprises to assume that all the players involved can share responsibility for security. However, it could be a mistake to assume that partners—much less customers—should or will take responsibility for maintaining data confidentiality and guarding against breaches. In other words, enterprises should consider behaving as if the responsibility for security were theirs, and theirs alone.
The smart home provides a particularly resonant example of the risks involved when multiple brands, devices, and stakeholders aggregate and analyze multiple data sets and are knit together to form an ecosystem. Take, for example, the garage door opener. This device provides access to not just the garage but also the primary home. In some configurations, opening the garage door deactivates the home alarm—a welcome convenience to someone coming through the door laden with groceries. This, however, means that the entire alarm system is deactivated if only the garage door opener is compromised.
Vigilance in this case means looking across all the relevant information that can be gathered and analyzing that against a baseline normal before declaring an “all clear.” For example, if neither the owners nor their cars are near the home—determined by using GPS data on registered smartphones and automobiles—then the garage door opening would not only leave the alarm system active but trigger an alarm, along with security cameras and a text message to the registered phones or security services. This is relatively easily done when one security company provisions the entire system. For companies operating as part of an ecosystem, however, it might well make sense to provide for this sort of integration, and even be able to act as the hub for it.6
Companies can remain vigilant for threats in several ways. First, they can develop and maintain clear accounting within the IoT ecosystem, so that each player knows where its responsibilities begin and end, and what each is charged with protecting. Reviewing the responsibilities of all the stakeholders that touch the data in each of your value loops in some way, as well as the measures in place to fulfill those responsibilities, and assessing the potential risks to protect against them are central to effective vigilance.
No amount of security and vigilance can guarantee that there will never be a breach or compromise. Far closer to certain is that some sort of failure will occur at some point. And in the face of almost certain failure, a system’s resilience defines how quickly a realized risk can be addressed and normal operations restored. Consider the following two ways in which the need for resilience is relevant to IoT deployments—one driven by data management, the other by the design systems in the physical world.
Many companies aggregate information of wide scope from multiple devices with the assumption that more data must be better—more valuable, more useful. It is tempting to cast a wide net and operate under a “collect it if you can” bias, believing the data will be useful at some point.7 Advances in IoT technology aid this impulse: Sensors’ low cost and increasing flexibility provide companies with the ability to easily collect more data than they currently need.
Deloitte & Touche LLP’s Cyber Risk Services practice offers a range of services to help our clients establish Secure. Vigilant. Resilient.TM cyber risk programs. Rather than being a necessary burden, the program is a positive aspect of managing business performance. Cyber Risk Program Alignment and Governance services help leaders invest in and manage the cyber risk program. SECURE services help organizations establish risk-focused controls around sensitive assets. VIGILANT services use analytic and correlation technologies to help develop monitoring solutions around critical business processes. RESILIENT services help organizations be prepared for when incidents do occur. Managed Security services help organizations manage controls pertaining to enterprise applications, identity and access management environments, and outsourced security operations. Read more about our Cyber Risk Services practice on www.deloitte.com.
Such practices bring to the fore an often-overlooked domino effect that arises from gathering ever-more diverse data: unauthorized inferences. For example, a customer might be willing to hand over location data and grocery shopping patterns in return for discounts or real-time coupons, but that same person may turn out to be strongly averse to those data being used to infer her health status. Without limitations on how data can be combined, each new data field dramatically increases the transparency of a person’s life to whoever holds that information.
Establishing data governance can help mitigate some of the risks arising from aggregation. Setting limits on what can be collected in the first place can help sidestep many risks altogether, as companies can avoid collecting data they won’t use and collect only those data that will generate enough value to justify the risk. Guidance concerning data ownership (which stakeholder within the ecosystem owns each piece of information) and the length of the data’s life cycle must be established to ensure that data cannot be retained beyond a suitable timeframe or used for nonprescribed purposes. Such measures make it far more likely that as a company collects more and more data, any compromises will be far better contained than otherwise.
Moving from bits to atoms, the value loop is complete when actions are taken based on the data gathered and the insight generated. This often occurs independently of any human intervention. The appeal of many IoT deployments depends on precisely this characteristic, which typically calls for tightly coupled systems. When these work, they work very well, but they are vulnerable to more widespread havoc. In one particularly illustrative case, a German computer science professor, who built one of the very first smart homes, discovered what can happen when one element—in this case a smart lightbulb—goes rogue. Like a string of Christmas lights that goes dark because of one errant bulb, one afternoon his entire smart home failed to respond; only after monitoring his internal home network traffic did he discover that a defective lightbulb had been swamping the automation hub with error messages. The lightbulb had, by itself, created a denial-of-service attack that rendered the entire house nonfunctional.8
This anecdote is a small-scale illustration of a data-chain domino effect: Any element of the system can disrupt the entire system. Avoiding this sort of self-propagating disaster requires fail-safe systems—that is, if there is a system failure, the consequences are not catastrophic and do not trigger knock-on system failures. Thus threats can be contained to a smaller area, averting a more catastrophic failure. In some IoT deployments, this takes the form of loosely coupled systems. In our home automation example, this could have taken the form of implementing stronger security-event-monitoring controls at the hub to effectively shut down the affected smart component in a fail-safe manner, with more effective incident or error handling at the smart-lightbulb component level. These resilient controls would have prevented one element compromising the entire connected home network.
Effective risk management in any IoT deployment will draw on all three factors: secure, vigilant, and resilient. To illustrate the application of these principles, however, we focus below on applications in which each, in turn, is especially salient.
The importance of securing individual sensors is perhaps most important in today’s connected car, which has evolved into a data center on wheels with any number of Internet-connected features. A typical automobile today contains about 70 computational systems running up to 100 million lines of programming code—twice as many lines of code as in the Windows Vista operating system.9 Along with GPS devices that aid navigation and report on real-time traffic and road conditions, diagnostic devices assess maintenance needs and alert authorities in the event of an accident or breakdown. As infrastructure evolves, smart cars will have the ability to communicate with roadside devices such as traffic lights as well. Therefore, they must be designed keeping security in mind at the outset.
It’s no surprise that some automakers might rush to develop and install IoT-enabled features to attract early-adopter customers and aid safety and convenience. In today’s cars, IoT-enabled technologies include power and infotainment systems, remote locking and unlocking, and remote engine start, with data flowing between different vendors. Vehicle-to-vehicle communication spans ecosystems as well—for instance, connecting an automobile to the driver’s home. Through in-vehicle platforms, smart cars can communicate with smart home hubs to open garage doors, unlock front doors, and turn on house lights as the in-car GPS registers that the driver is nearing his or her home. The scope of data communicated between connected vehicles encompasses a wide swath of personal yet highly sensitive information such as driving habits, real-time location, entertainment preferences, and daily schedule.
Much of this communication is accomplished via existing tools that have been repurposed for IoT technologies, including mobile apps, cellular networks, and SMS technologies typically used for casual texting and not intended for secure communications. These extended IoT functionalities leave networks vulnerable to security breaches. Indeed, a recent survey of automakers found that nearly 100 percent of cars currently on the market include wireless technologies that may be inadequately secure, and most automobile manufacturers may not be able to easily determine whether their vehicles have been hacked.10 Hackers, on the other hand, have demonstrated the ability to infiltrate various vehicular systems simply by using SMS texting.11Physical attacks via onboard diagnostic devices have shown it could be possible to manipulate some systems even while cars are moving.12
Further complicating the matter, those managing the development and deployment of these technologies traditionally tend to have less experience doing so, and that, coupled with the newness of the technology, may mean many take fewer precautions to secure data at the device level. Thus manufacturers have yet to develop common security standards, and measures to prevent remote access to an IoT-enabled automobile are haphazard at best. Data transmission between multiple vendors—the automaker, dealership, third-party data centers, GPS and onboard diagnostics systems, smart home devices, and others—creates multiple vulnerable points that should be remotely monitored.13 Hardening the current systems to install more appropriate security measures will be crucial to safeguarding the connected automobile.
The importance of vigilance is perhaps most apparent when it comes to large networked systems such as power grids, transportation systems, and manufacturing plants. IoT integration into these systems promises efficiency benefits. However, remote ICS—once isolated within a factory or out in the field, and now interconnected online—has less of a legacy of mature cyber risk practices, and its developers and owners may have insufficient institutional knowledge to adopt an appropriately vigilant approach to security.
Security for ICS is often governed by cost-benefit analyses that place short-term production needs ahead of safeguarding systems over the long term. Concerns about production loss during maintenance downtime may trump safety concerns, even as production loss in the event of a security breach would likely be much higher. Further complicating the matter, ICS consists of mostly proprietary vendor-certified configurations and may contain components from multiple vendors, making a unified approach more difficult.
Asset age presents further risks. Older systems may have been retrofitted to make them IoT-enabled, a more cost-effective approach than replacing them entirely. However, they run into the same challenges described earlier—a lack of advanced security protections or inadequate safeguards. Enterprises may also be employing traditional information security practices or traditional shop floor measures that simply don’t apply to an IoT-enabled device.
For ICS, one critical factor is the need to maintain 24/7 business operations. This illustrates the importance of having a vigilant security strategy, one that proactively looks for security gaps and anticipates malicious acts to prevent their causing unplanned downtime.
A traditional steel mill in Germany, for example, fell prey to a cyber attack in (probably) 2014 that disrupted internally networked control systems to the point that a blast furnace did not shut down properly, resulting in massive physical damage to the facility.14 While this incident was limited to one mill, as systems grow ever more networked across facilities and span multiple players, the scale of data communicated and thus the risks for disruption on a wider scale grow larger, as well as the need for better monitoring. Indeed, establishing a baseline of “normal” data will help companies recognize when such anomalies arise, to stem the flow before they create a larger catastrophe.
Thus far, even the most personally inconvenient data breaches—for example, theft of credit card information—have left consumers remarkably unfazed.15 But the IoT, by incorporating unique personal information gleaned from sensors, may alter that equation, and companies may find themselves in uncharted territory. Scenario planning, then, is key to preparing for reputation risk management and possible crises based on data breaches or worse. For instance, if a cyber criminal’s work compromises a communication network partner’s information flow, it is useful to have a sense of how to contain the problem, continue operations, and work with partners to restore the network.
Previews of the potential problems have already surfaced: In recent years, several major retailers, victims of high-profile thefts of customer information from infected point-of-sale devices, have been forced into crisis management mode, promising new, stringent security measures from the payment industry. Thus retailers must be resilient, prepared with a security response that enables them to bounce back from a massive data breach.
In addition to safeguarding their own internal data troves, retailers must contend with external supplier risks, including counterfeiting. Retailers will want to avoid being a party to selling faux products that leave customers vulnerable, however inadvertently. In particular, retailers will need to implement product verification to mitigate the risk of counterfeiting wearables, a market in which the buying channels are bigger and therefore prone to cheap imitations with potentially embedded malware.
For their part, consumer product manufacturers should consider their ability to be resilient in the face of a data breach. The range of connectable home devices—TVs, webcams, home thermostats, remote power outlets, sprinkler controllers, door locks, home alarms, smart home hubs, and garage door openers—creates multiple opportunities for hackers to gain entry into home ecosystems, entire customer bases, or even manufacturers’ back-end systems each time data traverse the ecosystem.16
Specific risks from unprotected consumer devices may come in the form of eavesdropping, manipulated data in a man-in-the-middle attack, or data halted entirely due to a denial-of-service attack. An IoT-enabled door lock may allow entry into a homeowner’s house by disabling the alarm and unlocking the front door; and a lock that’s been tampered with, either by including parts corrupted somewhere along the supply chain or via malware, or is counterfeited could offer just about anyone access to a private home—a nightmare for customers and a potentially fatal scandal for an implicated manufacturer or retailer.
With the IoT and its attendant privacy and security concerns still at an early stage, any company’s worst-case breach scenario is just that: a scenario, with no precedent. It’s critical, then, for any firm looking to capture value from IoT technology to consider next steps if a data breach compromises a product or network—not only how to manage reputation risk but also how to continue operations. Establishing governance around which data can be collected, by whom, and how they can be used can help mitigate some of the effects of a breach. Additionally, establishing clear accounting so that each stakeholder understands its responsibilities and what it needs to protect can help further safeguard the system. Loosely coupling devices within the network will also help ensure that an attack on one node won’t spread.
For enterprises and individuals alike, smart, connected objects offer tremendous opportunities for value creation and capture. Those same objects, however, also create tremendous risk, demanding new strategies for value protection: A single vulnerable device can leave an entire ecosystem open to attack, creating the potential for disruptions ranging from individual privacy breaches to massive breakdowns of public systems.
In the face of such challenges, companies can remain secure, vigilant, and resilient by taking several steps to safeguard their ecosystems and the data they create:
Work to define standards for interoperability. Adhering to one standard only or actively getting involved with consortiums to develop a set of standards can help ensure that devices within a network can all communicate and work together safely and effectively.
Use purpose-built devices or add-ons, rather than pre-IoT solutions. Rather than retrofitting or extending functionality of old systems in ways for which they weren’t designed, companies should strongly consider wholly new, secure technologies designed specifically for the IoT. If this is impossible, any add-ons used to retrofit the device should, at the least, be purpose-built specifically for that use, outfitted with appropriate cyber security measures.
Develop clear responsibilities for the players in your ecosystem. Rather than sharing responsibility across a diffuse ecosystem, players must know where their responsibilities begin and end, and what they are responsible to protect. Taking an assessment of all stakeholders and assessing the potential risks at each point—and making sure the stakeholders are aware of those risks—can help make a solution more secure.
Establish a baseline of data. Viewing IoT systems more broadly and monitoring environmental attributes such as usage, location, and access would better enable enterprises to gather a broad enough scope of data to establish a baseline, helping companies to discern what is normal and what constitutes a suspicious aberration. This, in turn, enables enterprises to take appropriate and effective action when data do stray from the norm.
Institute data governance. Enterprises should consider playing a stronger governance role by defining which data to secure, what it means to be sufficiently secure, and, by extension, which products meet that goal. Guidance around how data can be securely collected, used, and stored can help prevent unwanted breaches and prevent a risk event from snowballing into something larger, and can also outline the lines of responsibility in the event of a breach.
Create loosely coupled systems. Ensure devices within an ecosystem are loosely coupled and resilient so that the failure of one device does not lead to widespread failure.
The prospects for creating and maintaining a seamless, secure network—with or without external partners—may seem daunting, considering that vulnerabilities exist on all sides, be they physical or virtual, inadvertent or malicious. Security cannot be an afterthought—it must be integral throughout the design process. IoT solutions will need to blend a deep understanding of organizational operations with knowledge of multilayered cyber risk management techniques, creating offerings that are secure, vigilant, and resilient.August 18, 2020 For the past couple of decades, the emergence of electronic medical records, telemedicine, and big data have held the promise of revolutionizing healthcare for both patient and provider, making it more efficient, effective, and affordable. Yet so far, the payoff has been elusive, with technology arguably causing as many (if not more) headaches in the system as it cures.
Still, there is no doubt that advanced connectivity has the potential to deliver big savings to the healthcare industry by improving productivity and outcomes that in turn will free up money to invest elsewhere in the business. The McKinsey Global Institute (MGI) and the McKinsey Center for Advanced Connectivity (MCAC) estimate that those improvements will add $250 billion to $420 billion to global GDP by 2030, some 80 percent of which can be realized with existing advanced connectivity.
Three use cases in particular—remote patient monitoring, AI-enabled decision support, and integrated command centers—highlight the massive potential value of advanced connectivity in healthcare.
Newly sophisticated and affordable, wearable sensors can deliver information about heart rates, glucose levels, and oxygen saturation to care providers anywhere in real time. This approach to patient care and oversight can reduce the length and number of hospital stays and lower readmission rates, as well as help patients keep chronic diseases such as diabetes and hypertension under control without constant in-person medical intervention. We estimate that such systems running on advanced mobile networks can deliver $70 billion to $120 billion in annual value globally, not to mention lower morbidity and increased patient satisfaction.
Advanced connectivity allows the use of artificial intelligence to learn from large data sets, fueling systems that can collect and update patient histories, evidence-based protocols, and information from patient monitoring. This will allow healthcare professionals to make better decisions and deliver treatment faster, even from far-flung locations. In Birmingham, England, for example, doctors have tested a system using virtual-reality headsets and joysticks to help paramedics take an ultrasound scan with a haptic glove and instantaneously transmit the data back to the doctors for faster diagnosis. These support systems—enabled by high-bandwidth, low-latency networks and advances in computing, storage, and sensors—could unlock $40 billion to $70 billion in efficiencies, including reductions in medical errors.
Capturing information delivered by radio-frequency identification (RFID) and sensor tags installed across a hospital, bar codes from patient bracelets, and other connected devices can radically transform patient care. A connectivity-enabled central dashboard using this data can better manage patient flows, freeing up beds and optimizing staff scheduling. Similarly, advanced connectivity can link multiple healthcare IT systems as well as sensors and tags in a continuum of care. Integrated command centers could generate efficiencies that add $40 billion to $70 billion annually.
These three use cases are just the most prominent examples of how advanced connectivity could dramatically benefit individuals’ healthcare, as well as health systems and even whole economies, within a decade. Connectivity-enabled remote patient monitoring and telemedicine will help people better manage long-term health conditions and gain access to preventative care. Advanced technologies will improve patient outcomes by delivering more accurate diagnoses or rapidly adjusted treatments. Health systems will be able to deploy staff, coordinate patient care, and tap limited resources more efficiently. Israel’s largest healthcare organization, for instance, is already using IoT-based “smart cabinets” to manage its inventory of medical devices and supplies. All of the resulting improvements in population health should ultimately increase productivity and economic growth, potentially adding $2.1 trillion annually to global GDP.
Such achievements, however, require more than advanced connectivity and smart devices. Governments must prioritize funding for healthcare innovations, and insurers must implement clear reimbursement paths for digital offerings. Healthcare systems need to hire for a wide range of new roles, including systems architects, data scientists, and user-experience designers. Common data standards and governing regulatory guidelines will have to be set, just as clear, proven procedures for protecting patient data are paramount. Within and across countries, frameworks to guide investment in technology-driven healthcare services and to test and confirm the validity of connectivity-enabled use cases are essential.
Finally, it is critical that all stakeholders—from providers and systems to payors, employers, and technology/connectivity providers—learn to collaborate, most importantly on solving the issue of interoperability across systems and solutions. Only by moving beyond their traditional silos and working together for the good of the entire system can all these varied players each reap the benefits of connectivity in healthcare while delivering the most crucial reward to patients themselves.
This post was adapted from the recent MGI/MCAC discussion paper, Connected world: An evolution in connectivity beyond the 5G revolution. It is part of an ongoing series.
Sign up here to receive updates on the latest research and insights from the McKinsey Center for Advanced Connectivity.We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Earlier this week, 90 guests, including media, industry, and tech experts, toured the new Digital Capabilities Center (DCC) in Singapore, for a glimpse of the future. The future of manufacturing, that is.
This center, one of five digital model factories, will serve as a showcase and teaching ground for the emerging technologies of “Industry 4.0.”—advancements in data and analytics, robotics and automation, and production methods such 3-D and 4-D printing. Each of these advancements plays a critical role in reshaping manufacturing and operations, and helping companies achieve significant—even sensational—improvements in productivity. For example, Oliver Tonby, managing partner of Southeast Asia, points out that “automation and real-time dispatching in a semiconductor business can ramp up production by up to 50 percent.”
In our recent survey, 90 percent of manufacturers agree that Industry 4.0 technologies will change their operations—yet less than half think they are ready, with the strategy, people, data, or processes in place. To help companies prepare for this sea change, we designed five learning environments to make “the digital as tangible as possible,” explains Jörg Bromberger, the senior practice manager who has led the initiative over the past two years. In addition to Singapore, the new centers will be located in Aachen (Germany), Beijing, Chicago, and Venice (Italy).
Like our existing network of capability centers, each digital center is completely different with a production line tailored to the local client base; for example, “smart” radio-frequency-identification (RFID) wristbands in Germany and iced-tea processing in China. “But they will all share the same 25 digital learning modules—so the person in Venice will have the same learning experience as the participant in Chicago,” says Jörg. “We’ve taken a full production line in each setting and layered it with digital technology - so users can experience the possibilities at every touchpoint.”
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com The Digital Capabilities Center in Aachen, Germany, opened in March 2017.
Each center is connected with a leading industry consortium, government organization, or research institution that serves as the scientific backbone. The centers will be dynamic, updating and adding new technologies on a regular basis—such as artificial intelligence, cybersecurity, and cobots and robots later this year.
The Singapore DCC recreates the environment of a manufacturer of industrial gearboxes. The fictional $2 billion company has 8,000 employees spread across five key geographies. During workshops, participants watch as plant workers use digital technologies to manage scenarios, such as a pending equipment failure or a spike in demand that threatens to overwhelm the supply chain.
As the set of actions unfold, “participants can see the digital thread of communications flashing across the screens, from war-room planning of raw materials all the way to customer service, as the company responds to these situations,” says Alpesh Patel, who leads the Singapore center. The scenarios are drawn from the direct experience of 40-plus aerospace and manufacturing companies who participate in the public-private collaboration behind the center.
In Aachen, the manufacturing line of RFID wristbands is set up to show a “before” and “after” state. Participants start the program observing a fully operating lean-production facility. “Throughout the workshop, they can ‘turbo charge’ the line with a set of digital tools that penetrate—and provide visibility and analytics—into every step of the process,” explains Jörg. “For example, by applying digital condition monitoring, which provides information every few seconds—rather than a once a day—they can reduce equipment downtime by as much as 75 percent.”
The workshops are open to large and small companies and are tailored to the participants’ experience, ranging from an introduction to Industry 4.0 capabilities to running an actual technology pilot to skills building for a large-scale implementation.The IoT revolution has been a driving force for further digitalization in many industries, the development of innovative business models and the building of collaborative ecosystems. IoT use cases differ inherently from web or other digital applications, as IoT combines both the digital as well as the physical world. Therefore, IoT requires a holistic user-centric approach and cross-functional collaboration between design, technology and business.
With this in mind, user-centricity in IoT development is essential in order to provide business value for the targeted users. Design decisions that do not take into account the whole experience of the end user might create an incoherent, or even bad, user experience.
The main idea of user-centric thinking is simple: First, the overall strategy needs to be defined. After user segmentation and pooling, the user needs are prioritized. However, this is not easy. When applying principles of user-centricity to IoT, several questions need to be considered:
Strategy is always first. Before focusing on the user, the strategy needs to be defined and aligned. A clear vision is essential for the overall success. By using methodologies and techniques like design thinking and prototyping and in combination with proven design frameworks like business model canvas or the Deloitte industry print, it is possible to transform IoT use cases into an operable IoT solution.
If the aim is to be more user-centric in IoT development, there is a need to evaluate the user. However, this is not an exercise that should be done only once, at the beginning of a project. Instead, understanding the end user and solving the problem by using IoT needs to be the main priority in all stages of IoT development.
Often initiated out of company’s technology units, with a stronger focus on technological advancement and functionality than business value or user design, IoT use cases sometimes neglect that there is always an end user that should be targeted. From a retail perspective, this might be a customer purchasing and using home appliances. From an industrial perspective, it might be a factory worker handling IoT devices as part of a manufacturing process. The goal is to understand the user’s motives, needs and pains in using a product or service and enhancing the overall experience. It is essential to know who the end user and other relevant stakeholders are, how they interact with the application and what their requirements are.
It is not only important to realize who the end user is and which potential preferences for products and services they have. IoT adds real value when it solves a user problem and enhances a holistic user experience. It is important to understand the user’s whole journey and develop a full view of the problem at hand.
User research can be conducted to gain insights and a better understanding of the end user. While quantitative methods are great for testing hypotheses and processing big amounts of data, qualitative research will uncover hidden user motivations and any pains and gains in the user journey. Methods like defining personas, conducting in-depth interviews or even ethnographic research could all help to better understand users and their challenges.
Ethnographic interviews aim to immerse the interviewer into a subject’s environment and daily routine. Using observation and qualitative interview techniques, IoT developers can gain deep insights on how their targeted user behaves on a day-to-day basis, which user problems are relevant and demand for IoT solutions, and where potential touchpoints with the IoT applications could be implemented. In an industrial setting, factory workers could – for example – be asked about their daily routines, challenging tasks in a typical working day, or how current products and services are used.
Building on these insights, IoT use cases can be defined and embedded in the overall user journey. It is important to make the IoT solution part of the overall experience and create touchpoints, which seamlessly integrate with existing processes or actions in the user journey.
With the user motivations, needs, preferences and user journey touchpoints in mind, these insights need to be translated into requirements in order to set up the IoT use case. It is important to keep in mind that user preferences and touchpoints might also influence underlying systems and processes that are not immediately visible to the end user, but nevertheless contribute to an overall seamless user experience.
The IoT solutions needs to be integrated into the existing technical environment from a functional (e.g. connectivity to other devices/platforms, handling of data streams, etc.), non-functional (security, scalability, etc.) and hardware perspective. User insights might also influence decisions in the realm of business and governance of IoT applications or platforms.
Combining the best of the waterfall and agile approach, the hybrid agile approach allows executing the project on a priority basis, taking into account constraints and dependencies. In addition, the hybrid agile approach focuses on shorter sprints with targeted functionality that enables teams to develop prototypes and to confirm requirements when needed while issues are identified early. Thus, this increases transparency and feedback. The design process of an IoT solution is not linear, rather, fast and iterative feedback is needed to develop valuable IoT solutions and in order to make sure that the proposed use case is relevant and is headed in the right strategic direction.
As emphasized before, it should be the priority to keep the end user at the center of all decisions in designing and developing an IoT use case after the strategy is set. This means that the user insights should be considered at each stage of developing an IoT use case.
A “fail early and fast” mentality is helpful in order to avoid going in the wrong direction. If not tested in early development stages, IoT solutions run the risk of adding limited value and of being used in different ways than originally intended. Prototypes and tests should be used at each stage of IoT development to figure out how users will use the solution. The goal is to explore requirements, develop alternatives on how to implement them in the overall user journey and to choose the alternative with the best usability.
Prototyping and testing are intertwined and work together in iterations. Early prototypes can be used to evaluate function and features, whereas late prototypes are a good indicator to evaluate performance.
Even though the end user is hardly visible in IoT projects in comparison to more traditional areas of user-centric design, they should still be considered and prioritized in the user-centric development of IoT use cases. Of course, applying these principles is not the only approach to ensure that IoT solutions are successful. However, looking into the future as IoT platforms grow together and build ecosystems with partners, it might not be a bad idea to keep the end user in focus.The Internet of Things (IoT) has generated excitement for a few years now, with start-ups and established businesses placing bets on the industry’s growth. Some of the earliest investments have begun to pay off, with smart thermostats, wearable fitness devices, and other innovations becoming mainstream. With new IoT products under development or recently launched—ranging from medical-monitoring systems to sensors for cars—some analysts believe that the Internet of Things is poised for even greater gains.
Semiconductor companies, perhaps even more than other industry players, might benefit from the IoT’s expansion. With growth rates for the smartphone market leveling off, the Internet of Things could serve as an important new source of revenue. Given the size of the potential opportunity, McKinsey recently collaborated with the Global Semiconductor Alliance (GSA) to investigate the Internet of Things more closely, with a focus on risks that could derail progress. In addition to assembling a fact base, we surveyed and interviewed senior executives from the semiconductor sector and adjacent industries, as described in the sidebar, “Our methodology.”
Sidebar Our methodology The joint McKinsey–GSA work, which was led by a steering committee composed of McKinsey semiconductor experts and 11 senior executives from GSA member companies, had multiple components. To gain a leadership perspective on the Internet of Things, McKinsey interviewed 30 GSA members who had leadership roles at semiconductor companies or at companies in adjacent industries that are customers of semiconductor companies and part of the IoT ecosystem, such as network equipment and industrial automation. We also surveyed 229 semiconductor executives at GSA member companies in November 2014 to gain a broader industry perspective. Finally, McKinsey consultants assembled a fact base on the Internet of Things, focusing on issues relevant to semiconductor companies.
Our research suggests that the Internet of Things does indeed represent a major opportunity for semiconductor companies—one that they should begin pursuing now, while the sector is still developing. We also found, however, that the timing and magnitude of the IoT’s growth may depend on how quickly industry players can address several obstacles, including inadequate security protections, limited customer demand, marketplace fragmentation, a lack of standards, and technology barriers. Semiconductor companies, which have encountered similar problems in other nascent technology sectors, are well positioned to serve as leaders in resolving these issues.
Another important insight relates to the nature of semiconductor companies themselves. Their traditional focus on silicon, which allowed them to profit in many industries, may not be optimal for the Internet of Things because chips represent only a small portion of the value chain. Instead, semiconductor companies will be required to provide comprehensive solutions—for instance, those that involve security, software, or systems-integration services in addition to hardware. As with any major change, this move entails some risk. But it could help semiconductor companies transform from component suppliers to solution providers, allowing them to capture maximum benefits from the Internet of Things.
The McKinsey Global Institute recently estimated that the Internet of Things could generate $4 trillion to $11 trillion in value globally in 2025. These large numbers reflect the IoT’s transformational potential in both consumer and business-to-business applications. Value creation will stem from the hardware, software, services, and integration activities provided by the technology companies that enable the Internet of Things.
Analysts also estimate that the current Internet of Things installed base—the number of connected devices—is in the range of 7 billion to 10 billion. This is expected to increase by about 15 to 20 percent annually over the next few years, reaching 26 billion to 30 billion by 2020.
In keeping with these projections, many executives we interviewed stated that the Internet of Things would significantly boost semiconductor revenues by stimulating demand for microcontrollers, sensors, connectivity, and memory. They also noted that the Internet of Things represented a growth opportunity for networks and servers, since all the new devices and services will require additional cloud infrastructure. Overall, the Internet of Things could help the semiconductor industry maintain or surpass the average annual revenue increase of 3 to 4 percent reported over the past decade. These results are particularly significant in light of slower growth in the smartphone market, which has served as the major driver for the past few years.
Our interviews did reveal some ambiguity about whether the Internet of Things would be the semiconductor industry’s top growth driver or just one of several important forces. In particular, interviewees questioned whether the Internet of Things will trigger demand for new products and services, or if there will just be an increased need for existing integrated circuits. Similarly, our survey showed that executives from GSA member companies had mixed feelings about the IoT’s potential, with 48 percent stating that it would be one of the top three growth drivers for the semiconductor industry and only 17 percent ranking it first.
Despite the size of the IoT opportunity, some semiconductor companies have hesitated to make significant investments in this sector. The greatest issue is that products within the Internet of Things tend to appeal to a niche market and generate relatively low sales volumes. With individual products delivering a relatively low return on investment, some semiconductor companies have limited their R&D expenditures for IoT-specific chips, preferring instead to adapt existing products. For instance, wireless system-on-chip players may offer repurposed wireless processors and chip sets for the Internet of Things, while microcontroller players often bundle lower-end processors and connectivity-chip sets to compete for the same opportunity.
As the IoT market matures and increases in scale, semiconductor companies may decide to pursue new approaches more aggressively. Before moving ahead, however, they should first determine which verticals and applications are growing strongly and assess when their markets will be large enough to justify significant investment. While semiconductor companies could potentially capture growth in many IoT verticals, six of the most promising markets—those where we chose to focus our research—include the following:
smart cities, with applications to assist with traffic control and other tasks within the public sector
Like many other high-tech innovations, the Internet of Things is garnering intense interest in the press, with reports of connected cars and smart watches making headlines. Although we do not want to diminish the IoT’s potential, our research suggests that the following six issues could derail its growth:
the proliferation of niche products, resulting in a fragmented market and an unprofitable environment for creating application-specific chips
the need to extract more value from each application by providing comprehensive solutions, rather than focusing solely on silicon
These problems are not insurmountable, particularly if semiconductor companies are willing to take an active role in solving them.
A majority of our interviewees cited security as an important requirement for growth in IoT applications. One called it the “critical enabler,” claiming that many developers and companies initially underestimate its importance when creating IoT devices. He noted, “Security is not a key issue while your application or product has not reached scale, but once you are at scale and maybe have a first incident, it becomes a most important problem.” Our survey results echoed the interview findings, with respondents ranking security as the top challenge to the IoT’s success. Recent hacks to online car systems also highlight the importance of addressing security challenges for connected devices, vehicles, and buildings.
Ensuring security will not be easy, however, given the numerous applications and verticals within the Internet of Things, each with its own quirks and requirements. For instance, fitness wearables might only require relatively basic security measures that ensure consumer privacy, such as software-based solutions. But IoT applications that control more critical functions, including medical electronics and industrial automation, need much higher security, including hardware-based solutions.
Most executives we interviewed believed that the technology needed to secure the Internet of Things was already available. They were concerned, however, with the piecemeal nature of most security products and wanted to ensure that players protected the entire IoT stack—cloud, servers, and devices—rather than focus on only one of these areas. As one executive said, “Overall security is only as good as its weakest point.”
Semiconductor companies can assist with end-to-end solutions by providing on-chip security, partitioning processor functions on chip, or supplying comprehensive hardware and software services, including authentication, data encryption, and access management. Those that specialize in security might be able to use their own products to provide comprehensive solutions, but others will need to undertake M&A or form partnerships with players further up in the stack to gain broader expertise in software or the cloud. For instance, semiconductor companies could lend their knowledge of hardware security to application designers or network-equipment manufacturers, since this information would assist with the design of secure software.
Many of our interviewees envisioned a future in which IoT applications are more common than cell phones are today. Others were more cautious, however, with one noting, “No one really knows when the volume will show up; this is a clear challenge. . . . If you cannot show a $1 billion opportunity, then it’s hard to get attention.”
In other technology sectors, a single groundbreaking application or use case—a so-called killer app—has often spurred explosive demand. Such was the case in 2007, when the introduction of the iPhone triggered significant growth in the smartphone market. While the Internet of Things could potentially follow this path, most of our interviewees felt that growth would stem from a string of attractive but small opportunities that use a common platform, rather than a single killer app.
Some of the most innovative IoT applications—and those most likely to stimulate customer demand—could come from start-ups. Businesses outside the technology sector, such as retailers, insurers, and oil and gas players, might also develop interesting products that appeal to a wide customer base, although some of our interviewees felt that these companies would face tough odds. Semiconductor players could help indirectly stimulate demand for IoT devices if they adopt new strategies to help these players thrive. For instance, start-ups and nontechnical businesses often have limited experience with semiconductors, so they might appreciate simple solutions and more hands-on support, including guidance from dedicated field engineers who assist with board-level design and solution integration (from silicon through applications in the cloud). IoT customers might also prefer one-stop solutions—complete platforms with all relevant elements that an IoT device needs, including connectivity, sensors, memory, microprocessors, and software. For some small businesses with limited funds, such platforms may be the only economically feasible option.
Some layers of the IoT technology stack have no standards, and others have numerous competing standards with no obvious winner. In our survey and interviews, most respondents cited this situation as a major concern, with one executive stating, “What is critical is which standards will win and when this will happen.”
To see how a lack of uniform standards can complicate product development and industry growth, consider connectivity issues. There are competing, incompatible connectivity standards for devices with a low range and medium-to-low data rate—for instance, Bluetooth, LTE Category 0, and ZigBee. With so many options, product designers may be reluctant to create new devices, since they do not know if they will comply with future standards. Similarly, end users may be reluctant to buy devices that may not be interoperable with existing or future products of the same type (Exhibit 1).
Exhibit 1 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Although multiple organizations, including interest groups and industry consortia, are attempting to establish standards, it is impossible to predict which ones will prevail in each IoT vertical. Faced with this uncertainty, semiconductor players should pursue a hedging strategy, focusing on selected standards that are likely to gain widespread acceptance while simultaneously planning for alternative scenarios. In all cases, semiconductor players should actively engage with industry associations or other groups that are trying to develop IoT standards, with the goal of supporting the best ones.
IoT devices have widely varying requirements for power, data-processing speed, form factor, price, and other dimensions. Smart water meters, for instance, need to run for months, if not years, independent of power supply. They also require high-range connectivity, but data rates can be under one kilobit per second. By contrast, IoT devices used for industrial automation typically require a direct connection to a power supply and high data rates, but their connectivity range is lower than that for smart meters.
These variations in device specifications become significant when considering R&D costs for a single chip. Assuming typical integrated-circuit design costs and product lifetimes, semiconductor companies will need to ship 20 million to 70 million chips annually to break even. Only a few segments, such as wearables, are large enough to require so many chips, making it impractical to create customized solutions for individual applications. But rather than abandon the IoT market, semiconductor companies should investigate an approach that involves classifying devices into archetypes based on their specifications and then creating a single platform to cover each one.
Products from multiple verticals can fall under one archetype as long as they have similar specifications. For instance, many low-cost applications have common requirements for short-range, medium-data-rate connectivity and limited data processing. If semiconductor companies create a common platform for applications that fit this archetype, they will simultaneously increase demand and reduce R&D spend. One downside of a platform approach is that the chips may not deliver optimal performance for every application they cover.
Semiconductor companies have a well-deserved reputation and track record for technological innovation, with some of their inventions spurring advances in personal computing, mobile telecommunications, and elsewhere. But they are also known—fairly or unfairly—for failing to extract full value from their innovations, with other high-tech players, such as software firms, profiting most from device enhancements. Our analysis suggests that semiconductor companies might face a similar dilemma with the Internet of Things. One executive we interviewed noted, “Value extraction has always been a particular challenge for semiconductor players, and it becomes particularly challenging in the Internet of Things, as even more players participate in the stack and business models are still immature.” Other interviewees stated that big data and cloud companies were positioned to capture far more value from the Internet of Things than semiconductor businesses.
To tackle this problem, some semiconductor companies have already begun to create complete solutions that cover multiple layers of the technology stack, especially since nontraditional customers—start-ups and businesses outside the technology sphere—prefer this approach. It is still too early to identify winning strategies, but the advantage may go to companies that pursue the following three opportunities (Exhibit 2).
Exhibit 2 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Software. Semiconductor companies have been complementing integrated circuits with supporting software for many years, but this trend will become even more important as the Internet of Things grows. Many semiconductor companies have recently sought to build their software skills through M&A or partnerships, while others have focused on improving their in-house capabilities.
Security. As noted earlier, the Internet of Things requires end-to-end security across the stack. Semiconductor players have traditionally provided chip-security solutions, but they may find additional opportunities in other layers, particularly if they can offer software products.
Systems integration. One interview subject stated, “Today most players have a partial but not full solution for integrated systems, so who is the integrator?” Semiconductor companies could fill this role, especially if they provide system- or application-level software supporting integrated circuits, although some interviewees noted that this might be too much of a departure from their core competencies.
In our survey, two-thirds of respondents stated that technological issues present little to no challenge to the success of the Internet of Things. The remaining respondents were split evenly between those who thought that technological issues were above average in importance and those who considered them a major challenge. Executives may hold varying opinions because technological issues differ by vertical and application. For instance, the interviewees agreed that wearable technology needs improvement. “With wearables, there is a constant issue of charging,” one executive stated. “We need to make devices last for a trip.” By contrast, technology for smart-home applications is well advanced, but there are few standards governing interoperability, which has limited their adoption.
When we asked our interviewees about the most crucial technological innovations for the Internet of Things, most focused on lower power consumption and battery life. A step change in the time between charges will increase demand for existing devices while also enabling product designers to create new applications. Wearable computers, distributed sensors for agricultural applications, and retail beacons are just a few of the applications that require improvement. Innovation in power and battery life will likely come from various sources, such as on-device power management, further advances in storage, over-the-air and wireless charging, and energy harvesting.
Although semiconductor companies that offer leading-edge technological advances will find themselves in high demand, not every player has to focus on innovation. Those companies that offer more dated solutions will still have a role in the Internet of Things, since many applications—particularly the sensors they contain—will continue to rely on existing (albeit highly specialized) technology.
Semiconductor companies that want to capture the IoT’s enormous growth potential might be tempted to move ahead quickly, without changing their existing operating model, but this could be a mistake. The Internet of Things is unlike any high-tech segment that they have previously served, and their traditional strategies may not succeed with the new customer base. With so much at stake, semiconductor companies need to reevaluate all aspects of their businesses and potentially make some significant changes. From a strategic perspective, three tactics will be particularly important.
There are likely to be many profitable I0T niches within the fragmented market, and semiconductor companies will need to identify the most promising ones that represent a fit with their capabilities. The use of a platform approach to cover multiple niches will be important, since R&D costs may otherwise be prohibitive. When companies are selecting the right niches, one of the most important considerations is their own expertise. Semiconductor players that have strong ties to consumer-electronics companies and possesses full-system-integration capabilities might best focus on wearables and smart-home devices, developing silicon, software and algorithms, and device-level designs. They could also potentially provide server-side software, connectivity gateways, and associated infrastructure. By contrast, a company with specific expertise with high-reliability integrated circuits and security might be well suited to provide full IoT solutions for medical applications.
Semiconductor companies are mostly well aware that their chips represent only one small part of the IoT value chain, so they are exploring opportunities in software, the cloud, and other services. But they may also need to consider more radical approaches to improve the value captured, including a shift to new business models. For instance, a move to usage-based pricing would allow semiconductor players to capture revenue for the entire lifetime of a device or service, not just at the time of chip purchase. (This might only be possible if a semiconductor company is willing to provide the full system or partner with a system-level player.) To mitigate risks and avoid moving too far from their core competencies, however, new solutions should be carefully evaluated. The fact that the IoT has many niches will be helpful during the evaluation process, since companies can test solutions in one of them and make necessary adjustments before undertaking a broader rollout.
Operating models focusing on hardware and embedded software helped semiconductor companies thrive in many high-tech segments, but they may not be well suited to I0T customers. For instance, most companies now include a limited number of large business units, a focus on direct sales and field-application engineers, and an emphasis on application-specific R&D programs. A more appropriate organizational structure for the Internet of Things would emphasize a multimarket sales approach and a greater reliance on channel partners, such as distributors, as part of the go-to-market strategy. This arrangement is well suited to the I0T’s fragmented market, which contains very different companies, including many small businesses, with unique needs. Other possible areas for improvement include the following:
R&D. The move from customized chips to a platform approach should occur as soon as possible, but this does not always entail massive internal changes. Instead, companies may be able to license another player’s intellectual property to build a platform—for instance, for image processing—thereby gaining access to new technologies without increasing development costs.
Investments. Rather than making a limited number of large portfolio bets under the direction of a business-unit lead, companies should investigate numerous applications in diverse markets. This approach will help companies avoid the common mistake of allocating most funds to core products, rather than using them to develop new applications.
Change management. If management wants employees to cultivate new capabilities or develop innovative products, they may need to revise their key performance indicators. For example, companies should provide incentives that encourage R&D to develop chip platforms that are appropriate for several verticals, such as connected cars and industrial automation, rather than optimize integrated circuits for a single vertical. Likewise, leaders that want to focus on mergers or other outside alliances must help companies recognize their importance by encouraging such partnerships more aggressively.
Our survey, interviews, and research show that semiconductor executives are optimistic about the Internet of Things and its potential to transform the industry. More important, they recognize its ability to help society as a whole, with one executive calling it “a chance to change and enrich our lives.” The exact form that this change will take is still uncertain, as is the point at which the Internet of Things will be widely adopted. It is clear, however, that the semiconductor sector will play a major role in its ascent. Those companies that take action now, while the Internet of Things is in its early stages, stand to gain the most.In order for IoT to be successful and valued for both companies and consumers, it has to be included as part of a broader information value loop. The graphic above illustrates how its sustainability depends on both parties gaining sufficient value.
Rather than see this value loop as an obstacle, there are limitless opportunities to complete the information value loop with customers. IoT technology is creating opportunities for companies to create and capture this value in unexpected places and ways, including Internet-connected wearable fitness monitors, insurance policies, pill bottles that know when you’ve opened them, retail supply chains, and even tennis racquets. For example, a tennis player doesn’t just value the stiffness of a racquet’s frame, the string tension, and its weight and balance. She might also learn to value it as a source of information about her tennis stroke and how to improve it.
Value capture can also extend to companies in the form of ongoing customer interaction. Smart automobiles now drive off the showroom floor with remote diagnostics and system monitoring capabilities pre-installed. By linking maintenance programming to the dealership, customers are encouraged to return for tune-ups rather than go elsewhere, leading to continued purchases in the long term.
Businesses have some leeway in the give and take of the information value loop depending on the type of data, customer, and industry they are working with. Some areas, such as those included in smart home technologies, face a gridlock of actually aggregating customer data from multiple devices, using it, and applying value for both companies and customers. There are also technological constraints such as interoperability and mismatched technological standards. These complications, not to mention the high cost for adoption and integration, create a barrier for customers to see where the value is for them.
In other industries, like automotive and home insurance, customers have less of a say in how companies use their data. On the opposite side of the coin, some industries such as retail are extremely influenced and potentially restricted by their customers’ say. Marketers should help their companies seek a balance that creates business value while also giving customers, at the very least, a perception of choice and value.
Striking that balance looks different, depending on the industry. Retailers have perhaps tapped into the IoT capabilities of consumer collection with the most enthusiasm—but they are perhaps the most inclined to do so, in an industry where customers have a lot of choice and maintain more power over data sharing. They’ve found balance in the information value loop by offering customers relevant and customized offers and the best available price. The retailer benefits through sales, increased customer satisfaction, gathering more customer data for future shopping encounters, and converting a browser into a buyer—all enabled by the data their customer provided.
On the other hand, for automotive insurance, customers do not have much of a choice in how their data are collected or used by insurance companies. IoT data are more accurate and personalized than the previous forms of data collection used to determine their premium, usually proxy indicators such as credit scores and demographic data, but absent insurers striking a balance in what information they collect and use, customers may potentially still feel violated or out of control of their data, leading to resistance of IoT data collection and hostility toward the company trying to collect it.The Internet of Things (IoT) comprises a rapidly evolving suite of technologies to monitor, compare and act on insights across and within systems that previously operated in digital isolation. Devices now have growing capabilities to communicate with one another, fundamentally changing the way companies run their manufacturing plants, how energy utilities manage demand, and even how families keep their homes safe.
For private companies, the IoT can transform conventional processes, such as supply chain management, into a true competitive advantage. By arming a company’s sourcing, manufacturing and logistics teams with more sophisticated data from IoT-enabled equipment, companies can prevent errors, correct missteps more quickly, identify and alleviate bottlenecks, and ensure they’re not leaving valuable scraps on the factory floor.1
There is incremental opportunity to improve existing systems, such as embedding sensors in baggage and cargo carts at the world’s busiest airports. There is optimization, which can help seaports handle more cargo in a particular location, for instance. There are entirely new business models, such as the case of a major logistics provider that is looking at ways to confirm whether packaged medications already hold certification assurance, which would provide valuable intelligence to both regulators and drug manufacturers.
It’s very easy to get caught up in the hype of the Internet of Things—to chase new gadgets. Instead, we should think about how we actually create value—where should we play and how can we win?
The IoT is revolutionizing the way companies think about information. The increasing arsenal of data on physical objects, employees, customers and other stakeholders can now travel across devices, influence the way people act, and enable a growing range of autonomous actions. While the value of these insights is clear to marketers and product developers, there are concerns regarding stewardship and transparency of the information. Says the University of Chicago economist Richard Thaler, “If a business collects data on consumers electronically, it should provide them with a version of that data that is easy to download and export to another website.”2
Private companies looking at potential avenues for innovation within the IoT also need to stay abreast of privacy rules, as there are times when data cannot be shared at all. For example, the US Health Insurance Portability and Accountability Act (HIPAA) offers protection of medical information collected by health professionals and insurers.3
More broadly, there are challenges in adapting certain ecosystems for an IoT-powered future.4 For technology, media and telecommunications companies, the formerly standalone device is now a potential target for hackers.5 Likewise, dropping sensors into existing systems such as utility meters may expose weak links within older systems with less robust security features. Instead of retrofitting, companies should consider how new technologies specifically equipped for IoT can avoid security lapses.
In addition, there still are no uniform standards governing security and enforcement within the IoT.6 Therefore, it is largely up to business and technology leaders to develop rules to combat security risks in this emergent field.
Despite these concerns, IoT technologies can empower private companies to potentially change lives. The battle against chronic disease is one example. Consider that about half of American adults have one or more chronic health conditions, according to the Centers for Disease Control and Prevention.7 Wearables, monitors and implantable devices can truly maximize their potential when patients and health care providers are able to interpret and use the information they extract from the technology. Potential benefits increase as this ecosystem expands to include payors, but with the trade-off of higher regulatory hurdles, potential risk, and barriers to adoption.
The IoT is helping people modify their own behaviors across a range of activities through social proof, where people feel more confident making decisions that mirror their peers. For instance, one Software-as-a-Service (SaaS) provider is partnering with utility companies to provide graphical- and emoticon-filled alerts on energy usage. Users can see how their consumption compares to that of their neighbors, and even get suggestions on how to cut back on energy costs.8
The IoT is also helping change behaviors in automotive-related industries. The typical car today has 70 computing systems and up to 100 million lines of code.9 To use that data for the collective benefit of motorists, some insurance companies are capturing information and providing peer-to-peer driving comparisons that can ultimately affect premiums.10
Yet another area for opportunity within the IoT is emerging through improvements in supply chain management.11 For example, a large household appliances manufacturer switched to radio frequency identification (RFID) tags to help managers track parts in one of its factories, improving an earlier process that required workers to read paper tags. The company reported that the new system exceeded expectations for ROI through the reduction in cost of the paper tags alone. In another example, shipping companies, for instance, are arming their customers with real-time updates on orders. The tools monitor potential roadblocks such as postal strikes, route closures, natural disasters, and other incidents. Some of the tools can adjust the timing or mode of shipments to minimize the disruption from such events.12
According to a global survey of business leaders, 74 percent of those who implemented initiatives such as sensor-based logistics saw increases in revenue, demonstrating how the IoT can improve efficiency and increase differentiation within supply chains. Some companies are using the sensor-based systems to get around delays, further evidence of the impact of the IoT.13
You can create value in IoT by enhancing the flow of information. You can capture value by controlling the flow of information.
In spite of apparent and often compelling benefits, understanding of the IoT remains uneven. For example, more than one in 10 adult Americans now owns a fitness tracker, demonstrating consumer eagerness to put the power of connected devices to use in their daily lives. However, more than half of US consumers who have owned an activity tracker no longer use it.14
By itself, the IoT is no silver bullet. Private companies can play an important role in exploring how IoT-related technologies can transform the way we work, manage our communities, and play.AI provides the ability to wring insights from IoT data more quickly and accurately than traditional business intelligence tools. Using the two technologies to complement one another can provide significant advantages for businesses, such as:
Predictive maintenance—using analytics to predict equipment failure ahead of time in order to schedule orderly maintenance procedures—can mitigate the damaging economics of unplanned downtime. Because AI technologies can help identify patterns and anomalies, and make predictions based on large sets of data, they are proving to be particularly useful in implementing predictive maintenance.
Predictive maintenance—using analytics to predict equipment failure ahead of time in order to schedule orderly maintenance procedures—can mitigate the damaging economics of unplanned downtime. Because AI technologies can help identify patterns and anomalies, and make predictions based on large sets of data, they are proving to be particularly useful in implementing predictive maintenance. Increasing operational efficiency.
Machine learning can generate fast, precise predictions and deep operational insights. Other AI technologies can automate a growing variety of tasks. Companies such as Hershey and Google have used AI in combination with IoT sensor data to significantly cut operational costs.
Machine learning can generate fast, precise predictions and deep operational insights. Other AI technologies can automate a growing variety of tasks. Companies such as Hershey and Google have used AI in combination with IoT sensor data to significantly cut operational costs. Enabling new and improved products and services.
IoT technology coupled with AI can form the foundation of improved and eventually entirely new products and services. For instance, for GE’s drone and robot-based industrial inspection services, the company is looking to AI to automate both navigation of inspection devices and identification of defects from the data captured by them. This could result in safer, more precise, and up to 25 percent cheaper inspections for the client.
IoT technology coupled with AI can form the foundation of improved and eventually entirely new products and services. For instance, for GE’s drone and robot-based industrial inspection services, the company is looking to AI to automate both navigation of inspection devices and identification of defects from the data captured by them. This could result in safer, more precise, and up to 25 percent cheaper inspections for the client. Enhancing risk management.
A number of applications pairing IoT with AI are helping organizations better understand and predict a variety of risks as well as automate for rapid response, enabling them to better manage worker safety, financial loss, and cyber threats.
For enterprises across industries, AI has the potential to boost the value created by IoT deployments, enabling better offerings and operations to give a competitive edge in business performance.Transportation providers’ customers want more speed, visibility, and customization. Outfitting trucks with IoT sensors was the first step. Next: Companies are moving to create connected ecosystems.
Many companies across industries are feeling the pressure of rising customer expectations for speed, customization, and more1—and looking to their supply chains to meet the new demand. The problem: Most leaders know far less about what’s going on than they would like. Deloitte’s Global chief procurement officer study 2018 found that only 6 percent of organizations have full visibility into their supply chain, and 65 percent of organizations have poor or no visibility beyond their tier-1 suppliers.2
To shed some light on supply chains, transportation providers seem to be embracing Internet of Things (IoT) technologies. The goal is visibility as well as agility—the ability to quickly respond to demand—while ensuring regulatory compliance.
Of course, it’s not as simple as installing a few sensors. Logistics companies are looking to create holistic ecosystems in which the physical and digital worlds are not only constantly exchanging information, but also drive meaningful action. Such a transformation requires moving from a traditional siloed approach to implementing IoT technologies and then to a more holistic, integrated one that aims to manage execution by connecting IoT technologies to traditional systems and other application technologies.3
This article will focus on these IoT-connected ecosystems within transportation and discuss some key strategic considerations for transportation organizations as they strive to successfully design, implement, and operate them in their organizations.
IoT-enabled processes are increasingly common across a range of industries, spurred by the growing availability of cloud storage and faster, more ubiquitous connectivity.4 The global IoT market is forecast to surpass the US$1 trillion mark in 2022,5 and a recent survey suggests that 80 percent of companies expect to adopt IoT technologies over the next five years.6
The transportation industry, for its part, has been moving to incorporate IoT technologies such as telematics hardware and software in trucks, with an estimated spend of US$71 billion in 2019,7 although progress has been uneven. North America has been leading the adoption, with 42 percent of all owned commercial vehicles forecast to have telematics by 2021,8 driven in part by compliance requirements necessitating the use of digital logs equipped with position tracking. Other key markets are quickly catching up, with the penetration for telematics hardware and software forecasted to top 95 percent for all new trucks sold by 2026 in North America, Western Europe, and developed Asia.9 As barriers to implementation fall and deployment proliferates across distinct use cases, the days when IoT-enabled operations offered a competitive advantage in transportation are likely coming to an end.10
More and more, the increased visibility and lower latency provided by IoT systems are becoming table stakes for carriers and others in the logistics space.
Organizations are rapidly adopting digital technologies beyond the IoT, of course. Over the next five years, the adoption rate for robotics and automation could reach 70 percent, with nearly two-thirds of companies deploying predictive analytics and artificial intelligence.11 The growing use of these additional technologies within transportation and logistics creates an opportunity to integrate disparate systems and move to a more advanced stage of digital capability. To truly differentiate and drive value creation for themselves and their customers, transportation providers should embrace the next generation of sensor-based systems: true IoT ecosystems.
Defining an IoT ecosystem An IoT solution consists of sensor networks that generate various types of data that a company can analyze to create insights for making business decisions. An IoT ecosystem links those solutions with other digital tools and technologies to create even greater value for the company and its customers. Today in logistics and distribution, the most relevant technologies for an IoT ecosystem tend to be artificial intelligence (AI), predictive analytics, blockchain, and cloud computing. But the concept of an IoT ecosystem is technology-agnostic: In the future and in other industries, compelling value could be created by integrating edge and quantum computing, augmented reality, and other technologies. Regardless of the specific technologies involved, all elements of the ecosystem work together to ensure the seamless flow of information to action.
To see the power of a truly connected IoT ecosystem, consider the example of connected vehicles. As figure 1 illustrates, today’s connected trucks not only move freight but typically generate vast amounts of data, such as location, engine status (speed, idle time, fuel levels), environmental conditions (temperature, moisture, light exposure), vehicle data (shocks, movement), driver behavior (tiredness, erratic driving patterns), and security (theft, tampering, alarm activations).
Uploading this data from a smart fleet to a cloud-based data system and feeding it into other technologies and transportation processes can support routing, shipment tracking, quality compliance, fleet management, driver performance management, and safety. In an end-to-end IoT-enabled transportation ecosystem, information would flow seamlessly throughout the network creating an information value loop (see figure 2).13
Here, different vehicles’ in-fleet sensors can automatically upload telematics data such as fuel consumption, location, and cargo temperature into connected cloud architectures, which can aggregate the information into structured data sets and feed it into predictive analytics algorithms that leverage AI. The resulting insights on vehicle condition, driver performance, cargo quality, and more, can enable the enterprise’s control center to monitor fleet performance and safety metrics and predict maintenance issues, downtime, cargo problems, and even road accidents. Transportation businesses can utilize these real-time insights to take appropriate action, including route optimization, dynamic scheduling, preventive maintenance, and rapid response in the event of a breakdown or crash.
Terminal operations. With the help of IoT and location tracking technologies such as GPS, terminals (or trucking stations) can get updated information on inbound shipments, such as expected time of docking, shipment quantity, and storage requirements. Combining IoT with AI and predictive analytics enables terminals to use this data intelligently to better plan outbound shipments and manage capacity. Using IoT-enabled dashboards, the terminal can maintain updated metrics on capacity utilization and shipment timing.
Recently, a leading port began testing the use of object detection sensors in order to track cargo-filled trucks lining up at each lane at ports with multilane terminals,15 enabling automated monitoring of congestion at the lane level (see figure 3). This data is uploaded to a cloud-based system. When the congestion threshold—determined using predictive analytics—is breached, a trigger is sent to the controller to redirect and streamline traffic. With the help of an IoT-enabled ecosystem leveraging AI, the port authorities are able to increase lane efficiency, reduce truck turnaround time, and improve operations planning at the terminal.
Transportation safety. Accidents, injuries, ineffective drivers, road safety—and the resulting losses—are some of transportation companies’ most visible and high-risk issues. Relevant technologies in the market focus on improving transportation safety: In-vehicle telematics solutions use accelerometers, trackers, and engine monitors to gather location, fuel consumption, speed, and braking data.16 Aggregated data points are fed to safe-driving analytics applications to monitor digitally calculated safety limits. Connected physical devices (such as mobile phones) provide feedback to drivers and others via alerts when safety thresholds are breached, completing the physical-to-digital-to-physical loop of a complete ecosystem. Analysts expect IoT telematics solutions to reduce both fuel consumption and the cost of incidents and insurance.17
Predictive maintenance. Smart technologies—marrying IoT to safety and maintenance plans within asset management systems—can enable transportation providers to manage asset maintenance holistically.18 Trenitalia has implemented an IoT-enabled solution that uses data-gathering sensors capturing weather conditions and equipment stress in its trains to feed a remote diagnostics platform in real time. Combined with AI and predictive analytics, this can enhance predictive maintenance capabilities to predict impending failures.19 This allows for fixes to be enabled when the asset is being utilized—improving productivity, efficiency, and asset longevity—and is expected to reduce fleet maintenance costs by up to 8 percent.20
Fleet monitoring and routing. The IoT ecosystem enables all points in the network to communicate with each other in real time with integrated communications systems technology. Leveraging low-latency information, a transportation provider can establish a dynamic network that accounts for demand and fleet availability and make real-time decisions regarding fleet routing and management.
For example, for a transporter, an IoT ecosystem consists of connected devices on the on-road fleet, collecting route information and sending constant updates to the cloud. With the effective use of analytics, business owners can take dynamic routing decisions and communicate with the network in real time using integrated communications systems technology.21 In addition to advanced safety and better predictive maintenance, transporters can make use of driver assist technologies to determine conditions suitable for fleet platooning in order to reduce draft and increase fuel efficiency.
DHL’s fleet management solution, SmarTrucking,22 uses sensor-enabled trucks to gather fleet data (location, weather, traffic, and shipment information) and telematics to transmit this data to a centralized control tower. Using predictive analytics, intelligent data science, and onboard diagnostics, the control tower makes real-time decisions on dynamic routing and fleet allocation, resulting in route optimization and efficient fleet scheduling and improved shipment visibility. SmarTrucking is expected to reduce transit times by up to 50 percent and increase real-time tracking reliability to over 95 percent across road networks in India.23
Product life management (cold chain). Traditionally, moving sensitive products through the supply chain (for example, pharmaceuticals or temperature-sensitive food products) has carried a high risk of losses, further magnified by the challenge of measuring these losses during transportation while ensuring compliance with stringent food safety requirements. IoT ecosystems can help improve cold chain transportation efficiency while ensuring product safety and quality—and can pinpoint issues causing product value loss by using analytics on sensor data.24
A leading industry retailer has been testing the use of IoT ecosystems for its cold chain management, with sensors enabling real-time temperature and humidity monitoring during product movement. This enables the company to monitor and distribute products more safely and efficiently and improve delivery quality while lowering loss-based costs and gaining visibility into the cold chain transportation process, with projected annual savings of US$1.3 million in cold chain compliance and asset efficiency.25
IoT ecosystems that stitch together sensor-based data with legacy systems (such as transportation and warehouse management systems) and newer technologies (such as cloud-based storage, AI, and predictive analytics) hold tremendous promise for those engaged in moving goods. And while dreaming big is important, it is just as crucial to understand that mastery takes time. Moving an organization from a world of manual, often paper-based systems to a digitally enabled and fully integrated enterprise happens in steps (see figure 4). In the disconnected state, communication between nodes is manual, with no real-time visibility or traceability. With the addition of tracking and tracing capabilities, the organization is able to quickly detect variations such as delays, breakdowns, and noncompliance. This connected state enables businesses to act on the system’s real-time data. In the integrated state, IoT solutions are used in conjunction with other technologies to predict events and enable real-time dynamic decision-making.
To move up the maturity curve, as with any successful digital transformation, it can be helpful to look at each of three strategic levers: process, people, and technology.
What are your business needs? Assess your current state of operations and identify the gaps between your organization and consumer/industry expectations, by looking at customer metrics and competitors’ technology adoption rates. After aligning on pain points and what you are trying to solve for, identify high-value, target-rich data that is easy to access, available in near-real time, has a large footprint (affecting major parts of the organization or its customer base), and can effect meaningful change in prioritized areas.
What adoption strategy is best suited for your business? Once you have scoped out your needs and goals, chalk out your road map for this journey. Since IoT-driven implementations can be data-heavy, invest your time in understanding the data being collected through IoT technologies and how it can be leveraged by other technologies and processes to create a rich and impactful ecosystem. Use the mantra “Think big, start small, scale fast” to assess your risks and returns while having your goals in mind.
It’s no secret that preparing your talent is a key factor in any successful technological evolution. In a recent Deloitte survey, around 63 percent of the respondents identified hiring and retaining the ideal skilled workforce as the biggest barrier in their respective organization’s transformation.27 Once you have identified the technological requirements (what) for your organization:
Identify your organizational and talent needs (who). Do you need technical resources to support the business? Will you require full-time employees or contractors/partners? Do you need personnel with nontransportation skill sets (analytical, health and safety, etc.)? Think creatively and holistically about what work will need to be done, where, and by whom in the future.
Explore strategies to recruit, retain, manage, and develop those people (how). Recruit the right talent. Invest in the importance of career experience. Create compensation and rewards that are not only competitive among your peers but also among the broader set of employers you may be vying with for talent—including tech companies.28
Most commonly, organizations can run into interoperability problems when overarching, cross-platform, and cross-domain applications are to be built. Given the large number of stakeholders involved, which can include platform and software providers, sensor vendors, developers, and users—not to mention multiple parts of your own organization—setting up an IoT ecosystem requires deep collaboration across the technology stack. Failure can mean lost business opportunities and stifled innovation.29
One effective way for organizations to build their IoT ecosystems is to look for solutions that are specific to your industry and are already rooted in your issues. Solutions that come tailored to industries and sectors are typically able to generate results more quickly than those that have to be reworked to fit your environment.30 For example, transportation companies can look into evolving their current telematics solutions into IoT-enabled ecosystems that can be connected to asset management solutions, resulting in increased asset turns and improved asset safety and security. At the same time, companies should be creative and look into applicable use cases from other industries.
Identify enhancements required to modernize platforms and create an ever-evolving ecosystem in order to harness the power of data to drive smarter, faster decisions.
Look out for potential roadblocks when setting up the information flow (for example, connectivity issues in the communication layer, data volume, and the frequency being transmitted across interfaces).
Leverage scalable solutions through accelerators and aggregators, which can result in eliminating a majority of the development work, hastening ROI, and increasing profitability.
Integrate current frameworks and partner solutions, with data seamlessly flowing through cloud-based solutions.
Technology adoption is an evolutionary process. As logistics and distribution organizations embark on the journey of digital adoption, they should keep in mind these overarching principles:
Focus on the business of IoT, using the technology to create real business value, not just connecting stuff for the sake of connecting stuff. Start with the end in mind.
Logistics and distribution organizations should not stop at embracing digital connectivity. To unlock the full competitive advantage and drive down their operational costs, organizations should think about integrating IoT technologies with automation and analytical capabilities. The advantage to IoT is visibility; the advantages to a connected IoT system are more educated and efficient supply chain decisions that can drive value to the business.
organizations should not stop at embracing digital connectivity. To unlock the full competitive advantage and drive down their operational costs, organizations should think about integrating IoT technologies with automation and analytical capabilities. The advantage to IoT is visibility; the advantages to a connected IoT system are more educated and efficient supply chain decisions that can drive value to the business. Transportation organizations are expected to need to develop alliances and partnerships to be leaders in the years ahead. This will likely require data sharing and a willingness to collaborate to gain higher performance and improved customer service. Companies should choose their partners wisely and leverage their IoT ecosystems to enhance the strength of their networks.
People are critical to your success. Invest in elevating your talent to effectively manage new technologies and processes.Digital has transformed manufacturing over the past decade. The cloud and IoT have helped companies make gains in efficiency and productivity that are nothing short of revolutionary. And the revolution isn't over. In this episode of the podcast, Deloitte's David Linthicum and guests, Deloitte's Subrata Roy and AWS's Michael Garcia, discuss announcements from AWS re:Invent 2019 and Smart Factory Fabric, a new suite of services from Deloitte that enables companies to use IoT and the cloud to reimagine the way they do business. They cover how Smart Factory Fabric works, the expected impact that it will have on manufacturing, and how companies can use Smart Factory Fabric to realize more of what's possible with cloud.
There are several point solutions that are available in the market, but they really do not share the data and the insights that come from each one of them…this product is unique because it brings together people, machines, and materials into one place where you can actually have a full view of your plant and how it is performing.
Subrata Roy is a managing director in Deloitte Consulting LLP's Supply Chain practice focused on AWS. He has 22 years of experience leading large global supply chain digital transformation programs.
Michael Garcia works as a principal product solutions architect at Amazon Web Services where he is part of the IoT (Internet of Things) service team. He helps customers deploy IoT applications while working closely with the IoT service team to improve existing products and launch new ones.​If you love your smartphone's AI-enhanced camera, wait until you find out what edge AI chips could do for enterprise.
Many people may be familiar with the frustration of calling up their smartphone’s speech-to-text function to dictate an email, only to find that it won’t work because the phone isn’t connected to the internet. Now, a new generation of edge artificial intelligence (AI) chips is set to reduce those frustrations by bringing the AI to the device.1
We predict that in 2020, more than 750 million edge AI chips—chips or parts of chips that perform or accelerate machine learning tasks on-device, rather than in a remote data center—will be sold. This number, representing a cool US$2.6 billion in revenue, is more than twice the 300 million edge AI chips Deloitte predicted would sell in 20172—a three-year compound annual growth rate (CAGR) of 36 percent. Further, we predict that the edge AI chip market will continue to grow much more quickly than the overall chip market. By 2024, we expect sales of edge AI chips to exceed 1.5 billion, possibly by a great deal.3 This represents annual unit sales growth of at least 20 percent, more than double the longer-term forecast of 9 percent CAGR for the overall semiconductor industry.4
These edge AI chips will likely find their way into an increasing number of consumer devices, such as high-end smartphones, tablets, smart speakers, and wearables. They will also be used in multiple enterprise markets: robots, cameras, sensors, and other IoT (internet of things) devices in general. Both markets are important. The consumer edge AI chip market is much larger than the enterprise market, but it is likely to grow more slowly, with a CAGR of 18 percent expected between 2020 and 2024. The enterprise edge AI chip market, while much newer—the first commercially available enterprise edge AI chip only launched in 20175—is growing much faster, with a predicted CAGR of 50 percent over the same time frame.
Here, there, and everywhere: The many locations of AI computing Until recently, AI computations have almost all been performed remotely in data centers, on enterprise core appliances, or on telecom edge processors—not locally on devices. This is because AI computations are extremely processor-intensive, requiring hundreds of (traditional) chips of varying types to execute. The hardware’s size, cost, and power drain made it essentially impossible to house AI computing arrays in anything smaller than a footlocker. Now, edge AI chips are changing all that. They are physically smaller, relatively inexpensive, use much less power, and generate much less heat, making it possible to integrate them into handheld devices such as smartphones as well as nonconsumer devices such as robots. By enabling these devices to perform processor-intensive AI computations locally, edge AI chips reduce or eliminate the need to send large amounts of data to a remote location—thereby delivering benefits in usability, speed, and data security and privacy. Of course, not all AI computations have to take place locally. For some applications, sending data to be processed by a remote AI array may be adequate or even preferred—for instance, when there is simply too much data for a device’s edge AI chip to handle. In fact, most of the time, AI will be done in a hybrid fashion: some portion on-device, and some in the cloud. The preferred mix in any given situation will vary depending on exactly what kind of AI processing needs to be done. Figure 1 shows the various locations where AI computing can occur, all of which are likely to coexist for the foreseeable future. The term “telecom edge” deserves some explanation here. Telecom edge compute (also known as telco edge compute)—the “far edge network” depicted in figure 26—refers to computing performed by what are basically mini data centers located as close to the customer as possible, but owned and operated by a telco, and on telco-owned property. They currently use data center–style AI chips (big, expensive, and power-hungry), but they may, over time, start incorporating some of the same kinds of edge AI chips (consumer or enterprise) that we discuss in this chapter. Unlike edge device computing, however, the chips used in telecom edge compute are located at the edge of the telco’s network, not on the actual end device. Further, not all telecom edge computing is AI computing. According to industry analysts, revenues for the telecom edge compute market (all kinds of computing, not just AI) will reach US$21 billion in 2020. This is up more than 100 percent from 2019, and the market is poised to grow more than 50 percent in 2021 as well.7 A precise breakdown of this market by category is not publicly available, but analysts believe that the AI portion will likely be still relatively nascent in 2020, with revenues of no more than US$1 billion, or 5 percent of total telecom edge compute spending.8
In 2020, the consumer device market will likely represent more than 90 percent of the edge AI chip market, both in terms of the numbers sold and their dollar value. The vast majority of these edge AI chips will go into high-end smartphones, which account for more than 70 percent of all consumer edge AI chips currently in use.9 This means that, in 2020 as well as for the next few years, AI chip growth will be driven principally by smartphones: both how many smartphones are sold and what percentage of them contain edge AI chips. In terms of numbers, the news appears to be good. After a weak 2019, which saw smartphone sales decrease by 2.5 percent year over year, smartphones are expected to sell 1.56 billion units in 2020, roughly the same number as in 2018—a 2.8 percent increase.10 We believe that more than a third of this market may have edge AI chips in 2020.
Smartphones aren’t the only devices that use edge AI chips; other device categories—tablets, wearables, smart speakers—contain them as well (figure 3). In the short term, these nonsmartphone devices will likely have much less of an impact on edge AI chip sales than smartphones, either because the market is not growing (as for tablets11) or because it is too small to make a material difference (for instance, smart speakers and wearables combined are expected to sell a mere 125 million units in 202012). However, many wearables and smart speakers depend on edge AI chips, so penetration is already high.
Currently, only the most expensive smartphones—those in the top third of the price distribution—are likely to use edge AI chips. That said, some phones under the US$1,000 price point do contain AI as well. Several AI-equipped phones from Chinese manufacturers, such as Xiaomi’s Mi 9,13 sell for under US$500 in Western countries. Further, as we’ll see below, putting an AI chip in a smartphone doesn’t have to be price-prohibitive for the consumer.
Calculating the cost of a smartphone’s edge AI chip is a roundabout process, but it’s possible to arrive at a fairly sound estimate. The reason one must estimate instead of simply looking up the cost outright is that a smartphone’s “AI chip” is not literally a separate chip unto itself. Inside a modern smartphone, only 7 to 8 millimeters thick, there is no room for multiple discrete chips. Instead, many of the various necessary functions (processing, graphics, memory, connectivity, and now AI) are all contained on the same silicon die, called a system on a chip (SoC) applications processor (AP). The term “AI chip,” if a phone has one, refers to the portion of the overall silicon die that is dedicated to performing or accelerating machine learning calculations. It is made from exactly the same materials as the rest of the chip, using the same processes and tools. It consists of hundreds of millions of standard transistors—but they are arranged in a different way (that is, they have a different architecture) than in the chip’s general processing or graphics portions. The AI portion is commonly, though not always, known as an NPU, or neural processing unit.
To date, three companies—Samsung, Apple, and Huawei—have had images taken of their phone processors that show the naked silicon die with all its features visible, which allows analysts to identify which portions of the chips are used for which functions. A die shot of the chip for Samsung’s Exynos 9820 shows that about 5 percent of the total chip area is dedicated to AI processors.14 Samsung’s cost for the entire SoC AP is estimated at US$70.50, which is the phone’s second-most expensive component (after the display), representing about 17 percent of the device’s total bill of materials.15 Assuming that the AI portion costs the same as the rest of the components on a die-area basis, the Exynos’s edge AI NPU represents roughly 5 percent of the chip’s total cost. This translates into about US$3.50 each.
Similarly, Apple’s A12 Bionic chip dedicates about 7 percent of the die area to machine learning.16 At an estimated US$72 for the whole processor,17 this suggests a cost of US$5.10 for the edge AI portion. The Huawei Kirin 970 chip, estimated to cost the manufacturer US$52.50,18 dedicates 2.1 percent of the die to the NPU,19 suggesting a cost of US$1.10. (Die area is not the only way to measure what percent of a chip’s total cost goes toward AI, however. According to Huawei, the Kirin 970’s NPU has 150 million transistors, representing 2.7 percent of the chip’s total of 5.5 billion transistors. This would suggest a slightly higher NPU cost of US$1.42.)20
Although this cost range is wide, it may be reasonable to assume that NPUs cost an average of US$3.50 per chip. Multiplied by half a billion smartphones (not to mention tablets, speakers, and wearables), that makes for a large market, despite the low price per chip. More importantly, at an average cost of US$3.50 to the manufacturer, and a probable minimum of US$1, adding a dedicated edge AI NPU to smartphone processing chips starts looking like a no-brainer. Assuming normal markup, adding US$1 to the manufacturing cost translates into only US$2 more for the end customer. This means that NPUs and their attendant benefits—a better camera, offline voice assistance, and so on—can be put into even a US$250 smartphone for less than a 1 percent price increase.
Companies that manufacture smartphones (and other device types) can take different approaches to obtaining edge AI chips, with the decision driven by factors including phone model and (sometimes) geography. Some buy AP/modem chips from third-party companies that specialize in making and selling them to phone makers, but do not make their own phones. Qualcomm and MediaTek are two prominent examples; combined, these two companies captured roughly 60 percent of the smartphone SoC chip market in 2018.21 Both Qualcomm and MediaTek offer a range of SoCs at various prices; while not all of them include an edge AI chip, the higher-end offerings (including Qualcomm’s Snapdragon 845 and 855 and MediaTek’s Helio P60) usually do. At the other end of the scale, Apple does not use external AP chips at all: It designs and uses its own SoC processors such as the A11, A12, and A13 Bionic chips, all of which have edge AI.22 Still, other device makers, such as Samsung and Huawei, use a hybrid strategy, buying some SoCs from merchant market silicon suppliers and using their own chips (such as Samsung’s Exynos 9820 and Huawei’s Kirin 970/980) for the rest.
What do edge AI chips do? Perhaps the better question is, what don’t they do? Machine learning today underlies all sorts of capabilities, including but not limited to, biometrics, facial detection and recognition, anything to do with augmented and virtual reality, fun image filters, voice recognition, language translation, voice assistance … and photos, photos, photos. From hiding our wrinkles to applying 3D effects to enabling incredibly low-light photography, edge AI hardware and software—not the lens or the sensor’s number of megapixels—are now what differentiates the best smartphone cameras from the rest. Although all these tasks can be done on processors without an edge AI chip, or even in the cloud, they work much better, run much faster, and use less power (thereby improving battery life) when performed by an edge AI chip. Keeping the processing on the device is also better in terms of privacy and security; personal information that never leaves a phone cannot be intercepted or misused. And when the edge AI chip is on the phone, it can do all these things even when not connected to a network.
If the edge AI processors used in smartphones and other devices are so great, why not use them for enterprise applications too? This has, in fact, already happened for some use cases, such as for some autonomous drones. Equipped with a smartphone SoC AP, a drone is capable of performing navigation and obstacle avoidance in real time and completely on-device, with no network connection at all.23
However, a chip that is optimized for a smartphone or tablet is not the right choice for many enterprise or industrial applications. The situation is analogous to what chip manufacturers faced in the 1980s with central processing units (CPUs). In the 1980s, personal computers (PCs) had excellent CPUs; their high computational power and flexibility made them ideal for such a general-purpose tool. But it made no sense to use those same CPUs to put just a bit of intelligence into (say) a thermostat. Back then, CPUs were too big to fit inside a thermostat housing; they used far too much power, and at roughly US$200 per CPU, they cost too much for a device whose total cost needed to be less than US$20. To address these shortcomings, an entire industry developed to manufacture chips that had some of the functions of a computer CPU, but were smaller, cheaper, and less power-hungry.
But wait. As discussed earlier, the edge AI portion of a smartphone SoC is only about 5 percent of the total area, about US$3.50 of the total cost, and would use about 95 percent less power than the whole SoC does. What if someone built a chip that had only the edge AI portion (along with a few other required functions such as memory) that cost less, used less electricity, and was smaller?
Some already have—and more are coming. Intel and Google, for instance, are currently selling internally developed standalone edge AI chips to developers. Nvidia, the leading manufacturer of graphics processing units (GPUs) commonly used in accelerating data center AI—which are very large, use hundreds of watts of electricity, and can cost thousands of dollars—now sells a customized AI-specific chip (that is not a GPU) suitable for edge devices that is smaller, cheaper, and less power-hungry.24 Qualcomm, the leading maker of merchant market SoCs with embedded edge AI processing cores for smartphones and other consumer devices, has released two standalone edge AI chips that are less powerful than its SoCs, but that are cheaper, smaller, and use less electricity.25 Huawei is doing the same.26
In all, as many as 50 different companies are said to be working on AI accelerators of various kinds.27 In addition to those working on application-specific integrated circuit (ASIC) chips, field-programmable gate array (FPGA) manufacturers now offer edge AI chip versions for use outside data centers.28
The standalone edge AI chips available in 2019 were targeted at developers, who would buy them one at a time for around US$80 each. In volumes of thousands or millions, these chips will likely cost device manufacturers much less to buy: some as little as US$1 (or possibly even less), some in the tens of dollars. We are, for now, assuming an average cost of around US$3.50, using the smartphone edge AI chip as a proxy.
Besides being relatively inexpensive, standalone edge AI processors have the advantage of being small. Some are small enough to fit on a USB stick; the largest is on a board about the size of a credit card. They are also relatively low power, drawing between 1 to 10 watts. For comparison, a data center cluster (albeit a very powerful one) of 16 GPUs and two CPUs costs US$400,000, weighs 350 pounds, and consumes 10,000 watts of power.29
With chips such as these in the works, edge AI can open many new possibilities for enterprises, particularly with regard to IoT applications. Using edge AI chips, companies can greatly increase their ability to analyze—not just collect—data from connected devices and convert this analysis into action, while avoiding the cost, complexity, and security challenges of sending huge amounts of data into the cloud. Issues that AI chips can help address include:
Data security and privacy. Collecting, storing, and moving data to the cloud inevitably exposes an organization to cybersecurity and privacy threats, even when companies are vigilant about data protection. This immensely important risk is becoming even more critical to address as time goes on. Regulations about personally identifiable information are emerging across jurisdictions, and consumers are becoming more cognizant of the data enterprises collect, with 80 percent of them saying that they don’t feel that companies are doing all they can to protect consumer privacy.30 Some devices, such as smart speakers, are starting to be used in settings such as hospitals,31 where patient privacy is regulated even more stringently.
By allowing large amounts of data to be processed locally, edge AI chips can reduce the risk of personal or enterprise data being intercepted or misused. Security cameras with machine learning processing, for instance, can reduce privacy risks by analyzing the video to determine which segments of the video are relevant, and sending only those to the cloud. Machine learning chips can also recognize a broader range of voice commands, so that less audio needs to be analyzed in the cloud. More accurate speech recognition can deliver the additional bonus of helping smart speakers detect the “wake word” more accurately, preventing it from listening to unrelated conversation.
Low connectivity. A device must be connected for data to be processed in the cloud. In some cases, however, connecting the device is impractical. Take drones as an example. Maintaining connectivity with a drone can be difficult depending on where they operate, and both the connection itself and uploading data to the cloud can reduce battery life. In New South Wales, Australia, drones with embedded machine learning patrol beaches to keep swimmers safe. They can identify swimmers who have been taken by riptides, or warn swimmers of sharks and crocodiles before an attack, all without an internet connection.32
(Too) big data. IoT devices can generate huge amounts of data. For example, an Airbus A-350 jet has over 6,000 sensors and generates 2.5 terabytes of data each day it flies.33 Globally, security cameras create about 2,500 petabytes of data per day.34 Sending all this data to the cloud for storage and analysis is costly and complex. Putting machine learning processors on the endpoints, whether sensors or cameras, can solve this problem. Cameras, for example, could be equipped with vision processing units (VPUs), low-power SoC processors specialized for analyzing or preprocessing digital images. With edge AI chips embedded, a device can analyze data in real time, transmit only what is relevant for further analysis in the cloud, and “forget” the rest, reducing the cost of storage and bandwidth.
Power constraints. Low-power machine learning chips can allow even devices with small batteries to perform AI computations without undue power drain. For instance, ARM chips are being embedded in respiratory inhalers to analyze data, such as inhalation lung capacity and the flow of medicine into the lungs. The AI analysis is performed on the inhaler, and the results are then sent to a smartphone app, helping health care professionals to develop personalized care for asthma patients.35 In addition to the low-power edge AI NPUs currently available, tech companies are working to develop “tiny machine learning”: Deep learning on devices as small as microcontroller units (which are similar to the SoCs mentioned earlier, but smaller, less sophisticated, and much lower power, drawing only milliwatts or even microwatts). Google, for instance, is developing a version of TensorFlow Lite that can enable microcontrollers to analyze data, condensing what needs to be sent off-chip into a few bytes.36
Low latency requirements. Whether over a wired or wireless network, performing AI computations at a remote data center means a round-trip latency of at least 1–2 milliseconds in the best case, and tens or even hundreds of milliseconds in the worst case. Performing AI on-device using an edge AI chip would reduce that to nanoseconds—critical for uses where the device must collect, process, and act upon data virtually instantaneously. Autonomous vehicles, for instance, must collect and process huge amounts of data from computer vision systems to identify objects, as well as from the sensors that control the vehicle’s functions. They must then convert this data into decisions immediately—when to turn, brake, or accelerate—in order to operate safely. To do this, autonomous vehicles must process much of the data they collect in the vehicle itself. (Today’s autonomous vehicles use a variety of chips for this purpose, including standard GPUs as well as edge AI chips.) Low latency is also important for robots, and it will become more so as robots emerge from factory settings to work alongside people.37
The difference between training and inference, and what it could mean for data center–based AI The AI enabled by an edge AI chip is more properly known as deep machine learning, which has two components. The first component is training. Training involves repeatedly analyzing a large amount of historical data, detecting patterns in that data, and generating an algorithm for that kind of pattern detection. The second component is inference. In inference, the algorithm generated by training—often updated or modified over time through further training—is used to analyze new data and produce useful results. Until recently, machine learning software used the same standard chips—a mix of CPUs, GPUs, FPGAs, and ASICs—for all their training and inference. These chips are all large, expensive, power-hungry, and produce a lot of heat; consequently, AI hardware built on these chips is always housed in a data center. In contrast, the edge AI chips discussed in this chapter perform mainly (or only) inferencing, using algorithms that were developed by training back in a data center. Although some edge AI chips do training as well, most training still occurs in data centers. Interestingly, although data center chips have historically been used for both training and inference, we are now seeing the development of different flavors of data center chips, with some optimized for training and some for inference.38 The implications of this relatively new development are not yet clear. But it is possible that, due to the emergence of edge AI chips, data centers will see their current mix of training and inference processing shift toward more training and less inferencing over time. If this happens, these more specialized data center chips could be especially useful for flexibility, allowing a data center that sees its ratio of training to inferencing shifting to change its hardware mix accordingly.
Who will benefit from the edge AI chip market’s growth? Obviously, it’s good for the companies that make edge AI chips. From essentially zero a few years ago, they will earn more than US$2.5 billion in “new” revenue in 2020, with a 20 percent growth rate for the next few years, and likely with industry-comparable margins. But that number should be placed in context. With 2020 global semiconductor industry revenue projected at US$425 billion,39 edge AI chips make up too small a fraction of that to move the needle for the industry as a whole, or even for its larger individual companies.
In truth, the bigger beneficiaries are likely those who need AI on the device. Edge AI chips can not only enormously improve the capabilities of existing devices, but also allow for entirely new kinds of devices with new abilities and markets. Over the longer term, edge AI chips’ more transformative impact will most probably come from the latter.
Will companies that make AI chips for data centers be harmed as some of the processing (mainly inferencing at first) moves from the core to the edge? The answer is uncertain. All of the companies that make data center AI chips are also making edge versions of these chips, so the shift in processing from the core to the edge may have little or no net effect. Also, demand for AI processing is growing so quickly that its rising tide may lift all boats: The AI chip industry (edge and data center combined) is expected to grow from about US$6 billion in 2018 to more than $90 billion in 2025, a 45 percent CAGR.40 A more likely potential negative is that the emergence of cheaper, smaller, lower-power edge AI chips may exert downward pressure on data center AI chip pricing, if not units. This has happened before: In the semiconductor industry’s history, the spread of edge processing chips frequently caused prices for mainframe/core processing hardware to fall faster than would have been expected based only on improvements according to Moore’s Law.
Some might also think that moving AI processing from the core to the edge will hurt cloud AI companies. This is unlikely: Recent forecasts for the cloud AI or AI-as-a-Service market predict that its revenues will grow from US$2 billion in 2018 to nearly US$12 billion by 2024, a 34 percent CAGR.41 Perhaps that growth would be even larger if edge AI chips did not exist, but it still means that cloud AI is growing twice as quickly as the overall cloud market, with a predicted CAGR of 18 percent to 2023.42
Equally, some might fear that if edge devices can perform AI inference locally, then the need to connect them will go away. Again, this likely will not happen. Those edge devices will still need to communicate with the network core—to send data for AI training, to receive updated AI algorithms for inference, and for many other reasons. For these reasons, we expect that all or almost all edge AI devices will be connected.
The nature of that connection, however, may be different than what was expected only two to three years ago. At that time, AI inference was restricted to large data centers, meaning that smart IoT devices had to be connected to access those AI inference capabilities—and not just to any old network, but one with ultra-high speeds, guaranteed quality of service, high connection densities, and the lowest possible latency. These attributes were (and still are) only to be found on 5G wireless networks. The natural assumption, therefore, was that all IoT devices that used AI would also need to use 5G, and only 5G.
That assumption no longer holds. If a device can handle a significant amount of AI processing locally, it doesn’t eliminate the need for a connection of some sort, but the connection may not always need to be through 5G. 5G will still be necessary some of the time, of course. And the 5G market is poised to grow enormously, at a 55 percent CAGR—more than US$6 billion annually—through 2025.43 But thanks to edge AI chips, the market opportunity in 5G IoT may be slightly smaller than was expected a few years ago.
The spread of edge AI chips will likely drive significant changes for consumers and enterprises alike. For consumers, edge AI chips can make possible a plethora of features—from unlocking their phone, to having a conversation with its voice assistant, to taking mind-blowing photos under extremely difficult conditions—that previously only worked with an internet connection, if at all. But in the long term, edge AI chips’ greater impact may come from their use in enterprise, where they can enable companies to take their IoT applications to a whole new level. Smart machines powered by AI chips could help expand existing markets, threaten incumbents, and shift how profits are divided in industries such as manufacturing, construction, logistics, agriculture, and energy.44 The ability to collect, interpret, and immediately act on vast amounts of data is critical for many of the data-heavy applications that futurists see as becoming widespread: video monitoring, virtual reality, autonomous drones and vehicles, and more. That future, in large part, depends on what edge AI chips make possible: Bringing the intelligence to the device.Email* Single Sign-On non disponibile per Internet Explorer 11 e Microsoft Edge Per nome e cognome non sono ammessi caratteri specialiIncorporating Internet of Things technology into products and services can represent quite an undertaking: There's a world of sensors and networking technology, plus legacy IT systems that must be integrated. How to get everything up and running quickly? Some companies are turning to bundled IoT systems.
The effort to deploy an Internet of Things (IoT) solution can be massive: Developing and deploying enterprise-grade IoT solutions may involve thousands of sensors, disparate networking and communication technologies, and integration with legacy IT systems. An emerging trend is taking aim at this complexity, however. Vendors are working to meet demand with IoT solutions that bundle and pre-integrate sensors, analytics, a sensor management and data ingestion platform, and user interface tools—and increasingly offering them as a service. While enterprises still need to configure and integrate these bundled solutions with legacy systems, these offerings help streamline the complexity and accelerate ROI for IoT projects.
Venture capital investments in bundled IoT solutions providers increased 85 percent in 2015 versus the prior year, totaling $2.2 billion and accounting for 61 percent of total IoT venture funding.1
Several large technology companies, including Amazon,2 IBM, Microsoft,3 and Hitachi,4 launched bundled IoT solutions within the past year.
Telecom companies, including AT&T,5 Rogers,6 and Verizon,7 are also introducing bundled IoT solutions.
Dozens of enterprises across sectors, such as online8 and offline9 retail, insurance,10 and consumer products,11 have deployed bundled IoT solutions over the last 12–18 months.
Architecting an IoT solution can be daunting, requiring the architect to select from among: hundreds of different types of sensors and devices, at least a dozen commercially available IoT integration platforms, multiple networking technologies, and various communications protocols. The architect then needs to integrate the solution with legacy IT systems and business intelligence tools. (For more of Deloitte’s thinking on IoT technology and applications, see the Deloitte University Press collection of articles at http://dupress.com/collection/internet-of-things.)
Buying and integrating these technologies is only part of the challenge: Conceptualizing the use cases and architecting solutions requires expertise in multiple technology domains to pilot and iterate until successful. Maintaining these systems means additional capital and operating expenditure commitments. For companies looking to deploy IoT applications, realizing ROI can seem risky and a long way off. It makes sense, therefore, that enterprises would welcome solutions that eliminate much of this complexity.
These challenges have created an opportunity for technology vendors, which are increasingly bringing bundled solutions to market. Systems integrators, too, have an opportunity to help enterprises connect those bundled solutions with legacy systems to enhance the level of business insights or achieve greater automation.
What do you get when you buy a bundled IoT solution? Vendors pre-integrate sensors, a sensor management and data ingestion platform, analytics, and user interface tools to work together. This reduces the time, effort, and costs of identifying, developing, and integrating individual technology components. And it reduces the time required to realize value from the deployment. The technology components may be sold directly to the client, but increasingly vendors are offering as-a-service models.
Note that even comprehensive IoT bundles aren’t exactly turnkey solutions: Getting optimal value from bundled solutions may require additional systems integration. This could include ingesting data from internal or external sources and combining these with sensor data to generate better insights. Or it could mean using the insights to take actions such as controlling machines or automatically generating trouble tickets when a threshold is breached. Some change management may also be required to properly embed the new solutions within the organization and ensure that people are using them effectively.
VCs have invested in bundled IoT technology for the last few years.12 But support has expanded dramatically recently, increasing 85 percent in 2015 over 2014, to an annual total of $2.2 billion. To capitalize on the growing importance of bundled solutions, some IoT technology vendors are changing their go-to-market strategies, pivoting from offering technologies to pre-integrated IoT solutions with as-a-service or pay-as-you-go payment models. The idea is to appeal to enterprises that prefer to pay for outcomes rather than technology.13
For example, Airware, a drone software company that raised $39 million in 2016, recently changed its strategy to include hardware, offering a bundled solution on a subscription basis.14 Enlightened, an energy-management-as-a-service provider, offers clients the option of sharing energy savings over a defined period in lieu of deployment costs.15
Some vendors are also incorporating connectivity into their bundled solutions. This makes it easier for enterprises by eliminating the need to negotiate separate connectivity contracts with telcos. For example, Enevo, a Finland-based waste-management-as-a-service provider, bundles connectivity from Finnish telecom operator DNA. Some 145 customers in 35 countries are already deploying Enevo’s solutions, according to the company.16
A review of bundled IoT use cases and vendors shows these solutions to be broadly applicable across sectors. Some are “horizontal” solutions for cross-industry issues such as energy management, supply chain monitoring, and predictive maintenance. Others target specific industries such as health care, retail, industrial, and automotive.
Revenue improvements, by improving customer experience (retail in-store customer navigation, real-time promotions and discounts), creating new services (medication adherence, equipment-as-a-service), or reducing stock-outs (supply chain, reordering services)
Cost reductions, via improved visibility into operations (switching off machines and equipment when not in use, managing capacity, collecting waste only when required), supply chain efficiencies (reducing inventory and spoilage), and cutting overhead expenses (reducing energy usage)
Asset utilization improvements, by reducing downtime (predictive maintenance on equipment), better load management (through better scheduling), and adding tracking (location tagging on expensive, movable equipment)
Vendors generally offer bundled solutions to handle processes that are not considered core competencies (for example, energy management or predictive maintenance on machinery) or to enhance a core capability such as claims processing in home insurance through use of drones. But, as with fully custom solutions, bundled solutions can be employed to differentiate a company from its competitors. For instance, solutions are available to retailers to improve customers’ in-store experience; vehicle monitoring insight solutions enable insurance companies to offer usage-based insurance.
The potential benefits of bundled IoT solutions are clear: faster implementation with less effort and more rapid ROI than either in-house development or piecing together solutions from multiple component vendors. But as always, outsourcing technology carries risks, and companies evaluating bundled IoT solutions need to consider a number of issues:
Data governance and security. As bundled IoT vendors enable new ways of capturing and using data17—think of insurance companies using data shared by smart home service providers to factor risk—enterprises must exhibit extra caution and lay down strong data governance and security policies to ensure safe storage and fair usage.
Risk mitigation. As with any significant IT purchase, buyers should plan ahead to cover the eventuality that a bundled IoT vendor could go bust or get bought—or that the CIO may want to switch to a different or better technology someday. Consider engaging providers that use open standards and publish their data models to retain access to data; failing that, contract for the right to the code in case the vendor goes bust, and for continuity of service in case the firm is acquired.
Competitive advantage. Develop custom analytics on top of bundled solutions and embed them into key decision-making processes to create differentiated, semi-custom solutions. When developing new services or capabilities, enterprises may want to explore including clauses to protect the IP and restrict bundled IoT vendors from replicating or developing similar products or capabilities with competitors.
The growing importance of bundled IoT solutions has implications for specific types of companies as well:
Technology and telecommunications companies may want to explore partnering with or acquiring vendors in order to offer bundled IoT solutions that promise to deliver specific outcomes—for instance, lower stock-outs in retail through intelligent sales tracking and automated reordering. Verizon partnered with rfXcel to launch the Verizon Intelligent Track and Trace solution for pharmaceutical companies; IBM acquired the Weather Company, then launched a weather insights service for insurance providers. Offering new business models for bundled IoT solutions, with low upfront investments along with flexible payment options, can also help drive adoption and create recurring revenue streams.
IoT start-ups should evaluate the opportunity of either creating bundled solutions or becoming part of one. Not only are VCs channeling ever more funds toward these solutions—enterprises are likely to show increased willingness to buy bundled IoT solutions to get going faster and at lower risk.
As has been widely noted, the Internet of Things has the potential to create enormous business value. But this rapidly evolving domain, still short on standards and long on complexity, presents obstacles that cause some enterprises to delay adoption. The emergence and proliferation of bundled solutions present an opportunity for enterprises to pursue the benefits of IoT technology with less complexity and lower risk.The COVID-19 pandemic has wreaked havoc on the economy, no doubt, but it has provided opportunities for companies to modernize their business infrastructure (in some cases just to survive), and therefore, accelerate their cloud adoption. That accelerated adoption is underway. Cloud spending increased by 11% in Q2 2020 over the same period last year.1 Companies that move quickly to follow the cloud adoption trend will have the opportunity to rethink how they operate—and to reshape their business to use cloud as a competitive differentiator.
That reshaping starts with companies moving forward in their cloud journeys from deciding on a horizontal multicloud strategy to building a vertical (full-stack) multicloud solution. Companies must also rethink their security posture—especially vis-à-vis what needs to change in a remote-centric, cloud-centric working environment that will test infrastructure security across a more distributed network. Finally, companies must also embrace new development operations and ways of working—to get applications, and new releases, into production faster and with flexibility given tremendous uncertainty. To do this, organizations will have to coordinate across business and technology leadership to implement effective business transformation with sound technology, security, and operations strategies.
Most medium-to-large organizations have at least a nascent cloud strategy, and some companies are already well on their way in implementing it. They’ve selected their cloud providers, determined which workloads to migrate, and started to understand interoperability issues. For those who haven’t started down the path, the road is paved.
It’s time to put those strategies into action. The next challenge for companies looking to thrive, not just survive, in a post–COVID-19 world will be to manage cloud complexity and build on their strategic foundation by configuring the appropriate tools, software, and technology to deliver and manage an IT infrastructure to power the future.
Build common data services with a single virtual database or by managing data in a distributed way. Develop multicloud solutions that focus on access, network management, operations, and endpoint complexity for a full-stack solution. Extend CloudOps to include AIOps, which goes beyond reactive monitoring to automated response.
Companies that take these steps could see significant benefits, such as the elimination of operational redundancies, improved insights into their data, and enhanced ability to govern that data. They could also achieve more flexible IT resource consumption models and more effectively manage costs.
Because the pandemic has forced companies to abandon physical infrastructure and embrace remote work and distributed infrastructures, security concerns become obsolete in some areas and heightened in others. To address shifting security concerns, companies must change the way they approach security to implement a more federated model across distributed work infrastructures. They must:
Manage federated computing infrastructures down to the endpoint level across tiers and devices (cloud, edge, mobile, IoT).
Use embedded, zero-anonymity security features, multifactor authentication, and privileged access management.
Look to replace perimeter-level security with device-level security; embrace virtualization and remote IoT devices; and secure every component of their environment, including object repositories, network segmentation, and web services.
Shift from single-vendor IM solutions to integrated, federated IM solutions to fully leverage cloud providers’ technology.
Those companies that embrace federated security will be able to increase their situational awareness, better manage attack vectors, and enable more dynamic threat intelligence and remediation. They will also be able to manage their security across an ever-shifting threat surface area. With this comes improved system interoperability, collaboration, and information-sharing.
Security isn’t the only concern in managing a newly distributed workforce and workplace. Companies that migrate to the cloud will need to find new ways of working—especially in terms of core infrastructure and application development to remove development bottlenecks and get new releases out faster.
For many companies, DevOps is one solution. DevOps encourages better communication and collaboration, and when combined with cloud, it is a force multiplier that enables companies to better meet performance demands and customer satisfaction goals. However, when implementing DevOps, companies must focus just as much on the cultural change required to live by DevOps principles as on the technology behind it.
Foster improved communication and collaboration across project teams, departments, and organizations.
Reimagine traditional roles and embrace an IT-as-a-service operating model with cloud architects who understand business as well as technology.
With effective DevOps, companies can align development activities better across full-stack product teams. This will help them react and respond quickly and focus on work that provides tangible, quick value. Development teams can also share knowledge in real time to enable better organizational knowledge management with automated, standardized, and repeatable processes that speed up development, free up workers to focus on more value-added activities, and enhance governance and the end-customer experience.
There will be a postpandemic world. It won’t be anything like the world that came before it, but that actually presents tremendous opportunities for companies that tackle its challenges successfully with technology-enabled business transformation to support the future of work. To meet those challenges, companies must double down on their technology modernization strategies and focus on building full-stack, cloud-enabled business solutions that are secure and enable collaboration and cohesion, no matter the location or device. They must embrace new ways of working that enable faster, better application development to be able to shift developer strategies as business needs change. Those companies that can navigate these layers of cloud complexity will modernize their businesses and most likely thrive. For those that don’t, if they are able to survive, infrastructure modernization will remain a future obstacle, with an even wider competitive gap to tackle.
If you’d like to read more about the future of the cloud-enabled work infrastructure, check out this new Deloitte Insights piece here.
1 Angus Loten, “Cloud spending hits record amid economic fallout from COVID-19,” Wall Street Journal, August 3, 2020.In the oil and gas industry, the promise of IoT applications lies not with managing existing assets, supply chains, or customer relationships but, rather, in creating new value in information about these. An integrated deployment strategy is key for O&G companies looking to find value in IoT technology.
After years of high and rising oil prices led to a longstanding oil price of more than $100 per barrel, new extraction technologies have opened up fresh sources of supply that suggest a new price equilibrium of $20 to $30 less per barrel.1,2 This new normal of lower oil prices not only will lay bare inefficient oil and gas (O&G) companies but will push even the efficient ones to find ways to preserve their top and bottom lines. Luckily for the O&G industry, a new suite of technologies promises to help companies tackle these challenges.
The Internet of Things (IoT), which basically integrates sensing, communications, and analytics capabilities, has been simmering for a while. But it is ready to boil over, as the core enabling technologies have improved to the point that its widespread adoption seems likely. The IoT’s promise lies not in helping O&G companies directly manage their existing assets, supply chains, or customer relationships—rather, IoT technology creates an entirely new asset: information about these elements of their businesses.
In an industry as diverse as O&G, it is no surprise that there is no one-size-fits-all IoT solution. But there are three business objectives relevant to IoT deployments in the O&G industry: improving reliability, optimizing operations, and creating new value. Each O&G segment can find the greatest benefit from its initial IoT efforts in one of these categories, which are enabled by new sources of information. With this in mind, this article provides segment-level perspectives, aimed at helping companies understand how information creates value, the impediments to value creation and how they can be addressed effectively, and how companies can position themselves to capture their fair share of that value.3
Upstream companies (e.g., exploration and production) focused on optimization can gain new operational insights by analyzing diverse sets of physics, non-physics, and cross-disciplinary data. Midstream companies (e.g., transportation, such as pipelines and storage) eyeing higher network integrity and new commercial opportunities will tend to find significant benefit by building a data-enabled infrastructure. Downstream players (e.g., petroleum products refiners and retailers) should see the most promising opportunities in revenue generation by expanding their visibility into the hydrocarbon supply chain and targeting digital consumers through new forms of connected marketing.
The new period of much lower prices is taking hold in the O&G industry, which is putting heavily indebted O&G companies on credit-rating agencies’ watchlists and derailing the capital-expenditure and distribution plans of even the most efficient ones.4 Addressing this structural weakness in oil prices requires more than financial adjustments. It demands a change in the industry’s approach to technology: from using operational technologies to locate and exploit complex resources, to using information from technologies to make hydrocarbon extraction and every successive stage before sale more efficient and even revenue-generating.
Enabling this shift to information-based value creation are the falling costs and increasing functionality of sensors, the availability of advanced wireless networks, and more powerful and ubiquitous computer power, which have collectively opened the floodgates for the amount of data that the industry can swiftly collect and analyze. Sensor prices have tumbled to about 40 cents from $2 in 2006, with bandwidth costs a small fraction of those even five years ago, helping the industry amass individual data sets that are generating petabytes of data.5,6
The industry is hardly resistant to adopting these new technologies. During the past five decades, it has developed or applied an array of cutting-edge advances, including geophones, robots, satellites, and advanced workflow solutions. However, these technologies primarily function at an asset level, or they are not integrated across disciplines or do not incorporate business information. According to MIT Sloan Management Review and Deloitte’s 2015 global study of digital business, the O&G industry’s digital maturity is among the lowest, at 4.68 on a scale of 1 to 10, with 1 being least mature and 10 being most mature. “Less digitally mature organizations tend to focus on individual technologies and have strategies that are decidedly operational in focus,” according to the study.7
O&G companies can reap considerable value by developing an integrated IoT strategy with an aim to transform the business. It has been estimated that only 1 percent of the information gathered is being made available to O&G decision makers.8 Increased data capture and analysis can likely save millions of dollars by eliminating as many as half of a company’s unplanned well outages and boosting crude output by as much as 10 percent over a two-year period.9 In fact, IoT applications in O&G can literally influence global GDP. Industry-wide adoption of IoT technology could increase global GDP by as much as 0.8 percent, or $816 billion during the next decade, according to Oxford Economics.10
Deploying technology does not automatically create economic value. To do so, companies must link IoT deployments, like any technology deployment, with specific business priorities, which can be described, broadly, using three categories of increasing scope. In the narrowest sense, companies seek to minimize the risks to health, safety, and environment by reducing disruptions (improving reliability). Next, companies seek to improve the cost and capital efficiency of operations by increasing productivity and optimizing the supply chain (optimizing operations). At the largest scope, companies seek to explore new sources of revenue and competitive advantage that transform the business (creating new value) (see figure 1).
Upstream players have together taken great strides in enhancing their operations’ safety, especially in the five years since the Macondo incident.11,12,13 Although technologies will continue to play an important role in improving the safety record of exploration and production (E&P) firms, lower oil prices are driving companies to place a higher business priority on optimization where IoT applications are relatively immature. Improving operational efficiency is more complex than ever given the increased diversity of the resource base being developed: conventional onshore and shallow water, deepwater, shale oil and gas, and oil sands.
The midstream segment traditionally has been a stable business connecting established demand and supply centers. Not any longer: The rise of US shale has altered the supply-demand dynamics—including the growing exports of liquids and natural gas—and increased midstream companies’ business complexity. To effectively serve this newly found growth and increased dynamism in the business, midstream companies are focusing on maintaining and optimizing their networks, a priority for which technology exists but that midstream companies have yet to fully integrate across their full network of pipelines and associated infrastructure.
By contrast, downstream players are relatively mature in monitoring risks and optimizing operations because of their standardized operations and long history of automation and process-control systems. But slowing demand growth worldwide, rising competition from new refineries in the Middle East and Asia, and changing and volatile feedstock and product markets are pressuring downstream players to explore new areas of optimization and extend their value beyond the refinery.
Regardless of the business priority served by new sources of data, the way in which the resulting information creates value can be understood using a common analytical framework: the Information Value Loop (see page 6). It is the flow of this information around this loop that creates value, and the magnitude of the information, the risk associated with that flow, and the time it takes to complete a circuit determine the value that is created. Organizations should design IoT deployments to create a flow of information around the value loop most relevant to a given business priority. Impediments to that flow can be thought of as bottlenecks in the value loop, and so a key challenge to realizing the value of any IoT deployment is correctly identifying and effectively addressing any bottlenecks that materialize.
The suite of technologies that enables the Internet of Things promises to turn most any object into a source of information about that object. This creates both a new way to differentiate products and services and a new source of value that can be managed in its own right. Realizing the IoT’s full potential motivates a framework that captures the series and sequence of activities by which organizations create value from information: the Information Value Loop.
For information to complete the loop and create value, it passes through the loop’s stages, each enabled by specific technologies. An act is monitored by a sensor that creates information, that information passes through a network so that it can be communicated, and standards—be they technical, legal, regulatory, or social—allow that information to be aggregated across time and space. Augmented intelligence is a generic term meant to capture all manner of analytical support, collectively used to analyze information. The loop is completed via augmented behavior technologies that either enable automated autonomous action or shape human decisions in a manner leading to improved action.
Getting information around the Value Loop allows an organization to create value; how much value is created is a function of the value drivers, which capture the characteristics of the information that makes its way around the value loop. The drivers of information value can be captured and sorted into the three categories: magnitude, risk, and time.
The fall in crude prices and the push to optimize operations come as E&P players face a period of rising technical and operational complexity. Players are placing more equipment on the seabed and developing systems that are able to operate at pressures of 20,000 pounds per square inch and withstand temperatures of up to 350°F particularly in deepwater; increasing downhole intensity and above-ground activity in shales; moving to hostile and remote locations where safety is key; and producing from old fields that have significant maintenance needs.14
This increased complexity, when captured with the tens of thousands of new sensors now deployed, has driven a data explosion in the E&P segment; by some estimates, internal data generated by large integrated O&G companies now exceed 1.5 terabytes a day.15 This data surge, however, has yet to generate the hoped-for economic benefits. “The upstream industry loses $8 billion dollars per year in non-productive time (NPT) as engineers spend 70 percent of their time searching for and manipulating data,” according to Teradata.16
On the one hand, the growing scale and frequency of hydrocarbon reservoirs data (or physics-based data that follow established scientific principles) are challenging E&P companies’ data-processing capabilities. On the other hand, the rising need to expand the scope of data (inclusion of non-physics-based data independent of scientific principles that add assumptions, conditions, uncertainties, and scenarios and cross-disciplinary data that cut across exploration, development, and production) is restricted by companies’ weak data-management capabilities. “Ample opportunities exists for upstream oil and gas companies to improve performance via advanced analytics, but weak information management is inhibiting the progress for many,” according to Gartner.17
Companies are struggling to alleviate these bottlenecks, in large part due to a lack of open standards that is limiting the flow of data at the aggregate stage and thus analysis. For example, a company operating several thousand gas wells in the Piceance basin in Colorado wanted to upgrade its supervisory control and data acquisition system to manage growing complexity in operations. As the system was using a vendor-proprietary data-communications format, the new vendor had to write a new driver from scratch to communicate with the old system, costing $180,000 to the operator.18 In some cases, not even this sort of additional investment is enough, and data flow comes to a standstill, choking process flows as well. To eliminate such costs across the industry, users, vendors, and industry councils (e.g., the Standards Leadership Council) could collaborate to create open standards, enabling compatibility and interoperability.
In addition, oilfield service (OFS) companies could play a larger role in standardizing and integrating data. Their deep understanding of physics-based data and long history of working with data-management and IT service providers position them well to play a de facto standardizing role in the industry’s value loop. Building on this expertise might allow OFS companies to create a new revenue stream and help them fend off advances from IT service providers that are beginning to vertically integrate and market their developed OFS capabilities directly to E&P companies.19
Delivering insights from aggregated data may have no value if those insights get to decision makers late or if the data overload a company’s infrastructure. The data explosion—coupled with bandwidth challenges—increasingly calls for a complementary, localized data-processing infrastructure that pre-processes information closer to where it is generated and transmits only selective data to the cloud. While moving network intelligence closer to the source has broader uses, it is well suited for remote locations that generate terabytes of data and demand predictable latency.
No matter what data-processing architecture a company erects, it must analyze that data if it is to optimize existing operations and, more importantly, to identify new areas of performance improvement. For E&P companies, the analysis of standardized data will likely most affect production, followed by development and exploration. By some projections, IoT applications could reduce production and lifting costs by more than $500 million of a large O&G integrated company with annual production of 270 million barrels.20 For example:
Production: The opportunity to automate thousands of wells spread across regions (a large company handles more than 50,000 wells) and monitor multiple pieces of equipment per well (a single pump failure can cost $100,000 to $300,000 a day in lost production) makes production the biggest potential O&G beneficiary of IoT applications. 21
The opportunity to automate thousands of wells spread across regions (a large company handles more than 50,000 wells) and monitor multiple pieces of equipment per well (a single pump failure can cost $100,000 to $300,000 a day in lost production) makes production the biggest potential O&G beneficiary of IoT applications. Development: Smart sensors, machine-to-machine connections, and big data analytics can increase active rig time, while a connected supply chain dependent on networked mobility and big data can reduce cost inflation and delays in new projects.
Smart sensors, machine-to-machine connections, and big data analytics can increase active rig time, while a connected supply chain dependent on networked mobility and big data can reduce cost inflation and delays in new projects. Exploration: Advancements in seismic data acquisition (4D, micro-seismic) and computing power have already improved E&P companies’ understanding of subsurface geology by providing more and better data about what lies beneath.22 However, still greater opportunity lies in faster processing of existing seismic data and transforming them into surface models.
Beyond the technical advantages, if common data standards are able to integrate diverse sets of data, companies can likely gain insights into previously invisible aspects of operations and adjust how they make decisions. For example, analytics applied to a variety of physics-based data at once—seismic, drilling, and production data—could help reservoir engineers map changes in reservoirs over time and provide insights for production engineers making changes in lifting methods.23 Similarly, a company could generate savings by analyzing the non-physics-based data, such as the impact that choices made during a well’s development phase would have on the design and effectiveness of production decisions.
For example, Apache Corp., a large US E&P company, in collaboration with an analytics software firm, not only improved the performance of its electrical submersible pumps (ESPs) but also developed the ability to predict a field’s production capacity in three steps. The first step used hybrid and multi-disciplinary data about pumps, production, completion, and subsurface characteristics to predict submersible-pump failure with prescriptions to avoid future failures. The second step enabled Apache to use the additional data generated in the first stage to prescribe the optimal pump configuration for the next well. The third step helped the company to use these additional ESP performance data to evaluate fields’ potential production capacity before acquiring them.24
This “compounding effect,” in which one level of data analytics provides insights that can then lead to additional analytics, promises to give E&P companies new operational insights that simply were never before available or visible.
Since the start of the US shale boom, pipeline companies have seen their business shift from a simple business model—transporting limited grades of liquids and natural gas between fixed supply and demand centers—to a complex and more dynamic model of transporting variable volumes and grades of products from multiple locations to new end users and markets.
This rising business complexity—combined with aging pipeline networks, legacy and manual monitoring and control devices, and the ongoing challenge of service differentiation—presents both challenges and opportunities for midstream companies. With annual losses of approximately $10 billion due to fuel leaks and thefts in the United States alone,25 companies face considerable upside in improving pipeline safety and reliability.
Installing more operational hardware and software with limited pre-defined tags (e.g., pressure, temperature, volume, vibration) and following rules-based approaches (e.g., statistical, historical) would likely do little to reduce risks or improve a network’s reliability. What may be needed is a shift toward data-enabled infrastructure—in other words, getting started on the Information Value Loop by investing in sensors that create new data. “Midstream energy companies lag far behind what other industries invest in information technology,” according to Oil and Gas Monitor.26
Enbridge, TransCanada, and PG&E, for example, are relieving this bottleneck by creating data about potential pipeline breaches from advanced sensors installed inside or outside the pipeline. TransCanada and Enbridge are testing four technologies that essentially see, feel, smell, and hear various aspects of their oil pipelines: vapor-sensing tubes that “see” bitumen spilled by shooting air down a tube; a fiber-optic distributed temperature sensing system that “feels” fluctuations in temperature caused by bitumen leaking into ambient soil; hydrocarbon sensing cables that send electric signals to “smell” hydrocarbons; and a fiber-optic distributed acoustic sensing system that “hears” sound variations and can indicate a pipeline leak.27,28
PG&E, along with research institutions and government agencies, is testing many non-invasive, three-dimensional (3D) imaging technologies such as the 3D toolbox, first developed for the dental industry, which accurately identifies and measures dents, cracks, and corrosion on the pipeline’s outer surface. The system automatically collects and feeds images into calculation tools to generate an assessment within minutes, helping engineers to put together a corrective-action plan immediately. Similarly, PG&E is adapting NASA’s airborne laser-based system for methane leak detection, in which leaks’ GPS coordinates are automatically stored and the data captured can be correlated with variables such as temperature, time, and pipeline configuration for improved monitoring and control.29
Enhancing pipeline safety is in all players’ interest, since a spill by any single operator can lead to higher costs and tighter regulations for the entire industry. As a result, companies are joining forces in developing a data-enabled monitoring infrastructure. Thus, the industry-wide benefit of this collaboration outweighs any single company’s competitive or commercial advantage. Ensuring safety and minimizing risks are table stakes—to truly differentiate itself in the midstream segment, a company often must go further.
In fact, a midstream company would likely accrue a larger competitive and commercial advantage if it analyzes product and flow data more comprehensively all along its network— similar to the way US electric companies are analyzing energy data using smart devices and meters. According to some estimates, every 150,000 miles of pipeline generates 10 terabytes of data, an amount of data equal to the entire printed collection of the Library of Congress.30
The “midstream majors” are well positioned to create insights from this new data of volumes because of their diverse portfolio and integrated network.31 A big midstream company can leverage the data across its pipelines, helping shippers find the best paths to market and charging them differently for having route optionality in contracts. Forecasting algorithms on historic volumes transported can reveal ways in which a midstream major might use pricing incentives that induce producers and end users to smooth volumes.32 Similarly, a real-time analysis of changing volumes across its network of shale plays can alert the company to new price differentials.
The pipeline data, when combined with growing data from an expanding network of export facilities, markets, marine terminals, and product grades in a timely manner, can give rise to a data-equipped midstream enterprise. “Forward-thinking, innovative midstream organizations can take advantage of the unprecedented volume of new types of data. Emerging types of data, such as machine and sensor data, geolocation data, weather data, and log data become valuable at high volumes, especially when correlated against other data sets,” according to Hortonworks.33
Crude-oil refining is a mature business with few recent innovations in processing technology. This, and the highly commoditized nature of petroleum products, make refining the most commercially challenging part of the energy value chain. Consequently, refiners worldwide have traditionally focused on running refineries as efficiently as possible and seeking to increase the yield of higher-value products.
Avoiding shutdowns is a critical part of increasing refinery output. Between 2009 and 2013, there were more than 2,200 unscheduled refinery shutdowns in the United States alone, an average of 1.3 incidents per day.34 These shutdowns cost global process industries 5 percent of their total production, equivalent to $20 billion per year.35 Ineffective maintenance practices also result in unscheduled downtime that costs global refiners on average an additional $60 billion per year in operating costs.36
Typically, refiners schedule maintenance turnarounds for the entire refinery or for individual units on a pre-set schedule to allow coordination of inspection and repair activities and to plan for alternative product-supply arrangements. For individual components, refiners routinely pull devices into the workshop for inspection and overhaul, without much information about a particular device’s expected condition, perhaps wasting efforts on devices that need not be repaired. But now non-intrusive smart devices (sensors), advanced wireless mesh networks (network), open communication protocols (standards), and integrated device and asset-management analytics (augmented intelligence) are driving a shift away from time-based preventive planning to condition-based predictive maintenance strategies.
For example, a crude unit of Phillips 66 was subject to preheat train fouling (accumulation of unwanted material reducing plant equipment’s efficiency). There were no data to quantify how much energy was being lost, or which exchangers to clean or when to clean them. Using wireless temperature and flow-measurement sensors, the refiner was able to predict the health of exchangers by correlating these measurements with production and environmental data. Such integrated analytics helped the refiner quickly spot where and when energy loss could exceed the target, providing estimated annual savings of $55,000 per exchanger. Most importantly, it helped the refiner identify periods of best performance and define best practices by comparing the performance of exchangers across units, which in turn allowed the company to improve performance across the plant.37
This seems like a fairly straightforward example of deploying sensors to create new data and generate value. Despite many similar examples, why have so few refiners thus far failed to fully capitalize on these sorts of IoT-enabled improvements? In many instances, data capture and analytics, or the flow of information, mostly happens at an asset level or, to some extent, at an overall plant level. What has been less common is analysis of data across the system (including pre- and post- links in logistics and distribution) and, moreover, across the ecosystem (adding external variables such as consumer profile and behavior, etc.) (see figure 2).
Optimizing the supply chain by streamlining the planning and scheduling process is one aspect where IT service providers’ automated software and hardware solutions have already made significant inroads. Using the visibility into the fully hydrocarbon supply chain as a system for enhancing refining operations and flexibility is another aspect—integrated information can help create and capture new value for refiners. This, in particular, may make sense for US refiners, which are fast changing their crude sourcing strategy from mostly buying medium and heavy crude under long-term contracts (following a typical supply-chain process) to buying a greater range of light, medium, and heavy crude blends in the spot market (requiring greater supply-chain dynamism to reap benefits).
One US refiner, for example, wanted to properly value its future crude purchases, especially cheap crude available for immediate purchase on the spot market. However, the refiner had limited data on future operating and maintenance costs for the various crudes it processes and buys—varying sulfur and bitumen content in a crude can lead to additional operating and maintenance expense that could nullify the price benefit. The refiner first installed pervasive sensors on refinery equipment, which allowed it to gather data on the impact of processing various crudes. Once collected and analyzed, the data from the sensors was then integrated with market data on crudes (cargo availability, price, grade, etc.) on a central hub, allowing the refiner to effectively bid for its future crude cargoes in a timely manner.38
This analysis, if extended and combined with information on variations in oil delivery times, dock and pipeline availability, storage and inventory levels, and so on (scope), could help the refiner come up with several what-if scenarios, making its crude sourcing more dynamic and competitive.
Changing issues of efficiency and handling data don’t stop at the inbound logistics of crude-oil sourcing—there’s the outbound logistics of product distribution to consider. The distribution ecosystem includes not only refining and marketing companies but the customers to which they sell. The rapid innovation and proliferation of consumer personal-communication technologies—smart handheld devices and telematics systems in a vehicle—have led to the emergence of connected consumers who, by extension, are demanding a connected fueling experience. So how should fuels retailers think about competing in a digitally enabled consumer’s world?
Automotive companies, with a head start on IoT-based connected applications, provide telling clues. Toyota, for example, has developed, with SAP and VeriFone, a prototype solution that simplifies a driver’s fueling experience.39 Currently, drivers need to deal with multiple systems to find the “right” gas station—locating the station, swiping the card, punching in a memorized PIN, and, if required, keeping a record of receipts. The prototype is aimed at providing consumers a one-touch, one-screen solution that can aggregate information on a vehicle’s location, route, and, most importantly, fuel level using the SAP HANA cloud platform and Bluetooth Low Energy wireless standard; the system aims to navigate the driver to the closest “enrolled” gas station, authorize an automatic payment using VeriFone’s point-of-sale solution, and send personalized coupons and offers.
At this level, the challenges faced by companies are large and not entirely technical. While data can be brought together and displayed using existing communication and telematics, the greatest bottleneck is in getting consumers to act. The interface must be designed as augmented behavior complementing natural human decision processes or it risks being rejected by consumers as “dictatorial,” “creepy,” or “distracting.” Beyond mere technical challenges, designing such a system involves deep insight into human behavior.
However, if a company is able to design a workable and secure system, the benefits may be immense. At a minimum, fuels retailers can boost sales of their gas stations and convenience stores by partnering or, at least, enrolling in such connected-car prototypes. At a next level, they can add more appeal to their traditional loyalty and reward programs, which aim to incentivize customers by offering discounts or redeemable points. The use of collected customer information in running analytics is minimal or constrained by limited buying behavior data of any individual customer at pumps and linked convenience stores; aggregating data promises more useful information.
The future of retail marketing can correlate consumer profiles with fuel purchases and in-store purchases across a retailer’s owned stations and franchisees, mash up existing petro-cards data with the data collected by cloud-enabled emerging telematics solutions, and combine data from multiple sources such as status updates and notifications from social-media networks to facilitate behavioral marketing and predictive analytics. By industry estimates, about 33 percent of IoT-derived benefits for an integrated refiner/marketer can come from connected marketing.40
Facing the new normal of lower oil prices, the O&G industry is beginning to see the IoT’s importance to future success. But it’s not as simple as adding more sensors: Creating and capturing value from IoT applications requires clearly identifying primary business objectives before implementing IoT technology, ascertaining new sources of information, and clearing bottlenecks that limit the flow of information (see table 1).
Upstream players focused on optimization can gain new operational insights by standardizing the aggregated physics and non-physics data and running integrated analytics across the functions (exploration, development, and production).
the aggregated physics and non-physics data and running integrated analytics across the functions (exploration, development, and production). Midstream players targeting higher network integrity and new commercial opportunities can benefit by investing in sensors that touch every aspect of their facilities and analyzing volume data more comprehensively all along their network.
that touch every aspect of their facilities and analyzing volume data more comprehensively all along their network. Downstream players operating at an ecosystem level can create new value by expanding their visibility into the complete hydrocarbon supply chain to enhance core refining economics and targeting new digital consumers through new forms of connected marketing.
Investing in IoT applications is just one aspect. Companies need to closely monitor IoT deployments and results to keep applications on track, at least in the initial few years. Both IT and C-suite executives must regularly ask and answer questions as to whether the IoT is creating the necessary momentum and learning across the businesses and employees, what the future costs and complexities associated with retrofitting and interoperability of applications are, and what the security shortcomings are in light of new developments.
For a given company, IoT applications’ self vs. shared development will determine the time to commercialization and the magnitude of realizable benefits. Building proprietary capabilities, although essential for competitive advantage in some cases, can slow down the pace of development and restrict a company to realize the IoT’s transformative benefits. “We can’t do all of this [development of technology] alone. We believe that in the future we will have to be far more collaborative,” said BP Chief Operating Officer James Dupree.41 Collaborative business models can enable the industry not only to address current challenges but also to take the intelligence from fuels to a molecular level and extend the IoT’s reach from cost optimization to capital efficiency and mega-project management in the long term.42
By reinforcing the importance of information for all aspects of the business and elevating information to the boardroom agenda, a company can fundamentally change how it does business rather than just optimizing what it has always done (see figure 3).
Deloitte’s Internet of Things practice enables organizations to identify where the IoT can potentially create value in their industry and develop strategies to capture that value, utilizing IoT for operational benefit.​
To learn more about Deloitte’s IoT practice, visit http://www2.deloitte.com/us/en/pages/technology-media-and-telecommunications/topics/the-internet-of-things.html.
Read more of our research and thought leadership on the IoT at http://dupress.com/collection/internet-of-things/.In the airline industry, the focus on costs rarely wavers and the pace is constantly demanding. However, the ability to network exponential technologies continues to offer a rich potential to improve productivity, derive additional utilization from assets, and lower costs. Airlines need more than another hard-won half a percentage point. They need a game-changer.
The IoT—networks of sensor-equipped, intelligent, exponential technologies that can gather data, interpret it, and take action—may be that game-changer. By streamlining repetitive processes and making people more efficient, IoT can help transform cost-saving from an incremental struggle to a wide-open frontier.
This is already starting to happen. Two-thirds of surveyed airline leaders believe IoT offers clear benefits right now, 86 percent expect identifiable benefits within three years, and 37 percent have begun to explore and implement IoT improvements as a way to confront rising costs. What these first movers are finding is that an investment in smart devices is only part of the puzzle. They must also plan carefully for the architecture that links data, decision, and action into a self-driving loop.It is no surprise then that drone-based InsurTechs have garnered a lot of attention as well as investment dollars from venture capitalists and insurers alike. As many as eight deals were announced in 2018, totaling more than $145 million. Seven out of the eight deals were either later-stage or follow-on rounds of funding, a trend consistent with the one we identified in our recent report, "InsurTech entering its second wave," that investors have started leaning towards more established entities over new InsurTechs.2
This also signals increasing budgetary commitment by insurers to drones as an innovation. As noted by my colleagues Akash Tayal and Nikhilesh Ramani in their report, "Insurance industry drone use is flying higher and farther," with applications spanning the entire insurance value chain,3 many large carriers that piloted the technology in the last two to three years have started ramping up their investments.
The Travelers Companies, which launched its drone program in 2016 to support claims inspection, has completed more than 17,000 drone flights across 48 states4 and employs almost 600 claims professionals who double as FAA-certified drone pilots5, making it one of the largest commercial drone users across all industries in the US. Similarly, Allstate, which began testing drones for property claims in late 2015,6 settled approximately 12,600 claims in 2017 and about 16,500 claims in the first half of 2018 using drones.7
In September 2018, the federal aviation regulator for the first time granted State Farm permission to fly drones over populated areas beyond visual line of sight (BVLOS) in four states to survey losses from Hurricane Florence.8 While it was a one-off approval, BVLOS flights represent the potential for greater drone-driven automation and operational efficiencies in the future.Mastering the development in IoT is a critical challenge for many enterprises. The enablement to connect sensors and devices to vast mass amount of data as well as its analysis to innovate processes and business models is crucial for entrepreneurial success. In the discussion how to make IoT profitable, the focus is rather on data analytics. But: The extraction of strategic and operative relevant data is only one part. Barely recognized and underestimated are functionality and costs of the hardware components, which enable connectivity between sensors and devices.
The core component of every connected sensor or device is the incorporated chip set or more precisely, the functional design of the chip set, the intellectual property cores (IP-cores). Consequently, IP-Cores can be seen as the blue prints of IoT sensors or platforms that allow to define elements like data processing, storage or security.
Besides the technical dimension, there is also a market perspective. For decades, a few commercial intellectual property vendors dominated the market for IP-cores. Since 2010, the open source movement is increasingly changing this market, especially the RISC-V initiative. Both perspectives will be examined in more detail.
IP-cores are pre-fabricated, tested and a partially verified function block of a chip design. They are the basis for new chip designs or integrated into chip designs of other manufacturers. These modular components bring IoT to life since they enable sensors and micro controllers to collect and analyze data. For example, the average smartphone has 14 sensors that detect everything from external temperature to movement. Combined with a micro controller it is possible to give the data an IoT value.
But simple data collection and analysis is not enough. With the growing importance of real-time data analysis and the increasing amount of collected data you need high performing IoT processors to handle the increasing complexity. Moreover, since IoT devices are portable to a large extend power efficiency is also important.
Security is the third big issue that needs to be addressed in the context of IoT. With IP-cores it is possible to embed security features into the hardware by adjusting the hardware source code. This is a highly critical topic for the success of IoT. For example, in November 2017 Intel had to announce a security breach in the management engine (firmware) of their CPUs.
As mentioned before, IP-cores are modular functional blueprints that can be integrated into chip and micro controller designs. The core business model is based on licensing IP-core blueprints for chip manufacturers like Intel, AMD, or Nvidia. The licensing model is done by very specialized IP-vendors like ARM or MIPS. One reason why the market for IP-cores was dominated by a view companies for serval years.
This strong dependency and their lock-on standards raise the desire for an open source approach in order to reduce costs and licensing fees, increase the customization of IoT device functionality and to accelerate IoT diffusion by prototyping. Market players are hoping for an open source movement similar to the development of the open source software industry. Here, the industry changed from a technology-based industry to a service-oriented one. The core of the business model is no longer the source code, i.e. the program itself and its sale, but the services around the software, such as consulting, customer specification, support and maintenance.
The open source movement started 5-10 years ago for hardware development with open source IP-cores around 2010. This movement increases the efficiency and security of embedded micro controllers and it could enhances IoT usage. For example, many manufacturing companies are struggling with the implementation of IIoT use cases because of security concerns, since micro controllers have limited storage and functionality. An open source development of the MIT enables the transmission of the IoT standard security protocol “Datagram Transport Layer Security” (DTLS) to a DTLS protocol controller. In this way, memory capacity has been saved and security has been increased via integration into a chip set.
One of the main drivers of the Open Source IP Core movement is the RISC-V initiative. The open instruction set architecture (ISA) is licensed (Berkeley Software Distribution License). Thus, the open source ISA can be used by anyone to develop or update an open source IP without fee and the duty to republish the new development. Key players like Sifive or Western Digital are already using the RISC-V ISA or are developing respective devices. E.g, Sifive developed the first 64-bit quadcore SoC based on the free instruction set RISC-V. Western Digital also plans to create processors and micro controllers based on RISC-V architecture.
From a future perspective, open source IP will enable the development of customized System-on-a-Chip designs that can perform tasks that are more complex. This can be used in fixed (ASIC) as well as programmable (FPGA) chip sets. A company that is already on this way is CEVA. CEVA uses open source IP-cores in Wifi-boards and Bluetooth chips.
Also, the graphic processing unit manufacturer (GPU) Nvidia gives open access to its general-purpose graphics processing units (GUGUPs) the accelerate the deep learning development for self-driving cars, robots and other high-end autonomous platforms.
Open source IP-cores can improve the collaboration between IoT sensors and embedded micro controllers to drive the right data from the collected data.
Performance and functionality of processors can be customized to the IoT device application. Security components can be adjusted and incorporated into hardware source code. This important issue concerns many companies and industries while implementing Industrial IoT. An open source IP-core approach that addresses these concerns is the DTLS protocol controller developed by the Massachusetts Institute of Technology (MIT). The DTLS protocol controller is a transmission of the IoT standard protocol “Datagram Transport Layer Security” (DTLS). This open source controller can be directly integrated into the chipset and does not need a security software plug-in.
In summary, IP-cores can be the driver for the mass diffusion of IoT. The open source approach is speeding up this change.In order to get value from the Internet of Things (IoT), it helps to have a platform on which to create and manage applications, to run analytics, and to store and secure your data. Like an operating system for a laptop, a platform does a lot of things in the background that makes life easier and less expensive for developers, managers, and users.
In many mature markets, there are often two dominant platform choices and a long tail of smaller players; for example, iOS and Android in mobile, Windows and Mac OS in desktop operating systems, and PlayStation and Xbox in gaming. But not in IoT, not yet. In IoT, sometimes it seems like there may be more platforms than things. Search Crunchbase for venture-funded IoT platforms, and you will get well over 100 hits. And that list doesn’t include many bigger technology players entering the market with IoT platforms like Microsoft, IBM, and SAP or several industrial companies with similar aspirations like GE, Bosch, and Siemens.
There are IoT platforms of every shape and size. There are platforms for specific industries like commercial real estate and family health. Some focus on one type of device: for example, there are at least two platforms focused on augmented-reality headsets. Some are focused on a particular function, like manufacturing. There is an IoT platform for dogs.
Businesses and developers have a bewildering array of platform options to choose from, which may have very different capabilities. The term “platform” is overused to the point where it doesn’t convey much information beyond “more assembly required.”
Most broadly, a platform is software and hardware, which may include an operating environment, storage, computing power, security, development tools, and many other common functions. Platforms are designed to support many smaller application programs that actually solve business problems.
Platforms are helpful because they abstract a lot of common functions away from the specific application logic. For example, regardless of whether you are trying to write an application to optimize fuel consumption or classroom space, a lot of the underlying technology needs are essentially the same. Application developers just want to focus on the specific problem they are solving and use common capabilities for computing power or storage or security. A good platform dramatically reduces the cost of developing and maintaining applications.
In the Internet of Things, platforms are designed to deploy applications that monitor, manage, and control connected devices (Exhibit 1). IoT platforms must handle problems like connecting and extracting data from a potentially vast number and variety of endpoints, which are sometimes in inconvenient locations with spotty connectivity.
Exhibit 1 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Why so many platforms? Look at successful software platforms like Windows for operating systems. Platforms make a lot of money and are high-margin franchises that endure for decades. People and companies don’t switch platforms very often. Often, switching costs are significant and platform choices persist for many years.
As a result, many start-ups aspire to become platforms, because the winners create enormous shareholder value. Their investors push them to market themselves as platforms because winning platform companies can create 100-fold returns.
There are two main problems with this strategy. First, platform companies aren’t as focused on direct customer business value as application companies. A pure-play platform alone won’t solve a business problem; an application is still needed. The platform’s value proposition is harder to explain to business leaders. This translates into a higher cost of sales.
The second problem is that there can only be a small handful of winners in each platform space. Application developers don’t want to learn multiple platforms. Businesses and consumers don’t want to use and pay for multiple platforms. If there are 100 IoT platforms, then there is no platform, just aspirants. The market, over time, decides who the winners are, and the providers consolidate around two or three leaders.
Today, there is no one-size-fits-all best platform for every application. It may be years before the market anoints the winners in the IoT platform derby.
In the meantime, choosing a platform should start with a good understanding of your IoT strategy. Identify the kinds of problems you are trying to solve, get a short list of likely solutions and use cases, and try to determine where you will need specialization and depth. If you have an idea of what kind of business problem you are solving and where the biggest challenges are, you’ll be able to quickly come to a short list of platforms (Exhibit 2).
Exhibit 2 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Avoid the temptation to select a platform simply because it has a particularly interesting initial use case. This would be like choosing a game console because it included a cool game in the box. Included applications matter but are only part of one element of a platform strategy. We have identified the top five characteristics of IoT platforms on which to base an evaluation. While these five are not an exhaustive list, they are the areas most likely to differentiate platforms in an important and sustainable way.
There are three main application considerations when choosing a platform: what applications are available out of the box, what is the application-development environment like, and what are the common enterprise-application interfaces. Many platforms will include one or more applications that may be of some value out of the box, like the stock market or weather apps that ship with iPhones. Sometimes, very simple applications are the most popular. One manufacturing executive once told us, “I’d be thrilled to have an app that just told me what machines were on my factory floor and if they are switched on or off.”
However, you may need to develop sophisticated IoT apps yourself. Platform providers don’t understand your business problems the same way you do. Confirm that the application-development environment included in the platform is compatible with your own developers, or your trusted development partner. Make sure the development environment supports a way to “containerize” applications using a common service so that they can be ported to another platform should you decide to switch. Finally, you may need your platform to interface with large enterprise applications, like common customer-relationship-management or enterprise-resource-planning suites. Some platforms may include connectivity to popular CRM or ERP suites, and this may be an important feature depending on your IoT use cases.
Often, 80 percent of a data scientist’s time is spent combining, formatting, cleaning, and processing data to get it ready for analysis. Other companies have created new roles for data engineers, whose main job is to curate and cultivate data sources. Some platforms contain shortcuts or special tools that allow you to build a robust model of your important data much faster, reducing people costs and time to market significantly. Indeed there are some highly regarded platform companies that specialize in just this capability and use off-the-shelf technology for the other parts of the platform. Apart from the ability to conceptualize the data and understand what it is, also important is the ability of a platform to handle and manage a large number of high-velocity data streams coming from multiple different sources. The ability to handle vast, fast data may be critical, and there are some specialized technologies that focus only on that. Some are being licensed into different platforms.
Big IoT platform providers tend to also offer their own cloud hardware infrastructure (including storage, compute, networking, and data centers). For example, Amazon and Microsoft both provide a software-platform layer with IoT services, as well as a hardware-infrastructure layer that is broadly applicable across public cloud applications. The hardware infrastructure layer is capital intensive, has high fixed costs and significant economies of scale, and tends toward commoditization over time. As a result, most smaller platform players avoid offering it, providing only the software layer. They certify their platform on one or more of the leading public cloud providers. Many of the nascent platform companies may not be certified on all the major cloud providers (and often may run on only one of them). This is relevant for enterprises that may be seeking to standardize on a particular public cloud solution for other reasons. Make sure your IoT platform provider and your broader enterprise cloud strategy are compatible.
You may be content to have your data stored in the public cloud anywhere in the world with standard encryption. Or, it may be that for security or regulatory reasons, your data must be on your premises. Perhaps your data can be in the public cloud but only within certain political boundaries. You may have specific security requirements, either in the cloud or on your remote devices. There may be certain kinds of encryption, access management, or authentication that are required. Blockchain support may or may not be required. IoT platform capabilities vary here. Some are distinctive in certain areas of security.
It is one thing to have a platform that takes data from your things and pipes it all up to the cloud for analysis by humans. It’s another thing to run the analytics at the edge. Sometimes, the communications overhead of moving data to the cloud is onerous; transmitting terabytes of data from a remote mine or a ship at sea to the cloud could be prohibitive. Some platforms have specialized capability in handling this. Sometimes local autonomy is needed; some platforms allow you to take the human out of the loop and allow the platform to autonomously change the behavior of the connected endpoints or shift data only at convenient times. Moving applications from the cloud to the edge, and potentially allowing them to adjust operating variables like fuel flow or direction or temperature, may be a requirement.
To get value from IoT across multiple use cases, it helps to use one (and only one) platform in your organization. The IoT platform market is immature and there are over 150 options to choose from. As this market consolidates, try to find a partner who is either large and will be in it for the long run or highly focused, distinctive, and successful in solving your most difficult problems. Look at the whole technology environment, not just the applications. Your most important requirement may be data wrangling, security, or local automation. Use fungible/off-the-shelf technology for the things that are less critical.
Choosing a platform is an important decision, because whether it is game consoles, smartphones, or the Internet of Things, it’s likely that whatever platform you choose will be with you for a long time.The observation that the Internet of Things encompasses people holds a number of transformative business and societal implications. The data and information flows that continually emanate from people and devices can be aggregated and analyzed to create fundamentally new types of products and services that go with the grain of human psychology.
“We don’t even know what it is yet. We don’t know what it is. We don’t know what it can be, we don’t know what it will be, we know that it is cool.”
The protean inventor Nikola Tesla once made a prediction that must have seemed as fanciful to his Victorian contemporaries as the science fiction of the day. He wrote: “When wireless is fully applied, the Earth will be converted into a huge brain, capable of response in every one of its parts.”2
Today—a century and a digital revolution or two later—there is a sense in which Tesla’s “global brain” is becoming an actuality. Though the Internet is often discussed in terms of aspects of the world entering “virtual reality,” an opposing dynamic is increasingly at play. The Internet is also expanding into the real world thanks to the availability of such inexpensive technologies as wirelessly connected sensors, triggers, actuators, RFID tags, GPS locators, accelerometers, and even printed QR (quick response) codes.3 Everyday objects are therefore increasingly becoming components of the emerging entity known as the Internet of Things (IoT). Roughly five billion of such connected devices will be in use in 2015, increasing to tens of billions in just a few years.4 From smart thermostats in our homes, personal fitness bands on our wrists, observational devices in vehicles to noise, efficiency, and vibration sensors embedded in factory machinery and jet engines, these devices, and the insights and predictions emanating from the resulting analytics, will quite literally be everywhere.
At first blush, the obvious implication is that everyday objects can and will become better, more efficient versions of what they already are. For example, complex machines such as airplanes, automobiles, agricultural equipment, and power plants can be tagged to emanate streams of data used to monitor and predict the time to failure of critical parts—which allows replacements and repairs to be conducted before breakage or failure. Medical cargoes can be monitored for environmental changes and safe transport. Smart streetlights use less energy to illuminate neighborhoods. In short, we can make devices “smarter” versions of their current selves thanks to the information flows enabled by cheap and widespread smart components and interconnectivity.
The linking of devices to networks changes the nature of these devices in at least two fundamental ways. First, data and information—long used to achieve efficiencies in the creation, marketing, and distribution of things—increasingly become imbued in the things themselves. For example, T-shirts, eyeglasses, sports equipment, mobile phones, automobiles, and fashion accessories can double as data-capturing and information-delivery devices. They increasingly become media of data products and services. Second, as things become increasingly networked, the networks themselves emerge as new classes of products and services. It is now meaningful to speak of smart homes, smart farms, and smart cities thanks to the flows of information enabling improved efficiencies and coordination amongst linked devices. This gives product companies new opportunities to become providers of information and services.
The IoT is giving rise to what might be called a “transfiguration of the commonplace,” with all of the societal and business model implications that this implies.5 The nature and functions of everyday things—and the networked environments they comprise—will continue to evolve, thanks to the infusion of data, information, and network linkages into their basic designs. Things change.
As sweeping as it already is, this device-centric narrative omits a crucial point. Namely, people should also be regarded as part of the IoT. The publisher and veteran Internet observer Tim O’Reilly recently made the initially counterintuitive comment that the crowdsourced taxi company Uber exemplifies the types of changes the IoT has in store for business models and societies. In this case taxi drivers and people seeking rides are the IoT “things,” connected via their mobile devices.6
The observation that the IoT encompasses people is deceptively simple. But it holds a number of transformative business and societal implications. First, the data and information flows continually emanating from both people and everyday devices can be aggregated and analyzed to create fundamentally new types of products, services, and business models. Furthermore (as in the case of Uber) these information flows can be bi-directional: multitudes of small signals from thousands of individuals, aggregated, and analyzed to send personalized data products, recommendations, or services back to individuals.
Second, most of what falls under the term “big data” is in fact the “digital breadcrumbs” collected by the IoT as we go about our everyday activities. This IoT-collected data is to the study of people and organizations what the telescope was to astronomy in Galileo’s time. New varieties of data science are coming to prominence in response to this newfound treasure trove, going by such names as computational social science, social physics, behavioral analytics, and people analytics.7 These emerging disciplines afford both deeper and broader understandings of human, organizational, and social network behavior. Domains likely to be affected range from human resources and performance management to behavioral health to employee risk management.
Finally, design thinking—as in behavioral design thinking—is important. The past three decades have ushered in a behavioral revolution in our understanding of the ways people make judgments and decisions. In the wake of these discoveries, there is increasing recognition that products and services are considerably more effective when they are designed to go with, rather than against, the grain of human psychology. To paraphrase Ogilvy’s Rory Sutherland, IoT-connected devices and IoT-delivered services should be designed for the brains of humans, not Vulcans. The IoT is not just about “smart devices”; it is also about devices and services that help us become smarter.
Tim O’Reilly put the matter simply: “The IoT is really about human augmentation.”8 It is time to explore the possibilities.
Early IoT applications have typically focused on efficiency gains. For example, in 2008, UPS gathered data from telematics and mobile devices to better understand where efficiency gains could be made and how to achieve them.9 Using GPS tracking equipment and vehicle sensors, combined with a driver’s handheld mobile device, UPS captured data about each truck’s route, the time vehicles spent idling or maneuvering, and even whether drivers were wearing their seatbelts. This technology has recently been extended under the On-Road Integrated Optimization and Navigation (ORION) program, which now provides real-time route optimization to help individual drivers determine the most efficient way to deliver and pick up packages. Under ORION, a reduction of just one mile per driver per day will save UPS up to $50 million per year when it is rolled out to its entire fleet by 2017. With over 10,000 routes optimized, UPS has so far saved more than 1.5 million gallons of fuel and has reduced carbon dioxide emissions by 14,000 metric tons.
But the opportunities presented by the IoT do not end with the efficiency gains enabled by better monitoring, control, and optimization.10 In The more things change, Michael Raynor and Mark Cotteleer point out that these information flows can be used to create new products, services, and business models.11 One interesting paradigm is discussed by William Eggers and Paul Macmillan under the rubric “billion to one.”12 The idea is that small bits of information emanating from a crowd of individuals can be amassed, analyzed, and used to return customized bits of content or services back to each individual. The transportation app Waze is one example of this model: The app enables drivers (“the billion”) to instantaneously report experiences (such as road hazards, police activity, and traffic accidents) that, when aggregated and analyzed, result in a continuously updated, real-time model of the driving environment. Individuals (“the one”) can use this information to plan and adjust routes and destinations in real time.13
“If you had asked social scientists even 20 years ago what powers they dreamed of having, they would have said, ‘It would be unbelievable if we could have this little tiny Black Hawk helicopter that could be microscopic, fly on top of you, and monitor where you are and who you’re talking to, what you’re buying, what you’re thinking...’”
The “billion to one” model of apps like Waze illustrates one aspect of the IoT that deserves much greater attention than it typically receives. Recall the definition of the IoT as simply the expansion of the Internet into the everyday world. A helpful way of thinking about the Internet is articulated by Thomas Malone, the founder of the MIT Collective Intelligence Center. Malone points out that the Internet enables various forms of “collective intelligence,” which he describes simply as groups of humans acting in ways that seem intelligent.14 As Malone points out, collective intelligence is nothing new: Teams, families, armies, and businesses have displayed varying degrees of collective intelligence throughout history. What is new is the appearance of new forms of collective intelligence that were impossible before the advent of the Internet. Wikipedia is a classic example: a highly refined—quite literally encyclopedic—product that is produced and continually updated by thousands of dispersed individuals operating with fairly minimal central control.15
Because the IoT is the expansion of the Internet into the everyday world, it is reasonable to anticipate new products and services centered around the harnessing of collective intelligence in the everyday world. The “billion to one” logic of Waze illustrates how the bi-directional information flows through mobile Internet devices enable multitudes (in this case drivers) to better self-organize and collectively act in a way that seems intelligent. Uber—and the entire “Uberified” sector of the economy—similarly exemplifies the idea. Indeed an “Uber for parking spaces” would be a natural complement to Waze. Waze currently enables the driver to select the best route to her destination. But once she arrives in that neighborhood she often confronts a wasteful and time-consuming hunt for parking. In the future, parking garages will be able to guide the driver to a specific parking spot. Like birds in a flock, IoT-connected cars and drivers can achieve a kind of collective intelligence.
Of course opportunities for IoT-fuelled innovation are not restricted to the private sector. Consider California’s multiyear drought, which many fear is a permanent feature of the environment. In response, California Governor Jerry Brown announced the first mandatory water restrictions in that state’s history.16 It is likely that the IoT will be part of the solution. A “device-centric” IoT approach would be to attach sensors to elements of the water distribution system to unlock efficiencies akin to those achieved by “smart” hydroponic and irrigation systems. This is yet another example of linking devices to networks to achieve greater monitoring, control, and optimization.
A complementary IoT-enabled idea would be a Waze-like harnessing of collective intelligence: Concerned citizens could install smartphone apps that would enable them to effortlessly report suspected inefficiencies or breakdowns in water distribution and usage to the appropriate authorities. A robust uptick in such signals tagged to a certain location could trigger an investigation. The idea is loosely analogous to the use of Google search data to more efficiently track flu outbreaks.17 Similar crowdsourcing ideas could be employed to flag potentially unsafe roads, buildings, and workplaces; unhygienic restaurants and food trucks; emerging risks in complex supply chains; hot-spots of crime, violence, and human rights abuses, and so on.18
A sign hanging on Albert Einstein’s door read, “Not everything that can be counted counts, and not everything that counts can be counted.” This motto also belongs on the doors of business and public sector leaders. It is a useful corrective to the twin fallacies, more common than ever in the age of big data, that something is important only to the extent that it can be quantified; and conversely that current modes of quantification capture what is important. The IoT is expanding the scope of what can be measured in society, just as the invention of the telescope opened new vistas to astronomers. Important traits of individuals, teams, organizations, and populations that have traditionally been hidden from view are coming to the fore thanks to IoT-collected data. This will give the emerging field of “people analytics” greater scope to improve on unaided judgment in making human resource and other decisions that involve employees and teams.
The premise that the IoT encompasses people has an important implication for the notion of “big data”: Most of the data collected by the IoT are in fact human behavioral data, often collected continually and at vast scales.19 These new sources of data enable new forms of analytics, such as people analytics, social network analysis, behavioral health and precision medicine, and behavioral finance. Sandy Pentland of MIT comments:
The power of big data is that it is information about people’s behavior instead of information about their beliefs. It’s about the behavior of customers, employees, and prospects for your new business. It’s not about the things you post on Facebook, and it’s not about your searches on Google, which is what most people think about, and it’s not data from internal company processes and RFIDs. This sort of big data comes from things like location data off of your cell phone or credit card; it’s the little data breadcrumbs that you leave behind you as you move around in the world.20
Using large volumes of behavioral data to better understand the workings of groups and networks is the domain of an emerging, interdisciplinary field known as computational social science (CSS). The medical professor and computational social scientist Nicholas Christakis summarizes the perspective that motivates much CSS research:
If you had asked social scientists even 20 years ago what powers they dreamed of having, they would have said, “It would be unbelievable if we could have this little tiny Black Hawk helicopter that could be microscopic, fly on top of you, and monitor where you are and who you’re talking to, what you’re buying, what you’re thinking, and if it could do this in real time, all the time, for millions of people, all at the same time. If we could collect all these data, that would be amazing.”21
Christakis’s point is that the IoT makes yesterday’s data-“science fiction” today’s data-science. A study by the Cornell sociologists Scott Golder and Michael Macy illustrates the possibilities for understanding people and populations in new ways. Golder and Macy analyzed millions of publicly available Twitter messages and were able to measure and quantify the degree to which people awaken in a good mood which subsequently deteriorates throughout the day; and the degree to which the happiness of populations is correlated with varying lengths of daylight.22 Of course these findings are intuitive. But the point is that such population-level traits and behaviors are now the subject of scientific scrutiny by means other than surveys. (Recall Pentland’s comment about measuring people’s behaviors rather than their beliefs.)
Similar methods are used in the business world. For example, analysis of social media data is routinely used to measure changes in public sentiment following entertainment events and advertising campaigns. Computational social science also lends itself to innovations in public health. Christakis and Fowler, for instance, have concluded that obesity is “contagious” in social networks: Otherwise similar people are more likely to become obese themselves if they enter a social situation in which they are surrounded by obese people. Similar effects have been posited for teen pregnancy and smoking. Such insights are useful in the design of environments to prompt healthier behaviors.23
Other promising applications of CSS methods in the business world are only beginning to attain prominence. Human resources is a domain that has been notoriously slow to adopt data analytic methods.24 Hiring, evaluation, promotion, and coaching decisions are still routinely made largely based on subjective judgments. Now that it is increasingly possible to collect “digital breadcrumbs” of workers as they go about their daily jobs, data-driven methods might be poised to make inroads against reliance on unaided judgment when making decisions about people and teams.25
While such monitoring understandably strikes many as intrusive or “creepy,” it is worth considering the shortcomings of the alternative. The use of unaided judgment to evaluate job candidates and employee performance is plagued with cognitive biases such as groupthink, halo effects, the tendency to favor people like oneself, and overgeneralizing from easy-to-remember experiences. The implication of the celebrated book Moneyball is that such biases are so endemic to judgment-based hiring decisions that they can lead to inefficient markets for talent. Consistent with this, symphony orchestras began hiring a greater proportion of women after auditions began to take place behind screens so that candidates were evaluated based only on the sound they made, not their appearance.26
One of Sandy Pentland’s projects illustrates a more modern approach. Working for a call center outsourcing firm that wished to improve its productivity, Pentland’s team set up electronic devices, called sociometers, designed to capture speech patterns of the call center workers as they handled their calls. The devices didn’t record the substance of the conversations, only such conversational patterns as tone and pitch. The team found that the degree to which a call center worker’s voice fluctuates (indicative of speaking in an inviting or singsong, rather than authoritative, way) was highly predictive of a call’s success or failure.27
Pentland’s sociometer therefore measures something important that has traditionally been acknowledged only incompletely and inconsistently: the impact of nonverbal communication styles on success. One can envision such technologies being used to coach and train teachers, public safety workers, sales and marketing professionals, and health care workers. Indeed, in his book Blink, Malcolm Gladwell reported a study correlating physicians’ speech patterns with malpractice suits. The study found that physicians who spoke with warmth were sued for malpractice less frequently than physicians who conveyed an air of authoritativeness. Independent of other risk factors, likeable physicians were found to be sued less often than unlikeable physicians.28
Non-verbal communication ability is an example of an individual-level trait that can be better discerned with IoT-generated digital breadcrumbs. It turns out that sociometric data are also predictive of such group-level traits as the collective intelligence of teams. They can capture whether leaders are domineering or inquiring, the degree to which team members speak and listen in equal measure, whether they use helpful body language and other forms of communication, and so on.29 As digital exhaust brings a kind of data-rich, scientific study of teams into the realm of practical possibility, it is possible that organizations will reconsider whether team-level performance—as opposed to individual-level performance—is even the best unit of analysis to focus on when making hiring decisions and evaluating performance.
Consider for example two hypothetical employees, Alan and Beth. On the surface they are comparable in terms of role, tenure, domain, and so on. But less obvious is the fact that their respective network positions are quite different. Alan is central to a tight-knit cluster of workers; Beth is not central to any particular group, but is practically the only employee with strong connections to people in both the IT and marketing departments. On the surface, Beth might actually appear to be the weaker employee: From the perspective of any particular member of any particular group, her contributions might seem modest or intangible. Yet from the perspective of the organization as a whole, Beth, by virtue of her ability to maintain substantive ties to two disparate groups, fills an important “structural hole” that would otherwise exist in the organization’s professional network.30 It is likely that, appearances to the contrary, the loss of Beth to the organization would be more disruptive than the loss of Alan. Typically such facts are at best recognized inconsistently and at worst simply hidden from view when evaluating employees and determining compensation.
Here again, it is reasonable to expect IoT-mediated behavioral data to provide new perspectives. For example, sociometric data, data about who is emailing whom, and other data sources can be combined to create organizational social network graphs.31 The above hypothetical Alan/Beth comparison—novel, objective, and valuable from the perspective of traditional talent management—becomes a straightforward calculation with the social network graph in hand. In this example, Beth’s “betweenness centrality” (a standard metric used in social network analysis) would be much higher than Alan’s. Various measures of connectedness and centrality could also be used to predict attrition and performance, identify isolated employees or groups that could be connected in strategic ways, and so on. While conceptually straightforward, the implications for people analytics are considerable. For example, network size and position are correlated with attrition risk, and are highly relevant to properly recognizing individuals’ contribution to organizational success. Furthermore, email digital exhaust is potentially relevant in the early detection of rogue employees and the prevention of corporate scandals.32
While our discussion has focused on the potential of people analytics for reinventing various HR functions, behavioral digital exhaust and computational social science methods will continue to leave their mark in a wide variety of domains. For example insurers now realize that personal credit data is highly predictive of who is likely to crash their car; supermarket club card data is predictive of such chronic disease states as diabetes. Social scientists are increasingly able to track the spread of behaviors such as diabetes and smoking through populations; marketers can better understand customers using fine-grained data about both individual behaviors and social network position. In each case, digital breadcrumbs captured by the IoT help us do a better job of counting what counts.
The Waze and Uber examples discussed above illustrate the new forms of collective intelligence that can emerge as a result of connecting people (drivers, passengers, taxi operators) to each other and to things (cars, parking spaces).33 The bi-directional information flows that we have called “billion to one” give the individual the real-time information he or she needs to make a more informed decision. Analogous to free markets governed by the price system, individual (micro) utility-maximizing behavior results in crowd-level (macro) coordination.
But “well-informed deliberation” and “utility-maximizing rational choice” do not describe how most people go about their daily lives. In Thinking, Fast and Slow, psychologist and Nobel laureate Daniel Kahneman discusses how human cognition can be described in terms of a kind of “dual mental process” theory. What he calls Type 1 thinking (“thinking fast”), is rapid, automatic, and prone to narratively coherent stories rather than logically coherent analyses of data. Many of the mental shortcuts (“heuristics”) that comprise Type 1 thinking are systematically biased. They are both terrible at statistics and are present-biased in the sense of favoring tangible short-term gains to long-term benefits. In contrast, Type 2 thinking (“thinking slow”) is the logical, utility-maximizing behavior common to homo economicus and Star Trek’s Mr. Spock. It seeks out all available evidence, evaluates said evidence using logic rather than storytelling, and foregoes short-term pleasures to achieve long-term goals.
The Waze example illustrates how the IoT can enable better Type 2 thinking: If an app displays a faster route to work, we are likely to change our plans and take it. Similarly, if it enables us to prepay and be guided to a specific parking spot with the click of a button, there is a good chance we will take the offer rather than search for parking. Waze is an example of augmented intelligence: Presenting someone with the right information will likely prompt an appropriate decision.
But alas, thanks to the ubiquity of Type 1 thinking, not all decisions are so easily improved. Suppose Carl is deciding between an extra doughnut at breakfast and going for a morning swim. And suppose an app on his new smart watch displays side-by-side the number of calories in a typical doughnut together with the estimated number of calories burned by swimming a mile. Will this augmented intelligence prompt Carl to ditch the doughnut and go for the swim? Maybe, but probably not.34 What is needed in this case is not so much augmented intelligence, but augmented behavior. Carl already knows well enough that swimming is the right choice even without the additional quantification offered by his app. Borrowing the influential term of Richard Thaler and Cass Sunstein, a behavioral nudge might prompt Carl to go “the last mile” from intention to action.
A core concept of the science of behavioral nudges is choice architecture: Try to convey information and design menus of choices in ways that go with, rather than against the grain of human psychology. A general theme of behavioral economics is that people’s choices are influenced not only by the available options, but also by the way those options are presented. For example, a diner in a restaurant might be more likely to order a $50 entrée if a $75 entrée is also on the menu: Compared with the more expensive option, the $50 entrée seems like good value. A clever restaurateur might therefore place a very expensive item on the menu as a “decoy,” primarily to serve as a psychological reference point. This simple example illustrates how a certain kind of design thinking can prompt behavior change.35
One of the most powerful findings of behavioral science is that people dislike violating social norms, and often act more on the basis of “social proof” (what others are doing) than stable sets of preferences. The energy company Opower famously uses this insight to prompt more efficient energy usage. Their letters to customers reflect the finding that informing people that they consume more than comparable neighbors is more effective than either economic or environmental pleas.36
Peer comparisons might be similarly effective in prompting California citizens to use less water. This could be a complementary water conservation approach to the connected-device and collective intelligence ideas described above.
In the realm of behavioral health, self-tracking device apps show not only how well people are doing against their goals but how well they are doing relative to their friends.
The automobile telematics data captured by insurance companies to more accurately price insurance policies could be used to give both periodic feedback reports containing personalized driving tips (augmented intelligence), as well as peer comparisons serving as behavioral nudges to prompt safer driving (augmented behavior). 37
The behavioral finance company HelloWallet creates various composite measures of individuals’ financial health and also makes peer comparisons to help guide people to take better control of their personal finances.
The DebMed Group Monitoring System is an electronic soap dispenser equipped with a computer chip that records how often health care workers in different hospital wards wash their hands. It compares these results to expectations based on World Health Organization standards and reports the comparisons back to the wards. Clever “social physics” and nudge thinking is built into the conception: Feedback reports are given at the group level rather than individual level. The insight is that no one wants to be “that guy” who lets down the team.38
Peer comparisons and clever uses of “social physics” hardly exhaust the many varieties of behavioral science thinking relevant to the design of IoT-connected devices. The variety of possibilities defies easy summary. For example, Beeminder connects self-tracking devices with apps that can be programmed with commitment contracts: By committing ahead of time to pay a fine for not complying with your goals, you make it more likely that you will follow through.39 Companies that offer their customers large numbers of choices (such as mutual fund companies or cable TV carriers) can consider creating data-driven recommendation engines or personalized menus of simplified choices to improve customer engagement by avoiding choice overload.40 Finally, health, wellness, and patient compliance is a promising application of digitally enabled behavioral nudge design. For example, Senscio Systems’ IbisCare blends applied behavioral economics, data analytics, and IoT technology to improve the medical compliance of senior citizens suffering from chronic diseases.41 In the same genre is David Rose’s IoT-connected pill bottle equipped with “GlowCaps” that nudge the patient with a flash of light when it’s time to take a pill.42
The implication of the IoT including people is that issues of privacy, transparency, data stewardship, and data ownership are paramount. Many of us enjoy the benefits of smarter homes, cars, and transportation networks. But few relish the thought of Internet companies being able to track our every move and make highly personal inferences and predictions based on the digital breadcrumbs we leave behind as we go about our daily activities. Similarly, customers have long allowed grocery store chains to electronically capture data about shopping behavior in return for personalized promotions and discounts. One could imagine such data also being used for behavioral health and precision medicine applications as well, but many are understandably uncomfortable with the prospect of data brokers or insurance companies being able to amass and analyze such data in ways that are hidden or constantly changing. And more fundamentally, many people simply do not want to live in a world in which their every action is monitored. A trade-off must be struck between the benefits, innovations, and analytic insights that IoT brings with the need to maintain societies that people want to live in.
Observers such as Sandy Pentland and Richard Thaler suggest frameworks for data privacy and ownership that suggest a way beyond this impasse. Pentland calls for a “new deal on data,” which would involve giving people ownership of their data. In Pentland’s scheme, people would possess their data, have full control over how it is used, have a right to distribute the data as they see fit. At the same time, Pentland suggests policies that would encourage individuals to share anonymized data for computational social science applications that promote the common good.43
Richard Thaler, the University of Chicago economist and father of behavioral finance, makes consistent suggestions.44 He says that while issues of data privacy, veracity, and security are important, they do not address the larger issue that people should also be able to access the data collected about them. Thaler proposes the guiding principle that, “if a business collects data on consumers electronically, it should provide them with a version of that data that is easy to download and export to another website.” Intuitively: The individual has lent the company (bank, insurer, mobile phone carrier, Internet service) her data; so she should be able to request a copy for her own use.
Thaler’s ideas are being put into practice. For example the UK government has been encouraging banks, energy companies, and mobile phone carriers to comply with a program called “midata” that was modelled on Thaler’s framework. The government recently decided against drafting new regulations requiring compliance after finding that companies have been voluntarily complying reasonably well.45 In the United States, the federal government’s “blue button” program enables individuals to download their medical records in a standard format to share with medical providers whom they trust.46
If widely adopted, a framework such as Thaler’s could have the dual effect of defusing some of the distrust currently surrounding industrial and governmental efforts to collect and mine data about people while also spurring the new economies dedicated to helping people make the most of their data. “So let’s level the playing field,” Thaler writes. “Why not give you, the consumer, something in return for participating? Require that the supermarket make your purchase history available to you. Before you know it, a smart entrepreneur is likely to devise an app that will direct you to cheap and healthy alternatives that can slim your tummy and fatten your wallet. Apps could not only save money; they could also warn shoppers with allergies, for example, that they are buying foods that contain ingredients to which they are sensitive, like nuts or gluten.”
Such ideas illustrate how innovative uses of data from IoT-connected devices, infused with the right kind of behavioral design thinking, can enable traditionally product-centric industries such as insurance, utilities, and banking to modify their business models in ways that make them more customer-centric and less commoditized. More generally, the combination of data science, digital technology, and behavioral design thinking enables a distinctly modern way of “doing well by doing good.” Used imaginatively, the digital breadcrumbs pulsing through the IoT can be a force for good, helping us stick to our goals, drive more safely, make better medical, diet, exercise, and financial decisions, and use resources more sparingly.
It is fitting to close with another Tim O’Reilly remark: “When you think about the Internet of Things, you should be thinking about the complex system of interaction between humans and things, and asking yourself how sensors, cloud intelligence, and actuators make it possible to do things differently.”47
As O’Reilly suggests, the observation that the IoT includes people implies opportunities for IoT innovation that go well beyond the (already considerable) promise of smarter devices and smarter networks devices. First, the IoT enables new products and services premised around the creation of new forms of collective intelligence; and using aggregated information from “the billion” to provide useful products and services to “the one.”
Second, IoT-mediated behavioral digital breadcrumbs, analyzed with the emerging tools of computational social science, will help us better measure—and therefore manage—hitherto hidden traits of individuals, teams, organizations, and populations. Stay tuned for further innovations from such fields as people (HR) analytics, risk management, population health, and elsewhere.
Finally, we suggest that behavioral design thinking is indispensable when envisioning—and building—the 21st century world of complex systems of interactions between people and things that O’Reilly describes. This world must be designed for the minds of humans, not of Vulcans. The point of the IoT should not be to make smarter machines, but to make people smarter. It’s about us.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.The IoT’s true value lies in its disruptive potential for reimagining business processes and, ultimately, rewiring business, government, and society. Realizing that potential means shifting IoT applications’ strategic focus toward not just sensing, but doing.
Increasingly, forward-thinking organizations are focusing their Internet of Things (IoT) initiatives less on underlying sensors, devices, and “smart” things and more on developing bold approaches for managing data, leveraging “brownfield” IoT infrastructure, and developing new business models. Meanwhile, others are developing human-impact IoT use cases for boosting food production, cutting carbon emissions, and transforming health services. What impact will IoT have on your business and on the people around you? Rapid prototyping can help you find out.
Explore View Tech Trends 2016 Learn more about Deloitte Technology Consulting Create and download a custom PDF of the 2016 report
Like a wildfire racing across a dry prairie, the Internet of Things (IoT) is expanding rapidly and relentlessly. Vehicles, machine tools, street lights, wearables, wind turbines, and a seemingly infinite number of other devices are being embedded with software, sensors, and connectivity at a breakneck pace. Gartner, Inc. forecasts that 6.4 billion connected things will be in use worldwide in 2016, up 30 percent from 2015, and that the number will reach 20.8 billion by 2020. In 2016, 5.5 million new things will get connected to network infrastructure each day.1
As IoT grows, so do the volumes of data it generates. By some estimates, connected devices will generate 507.5 zettabytes (ZB) of data per year (42.3 ZB per month) by 2019, up from 134.5 ZB per year (11.2 ZB per month) in 2014. (A zettabyte is 1 trillion gigabytes). Globally, the data created by IoT devices in 2019 will be 269 times greater than the data being transmitted to data centers from end-user devices and 49 times higher than total data center traffic.2
Even as businesses, government agencies, and other pioneering organizations at the vanguard of IoT take initial steps to implement IoT’s component parts—sensors, devices, software, connectivity—they run the risk of being overwhelmed by the sheer magnitude of the digital data generated by connected devices. Many will focus narrowly on passive monitoring of operational areas that have been historically “off the grid” or visible only through aggregated, batch-driven glimpses. To fully explore IoT’s potential, companies should think big, start small, and then scale fast.
Many enterprises already have unused IoT infrastructure built into their manufacturing machinery and IT software. We call these dormant components “brownfields”: Like roots, bulbs, and tubers in the soil, they need a good “rain” and a bit of tending to begin to thrive. Activating and connecting these brownfield components may help companies leapfrog some implementation steps and give their IoT initiatives a needed boost. In contrast, “greenfields”—enterprise environments with no preexisting IoT infrastructure—require basic seeding and a lot of tending over time to yield a new crop.
The value that IoT brings lies in the information it creates. It has powerful potential for boosting analytics efforts. Strategically deployed, analytics can help organizations translate IoT’s digital data into meaningful insights that can be used to develop new products, offerings, and business models. IoT can provide a line of sight into the world outside company walls, and help strategists and decision makers understand their customers, products, and markets more clearly. And IoT can drive so much more—including opportunities to integrate and automate business processes in ways never before possible.
Often overlooked is IoT’s potential for impacting human lives on a grand scale. For example, in a world where hunger persists, “smart farming” techniques use sensor data focused on weather, soil conditions, and pest control to help farmers boost crop yields. Meteorologists are leveraging hazard mapping and remote sensing to predict natural disasters farther in advance and with greater accuracy. The health care sector is actively exploring ways in which wearables might help improve the lives of the elderly, the chronically ill, and others. The list goes on and will continue to grow. We are only beginning to glimpse the enormity of IoT’s potential for making lives better.3
With so few detailed use cases, the sheer number of IoT possibilities makes it difficult to scope initiatives properly and achieve momentum. Many are finding that IoT cannot be the Internet of everything. As such, organizations are increasingly approaching IoT as the Internet of some things, purposefully bounded for deliberate intent and outcomes, and focused on specific, actionable business processes, functions, and domains.
The time has come for organizations to think more boldly about IoT’s possibilities and about the strategies that can help them realize IoT’s full disruptive potential. To date, many IoT initiatives have focused primarily on sensing—deploying and arranging the hardware, software, and devices to collect and transmit data. These preliminary steps taken to refine IoT approaches and tactics are just the beginning. The focus must shift from sensing to doing. How do inputs from sensors drive closed-loop adjustments and innovation to back-, middle-, and front-office business processes? Where can those processes become fully automated, and where can the core be reconfigured using feedback from connected devices and instrumented operations? What future IoT devices might open up new markets? To yield value, analytics-driven insights must ultimately boost the bottom line.
One strategy involves harnessing the information created by the IoT ecosystem to augment worker capabilities, a process modeled in the Information Value Loop. When built to enhance an individual’s knowledge and natural abilities and deployed seamlessly at the point of business impact, IoT, in tandem with advanced analytics, can help amplify human intelligence for more effective decision-making. For example, the ability to monitor the vital signs of elderly patients remotely and in real time will empower medical personnel to make more accurate care decisions more quickly. Even more profound, automated drug delivery systems may be triggered to respond to complicated signals culled from several parts of the care network.
Likewise, companies may harness data-driven insights to augment or amplify operational activity in the form of transforming business processes, reimagining core systems and capabilities, and automating controls. Eventually, robotic process automation and advanced robotics will monitor events, aggregate sensor data from numerous sources, and use artificial intelligence capabilities to determine which course of action they can take to deliver the most desirable outcome.4
Take manufacturing, for example. At a Siemens facility in Amberg, Germany, machines and computers handle roughly 75 percent of the value chain autonomously, with some 1,000 automation controllers in operation throughout the production line. Each part being manufactured has its own product code, which lets machines know its production requirements and which steps to take next. All processes are optimized for IT control, which keeps failure rates to a minimum. In this facility, employees essentially oversee production and technology assets, handling any unexpected incidents that may arise.5
As organizations work to integrate vast, disparate networks of connected devices into core systems and processes, there will likely be new security and privacy concerns to address. These concerns could be particularly acute in industries like health care—which may be aggregating, analyzing, and storing highly personal data gleaned from sensors worn by patients—or in manufacturing—where risks may increase as heavy industrial equipment or infrastructure facilities become increasingly connected. More data, and more sensitive data, available across a broad network means that risks are higher and that data breaches could pose significant dangers to individuals and enterprises alike.
With IoT, data security risks will very likely go beyond embarrassing privacy leaks to, potentially, the hacking of important public systems. Organizations will have to determine what information is appropriate for IoT enablement, what potential risks the assets and information may represent, and how they can ensure that solutions are secure, vigilant, and resilient.6
Similarly, as companies add additional inputs to their IT and IoT ecosystems, they will be challenged to create new rules that govern how action proceeds and data is shared. Opening up IoT ecosystems to external parties via APIs will give rise to even more risk-related considerations, particularly around security, privacy, and regulatory compliance.
Acting on the information created by the IoT—putting intelligent nodes and derived insights to work—represents the final, and most important, part of the IoT puzzle. Options for achieving this vary. Centralized efforts involve creating orchestration or process management engines to automate sensing, decisioning, and response across a network. Likewise, a decentralized approach typically focuses on automation: Rules engines would be embedded at end points, which would allow individual nodes to take action. In still other scenarios, IoT applications or visualizations could empower human counterparts to act differently.
Ultimately, the machine age may be upon us—decoupling our awareness of the world from the need for a human being to consciously observe and record what is happening. But machine automation only sets the stage; real impact, business or civic, will come from bringing together the resulting data and relevant sensors, things, and people to allow lives to be lived better, work to be done differently, and the rules of competition to be rewired.
With this in mind, organizations across sectors and geographies continue to pursue IoT strategies, driven by the potential for new insights and opportunities. By thinking more boldly about these opportunities and the impact they could have on innovation agendas, customer engagement, and competitiveness (both short- and long-term), companies will likely be able to elevate their IoT strategies beyond sensing to a more potentially beneficial stage of doing.
At a remote mining region of western Australia, the IoT’s lofty potential meets the ground in a fleet of Caterpillar mining trucks—each boasting a 240-ton payload—that operate autonomously, 24 hours a day. These giant, driverless machines are outfitted with a variety of sensors that transmit information on oil pressure, filters, and other truck components via wireless connections (such as satellite, cellular, and others) back to Caterpillar headquarters in Peoria, IL, where an advisor monitors the equipment’s vital signs and can, when needed, make maintenance recommendations to the fleet’s owner.7
Though Caterpillar has been embedding sensors in its products for decades, only in the last few years has the global construction machinery and heavy equipment manufacturer begun exploring their potential application within the context of IoT. Today, IoT—or as they call it at Caterpillar, the “Internet of Big Things”—is a major strategic and technological focus, with the company exploring ways to mine IoT data that can then be used to develop predictive diagnostics tools, design products, and improve product performance.
For example, when compiled over time and analyzed, data generated by sensors embedded in construction-site machinery may be able to help engineers design heavy equipment that can accomplish more work with fewer passes. Fewer passes translates to reduced idle time, less operator fatigue, and lower fuel consumption. Ultimately, operating efficiently can help owners of Caterpillar equipment better serve their own customers.
Importantly, this information—combined with Caterpillar’s domain knowledge about heavy equipment and analytics—may help the company more accurately predict how specific pieces of equipment will perform in different environments and on specific types of jobs. To this end, Caterpillar recently announced it had entered into a technology agreement with analytics vendor Uptake to develop a predictive diagnostics platform to help customers monitor and optimize the performance of their fleets.8 Looking forward, Caterpillar expects IoT to help redefine business processes, drive better engagement with its customers, and evolve its products, services, and offerings.
Some companies in the health care industry—including health plans, providers, medical device manufacturers, and software vendors—are testing the IoT waters with a number of sensor-driven big data initiatives that could transform the way patients and their providers manage acute health conditions.
One leading health care delivery system is currently developing a suite of mobile applications to track, record, and analyze biometric data generated by Bluetooth-enabled sensing devices worn by patients. These apps, each configured to monitor a specific medical condition, will share a common digital platform and feature APIs to encourage external development. Once deployed, they will be able to analyze sensor data and pair them with electronic medical records and other clinical information to help caregivers make faster—and more informed—decisions for patients. For example, a diabetic patient’s glucose readings would be streamed from a monitoring device to a mobile app on his or her phone or tablet, and then on to an integrated big data repository. Care coordinators would be alerted to unusual changes in the patient’s glucose levels so that they can take appropriate action, such as bringing the patient into the hospital for closer examination or adjusting his or her medications.
The organization piloted its diabetes monitoring application with almost 40,000 diabetic patients, demonstrating the viability of the platform. Next on the agenda: Expanding adoption of the diabetes pilot and extending the platform to support other conditions such as congestive heart failure, chronic obstructive pulmonary disease (COPD), and high blood pressure, among others.
It’s morning in Amsterdam. An employee leaves her desk, walking casually toward a break room in the office building where she works. As she approaches, a custom app on her smartphone engages sensors embedded in a coffee machine, which immediately begins dispensing the employee’s preferred blend, complete with the add-ins she desires. When the employee arrives at the break room, her custom brew is waiting.
Welcome to life in “The Edge,” a futuristic office structure widely known as “the world’s smartest building.”9 Completed in 2014, The Edge—which is home to Deloitte Netherlands—is a showplace for leading-edge deployments of green architecture and advanced technology, including IoT applications. The innovative, connected lighting panels do more than sip minute amounts of voltage—they contain some 28,000 sensors that detect motion, light, temperature, humidity, and even carbon dioxide levels. It’s these sensors, providing real-time data, that make The Edge occupant-friendly.
The sensors allow facility managers to assess how and when certain parts of the building are being used. “In our building, IT and facilities management are a combined function,” explains Tim Sluiter, property manager, IT and Workplace Services, Deloitte Netherlands. In the short term, collected information can be used to determine where cleaning is and is not necessary on a given evening. Long term, emerging patterns showing light use in certain locales on certain days can lead to rooms or even entire floors being closed off to save energy.
IoT’s reach within this building extends far beyond lighting sensors. When employees approach The Edge’s high-tech garage, sensors identify their vehicles and then point them to available parking spots. Throughout the garage, sensor-equipped LED lights brighten and dim as drivers arrive and leave.
And that miraculous coffee app? It doubles as a digital office administrator that can assign daily workspaces that best fit users’ preferences and allows them to control the brightness of the lighting above their work surfaces and adjust the climate of their particular areas. It can direct people throughout the building—reading a meeting location from one’s online calendar, for example, and suggesting a route to get there. Employees can even use the app to track their progress in the on-site gym, where some of the fitness equipment actually feeds generated wattage into the building’s power grid.
Sluiter stresses that personal data generated by sensors and the app cannot be accessed by managers or anyone else. Privacy laws ensure that nobody can track a person’s whereabouts, monitor how many meetings he or she has missed, or see what times he or she is using the garage. “This building offers the technology to do certain things that would make tenants’ lives even easier,” Sluiter says. “But at the same time, it’s extremely important to protect people’s privacy and conform to the law.”
Those minimal barriers aren’t hindering The Edge’s reputation. “Our aim was to make The Edge the best place to work,” says Erik Ubels, director of IT and Workplace Services, Deloitte Netherlands. “Our meeting areas are filling up because every client and employee wants to experience this building. It’s not too small yet, but the economy is growing and the building is getting crowded. It’s possible we made it too popular.”10
Sandy Lobenstein Vice president, connected vehicle technology and product planning, Toyota Motor Sales U.S.A., Inc.
At Toyota, we are all about mobility. I’m not talking just about car ownership. Mobility also includes public transportation, ridesharing, hoverboards, walking—anything that can get people from place A to place B more efficiently and safely. Mobility is truly multi-modal.
Toyota sees the IoT as an enabler of mobility, and we are moving very quickly to embrace its potential. Big data generated by sensors located throughout our cars will help engineers develop automobiles that think for themselves. Likewise, Dr. Gill Pratt, the chief executive officer of the Toyota Research Institute (TRI), and other researchers at TRI, will leverage IoT data to advance the science of intelligent cars as we move into the future mobility of autonomous vehicles. Progress in these areas will likely deliver autonomous connected cars that are reliable, safe, and fun to drive when you want to. The benefits that these innovations may eventually provide to everyday drivers, drivers with special needs, and to seniors could be life-enabling.
Toyota is no stranger to connected vehicle technologies; Lexus began offering connected vehicles in 2001. Today, all Lexus vehicles are connected, which enables services like Destination Assist, which links drivers to live agents who can provide directions for getting from point A to point B. Lexus also offers sensor-driven “car health” reports on current tire pressure, oil levels, and maintenance needs.
These IoT applications are just the beginning. Cars are mechanical products built with mechanical processes. Sensors are so small that we can place them virtually everywhere on cars. And what if you extend the same sensor technologies that monitor tires and brakes to the machines used to build vehicles on the manufacturing floor? These sensors could alert production leaders that there is a problem at a particular station, and that the parts manufactured at this station within a specific time frame will have to be rebuilt.
As for new offerings, it’s sometimes hard for companies to wrap their heads around the value of data. For example, early on, everyone assumed consumers wanted apps in cars. Very quickly, the auto industry realized that what customers actually wanted was for the apps on their phones to work in their cars. Across industries and sectors, strategists, designers, and decision makers typically believe that current approaches and systems are just fine. It takes vision—and a considerable amount of courage—to break with the way things have been done for the last 100 years and embrace some exotic technology that promises to deliver new opportunities.
But in this era of historic technological innovation, all companies must work aggressively to reinvent themselves by embracing new opportunities and compelling visions of the future. This is exactly what Toyota is doing with IoT and mobility.
I’m a car guy. In high school, I loved working under the hood of my car, which was the embodiment of leading-edge technology at that point in my life. For the last 15 years, we amateur mechanics have been distracted by other mechanical wonders—the kind everyone now spends their days staring at and speaking into. That’s about to change. Connectivity and cool new services are going to make cars come alive. All those people who’ve developed relationships with their smartphones are about to fall in love with cars all over again.
The IoT connects critical infrastructure that has been previously unconnected. As organizations begin harnessing these connections to create value, they may also add functionality to IoT networks that will make it possible to take control of devices and infrastructure remotely, and to automate monitoring and decision-making within certain parameters based on sensory data.
Make no mistake: As companies put IoT to work, the smart, connected objects they deploy offer tremendous opportunities for value creation and capture. Those same objects, however, can also introduce risks—many of them entirely new—that demand new strategies for value protection.
For example, every new device introduced in an IoT ecosystem adds a new attack surface or opportunity for malicious attack, thus adding additional threat vectors to a list that already includes protecting devices, data, and users. Likewise, identity spoofing—an unauthorized source gaining access to a device using the correct credentials—may present problems. And even if devices aren’t directly compromised but experience a hardware failure or a bug in the code, they should be able to fail in a safe way that doesn’t create vulnerabilities.
Moreover, the ecosystem structures that organizations often rightfully deploy can give rise to vulnerabilities. For example, IoT applications typically depend on the closely coordinated actions of multiple players, from vendors along the supply chain to clients, transport agencies, the showroom, and end-use customers. Vulnerabilities exist within each node and handoff seam between sensors, devices, or players. It should not be assumed that partners—much less customers—have robust mechanisms in place to maintain data confidentiality and guard against breaches.
In the face of these and other challenges, companies can take several steps to safeguard their ecosystems:11
Work to define standards for interoperability: Internally, define data and service standards to guide consistent rollout within your organization’s boundaries. Also consider getting involved with consortia like the IIC 12 to develop broader standards and ease connectivity and communication.
Internally, define data and service standards to guide consistent rollout within your organization’s boundaries. Also consider getting involved with consortia like the IIC to develop broader standards and ease connectivity and communication. Refactor with care: Retrofitting or extending functionality of old systems may be exactly what your IoT strategy needs. But when doing so, understand that there may be potential security, performance, and reliability implications, especially when pushing legacy assets into scenarios for which they weren’t designed. Whenever possible, use purpose-built components for the refactoring, engineered specifically for the use case.
Retrofitting or extending functionality of old systems may be exactly what your IoT strategy needs. But when doing so, understand that there may be potential security, performance, and reliability implications, especially when pushing legacy assets into scenarios for which they weren’t designed. Whenever possible, use purpose-built components for the refactoring, engineered specifically for the use case. Develop clear responsibilities for the players in your ecosystem: Rather than sharing responsibility across a diffuse ecosystem, players should know where their responsibilities begin and end, and what they are charged with protecting. Assessing potential risks at each point—and making sure stakeholders are aware of those risks—can help make a solution more secure.
Rather than sharing responsibility across a diffuse ecosystem, players should know where their responsibilities begin and end, and what they are charged with protecting. Assessing potential risks at each point—and making sure stakeholders are aware of those risks—can help make a solution more secure. Get to know your data: The quantity and variety of data collected via IoT—and the fact that so much of that data is now held by third parties—can make it difficult for companies to know if their data has been breached. When dealing with tremendous volumes of IoT data, small, virtually unnoticeable thefts can add up over time. Companies can address this threat by developing a deep understanding of the data they possess and combining this knowledge with analytics to measure against a set “normal.” By establishing a baseline of access and usage, IT leaders can more readily and reliably identify possible abnormalities to investigate further.
As IoT gains momentum, many organizations find themselves paralyzed by the sheer volume of vendor promises, the number of novelty examples being imported from the consumer realm, and by an overarching conviction that something real and important—yet frustratingly out of focus—is waiting to be tapped into.
To maximize value, reduce risk, and learn fast, those just beginning their IoT journey should follow three innovation principles: “Think big, start small, scale fast”:
Ideate: Analyze the big ideas and use cases in your industry. Move beyond sensing to doing. Also, explore opportunities for achieving greater consumer and human impact with IoT.
Take stock: Before investing in new equipment, conduct an inventory of all the sensors and connected devices already on your balance sheet. Find your brownfields. How many sit dormant—either deactivated or pumping out potentially valuable information into the existential equivalent of /dev/null?
Before investing in new equipment, conduct an inventory of all the sensors and connected devices already on your balance sheet. Find your brownfields. How many sit dormant—either deactivated or pumping out potentially valuable information into the existential equivalent of /dev/null? Get to know the data you already have: Many organizations have troves of raw data they’ve never leveraged. By working with data scientists to analyze these assets before embarking on IoT initiatives, companies can better understand their data’s current value. Likewise, they may also be able to enhance this value by selectively installing sensors to plug data gaps.
Many organizations have troves of raw data they’ve never leveraged. By working with data scientists to analyze these assets before embarking on IoT initiatives, companies can better understand their data’s current value. Likewise, they may also be able to enhance this value by selectively installing sensors to plug data gaps. Pilot your ecosystem: Pick proven IoT partners to quickly pilot ideas, try new things, and learn quickly from failures. Many aspects of IoT cannot be tested or proven in laboratories but only with real enterprise users and outside customers.
Pick proven IoT partners to quickly pilot ideas, try new things, and learn quickly from failures. Many aspects of IoT cannot be tested or proven in laboratories but only with real enterprise users and outside customers. Get into the weeds: At some point, IoT initiatives require low-level expertise around the underlying sensors, connectivity, embedded components, and ambient services required to drive orchestration, signal detection, and distributed rules. The difference between a provocative “proof of concept” and a fully baked offering lies in a host of nuanced details: understanding the precision and variability of underlying sensing capabilities; MEMS sourcing, pricing, and installation; and wireless or cellular characteristics, among others. To fill knowledge gaps in the short term, some organizations leverage talent and skill sets from other parts of the IT ecosystem.
Adopt an agile approach: Go to market and iterate often. One benefit of all the investment being made in and around IoT is that the underlying technology is constantly improving as existing products evolve and new categories emerge. As you explore possible IoT strategies and use cases, consider using lightweight prototypes and rapid experimentation. This way, you can factor in feasibility concerns, but you won’t be saddled—at least for the time being—with the burden of “enterprise” constraints. As compelling ideas gain momentum, you can then shape your solution, refine the business case for it, and explore it at scale.
Go to market and iterate often. One benefit of all the investment being made in and around IoT is that the underlying technology is constantly improving as existing products evolve and new categories emerge. As you explore possible IoT strategies and use cases, consider using lightweight prototypes and rapid experimentation. This way, you can factor in feasibility concerns, but you won’t be saddled—at least for the time being—with the burden of “enterprise” constraints. As compelling ideas gain momentum, you can then shape your solution, refine the business case for it, and explore it at scale. Enhance your talent model: Just as aircraft manufacturers hire aeronautical engineers to design products and software vendors employ legions of coders with specific skills, so too must companies pursuing IoT strategies hire the right people for the job. Does your IT organization currently include talent with the hardware expertise needed to operate and maintain thousands of connected devices? Most don’t. Before pursuing an IoT strategy, consider enhancing your talent model not only to bring in new skills from the outside, but also to reskill current employees.
Just as aircraft manufacturers hire aeronautical engineers to design products and software vendors employ legions of coders with specific skills, so too must companies pursuing IoT strategies hire the right people for the job. Does your IT organization currently include talent with the hardware expertise needed to operate and maintain thousands of connected devices? Most don’t. Before pursuing an IoT strategy, consider enhancing your talent model not only to bring in new skills from the outside, but also to reskill current employees. Bring it home: Remotely deployed assets and equipment often have starring roles in IoT use cases. But call centers, manufacturing floors, and corporate offices also offer considerable IoT potential. Consider how creating an “intranet of things” might lead to improved workplace conditions and enhanced comfort and safety at individual work stations. Moreover, how might reimagining employee experiences in this way help your company attract new employees and retain existing ones?
The Internet of Things holds profound potential. It is a futuristic fantasy made real—the connected home, connected workplace, and connected government come to life. The sheer scope of IoT carries countless implications for business, both finite and abstract. To sidestep such distractions, focus on solving real business problems by creating bounded business scenarios with deliberate, measurable value. For example, how can you use IoT to get closer to customers or increase efficiency in your manufacturing operations or supply chain? Look for hidden value in your brownfields. Move from strategy to prototyping as quickly as possible. Only real data, actual users, and sensors that respond with actions can demonstrate the remarkable value proposition of IoT.
Deloitte Consulting LLP’s Technology Consulting practice is dedicated to helping our clients build tomorrow by solving today’s complex business problems involving strategy, procurement, design, delivery, and assurance of technology solutions. Our service areas include analytics and information management, delivery, cyber risk services, and technical strategy and architecture, as well as the spectrum of digital strategy, design, and development services offered by Deloitte Digital. Learn more about our Technology Consulting practice on www.deloitte.com.An article by Michelle Canaan, insurance research leader, Deloitte Center for Financial Services, Deloitte Services LP, and Prachi Ashani, insurance senior analyst, Deloitte Center for Financial Services
Global financing of InsurTechs continued to surge with a record $5 billion invested during 2019, which is only five percent shy of the prior two years combined. However, while $19.2 billion has poured into the sector over the past decade, investments have almost exclusively been devoted to the property-casualty side of the business...Continue readingIn the simplest form, IoT technology takes inputs from the physical world, uses digital technologies to derive insights from those inputs, and then makes outputs available for use back in the world. In linking the physical and digital world, the IoT has another impact as well. Traditional physical products create value for customers only by virtue of their performance: A standard lightbulb is valuable based on its brightness, efficiency, and lifespan. With connected objects, information also becomes a key determinant of value: A smart light bulb is valuable not just because it can brighten a room, but because it can enable automation, scheduling, remote controlling, and other abilities.5
Yet, due to possible unfamiliarity with the potential market opportunities, many leaders are taking a wait-and-see attitude toward IoT technology. A recent MIT and Deloitte survey of IT executives revealed that most of their companies intend to leverage IoT-generated data to pursue only small-scope applications aimed at efficiency improvement.6 While it is certainly prudent to start small and scale applications as they succeed, thinking big is also a benefit. And for businesses that need to rationalize initial tech investments, using IoT technology to generate revenue may be the key.
Turning IoT data into money is not necessarily a straightforward process, however: It requires knowledge of customers, and the governance capabilities to take advantage of that knowledge, to be able to offer the right item to the right customer in the right way. To develop these data governance capabilities, IoT players can learn from an industry in which information has long been a primary source of value—software—and explore the monetization drivers that leading firms are leveraging.
Selling technology in the software world has evolved from selling packaged software to selling services, building relationships focused on driving value to customers, and meeting customers’ expectations for flexibility in consumption.7 And from a monetization perspective, this means that new business models are expanding and becoming the norm. For instance, some content management services leverage the “freemium” model: A free service includes a personal account with limited storage and file size, while the premium service allows more storage, bigger file size, more users, enhanced collaboration, etc.8 Other models in the software sector employ pay-per-use (also known as utility) models, monthly subscription plans, and outcome-based models focused on the business value that the product or service delivers.9
All of these techniques can be grouped into three key monetization drivers—usage intelligence, feature-based packaging, and flexible consumption—that form the foundational pillars of top software firms’ monetization strategy (see Figure 1: What drives software monetization?). Executives in other industries can look to these pillars in developing strategies of their own. After all, many companies have little direct experience deriving revenue from customer-generated data, and effectively packaging and pricing products and services can prove challenging.10Sean, a partner at Deloitte & Touche LLP, is the Global Cyber Cloud leader and Cyber IoT leader for the Cyber Risk Services practice of Deloitte Risk & Financial Advisory. He delivers solutions to help organizations address their most pressing and pervasive cyber security challenges for Enterprise, Cloud and IoT environments including Cyber Risk, Cyber threat intelligence, Cyber war gaming, IoT and operational technology (OT) security, identity management, privacy and data protection, and business resilience focused. He has over 35 years of consulting experience and serves some of Deloitte’s largest clients.
Sean is a proven leader with diversified, in-depth experience in consulting and has demonstrated an ability to consistently achieve desired results and provide exceptional value to clients across a variety of business problems, technologies and industries. He specializes in application security; secure systems development; information technology risk management; governance, risk and compliance; and resiliency. His industry experience spans across automotive; consumer products; energy & resources; financial services; health care; life sciences; manufacturing; and media, entertainment & sports.
Sean is passionate about working with the community. He currently serves on the board of directors of YMCA of Orange County and is the chairman of CSUF College of Engineering & Computer Science College Leadership Council.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.August 22, 2018 From ice-cream manufacture to steel making, automated control is a fundamental part of industrial processes. Control technology has been around since the industrial revolution, when centrifugal governors were used to regulate the speed of steam engines. But it was the advent of electrical, electronic, and computerized control technologies over the course of the 20th century that defined the field as we know it today. During that time, three major generations of control technology have evolved. Today, the emergence of an entirely new approach could transform the way companies control their assets.
The first modern, flexible control technology was the programmable logic controller (PLC). Working on the proportional-integral-differential (PID) principle, a basic PLC monitors a single value, say the temperature of a freezer or a furnace, and compare that to a target setting for the machine. Depending on magnitude of the error, its duration and its rate of change, the PID controller output steers the machine, for example by adjusting a valve or changing the power flowing to a heating element or motor.
The earliest PLCs were extraordinarily simple devices by modern standards, but they could do some remarkable things. The PID control principle meant control engineers didn’t need to fully understand the complexities of the process under their care; with just three parameters to adjust, they could often achieve good performance with a little careful tuning. Using more elaborate configurations, such as cascaded control systems in which one PID controller generates the target value for another to meet, these systems could run quite complex processes. They are still widely used today.
The second major generation of control system emerged with the development of personal-computer technology in the 1980s and 1990s. The greater speed and power of these machines allowed engineers to build control systems where numerous inputs and outputs were managed by a single computer, and to connect multiple machines together into networks. These distributed control system (DCS) designs provided a host of benefits for operators, not least the availability of clearer, easier user interfaces and the power to change setpoints from a distance. Under the hood, however, DCS systems ran on the same basic principles as their PLC predecessors.
Toward the end of the 20th century, the availability of more powerful computers led a small number of the most demanding users to take a third step in control technology. These users were typically in industries running operations of huge scale and complexity, such as oil refineries or steel plants. For such applications, even small relative improvements in control-system performance could be worth millions of dollars in additional output, and owners were prepared to make big investments to achieve them.
The approach they adopted replaced the simple principles of PID control with complex and sophisticated mathematical models. By combining theoretical physicochemical models with carefully selected and calibrated sensor data, these advanced process control (APC) systems attempt to determine the current state of the process and decide how it should be adjusted to deliver the desired operating conditions. APC systems work very well, but their high cost means that their use is still limited to a minority of applications, in industries where plants are big enough and similar enough to pay back the enormous development effort required to implement them.
Today, a fourth generation of control systems is emerging, one the promises to exceed the performance of the APC approach at a fraction of its cost and complexity. This new approach uses advanced analytics (AA) or artificial-intelligence technologies (AI), such as so-called machine learning or even deep-learning approaches using artificial neural networks and equivalent methods.
These AA/AI systems work in a fundamentally different way from previous APC technologies. When IBM’s Deep Blue computer chess program beat grand master Gary Kasparov in 1997, it relied on thousands of explicit rules programmed by its designers, much like today’s industrial APC systems. 18 years later, when Google Deep Mind’s Alpha Go program defeated professional go player Lee Sedol, it used no such rules. Instead, the program developed its own strategy by analyzing past matches and playing thousands of simulated games. Alpha Go Zero, a more recent iteration of the company’s program, trained itself to beat its predecessor in three days, purely by playing games against itself.
It is now becoming possible to apply the same approach in industrial control systems, using an AI system that is “trained” using historical process data1. Many facilities have years of detailed records on operating conditions, process settings and the resulting performance. And once they are installed and operating, these systems can on learning, gradually improving their own performance over time.
AA/AI-based control works exceptionally well. Costly APC systems typically provide overall improvements in the order of two or three percent. AI systems can increase the performance of existing APC systems by an additional one or two percent and have boosted non-APC controlled systems by over 30 percent.
AA/AI-based control doesn’t require system designers to model every detail of their process and build complex theoretical models—it learns those intricacies for itself. That means AI can be applied to complex processes with interactions that may not be well-understood. In real-world applications, AI tools have identified issues and improvement opportunities that eluded even experienced control engineers.
AA/AI technology is much cheaper and easier to implement than earlier advanced control solutions. That paves the way for its use by companies with smaller plants or less common processes—especially as the latest generations of technology are user-friendly enough to be placed directly in the hands of the process engineer.
AA/AI control approaches work best alongside people. Capturing the full potential of the approach almost always depends upon a combination of better process steering, technical upgrades to address issues and opportunities identified by the system, and improved performance management. Each of these improvement levers brings roughly one third of the total value at stake, and each requires the input of people with deep process knowledge.
Industrial companies are just beginning to exploit the potential of advanced analytics and artificial intelligence technologies in process control. That won’t be the end-game. Ultimately, the ability of AI to assist the control and optimization of complex systems will unlock entirely new ways to manage not just machines and production processes, but also entire businesses.We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
September 9, 2020 Brian is McKinsey’s partner in charge of global recruiting. He’s been at the firm for 25+ years and started as a consultant before taking leadership roles focused on McKinsey’s people and candidates. He is also one of the firm’s inclusion and diversity leaders and a co-founder of GLAM, McKinsey’s LGBTQ+ network.
Absolutely – very much so! From the beginning of the pandemic, we’ve taken a through cycle approach to recruiting, meaning we continue to hire and have a long term view for our firm, our client service and our ever growing need for top talent.
It is clear our clients need us more than ever right now, so it is important we continue to attract, develop, and retain exceptional people. In terms of roles, we are hiring across the board - from consultant roles for people coming out of school or industry to tech consulting, IT and graphic design.
While many things look different today than they did at this time last year, McKinsey's recruiting process remains generally the same. Our top priority is to ensure candidates have a positive experience as they get to know McKinsey, whether that is in-person or via Zoom.
Long before the pandemic, we conducted some virtual interviewing and events. Starting in March, we had to quickly move all recruiting and our summer intern programs to virtual and we did it. We continued interviewing, hired new people and welcomed incredible groups of interns around the world. My newest proud McKinsey moment is that we honored all offers, including all summer internships and we are now hiring large numbers of new colleagues around the globe.
This summer we worked closely with career service leads at many universities to make sure campus recruiting could continue, even in places where we would not physically be on campus.
When faced with the challenge of COVID-19, we decided to innovate and lean in 100 percent. Instead of looking at this as an unfortunate year with less than ideal circumstances, we are aiming to make this recruiting year better than any other, to look at how we meet new candidates, go to campus, host events and find our new colleagues in totally new ways. We have been calling our efforts Reimagining Recruiting and we’re excited to show candidates how we’re going from best in class in-person events to world class virtual events and interviews. Our experiences this Spring gave us insights and confidence so we invite you to check out our many events and learn more about working at McKinsey.
I am ready for the next step in my professional career and wonder if McKinsey may be for me. What do I do?
To apply for a position, visit our Careers site. We will be hiring thousands of people this year from data engineers to consultants to executive assistants. You may know the kind of role you’re looking for so go ahead and search based on locations, interests, industries or functions.
If you’re not sure what kind of roles we have or which you might be the best fit for, take our quick Find Your Fit quiz.
Once you apply, your CV will be reviewed by a recruiter and you may be invited to play the McKinsey Problem Solving Game. This cutting edge game has been quite popular – hear from a couple recent hires who took it and learn what they liked about it.
In our interviews we look for inclusive leadership, personal impact, entrepreneurial drive and problem solving skills. To learn about how we think of these qualities and how to showcase yours, check out our interview tips and videos.
I recommend thinking about your experiences related to leadership, impact and being entrepreneurial – really bring yourself back to the specific example, and recall details about the challenges, goals and the actions you took. Practice telling your story out loud or with a friend. For interview tips from our colleagues, visit our Careers Blog.
I have hosted many virtual events and done a lot of remote based interviews. Here are my top tips for the best experience:
Eliminate distractions - To ensure you can concentrate, find a quiet room with some privacy. Some people find it helpful to wear headphones to tune out noise.
Gather the necessities and remove the rest - Make sure you have a notepad, pen, and water nearby. Remove resources like a calculator or prepared notes that you would not have if the interview were in person.
Speak up - If you feel stuck, confused or need clarification of what is being asked of you, ask your interviewer to repeat themselves. This is your interview and we want you to be comfortable so you can perform at your best. Though the virtual format has many positive aspects, we can't always read body language or facial expressions well, so we encourage you to speak up, clarify and ask your questions.
The health and safety of our candidates, colleagues and communities is our top concern. Depending on the timeframe and the location, there is a chance we will not meet you in person during your recruiting process. We are, however, monitoring what’s safe and possible in different locations with regard to office openings and safe social connections.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
We use Zoom for our virtual interviews and most of our events. This platform is stable and user friendly, and is used extensively with many clients and internally with our colleagues.
With the click of a link, you will be connected to us. Your interviewer will guide you on any Zoom features you need, and will be there to help in case anything goes wrong.
If you have a disability or require special accommodations, please let us know so we can work together to accommodate your needs.
We know technology can be unpredictable and issues can arise. You will in no way be penalized if something happens during a virtual interview. Our McKinsey colleagues are skilled in using technology and have contingency plans in place. Should you run into issues on Zoom, you can:
We do not expect you to wear a suit or dress formally. We are all in the same situation, and most of us have switched to business casual.
We also understand you may have roommates, pets, or family around – so do we – therefore don’t stress about these matters.
You should have your video on the entire time during interviews. This will help us connect with you, and you with us. Don't worry about your background or setting.
Be yourself! Interviewing helps us learn about you as a person and a potential colleague, and it helps you learn more about McKinsey, our people and what you could do here. We look forward to getting to know you!May 6, 2019 What level of impact can continuous improvement achieve? One of our clients would say ten weeks. Why? That’s how much time they were able to save in their product testing process—cutting the time by more than 80%—through a large amount of small changes to how its engineering and testing teams collaborated.
Continuous improvement is an ongoing effort to improve all elements of an organization—processes, tools, products, services, etc. Sometimes those improvements are big, often they are small. But what’s most important is they’re frequent. Companies that excel at continuous improvement start with the belief that success comes from:
Core to a continuous improvement mindset is the belief that a steady stream of improvements, diligently executed, will have transformational results.
Performance transparency starts with making goals public and cascading those goals (typically a balanced mix of financial and operational metrics) in a way that is tailored to individuals at all levels of the organization. Progress toward goals must be transparently tracked to give the frontline and management clear visibility into what is working and what needs work.
After conducting our Organizational Health Index (OHI) with one of our industrial clients, we saw an opportunity to create greater transparency among different areas of their operations. For instance, the company had capital assets that were poorly utilized, in part because they were shared across multiple teams that lacked the incentive to maximize the assets’ usage.
By instituting an easy-to-understand system to track overall utilization, the teams that used the assets instantly realized that low utilization was a bigger problem than any of them had realized, and it focused their creativity on finding new ways to make the assets more productive—leading to a 20% productivity increase in less than two months.
Knowledge sharing is critical to scale best practices across (and up and down) organizations. One of our clients became adept at deploying small cross-functional teams against any problem to break down the organizational silos that had previously prevented knowledge sharing.
The teams would collocate to promote informal and formal knowledge sharing and were given license to explore every idea and bring in additional expertise as needed. The team had to work together because no single team completely understood most problems “end-to-end.” But by working together in multi-week sprints, they were able to achieve 80%+ cycle time improvements.
Employee involvement is a necessity in continuous improvement organizations. Frontline employees are closest to the work, and thus typically have the richest insights on how their work can be done better. Capturing their perspectives is critical.
When our client struggled with morale among frontline managers, they went straight to the source. Through conversations with frontline management, leaders uncovered issues that needed to be addressed—insufficient onboarding, limited upward mobility and burdensome administrative duties that prevented them from effectively leading their teams.
Working with a coalition of frontline managers, the management team developed a set of focused interventions (many of which were led by managers now empowered to make the changes they sought) to expand opportunities for mobility, leadership development and mentorship, and to reduce waste in their daily workload.
Core to a continuous improvement mindset is the belief that a steady stream of improvements, diligently executed, will have transformational results.
Continuous improvement has helped clients across industries provide greater value to their customers. Are you looking to gain an execution edge for your company? Get in touch with us and check out our upcoming blog posts that will dispel several myths on creating continuous improvement cultures.This blog is part of a blog series around how HR needs to start reimagining their future to thrive in the post COVID-19 world. Click on the button on the right for the full overview of the blog series.
COVID-19 has changed the world, testing organizations’ collective resilience, agility, and adaptability, as it has fundamentally shifted how we work and do business. When there is disruption, there will also be recovery, so how we act in a time of crisis will often determine our long-term impact. It is likely that HR is expected to do the same (or more) with less resources and money. With budget cuts already starting, it is crucial for HR to focus on areas where real business impact can be made. We will most likely never return to “old ways” of doing business, as the pandemic has created an opportunity – or rather an imperative – for HR to focus on value adding activities. Yet, for HR to only focus on added value is easier said than done.
This year’s Human Capital Trends survey (2020) clearly shows that HR organizations are struggling with the prioritization of HR’s work and effort (click here for the full article ‘A memo to HR: the changing role of HR management’). This finding leads to a set of fundamental questions HR will need to answer: Which are the areas where the biggest business impact can be made? Which challenges surfaced during the COVID-19 outbreak and should therefore be addressed today? Where should we focus now that time and resources are limited?At the end of the day, we all want to know who’ll we work with and what makes someone successful at McKinsey. Meet some of our people here.Dr. Dhar is Vice Chairman and US Life Sciences and Health Care (LSHC) Industry Leader for Deloitte LLP leading the overall strategic direction for the life sciences and health care practices, including audit, consulting, tax, and advisory services. He is a respected health futurist and sought-after digital disrupter. Asif helps Governments, Life Sciences and Health Care clients reinvent wellness, solve disease, address pandemics and tackle health inequities. He is also Deloitte’s Lead Partner for the Firm’s US Food and Drug Administration (FDA) relationship and responsible for all work Deloitte performs with and for the Agency. His perspectives on real world evidence, regulatory sciences, digital health, and innovation are sought by clients around the world. Asif’s passion for the LSHC industry is evident in all that he does – as a pioneering thought leader who helped establish a framework for the Future of Health, formed ConvergeHEALTH, an award winning life sciences and health care software solution, and helped frame numerous COVID-19 health-oriented reboot and recovery solutions. He advises some of the world’s most innovative companies and Governmental agencies tackling disease and public health.Developing a successful strategy is essential to simplifying the complexities of transformation. These key areas to consider can empower your transformation strategy and clarify the road ahead for digital controllership.Process. Regulatory complexity is another factor. The growth and complexity of the requirements are continual challenges as businesses aim to meet the needs of external auditors, regulators, management, and others.
Technology. Lack of innovation is an issue as well. Many technologies are coming on the scene that are designed to make compliance processes more efficient and shed new light on the vast amounts of data now available in most organizations. The challenge is tapping into those capabilities, given budget and resource constraints, and beating the ever-ticking clock as companies approach their next compliance deadline.
Talent. As the Dbriefs audience indicated, many companies struggle to find and retain the right resources and skillsets. It’s often a challenge because, many times, SOX compliance programs serve as a feeder to the rest of the organization. That’s great for the overall business, but it makes it difficult to align the right people, with the right skillsets in the most meaningful way.Insert Custom CSS fragment. Do not delete! This box/component contains code needed on this page. This message will not be visible when page is activated.This blog is managed by Deloitte AG, a company registered in Switzerland with registered numbers CHE-101.377.666, with a registered office at General Guisan-Quai 38, 8002 Zurich, Switzerland.
Deloitte is committed to protecting your information by handling it responsibly and safeguarding it using appropriate technical, administrative and physical security measures.
We may collect or obtain information about you that you provide to us, that we obtain from third parties or that is publicly available, or which we infer from the way you interact with us.
For more details on how Deloitte handles and shares your information and for details on your rights and how to contact us, please click here.Michael leads Deloitte Consulting LLP’s Learning Consulting practice in North America. He focuses on working with global clients on building high-performance businesses that drive growth and optimization through talent and learning. Prior to joining Deloitte, Michael led the Learning Strategy business for a Big Four firm and was the head of training for a major online retailer in the UK. He has more than 20 years of experience leading key programs at market-leading clients, including running the learning and change management office for a top-tier merger in the Financial Services industry and driving learning transformation for a global brand in the food and beverage industry. Michael has presented at the Chief Learning Officer annual conference and has won learning program awards with his clients. He also lectures on learning at NYU School of Continuing Education.People are the heart of every business, and when it comes to M&A, tackling the human side of things can make all the difference between continued profits and potentially massive losses. Learn how Deloitte Digital helped Verizon Media successfully integrate two sales teams by putting their people first.Serves clients on a broad array of topics ranging from strategy to organizational design and transformation across industries, including consumer goods, retail, and fashion; leads our organization design work and helps companies through multiyear organizational transformations, focusing on bringing operating models in line with the realities of the markets, strategic shifts, and other success factors
Advises leading global companies in the consumer industry and other sectors on how to optimize organizational design and operating models to improve performance and culture, and boost organizational agility
June 8, 2020 Executives agree: The digital revolution will change the way their organizations operate. According to a McKinsey Digital Quotient survey from April 2019, 93 percent of executives believe that digital is critical to achieving their strategic goals. Even though organizations have been digitizing for decades, the digital revolution is still fairly new. Not only is the speed of technological progress often underestimated, but it is also getting increasingly faster.
Key digital technologies, such as automation, artificial intelligence, advanced analytics, the Internet of Things, and augmented and virtual reality, are constantly evolving. These technologies offer more groundbreaking application areas and will increasingly be implemented throughout the entire value chain. Against this background, corporations need to fundamentally rethink their organizational setup and embed digital in their DNA in order to remain competitive and reap the benefits of emerging technological opportunities.
However, few companies are set up for taking advantage of the new opportunities offered by digitization and for mastering the challenges that come with these. Nine out of 10 CEOs believe their organization is currently not ideally set up. Most companies focus on adjusting and extending their offerings to more digitally enhanced products or services. On the other hand, just as important, organizational implications are often neglected.
Adjusting the organizational setup to embrace digitization drives significant improvements in the financial performance of organizations. As indicated by McKinsey’s Digital Quotient Benchmark, corporations that adopt a digital-ready setup can quadruple their five-year Revenue CAGR and almost triple their five-year Total Return to Shareholders CAGR compared to corporations that do not foster and prepare for such organizational change.
In order to capture the potential of digital opportunities, organizations need to make fundamental design choices along three dimensions:
Structure Does the organization have a dedicated chief digital officer (CDO)? Is there a digital Center of Excellence (CoE) shaping digitalization centrally, or does every business unit have their own digital unit? Do we stay within existing structures or move towards a value-driven agile setup?
People Should the organization build digital skills internally through large-scale re-skilling, build on an external digital ecosystem of talent and partners, or a combination of both? Does the organization go for digital skill density with individual top performers or digital skill breadth across the organization? How do we best leverage our ecosystem of partners to get access to capabilities across the value chain?
Process Do we stick to today’s ways of working, or do we adjust ways of working and the culture coming with these? Should a phased or a big-bang approach be taken to organizational digitization? Are our business processes set up in the right way to meet the expectations of the digital era (e.g., intuitive interfaces, around-the-clock availability, real-time fulfillment, personalized treatment, global consistency and zero errors)?
An example of a European e-commerce player we served epitomizes how well a digital organization can hit the ground running, when structure, processes and people are all adequately addressed by the transformation.
On structure, the company at hand replaced the central digital department with dedicated tech employees staffed to cross-functional teams of buyers and software engineers, operations managers, UX designers, and brand managers throughout the entire organization. This new structural setup ensured that digital was embed in every function.
On the people side, a significant investment was made as the new organizational setup required a new set of skills. Some existing roles became redundant and new roles were created.
With respect to process, the entire process landscape was mapped, stack ranked against digitization impact and embedded into an end-to-end digitization process. In addition, the newly formed teams had to be steered in a completely new way, going from rather rigid, hierarchical processes to agile, output-focused, tech-driven ways of working.
The extent of organizational adjustments needed to meet the requirements of digitization can differ significantly from company to company and will take some time to implement. Nevertheless, in times of the digital revolution, they are of fundamental importance in order to maintain and expand a relevant position in the market.Consulting is the process of helping clients solve their most pressing business problems or issues. Consultants are enablers. We work across a wide range of roles, industries, and geographies to apply our methods of analyzing information, and to identify a new, positive way forward for our clients. Working at a fast (and sometimes unpredictable) pace, no two days or two journeys of a consultant are the same.
A consultant’s day is highly variable depending on the project and role. Your day can vary from building slide decks, designing business processes, or presenting status updates to the leadership team. It keeps us on our toes and allows everyone to stretch their skills and become more adaptable.
Diverse project work is one of the biggest perks in consulting as you get to try out different roles and industries all the while at the same job. With opportunities that range from working with smaller “mom and pop” shops to working with some of the largest multinational companies in the world, consultants get a crash course in dealing with an array of complex business challenges from the perspective of senior leaders and executives. Some of our clients produce cutting-edge technology products, and more than likely, you’ll get an opportunity to experience the products first hand. For example, imagine being coached on how to take a “drelfie”, your very own selfie taken by a drone! No selfie stick required.
As consultants, Excel and PowerPoint are admittedly our go to tools on a day-to-day basis to help synthesize multifaceted ideas to clients in a digestible, actionable manner. However, you do not have to be an Excel whiz or a PowerPoint master in order to work in consulting. Soft skills are highly important to communicate your ideas and manage client expectations, both of which are equally important when working in consulting.
Consulting also allows you to grow your skills amongst some of the best and brightest professionals, all of which are extremely motivated and happy to help at any time. We travel together, work together on client sites and get to know each person’s quirks and coffee orders. We work hard, but have fun while doing it.
All in all, there is no easy answer to the question of what is consulting, just like there is no easy answer to the problems that we are hired to solve. At Deloitte, you are given the skills, support and guidance in order to craft the career you want and truly define what consulting means to you.
Stephanie graduated from the Ivey Business School with an Honors Business Administration. She is currently a Business Analyst at our Vancouver practice.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.Advises leading organizations on how to strengthen their talent-management capabilities and build an HR function that operates as a true strategic partner and value driver for the business
January 23, 2018 The core of HR 3.0 – McKinsey’s vision for the future of employee-related activities – focuses singularly on driving value from talent. But let’s be candid: HR will not have the bandwidth, resources or credibility to achieve this goal unless it delivers smooth and continuous customer service.
To provide such stellar service, HR must employ technologies that are changing how consistent process execution and excellent customer care are delivered.
The biggest workplace disruptor is next-generation automation technologies. The McKinsey Global Institute estimates that nearly half of all work could be automated with current technologies.
For HR, intelligent process automation, which includes artificial intelligence and related new technology advances, can help deliver consistent people processes – something that has eluded many HR operations teams given the dynamic nature of the requests they receive.
Cost savings also materialize through deploying such technologies as robotic process automation, machine learning and cognitive agents. Our analysis suggests that 56 percent of typical “hire-to-retire” tasks could be automated with current technologies and limited process changes.
Robotic process automation is the most mature technology. Its use of software with AI and machine learning capabilities to handle repeatable tasks that humans have traditionally performed is already changing the delivery of HR services. For example, a leading consumer packaged-goods manufacturer deploys bots in its hiring process, starting with onboarding new employees (by, for example, porting application tracking system data over to the HR information system).
With time, opportunities will abound to automate more elements of the hiring process. For example, a bot can draft offer letters, write job descriptions or set up payroll and benefits data. And beyond robotic process automation, cognitive agents can potentially transform the interaction between HR and employees. Always-on chat agents can answer questions instantaneously and be available on employee phones – a better service experience than calling an HR hotline.
Consider the experience of a fast-growing tech company hiring employees rapidly and generating numerous offer letters. Those letters were drafted manually and required many quality checks to ensure compliance and accuracy. The company deployed a bot to automate the entire process, generating an offer letter that pulled information from several systems. Compliance and accuracy checks built into the programmed workflow limited human involvement to the occasional exception and quality control.
The result: Processing time fell 66 percent, compliance improved and four full-time employees moved to more value-added work. Given the generally low cost of bots, the business case for automation is clear – and the service impact is equally apparent. Beyond the measurable impact, faster turnaround time is likely to improve job offer acceptance rates. That would dwarf automation’s potential productivity value.
Still, some important caveats exist. HR has fewer opportunities to carry out more mature automation technologies, such as robotic process automation, than some other support functions, particularly finance.
On their own, only the largest HR organizations would likely possess the transactional base to justify the robotic process automation learning curve. What’s more, many automation technologies require a portion of people’s time, so capturing the opportunity requires real transformation of process and organization.
However, as part of a broader enterprise strategy, HR can and should be a significant deployment opportunity for automation technologies. For example, HR should be part of the charge to automate customer service, particularly at larger organizations with sizable HR call centers.
As technology continues to transform the world, HR clearly must be part of that change, embracing robotic automation and other technologies that promise greater efficiency, superb customer service and significant cost savings.You could spend all day searching for valuable information online. Or you could go directly to the trusted news and analysis you need to stay informed, stay connected, and make smart business decisions. The Deloitte Insights mobile app brings you the best of business insights: Deloitte articles and research, Dow Jones news, and real-time market updates, all side by side and readily available on your smartphone.
Read Deloitte Insights in line at the airport. Browse news waiting for a meeting to start. Check markets any time. Search by industry or topic for a quick, curated collection of news, analysis, and specialized content. The Deloitte Insights mobile app gives you one easy place to get up to speed quickly on what’s happening today and stay smart about what matters most to you and your business.
You can personalize your profile to focus on topics and industries you need to stay on top of and receive notifications about relevant new content based on your interests. View a customized content feed and save content of interest for quick reference under the My Insights tab. Get live updates on equity, currency, and global markets, and create a personalized watchlist of US stocks.We have entered a pivotal point in history that will likely create unprecedented challenges for companies of all sizes and in all sectors. While it will take time and effort, this crisis can become an opportunity to move forward. More than two months have passed since the World Health Organization (WHO) declared COVID-19 a pandemic. Since then, biopharma companies from across the globe have been racing to deliver needed supplies and develop new vaccines and novel therapeutic interventions. We are seeing unprecedented levels of cooperation among many of these companies as they seek first to help patients.
While nearly 135 vaccines are now in the research pipeline, developing, testing, and approving an effective vaccine is expected to take up to 12-18 months (as of mid-May, 2020). However, some drugs and antiviral treatments could be repurposed for treatment of COVID-19 much sooner. More than 215 novel and re-purposed therapies were in the pipeline in mid-May.2 Once effective antivirals have been identified and approved, drug manufacturers will need to rapidly scale up production and distribution capabilities to meet a massive demand.
The pandemic is affecting most parts of the pharmaceutical ecosystem—from supply chain to research and development (R&D) to commercial operations. Although pharmaceutical companies typically have a sufficient reserve of supplies to deal with supply chain disruptions, we are in unprecedented times. While the coronavirus forced some drug factories in China to close, manufacturing disruptions have not yet been substantial, and production has since resumed. For branded drugs and biologics, travel restrictions, quarantines or worker illness, and changes in demand could be disruptive. Branded drug sales, for example, could slow as patients opt to delay new treatment starts or elective medications. Moreover, some next-generation therapies might not be available to patients if hospitals don’t have the resources to prep and treat those patients.
Along with searching for new vaccines and therapies to prevent and treat COVID-19, pharmaceutical companies should also continue day-to-day business operations including R&D. But some pharmaceutical companies have had to slow or stop patient recruitment for clinical trials to reduce the risk to patients who could be exposed to the virus. Some companies are delaying trials and opting not to launch new ones to reduce the burden on health care systems.3
Many commercial field teams are now working from home. Market access and medical teams that are accustomed to meeting customers in clinical settings should be selective and thoughtful about how much to engage critical health care resources.
Once this health emergency passes, we expect biopharmaceutical companies will find themselves on an accelerated path to the future of health that Deloitte envisions. Our response to this global outbreak is already changing business processes for pharmaceutical companies in the following four areas:
1. Greater focus on vaccines and prevention: Biopharma business models could look much different by 2040. Twenty years from now, we expect that biopharma companies will place greater attention on early detection and prevention, which means the onset of some diseases could be delayed or prevented altogether. Biopharma companies are already turning their attention to the development of more vaccines and anti-virals. Lessons learned from this pandemic could lead some biopharma companies to shift R&D investments to prevention of infectious diseases.
2. Increased adoption on artificial intelligence (AI): In response to a request from the White House, five large research organizations released an open research dataset of scholarly literature about COVID-19, SARS-CoV-2, and the coronavirus group.4 Artificial intelligence (AI) could be used to mine the data—which includes nearly 40,000 machine-readable articles about the virus, the disease it causes, and other viruses in the same family—to learn more about COVID-19 and potential treatments. AI could help speed drug discovery by analyzing research data more effectively and screening chemical libraries, de-novo drug design, drug repurposing, and pre-clinical testing, according to a November 2019 report from our colleagues in the United Kingdom. Some biopharma companies that have vaccine and/or infectious disease experience are partnering with AI drug-discovery companies.5
3. Smart automation: Like many industries, pharma is quickly learning how much work can be done remotely, or with fewer onsite employees. Some manufacturing sites have increased the space between workers or are considering more shifts to spread workers out and minimize the risk of spreading infection. While some manufacturing employees always need to be on-site, the pandemic has illustrated how many jobs can be done virtually. Sales teams, for example, can no longer visit hospitals and other clinical settings. In response, some pharmaceutical reps are conducting online meetings with their clients. As more work is done virtually, companies should consider strategies to ensure customer-engagement, productivity, and a sense of team among employees.
4. Digital clinical trials: The need to limit potential exposure to the virus has brought the idea of virtual/digital clinical trials to the forefront. Research facilities tend to be located in metropolitan areas, which might be difficult for some people to reach and could create a risk of exposure to patients who might already be dealing with an illness. The process for recruiting and retaining patients for clinical trials has changed little over the past 30 years, as my colleague Dawn Anderson explained in a recent blog. But many facets of a clinical trial could be done remotely through the use of connected digital devices and the internet. Virtual clinical trials could lead to deeper pools of potential candidates, improve convenience for patients, and lead to more efficient trials. Further, some companies are now exploring new ways of delivering clinical supplies directly to a patient’s home, rather than from the site of the clinical study. We are optimistic that when we recover from this crisis, there will be even faster adoption of the technologies and approaches needed to make digital clinical trials a reality.
5. Regulatory flexibility: FDA, the European Medicines Agency (EMA), and other regulatory bodies have acted to protect both patients and clinical staff involved in clinical trials by relaxing some rules. Both agencies have emphasized the importance of patient safety. FDA recently created a special emergency program, called the Coronavirus Treatment Acceleration Program (CTAP), to approve possible COVID-19 therapies more quickly.6 On March 30, the US Department of Health and Human Services (HHS) announced that its Biomedical Advanced Research and Development Authority (BARDA) is working with a division of Johnson & Johnson to accelerate clinical trials for a COVID-19 vaccine.7 We could see more private-public collaboration in response to the pandemic.
Once the world recovers from this global pandemic, there will be a new normal. We expect the biopharma sector will help lead us through this emergency and will come away with new and more effective business processes that can help prevent future pandemics
1. HHS accepts donations of medicine to Strategic National Stockpile as possible treatments for COVID-19 patient, HHS.gov, March 29, 2020
3. Amid coronavirus, disruptions to clinical trial, drug development, accelerate, STAT, March 23, 2020
4. Call to action to the tech community on new machine-readable COVID-19 data set, White House press release, March 16, 2020
5. Catching up to coronavirus: Top 60 treatments in development, Genetic Engineering & Biotechnology News, March 18, 2020
7. HHS Accelerates Clinical Trials, Prepares for Manufacturing of COVID-19 Vaccines, HHS, March 30, 2020Take a look at those new, ultra-successful companies that have, seemingly, come out of nowhere. They may have started on a shoestring budget, with a skeleton staff, but they have the potential to scale rapidly, and almost infinitely, and to grow exponentially. They do things that older, more traditional companies sometimes can’t. Things that traditional companies wish they could do. They tend to respond to market demands more quickly. Their customer base is growing, while those of traditional companies may be on the decline. In many cases, influencers hawk products from these new companies.
Why? Because they are what many old-guard companies are not: they’re agile. Both traditional and new companies can anticipate changes in markets, but the difference is the newer, more agile companies can change direction quickly and seize opportunities. They often operate with higher margins and shorter lead times at earlier stages in their business lifecycle. Further, they can increase or decrease their tech footprint with growth or contraction and launch platforms and systems in new markets. Finally, they can manage their support systems from a single console anywhere in the world.
So, how do traditional companies deal with competitors they may not even see coming? They become perfectly scalable. And they do it quickly, before their competitors achieve the size and scale to dominate their sector. Here’s what that perfectly scalable enterprise (PSE) looks like. A PSE uses technology to leverage access to excess market capacity, align cost structures with growth, and efficiently use scarce resources to achieve economies of size and scale.
PSEs automate everything they can. They limit the impact of poor decisions and capture growth opportunities. PSEs also focus on avoiding waste and outsource wherever possible. Their financial resources are well-managed, and they target wide-moat competitive advantage plays to drive and sustain success.
PSEs can also launch digital products and services at a global scale with faster time to market. They use data-driven insights to enhance their agility, and minimize upfront capital investments, sunk costs, and technological obsolescence. Simply put: they epitomize enterprise agility.
How do companies become perfectly scalable? First they reimagine their business in a world powered by advanced technology. They redefine competitive barriers, realign partner networks, promote an innovation-based culture, and strive for operational and financial efficiency and flexibility.
For instance, a US-based health insurance startup leveraged the cloud to innovate by scaling its business and guiding customers towards better care by helping them more closely track their health. The company built and deployed its new cloud-based, HIPAA-compliant health insurance platform and analytics solution in less than three months.
They have been able to easily manage enormous usage spikes during open enrollment season, disrupting incumbents, and demonstrating the ability to scale to meet demand—and do it with a lean team to continually deliver value by better meeting business needs and improving the customer experience. The platform also afforded members to realize superior outcomes while reducing the associated cost of health care.
Clearly, the cloud is a key strategic choice that underpins the capabilities of a PSE and can help transform their business, and PSEs know that. PSEs value speed to market as a competitive differentiator, and they know that the cloud is the engine for that. It connects. It improves. It evolves. It integrates—at speed—enabling PSEs to start scaling quickly.
PSEs leverage the cloud to enhance their inorganic growth strategy. With cloud-based technology, they can acquire, integrate, and divest businesses more easily—and they can increase enterprise agility and simplify transformations—all keys to disruption. To that end, PSEs with an eye toward future M&A opportunities use cloud-based solutions to reduce future integration or divestiture costs, increase post-deal transition flexibility, enhance business agility, reduce risks, and facilitate a quicker exit when it’s time.
PSE’s use the cloud to make their technology operations more effective. They automate to drive improved productivity, increase accuracy, minimize waste, and enhance business results. PSEs use cloud-based automation technologies to improve operational spend and time-to-market by employing methods and tools that drive improved business outcomes—things like DevOps, self-service, auto-provisioning, integration platforms as a service, continuous integration and continuous development (CI/CD), microservices, and containerization.
PSEs also understand that deploying cloud solutions provides a quicker route for disruptive innovation, because it allows them to focus resources on finding solutions and delivering value, rather than engaging in capacity planning, procurement, and commoditized infrastructure management.
For example, a US-based financial services startup used the cloud—deployed by a lean team—to create an innovative, massively scalable securities trading app with strong built-in security and compliance features that supported hundreds of thousands of users at launch.
The app has disrupted the industry and is successfully competing with incumbents by offering no-fee securities trading capabilities, supported by a highly-scalable IT footprint. The startup is further exploiting the cloud to grow their online business, deliver and update their mobile trading app, securely store customer information and trading data, and perform advanced business analytics.
The bottom line? The competitive landscape is challenging. New, nimble companies are entering the market faster, with the latest technologies at their disposal—and potentially with little to no technical debt to prevent them from making significant strategic moves domestically and globally. Essentially, they are starting off as perfectly scalable enterprises.
Because they’re perfectly scalable, they have many choices—and limited downside if it doesn’t work out–which sometimes happens. Technology is a great equalizer, and acquiring the technology to become more flexible and scalable is critical to success. Getting smart on the cloud is a sound strategy to get perfectly scalable.Transforms large industrial sites and organizations by implementing the latest performance-based approaches and leveraging the core principles of organizational health to ensure sustainable change.
As a senior expert in culture and change, a facilitator, and a coach, counsels public- and private-sector leaders on building values-driven systems
July 15, 2019 The new CEO of a major multinational organization inherited a crumbling empire. Declining performance. Unsuccessful product launches. Leader infighting. A complete lack of strategic direction.
He could have jumped straight into market analysis or strategic planning to transform the organization. But he took an unconventional approach. The CEO’s first move was to reach out and listen to hundreds of people at all levels of the organization to set a new, organization-wide aspiration addressing both business performance and culture.
Why is it so important for the aspiration to be the priority in a transformation? In short, an aspiration is the foundation and catalyst for everything else that follows. Research from the book “Beyond Performance 2.0” found organizations that align on a clear aspiration across both performance and culture increase the odds of their transformation’s success by 300 percent.
Many books have been written about setting a strategic business performance aspiration, but how do you approach setting a cultural aspiration? Organizations can follow a four-step process. The first two steps are about developing an objective, science-driven perspective on the culture that will make the biggest difference to business performance. The last two steps are about translating data-driven insights into the language of that organization.
Align the organization with a successful cultural recipe. Leaders can select from a set of cultural “recipes”—the combination of complementary behaviors that have an outsized impact on building a performance culture. Our research found that the highest-performing organizations align with one of four recipes: leadership factory, market shaper, execution edge and knowledge core. Senior executives can orchestrate an organization-wide conversation around the recipe that best fits their organization’s industry and organizational strategy. Prioritize critical behaviors. Once aligned on a cultural recipe, leaders should select 6-10 behaviors to emphasize. Our research identified four management “power practices”—personal ownership, role clarity, strategic clarity and competitive insights—that are particularly important because they have a multiplier effect on the culture. Executives should both fix the broken practices and build on the core behavioral strengths of the organization. Agree on the cultural themes. The selected practices can then be grouped into cultural themes that embody the organization’s mission, vision, values and purpose. These themes guide the decision-making process of employees at all levels—from the CEO to the front line. The organizations that do this will often have fewer themes—some as few as three. These themes reflect and signal the management’s core commitments, which will help galvanize the whole workforce to build the organization’s culture. Set behavioral expectations for everyone. The last step is about translating the prioritized behaviors into a language that employees at all levels of the organization can understand and relate to through either a leadership or competency model—usually with no more than 15 behavioral competencies. This leadership model becomes the articulation of cultural aspiration specific to that organization. Leaders can then select a few behaviors—around 3-5—to focus on each year. We will discuss how to change these specific behaviors in subsequent posts.
When organizations follow this process successfully, their cultural aspiration is anchored in the performance objectives, based on data science, and written in a language that excites the entire organization.
For the multinational organization, the initial focus on setting a cultural aspiration has paid off handsomely. Performance improvements have continued steadily for the past five years, and its stock price has tripled. Most importantly, the aspiration has excited and engaged staff across the enterprise, unlocking creativity and innovation.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.Insert Custom CSS fragment. Do not delete! This box/component contains code needed on this page. This message will not be visible when page is activated.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.Insert Custom CSS fragment. Do not delete! This box/component contains code needed on this page. This message will not be visible when page is activated.By Jay Zhu, managing director; Robert Maul, senior manager; and Erich Sachse, senior manager, Deloitte Consulting LLP
Medtech has historically relied on a hands-on, face-to-face sales model where field sales forces communicate value propositions and develop deep relationships with key influencers and decision-makers on-site at hospitals and other health organizations.
The COVID-19 pandemic has turned that model upside down. States have issued stay-at-home orders and hospitals and other health facilities have restricted access. In response, many medtech companies have quickly adopted a work-from-home model to protect their customers and employees, and have turned to digital channels to stay connected to their customers.
Outside of medtech, virtual sales is common across a wide range of industries including financial services and technology. Even within medtech, virtual sales isn’t an entirely new concept. For example, a pioneering genomic sequencing company was able to sell a large capital instrument via its e-commerce channel directly without any face-to-face engagement. Many medtech companies have adopted inside sales and digital marketing over the years to enable multi-channel engagement and to reduce selling costs. These tactics have proven effective for some mature products, hard-to-reach customers, and certain activities along the sales cycle.
Despite some success, virtual sales tends to be a small part of the sales model in medtech. Most companies still rely heavily on in-person promotions and have been reluctant to expand the use of virtual selling. The COVID-19 outbreak abruptly flipped the switch for everyone. Some companies and sales people were not as prepared as others. Different skills and approaches are typically needed to engage customers in virtual settings, especially when it comes to new customer acquisition. Rather than reinventing the virtual sales model, medtech companies should look to other industries and learn what has worked.
Greater reliance on virtual engagement among medtech companies will likely be more than a temporary response to the pandemic. Even after the threat of COVID-19 fades, we expect a meaningful portion of the sales process will remain virtual due to continued limited access and lower revenue expectations. In a post-pandemic world, some customers might prefer engaging with sales reps virtually versus face-to-face. Additionally, many hospitals and health systems will likely be under significant pressure to reduce expenses, which will pose revenue challenges for medtech companies. In response, medtech companies should optimize their selling costs by increasing the use of virtual channels. Medtech companies that strategically incorporate a virtual component into their sales strategy will likely be best positioned to recover faster than their peers and thrive in the new landscape.
Converting face-to-face meetings into virtual meetings—that achieve the same or better effect—might require more than a videoconferencing solution. Sales reps and account managers should fundamentally rethink their interactions, and marketing should be empowered to support this new way of engaging customers. Not only should sales teams adapt quickly, they also should do it well. An ability to embed value into every customer interaction will likely separate the winners from the rest of the pack.
As patients return to medical facilities for the elective surgeries and non-critical procedures they had deferred, medtech companies should shift from responding to the pandemic to recovering from it. There are several key actions they should consider to maximize their virtual sales effectiveness:
Assess what has worked, and what created challenges: The initial response to the pandemic forced many medtech companies to pull together emergency plans and adapt their selling tactics. These early strategies should be assessed based on feedback from sales reps and customers. This could help improve the long-term plan for virtual sales. The lessons learned from the respond phase could lead to more effective sales strategies and tactics during the recovery and thrive phases.
The initial response to the pandemic forced many medtech companies to pull together emergency plans and adapt their selling tactics. These early strategies should be assessed based on feedback from sales reps and customers. This could help improve the long-term plan for virtual sales. The lessons learned from the phase could lead to more effective sales strategies and tactics during the and phases. Listen to the customer: The pandemic might have changed the customer’s near- and long-term needs as well as their preferences for engagement. Each customer is likely to follow a different path toward business recovery. Sales reps should listen to their customers and personalize their sales efforts based on the customer’s preferences and unique situations. This should be seen as an opportunity to build a more strategic relationship.
The pandemic might have changed the customer’s near- and long-term needs as well as their preferences for engagement. Each customer is likely to follow a different path toward business recovery. Sales reps should listen to their customers and personalize their sales efforts based on the customer’s preferences and unique situations. This should be seen as an opportunity to build a more strategic relationship. Reimagine the sales process for the long-run: Medtech companies should not try to just virtualize existing sales processes. Instead, they should evaluate their sales processes and customer-engagement models to determine how to segment and engage customers, leveraging virtual sales as part of an overall sales plan. The process should vary by product category. Larger companies, for example, might need to build multiple models for the future sales process. This is an opportunity to rethink and rebalance the go-to-market model to help enable a more modern customer experience and to optimize SG&A during difficult times.
Medtech companies should not try to just virtualize existing sales processes. Instead, they should evaluate their sales processes and customer-engagement models to determine how to segment and engage customers, leveraging virtual sales as part of an overall sales plan. The process should vary by product category. Larger companies, for example, might need to build multiple models for the future sales process. This is an opportunity to rethink and rebalance the go-to-market model to help enable a more modern customer experience and to optimize SG&A during difficult times. Consider a technology ecosystem to help enable and support virtual sales: Many companies were able to quickly ramp up their virtual sales tools to help ensure reps could continue to engage their customers via teleconference or videoconference. In addition to the basic conferencing tools, companies should also evaluate and enhance other technologies such as content management systems, interactive presentation software, virtual whiteboarding tools, ecommerce platforms, virtual reality tools for customer training, and visual assist tools for remote support. We expect virtual engagement will continue after COVID-19, and companies that can deliver a differentiated virtual experience using digital technologies will likely recover faster and develop stronger long-term relationships with customers.
Many companies were able to quickly ramp up their virtual sales tools to help ensure reps could continue to engage their customers via teleconference or videoconference. In addition to the basic conferencing tools, companies should also evaluate and enhance other technologies such as content management systems, interactive presentation software, virtual whiteboarding tools, ecommerce platforms, virtual reality tools for customer training, and visual assist tools for remote support. We expect virtual engagement will continue after COVID-19, and companies that can deliver a differentiated virtual experience using digital technologies will likely recover faster and develop stronger long-term relationships with customers. Refine and update digital content and sales aids: Sales materials and pitch decks used for face-to-face discussions likely will not work as effectively in virtual settings. Creative virtual approaches, content formats, and agile production models can improve speed to market, create a high level of personalization, and increase engagement. Medtech companies should revisit and adapt their sales materials to make a bigger and more memorable impact on customers.
Sales materials and pitch decks used for face-to-face discussions likely will not work as effectively in virtual settings. Creative virtual approaches, content formats, and agile production models can improve speed to market, create a high level of personalization, and increase engagement. Medtech companies should revisit and adapt their sales materials to make a bigger and more memorable impact on customers. Develop virtual sales training and coaching plans: Training will likely be needed as sales teams make the shift to virtual. They will likely need to improve their general digital fluency and master their company’s virtual technologies. Beyond basic training in virtual sales, companies should develop a longer-term plan to continuously enhance their virtual sales capabilities. A shift to digital also offers new opportunities for coaching. Sales managers can observe and assess virtual sales discussions and offer real-time feedback via virtual coaching tools. This can be a great opportunity for reps to log some product training time and schedule regular account-planning meetings with their teams.
Some hospitals and health systems have already begun to restart elective procedures, which could mean the recover phase of the pandemic response is arriving. Medical facilities may be anxious to get their revenue streams flowing again once concerns about the virus begin to subside. As the pandemic passes, we expect each therapeutic area will recover at a different rate and at a different pace. Additionally, the speed of recovery will likely vary based on geography, local government policies and guidance, and each provider’s strategy. Medtech companies that understand the changing demand curve, and strategically prepare for various scenarios, will likely be best positioned for the near- and long-term future.
The pandemic is likely to change the medtech sales landscape permanently. Companies should re-imagine their future customer engagement strategy and optimize the mix of virtual and in-person channels to accelerate recovery and thrive in the new world.October 7, 2019 Albert Einstein once famously remarked, “Today’s problems cannot be solved with the same level of thinking that created them.”
Consider the example of a Latin American consumer goods manufacturer under pressure to change its performance after not having performed well for several quarters. Due to urgency, the chief transformation officer went off to set more stretched targets and created a weekly governance to review performance initiatives with more rigor.
Yes, people worked hard. Yes, at first some KPIs improved, but all of this drained more energy than the results it was delivering. It soon became clear that the people would not last a marathon at the speed of a sprint; they had started to become disengaged.
Like in this organization, most enterprise transformations focus on changing business metrics and, at best, employee behaviors—and not the thinking what created the need for a transformation in the first place. And, not surprisingly, 70% of them fail. Companies with failed transformation programs identify employee resistance or management behavior as the major barrier (72%) to success.
To avoid that statistic, this manufacturer for the first time shifted the focus on the people. What was driving their behavior? What made their eyes shine? What would truly engage them in a transformation? Looking for these answers, the top team discovered that up until then, people were gaining praise for doing new things even if they were not delivering their promised results. They thought that short-term results were more important than satisfying the consumer. And when the time came to choose, they felt that their individual goals were bigger than the company’s. All this was limiting them from participating wholeheartedly in the transformation underway.
In fact, these mindsets, as we call them, needed to be flipped to make things work. Through a set of targeted initiatives, these mindsets were shaken. The people came to realize that satisfying the consumer is what will bring the short-term results. There is no success for the individual if the company is not doing well. And they started to be recognized for executing with discipline focusing on our full potential to deliver challenging goals. Sharing the story of why the transformation was necessary and addressing these mindsets engaged the employees with a whole new level of energy, and only few months later the organization was able to deliver its first quarter back on track and continue the trend.
Companies that take the time to identify and shift deep-seated mindsets were 4x more likely to rate their change programs as “successful,” according to the McKinsey Quarterly Transformational Change Survey, 2010. In fact, mindset shifts are linked to the highest impact behaviors a person wants to change.
Unless you first identify the mindsets, both limiting and enabling your people, your transformation initiatives may be wasting resources, time and energy. Another company, a telco, found that managers spent the majority of performance reviews explaining the complex rating process vs giving feedback. So, the telco simplified the process and rating system, increased frequency of conversations, and provided training on delivering feedback. However, it’s important to keep in mind that “from” mindsets aren’t necessarily bad; many rational, competent and well-meaning people could and do operate in this way.
In the case of the telco, leaders cancelled reviews and/or spent most time on small talk. Why? Leaders actually avoided difficult conversations and focused the feedback on process because they were afraid that criticism and difficult conversations would damage their relationships. Once this mindset transformed into “honesty (with respect) is the essence of building strong relationships,” leaders started to engage in regular, honest and courageous feedback conversations, and focus their feedback on performance.
Addressing the organization’s mindset has a tangible business impact and is the key that opens the door to successfully transforming an organization. In our next articles, we explore how to uncover those mindsets and how to turn them around.In September, the White House issued a new executive order that it says will reduce prescription drug prices.1 At the same time, many states have enacted, or intend to enact, laws that require pharmaceutical companies to create more transparency around their pricing strategies. The complexity of these laws, which vary by state, has created operational challenges for pharmaceutical companies—particularly those that continue to rely on low-tech reporting processes. More than 40% of small and mid-sized manufacturers, and 35% of large manufacturers, use spreadsheets and manual analyses, according to our recent survey of 235 pharmaceutical companies. Most respondents admit there is room for improvement in their company’s approach to meeting state price-transparency requirements.
Rising out-of-pocket costs for consumers—as well as state Medicaid programs—has been a major driver of drug price transparency initiatives. Along with attempting to drive down drug prices, some states are gathering data from drug manufacturers in an attempt to determine the nature of price changes. Transparency laws are typically triggered when the cost of a drug increases by a certain percentage within a certain period (e.g., one year), or when the annual cost of a therapy exceeds a particular amount (e.g., $10,000). When such rules are triggered, manufacturers need to explain the factors that led to the change in pricing. At least five states have enacted laws this year.
Pharmaceutical companies that fail to comply with state drug-transparency laws could face steep penalties of between $1,000 to $30,000 per day, depending on the state. Typically, the larger the company’s portfolio, the greater chance of triggering a law. While not all states have fines associated with the laws, pharmaceutical companies need to track each law and understand their nuances.
Since the COVID-19 crisis began, we’ve noticed that some state laws are getting more (and sharper) teeth, and enforcement appears to be ticking up in some areas. The California Office of Statewide Health Planning and Development, for example, has levied more than $17 million in fines against companies that failed to comply with its reporting requirements. In Nevada, 21 drug manufacturers have been fined more than $24 million for non-compliance. Reports need to be complete and accurate. Some states are closely scrutinizing information and are coming back to the companies if they believe the information is incomplete.
States are also creating commission boards or drug affordability review boards to set pricing caps for select higher-cost drugs, as well as to limit price increases by drug manufacturers, according to a recent report from the Deloitte Center for Health Solutions. Indiana, Missouri, Nevada, New Hampshire, and New Mexico are examples of states that have created these boards. Maine also worked on a Prescription Drug Affordability Board that sets prescription drug spending targets for public entities based on a 10-year rolling average, considering inflation.
Most of the manufacturers we surveyed said their manual processes are not able to keep up with all of the new state laws and changing requirements. Pharmaceutical companies should consider developing new reporting processes to confirm appropriate information is reported to each state to ensure compliance. Moreover, incorporating state price-reporting requirements into drug-pricing decisions can introduce efficiencies, create a more integrated approach to price management, and lead to more precision in forward-looking financial projections.
Automate and scale analytic processes: Technology and automation can be leveraged for reporting (e.g., having pricing and reporting information in one centralized repository via a system or tool that consolidates laws and regulations) along with business and legal interpretations. This can help companies keep up with a wide range of reporting requirements and determine when reporting requirements are triggered. It can also help generate and populate the reports that need to be submitted. Basic tools and mechanisms can include pricing-scenario models, price trackers, and an electronic inventory of each state’s reporting requirements. Automation can populate reports while analytics can help manufacturers make informed decisions about pricing strategies and understand how changes in one state could trigger broader business impacts.
Technology and automation can be leveraged for reporting (e.g., having pricing and reporting information in one centralized repository via a system or tool that consolidates laws and regulations) along with business and legal interpretations. This can help companies keep up with a wide range of reporting requirements and determine when reporting requirements are triggered. It can also help generate and populate the reports that need to be submitted. Basic tools and mechanisms can include pricing-scenario models, price trackers, and an electronic inventory of each state’s reporting requirements. Automation can populate reports while analytics can help manufacturers make informed decisions about pricing strategies and understand how changes in one state could trigger broader business impacts. Integrate software to generate state-specific reports: The ability to generate price transparency reports is a fundamental capability. Software can be implemented to help companies export data files tailored to each state and then submitted via email or uploaded to a state portal. Such a solution automatically updates any new state requirements. Once a triggering event has occurred and a report is generated, technology could ensure it goes through the proper reviews before being uploaded to a state portal—helping to mitigate compliance risk and avoid costly penalties. The system should also store all product and pricing information and qualitative data required by the state.
The ability to generate price transparency reports is a fundamental capability. Software can be implemented to help companies export data files tailored to each state and then submitted via email or uploaded to a state portal. Such a solution automatically updates any new state requirements. Once a triggering event has occurred and a report is generated, technology could ensure it goes through the proper reviews before being uploaded to a state portal—helping to mitigate compliance risk and avoid costly penalties. The system should also store all product and pricing information and qualitative data required by the state. Identify data ownership: Given the complexity and disparate nature of state regulations, pharmaceutical companies should determine who owns the data. We have found that the information needed to comply with state laws often resides in multiple systems within a variety of groups. This can make it difficult to effectively and consistently aggregate data. Determining who in the company is responsible for each piece of information can make it easier to collect data and ensure the process is repeatable. Smaller companies might not have an employee dedicated to tracking the laws. Instead, it might just be a part of one employee’s duties. Keeping up with new or changing rules could become overwhelming. Many companies that have limited resources worry they might miss something because new rules are being put in place so quickly. It’s dynamic.
Given the complexity and disparate nature of state regulations, pharmaceutical companies should determine who owns the data. We have found that the information needed to comply with state laws often resides in multiple systems within a variety of groups. This can make it difficult to effectively and consistently aggregate data. Determining who in the company is responsible for each piece of information can make it easier to collect data and ensure the process is repeatable. Smaller companies might not have an employee dedicated to tracking the laws. Instead, it might just be a part of one employee’s duties. Keeping up with new or changing rules could become overwhelming. Many companies that have limited resources worry they might miss something because new rules are being put in place so quickly. It’s dynamic. Develop processes to manage the complexity of each regulation: It can be difficult to stay on top of new state laws and changing regulations. Many states provide regular updates or frequently asked questions (FAQs) on their websites. An automatically updated central repository for rules and requirements could include the regulations, key elements (e.g., implementation dates and fines), and legal interpretations. This can ensure that information is organized consistently across the states. This could help serve as an audit trail for the overall process from the determination through the reporting.
Management of drug pricing is becoming more complex and government scrutiny is increasing. Transparency requirements are one more aspect of pricing that requires strong insight from analytics and system interoperability. There are broad implications of wholesale acquisition cost (WAC) price actions on product-lifecycle planning, launch strategies, and contracting. This changing landscape means pharmaceutical companies should build stronger compliance and reporting operations supported by automation and analytics to inform the impacts of state regulations on pricing strategy.
1. Executive order on lowering drug prices by putting America first, The White House, September 13, 2020An article by Michelle Canaan, insurance research leader, Deloitte Center for Financial Services, Deloitte Services LP, and Prachi Ashani, insurance senior analyst, Deloitte Center for Financial Services
Global financing of InsurTechs continued to surge with a record $5 billion invested during 2019, which is only five percent shy of the prior two years combined. However, while $19.2 billion has poured into the sector over the past decade, investments have almost exclusively been devoted to the property-casualty side of the business...Continue readingTo help bolster my resume, I quickly studied and became a Microsoft Certified Professional. I figured I was a shoo-in for this entry-level job. Turned out, the school system was Novell-based. I wasn’t hired.
A couple of weeks later I received a phone call from the person who had interviewed me for the position. He called me first because my last name was alphabetically the first on the list of candidates. One of the people he had hired hadn’t shown up on the first day of work. He offered me the job.
It may sound simple. But throughout my career, I’ve succeeded and moved forward in part because people around me know that I’ll be there, I’ll say yes, and I will do what I promise.
In fact, that’s how I ended up at Deloitte. In the years after I was hired for that first IT job, I grew my skills to encompass a range of capabilities, particularly in Cyber Risk. I moved out of the public school system and into the private sector. One day, a previous manager of mine called. He had taken a job at Deloitte and asked if I could meet him and a Deloitte partner at Starbucks. I showed up. And soon after that meeting I showed up for my first Deloitte client, ready to dive into the world of consulting.
In my work in Cyber Risk at Deloitte Risk and Financial Advisory, I have to show up every day for my clients. After all, they have hackers and other threats showing up at their digital doorsteps every day. It’s my job to help them be secure, vigilant, and resilient. If I don’t show up, problems will.
My colleagues and clients know that they can count on me to show up with the right solutions to new challenges. In 2009, I spearheaded the first implementation of SailPoint solutions for one of our clients. To make sure it went smoothly, I spent day and night learning everything I could to become an expert in the SailPoint products. Today I manage Deloitte’s alliance with that vendor—an alliance that we expect to yield more than $50 million in revenues next year.
Make no mistake. Success in this (and any) profession requires a vision of what you want to achieve and many steps along the way in order to get there. I took the long road to a career at Deloitte.
But as you fix your eyes on where you want to be tomorrow, don’t forget to show up where you need to be today.
Anthony J. Berg joined Deloitte’s Cyber Risk practice in 2009. He is the father of six children and his family lives on a hobby farm in north Georgia where they homeschool their kids, raise a few chickens, and Anthony builds furniture. Read more about his career journey.January 16, 2018 Imagine yourself in a beautiful, serene forest populated by many kinds of wildlife. As you take in the flora and fauna, you learn about an urgent matter demanding your attention: the animals are quickly succumbing to an unknown illness. It’s up to you to figure out what to do—and then act quickly to protect what you can.
In November, 520 recruiting candidates found themselves in just this scenario, on their computer screens. They were at our London testing site immersed in a digital, scenario-based assessment designed to understand and measure how they approach and solve problems—in other words, the type of thinking our own people do every day.
As the needs of McKinsey’s clients evolve, our firm is evolving as well, through both acquisitions and organic growth, and we are broadening the types of talent we recruit, including data scientists, implementation practitioners, IT experts, product and digital designers, and software developers.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com Screenshot from “Build a reef” scenario
McKinsey’s standard recruiting process involves evaluating résumés, administering a multiple-choice test, and then interviewing select candidates. “But the multiple-choice test has limitations,” explains Keith McNulty, McKinsey’s global director of people analytics and measurement. “Recruiting only knows if candidates got the right answer, not how they approached the question. Plus, there’s a large amount of strategy, preparation, and luck involved in multiple-choice tests, and if you use them in the selection process, it reinforces the status quo—at a time when you are looking to widen the scope of candidates you’re hiring.”
Our firm has deep experience using in-person, scenario-based assessments (such as case interviews) in recruiting. Yet we miss more nuanced perspectives on the skills of some candidates and miss out on other candidates completely because we can’t meet everyone in person. McKinsey began investigating this problem in collaboration with a start-up called Imbellus, which has a team of data scientists, engineers, and psychometricians who aspire to replace traditional standardized tests and are committed, above all, to science. We also enlisted the help of UCLA’s National Center for Research on Evaluation, Standards, and Student Testing (CRESST) to help identify and measure the skills we need.
The result of this collaboration is a new scenario-based assessment designed to help our firm attract new and different talent profiles from all parts of the world. It not only evaluates candidates in a lower-stress, more engaging environment than a traditional test does but levels the playing field by minimizing the influence of a candidate’s background.
It also provides a lot more insight into a person’s skills. When people analytics are applied to the test results of hundreds of recruits—a fast-growing data set—it can not only help determine whether a candidate is creative but also provide an understanding of a deeper subset of skills. How does this person absorb information? Is he or she an idea generator? Does he take an unusual approach to situations? Is she methodical in her analysis—or tend to follow intuition? Can he easily manage multiple factors? “When people join our firm, we can be more intelligent about placing them in a position—and on a course—that makes sense,” says Keith. “This approach offers, potentially, hundreds of different readings on a candidate and provides literally an anthology of skills.”
What’s next? The team is expanding the pilot to other geographies to collect additional data points before the assessment becomes a formal part of McKinsey’s recruiting practices. Another goal, in the next few years, is to make the assessment available online so we can understand candidates’ skill profiles without bringing them into the office. “This will especially help recruiting in emerging markets,” says Keith. “As a firm, we’re reinventing ourselves and becoming more diverse to benefit our clients. So if the way we serve clients is constantly evolving, our recruitment processes have to as well.”
Meanwhile, back in the forest, more and more animals are exhibiting symptoms, and time is running out. Our candidate chooses a course of action, and the diagnosis is revealed—and so is a way forward for the candidate at McKinsey.March 11, 2019 A national sales organization approached McKinsey with a talent problem. With record low unemployment and higher rates of attrition among its sales people, the organization was struggling to maintain its desired pace of growth while still making high-quality hires. While many organizations often find it quicker and easier to simply add more assessments to the hiring process, the client here wanted a more objective and data-driven approach—one that begins with a clear definition and measure of job performance.
Encouraging the client to start with the end state in mind (i.e., a clear definition of job performance) before adding more assessments may go against instincts to make quick and decisive talent decisions. However, it is critically important to ensure you think carefully about key performance criteria for different roles in order to avoid costly hiring mistakes at scale. The results from this approach are clear: The client realized a 40 percent increase in the quality of hires and a 12 percent decrease in first year attrition after they became more thoughtful and data-driven about hiring.
The client realized a 40 percent increase in the quality of hires and a 12 percent decrease in first year attrition after they became more thoughtful and data-driven about hiring.
This second part of our three-part series dives deeper into three specific steps organizations should take to be more thoughtful about hiring. In the process, we provide solutions to address two common hiring problems we identified in our previous post: the difficulty of measuring performance and the ill-defined view of what success looks like in different roles.
Job performance seems like a simple concept, but it’s surprisingly hard to define and measure for many roles. To help frame the discussion, it’s helpful to think about the ‘what’s and ‘how’s of performance.
The ‘what’s, more formally described as task performance, capture the core technical aspects of a role. For example, for an HR professional, task performance may encompass resolving employee relations issues, designing and executing new hire orientations, and organizing recruiting activities.
The ‘how’s, or contextual performance, refer to the fashion in which technical work is executed. This may include maintaining a positive attitude, volunteering for non-role tasks, and helping and supporting others. While the ‘what’s are role-specific, the ‘how’s will likely be consistent across the organization and should reflect core values and unique means of “getting things done.”
It’s important to consider a holistic view of performance that accounts for both ‘what’s and ‘how’s that drive distinctive value for the organization. For instance, maybe Joe, a sales manager, has the best sales numbers in the company (‘what’s), but he also fails to mentor new salespeople and actually has pushed people to quit based on his toxic behavior (‘how’s). In getting more concrete about performance, organizations need to think carefully about the ‘what’s and ‘how’s of performance and the trade-offs that may exist between them.
In today’s organizations, the challenge is rarely finding performance data—we have far more data than ever—but rather in identifying the “right data” for a given role that accurately captures an individual’s unique contribution to the achievement of organizational goals. Any single measure of performance is likely to be flawed in some way. For this reason, we recommend trying to acquire and combine several different data sources to prove someone is a high performer.
For example, it is well known that sales revenue numbers are significantly impacted by a salesperson’s assigned region. Overreliance on revenue numbers alone would therefore create a potentially biased, erroneous view of who the best salesperson is. When combined with data also showing that this salesperson makes 10 percent more cold calls to generate leads than colleagues, we solidify our view that this person is indeed a high performer.
The business landscape is constantly changing; what works today will not necessarily work one year from now. For that reason, it’s crucial for organizations to continually track and measure all new hires’ performance alongside their hiring assessment results to ensure that the criteria that predicted performance last year continues to do so. If not, it may be time to start back at step one—but this decision can only be made based on accurate, up-to-date data. In the case of the sales organization, not only were we able to reinvent their hiring approach based on a deeper understanding of high performers, but we also created the data and analytics infrastructure to allow for ongoing monitoring and optimization that will serve them well for years to come.
This second part of our blog series has made the case for being thoughtful about defining performance and capturing what success means for a given role. In the final post of this series, we’ll tackle the practical issue of how to select assessments that drive lasting value.A blog post by William Pollard, partner, Deloitte Risk and Financial Advisory and Samantha Parish, principal, Deloitte Risk and Financial Advisory
At a time when practically every detail, major and minor, is being captured in company data, businesses now can take a new, technology-enabled approach to internal fraud investigations: One that's more consistent, defensible, and efficient. Here's a quick look at five insights from our new report on tech-enabled ways to combat fraud:
Different types of investigations are often necessarily conducted by different departments in an organization with limited, if any, coordination or communication among them. The resulting lack of integration can cause potential fraud risks to be missed, improperly identified, and under analyzed. Cross-functional processes and technologies – like shared case management software and data sensing tools – can help internal investigators identify, communicate, and analyze issues through a broader lens. And this can ultimately lead to a better understanding of the true nature and scope of the fraud.
While the use of technology in investigations isn't new, the rapidly expanding and accelerating role of technology and data in personal and professional lives is. When virtually every action people take is being captured digitally, finding the fraud in ever-increasing data sets and sizes is an inherent challenge. It becomes increasingly important to apply a diverse portfolio of tech-enabled investigative techniques and approaches – from business queries to digital due diligence to data analytics.
The types of behaviors underlying fraudulent activities can be reverse-engineered by investigations, data, and business specialists to develop predictive models. If a company clearly understands what constitutes "bad behavior" among its employees, vendors, and other stakeholders, the results of tech-enabled investigations can be used to design algorithms that can predict, detect, and ultimately help prevent that behavior.
It's not unusual for multinational organizations to conduct tens or even hundreds of simultaneous investigations that, on the surface, have no connection to each other. But what if forensic, data, and business professionals in an organization could connect the dots between investigations? What if data sets could be harnessed to identify patterns or trends across the organization? With new tech-enabled investigation capabilities, organizations can develop a broad-based risk profile supported by a library of risk issues that enables the shift from reactive to proactive – and eventually to predictive fraud risk management.
With tech-enabled investigation capabilities, an organization can bring people, processes, and technologies together to seek out and respond to rare events that can cripple the organization. Organizations with predictive capabilities could find problems before they become systemic. And if a rare event does go undetected, the learning's from the event can be applied to preventive measures for the future.
In the fight against internal fraud and misconduct, it's important to remember that data science on its own won't make you victorious. Effective investigations require more than just the right technology support, they need humans with a strong understanding of data science, business, and criminal behavior.
To learn more about how your organization can harness investigation capabilities for accelerated performance, check out Deloitte's Tech-Enabled Investigations Spark Experience.
And please take a moment to comment below or send me a message. I'd like to hear your insights and experiences on using technology-enabled approaches to combat fraud.Our everyday experiences suggest that with other products—such as online commerce, ride-sharing services, or even person-to-person payments and online lending—account opening is generally smoother and quicker. Based on experiences in other domains, consumers, especially Millennials, want more from banks.
However, it might seem that banks cannot do much to improve the account opening experience given the constraints they face.
But is there an empirical justification for this view? We, at the Deloitte Center for Financial Services, decided to find out, using a detailed survey among 3,000 consumers. Some of the findings are shown below. The most notable insight is that even though many consumers are satisfied with the account opening experience with banks, a fair number of consumers, especially Millennials, think the process can be improved.
You may also see this report for more of the survey findings and on what we believe banks can do meet customer expectations in this area. Hint: speed and follow-up.
Please let us know what you think. Do you think banks can do a better job improving the account opening experience, and, if so, how?Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.November 26, 2018 A healthcare organization going through a massive transformation had to assess and consider more than 2,000 high-potential employees for more than 100 critical positions. By identifying the 45 most critical value-adding roles and defining markers for success supported by people analytics, it was able to build a unique competency model tailored toward its values.
For large enterprises that must match many employees to new roles, properly realigning talent to available and high-value positions proves especially daunting and game-changing. The first step requires gaining strategic clarity on the value agenda.
To compete in today’s competitive, disruptive environment and drive business value requires focusing on talent to ensure that the right employee is matched to the right role that will ultimately create the most value.
While this talent alignment is challenging, when it’s done right, rapidly and at scale by a large organization, the outcome can prove to be a significant performance differentiator. These organizations tend to outperform competitors 2-to-1, based on our research.
Taking a more organized approach to talent matching as part of a major digital transformation triggers several advantages:
Time: Faced with hundreds – and often thousands – of employees and roles, a more organized approach saves time when the information is at your fingertips.
Access: Collecting the data and datapoints for each position, as well as the organization’s leaders, digitally is far easier to peruse vs. poring over binders.
Effectiveness: Tactically, keeping track of the myriad choices you make during a digital transformation is difficult. Having a visual means for keeping track of options vs. choices makes clear the impact being made.
Applying this approach ensures that this process, which must occur no matter what, happens in the most effective way.
Whether a company is entering a new market, identifying ways to cut costs or becoming nimbler, HR business partners (HRBPs) must find more effective ways to deploy talent. When proper and efficient talent-matching practices are missing, filling roles rapidly can become a popularity contest. Positions are filled based on who knows who – which can lead to unconscious bias – rather than on identifying the best candidate.
Redeploying talent in a value-focused manner is essential. It must consider knowledge, skills, intrinsic traits and experiences to match the candidates best for each role. We recommend taking these steps:
Understand your value agenda. Begin by aligning with your organization’s ambition and deconstructing what will drive value across departments.
Identify the most important roles. Without an understanding of the most critical roles based on the value agenda and what matters most in each, it becomes virtually impossible to make informed, strategic decisions. Determine what experiences, skills and traits are needed and back it up with data about your talent pool.
When choosing the best candidate for any given critical role, you will need to understand what is required to succeed in that role.
Get the right talent in the right roles. Assess fit and match talent that reflects each role’s markers for success. It’s important to identify your top talent and ensure this stems directly out of the performance management process, using as much data as possible to understand the fit of the employee.
Solutions such as McKinsey & Company’s Talent Match can prove especially useful for aggregating data and supporting recommendations. The tool helped one client develop a companywide database of high potentials – identifying future leaders, enabling talent mobility and highlighting top candidates for each job.
By taking a methodical, visual and data-supported approach to making human capital decisions at scale, the benefits abound for large organizations. This approach saves time and simplifies the process. It also can help organizations combat unconscious bias, enabling leaders to keep track of the available options versus the actual choices that were made.Businesses need to learn innovating, although implementation of new solutions may be risky, difficult and bring unpredictable effects. In the beginning, performance may be lower than expected, or different, but mistakes are good teachers. Using proven methods, we can mitigate risks and learn faster.
Innovation does not “happen”; it is not the question of money, either. In order to prepare ground for innovation, an organization should focus on changing its own business and make it client-centric, developing creativity-fostering environment for its employees, at the same time giving them enough time and relevant tools.
Innovation stems from actual needs of people, which are defined based on observation, research, brainstorming and on testing of new ideas. The approach reduces the risk related to new solutions and increases the probability of success.To a growing percentage of workers, work is an activity, not a place. The unprecedented nature of COVID-19 has accelerated this trend and forced many companies to adopt a virtual, remote work model to keep business moving. Many organizations are looking to their leadership to build a virtual engagement framework that defines the future of work. But establishing an effective framework may also mean shedding conventions that can hinder success.
A holistic virtual engagement framework can help redefine how work is done, as well as ensure that workers understand their roles and responsibilities and have the support they need. With a virtual engagement framework, it’s possible for workers to be as, or even more, productive than they are with in-office work models.
Employers must nurture talent while improving productivity, so a sound strategy is key to get leadership to agree on the direction and key decisions.
Business drivers : It’s crucial to outline the case for virtual engagement—perhaps operational resilience or improved customer engagement. It’s also key to communicate the benefits—such as increased quality, autonomy, and performance—that talent will realize.
: It’s crucial to outline the case for virtual engagement—perhaps operational resilience or improved customer engagement. It’s also key to communicate the benefits—such as increased quality, autonomy, and performance—that talent will realize. Funding: Securing proper funding is also critical. Standing up virtual engagement may require increased funding in the short term, so any strategy should include that possibility. Funding might be secured more easily if it’s collectively advocated for across talent, technology, and tools. Remember, underfunded efforts often fail, but they can also cost more in the long run since doing it wrong means paying to fix it later.
Securing proper funding is also critical. Standing up virtual engagement may require increased funding in the short term, so any strategy should include that possibility. Funding might be secured more easily if it’s collectively advocated for across talent, technology, and tools. Remember, underfunded efforts often fail, but they can also cost more in the long run since doing it wrong means paying to fix it later. Measuring value: As The Phoenix Project articulates, there are four types of work: business projects, internal projects, operational change, and unplanned work. Unplanned work can stall everything else, which affects the delivery of projects, the deployment of changes, and almost always takes the organization away from meeting goals. Help reduce unplanned work by: visualizing all work to be done (see the section titled, “End-User Computing,” for more), mapping all the actions that should be taken to bring value to the business, eliminating non-value added efforts or work all together, constructing immediate feedback loops, leaving team capacity for the team to solve the problem permanently, and completing tasks rather than increasing the work in progress.
When workers work remotely, working norms change, but those changes can be overlooked. For example, workers need to feel engaged, but that engagement can happen outside the office. So, management must adjust how work is done to accommodate the evolving workforce.
Setting the tone: Leaders in the office typically create the virtual environment that increases productivity as well as worker satisfaction. Work culture should be outcome-driven to empower and hold teams accountable for progress. One caveat: success in a virtual setting doesn’t equate with compulsory oversight; instead, it may require consistent pulse checks, feedback loops, and informal engagement to monitor team effectiveness and personal performance.
Leaders in the office typically create the virtual environment that increases productivity as well as worker satisfaction. Work culture should be outcome-driven to empower and hold teams accountable for progress. One caveat: success in a virtual setting doesn’t equate with compulsory oversight; instead, it may require consistent pulse checks, feedback loops, and informal engagement to monitor team effectiveness and personal performance. Communication: Misalignment on communication is a leading reason virtual engagement models aren’t effective. So, it’s essential to choose the right tools for each scenario to minimize work interruptions and drive productivity. Close collaboration between Business, Technology, Information Security to select tools and deploy effectively is a comprehensive effort from training to ways of working. Once tools are selected, establish which channels to use for different needs (e.g., a 1:1 call to catch up, encrypted email for sensitive information or large status updates, chats for quick questions or decisions, and collaboration tools for working sessions).
Misalignment on communication is a leading reason virtual engagement models aren’t effective. So, it’s essential to choose the right tools for each scenario to minimize work interruptions and drive productivity. Close collaboration between Business, Technology, Information Security to select tools and deploy effectively is a comprehensive effort from training to ways of working. Once tools are selected, establish which channels to use for different needs (e.g., a 1:1 call to catch up, encrypted email for sensitive information or large status updates, chats for quick questions or decisions, and collaboration tools for working sessions). Keeping on track: Moving to remote working capabilities means establishing new routines, as well as understanding workers’ daily rhythms. Small, cross-functional teams with clear objectives and a common purpose can keep everyone on the same strategic course.
Talent is the fulcrum of remote work so it’s vital to fully involve workers in the process of creating a virtual engagement framework. Leadership should welcome ideas and details from across the workforce. For example, there might be specific needs or tools that centralized talent groups may not have considered that could amplify teams’ ability to do their jobs. Some key areas to consider are:
Expectations: Leadership and workers can work together to structure expectations on working remotely, including work schedules (e.g., regular, ad hoc, unscheduled, non-consecutive days), duration of virtual engagement, and which roles are considered essential or mission critical.
Leadership and workers can work together to structure expectations on working remotely, including work schedules (e.g., regular, ad hoc, unscheduled, non-consecutive days), duration of virtual engagement, and which roles are considered essential or mission critical. Eligibility: Many traditional occupations are being disrupted by automation, virtualization, or the gig economy. For example, chatbots are taking on increased volume of customer service questions, software engineers are collaborating albeit dispersed across the country, and consultants are picking up ‘gigs’ to increase exposure to different projects. Leadership and workforce representatives can work together to establish criteria for remote-working eligibility that align with business drivers. Start by breaking down job tasks that can be performed remotely. Then review previous performance experience and define the alternative workspace and equipment. These components serve as a foundation for a modernized model where talent has increased flexibility while being effectively supported.
Many traditional occupations are being disrupted by automation, virtualization, or the gig economy. For example, chatbots are taking on increased volume of customer service questions, software engineers are collaborating albeit dispersed across the country, and consultants are picking up ‘gigs’ to increase exposure to different projects. Leadership and workforce representatives can work together to establish criteria for remote-working eligibility that align with business drivers. Start by breaking down job tasks that can be performed remotely. Then review previous performance experience and define the alternative workspace and equipment. These components serve as a foundation for a modernized model where talent has increased flexibility while being effectively supported. Work time: With virtual engagement, work time can be anytime. Therefore, it’s necessary to redefine core business hours across time zones and service-level agreements, as well as to establish appropriate response times for decisions, deliverables and/or requests for operational roles, so that talent is supported while still effectively meeting customer needs.
With virtual engagement, work time can be anytime. Therefore, it’s necessary to redefine core business hours across time zones and service-level agreements, as well as to establish appropriate response times for decisions, deliverables and/or requests for operational roles, so that talent is supported while still effectively meeting customer needs. Expenses: Virtual engagement can be seen as a mirror of the centralized office, so organizations must determine how expenses are allocated and charged for remote workers—including internet, office space, electricity, and other relevant costs (e.g., travel to alternate worksites).
Virtual engagement can be seen as a mirror of the centralized office, so organizations must determine how expenses are allocated and charged for remote workers—including internet, office space, electricity, and other relevant costs (e.g., travel to alternate worksites). Engagement: Managers should be encouraged to have positive, non-work related interactions with workers. All employees need to feel appreciated and inspired, regardless of their physical location. Leaders set expectations on how and when teams engage with each other, and with leaders. Be mindful about access and availability to encourage productivity and well-being, however. Examples include conducting 15-minute check-ins with team members, encouraging video conferencing for working sessions, or establishing light-hearted themes for informal meetings to keep team members engaged.
Remote work no longer equals simply working from home. Now, work can be anywhere from a coffee shop to an airport. To enable and scale a secure remote working experience, there are three critical components for organizations to consider: software-defined networking in a wide area network (SD-WAN), client certificates, and virtual desktop infrastructure.
Software-defined wide area network (SD-WAN): An SD-WAN architecture can improve network performance as demand patterns change. For example, SD-WAN split tunneling can segment different types of network data traffic. The branching prevents bottlenecks in the data center by deciding what traffic to keep in and what to keep out. Another key to scalability is stress testing the network to plan for volume demand changes and understand the organization’s remote networking capacity.
An SD-WAN architecture can improve network performance as demand patterns change. For example, SD-WAN split tunneling can segment different types of network data traffic. The branching prevents bottlenecks in the data center by deciding what traffic to keep in and what to keep out. Another key to scalability is stress testing the network to plan for volume demand changes and understand the organization’s remote networking capacity. Client certificates: Secure sign-on capability is a fundamental issue in remote work. Single sign-on (SSO) can be insecure, while multi-factor authentication (MFA) can be frustrating to workers. One potential compromise is the use of client certificates—a process in which IT generates a certificate that is unique to that user (client) and installed on their device. Client certificates are defined as multi-factor because they are installed on a password-protected device with a unique certificate. Yet, the authentication is treated as an SSO, because the user takes no action on the client certificate. And, if the user's device is stolen, the certificate can be revoked, and the device can no longer authenticate for remote access.
Secure sign-on capability is a fundamental issue in remote work. Single sign-on (SSO) can be insecure, while multi-factor authentication (MFA) can be frustrating to workers. One potential compromise is the use of client certificates—a process in which IT generates a certificate that is unique to that user (client) and installed on their device. Client certificates are defined as multi-factor because they are installed on a password-protected device with a unique certificate. Yet, the authentication is treated as an SSO, because the user takes no action on the client certificate. And, if the user's device is stolen, the certificate can be revoked, and the device can no longer authenticate for remote access. Virtual desktop infrastructure (VDI): Unlike the decentralized management model of a VPN, VDI manages devices on a central server. It can help rapidly recover desktops and images of devices if a user machine fails. Companies can allow users to access VDI from any device, since data stays in the data center. However, greater flexibility for end-users comes at the cost of design, planning, and preparation to implement. VDI often demands a surge in processing power, storage, and memory to scale with high performance compared to VPN. Further, some applications can require configurations and settings specific to individual companies, customers, and divisions. These use cases pose challenges for IT management. The key is to work across the organization to operate at a consistent level of security and access.
The final component of a virtual engagement framework is end-user computing. More than ever, workers rely on all sorts of technology. Access to multiple tools—especially those used for collaboration—is vital in keeping everyone on track, but it’s important to get the basics right. Providing access to collaboration tools, complemented with training, sets up the workforce for success.
Upskilling: Current skills matter often less than the ability to learn new ones. Workers are responsible for becoming familiar with collaborative platforms. However, organizations also bear responsibility for providing education on tools. To encourage tool use, identify opportunities to utilize tools at your disposal so members can gain experience and discover new features.
Current skills matter often less than the ability to learn new ones. Workers are responsible for becoming familiar with collaborative platforms. However, organizations also bear responsibility for providing education on tools. To encourage tool use, identify opportunities to utilize tools at your disposal so members can gain experience and discover new features. Project or backlog management tools: Making work—including knowledge, culture, workflows, and security—visible to the team creates a platform for continued engagement and collaboration. Team-wide access to management tools should be encouraged so teams can visualize the progression of work, track tasks, and create transparency.
Making work—including knowledge, culture, workflows, and security—visible to the team creates a platform for continued engagement and collaboration. Team-wide access to management tools should be encouraged so teams can visualize the progression of work, track tasks, and create transparency. Collaboration tools: Tools to enable collaboration are also essential. Workers must be able to share files, chat in real-time, and collaborate virtually on projects. It’s also necessary to enable video and conference calls through the collaboration system for a comprehensive collaboration platform. A unified system helps teams keep track of documents, work in progress, conversations without having to technology switch constantly throughout the day.
Tools to enable collaboration are also essential. Workers must be able to share files, chat in real-time, and collaborate virtually on projects. It’s also necessary to enable video and conference calls through the collaboration system for a comprehensive collaboration platform. A unified system helps teams keep track of documents, work in progress, conversations without having to technology switch constantly throughout the day. Video chat and messaging: Periodic face-to-face time is essential to maintain team cohesion. The ability to conduct video conferencing across any device helps teams become acclimated to operating in a virtual environment and helps enable more productive conversations between teams and with clients. However, using these tools requires team-wide coordination and focus to stay on track and topic.
Periodic face-to-face time is essential to maintain team cohesion. The ability to conduct video conferencing across any device helps teams become acclimated to operating in a virtual environment and helps enable more productive conversations between teams and with clients. However, using these tools requires team-wide coordination and focus to stay on track and topic. Calendars: Work can happen anytime as well as anywhere, so it’s key to update enterprise calendars to help workers to reflect true working hours. It’s also a good idea to encourage—and institutionalize respect for—dedicated focus time so that workers can be optimally effective.
As with all change, unifying on the purpose and vision of virtual engagement drives a successful execution. Funding and technology underpin the virtual engagement framework. However, turning leaders across business, talent, security and technology into champions of virtual engagement often requires convincing them that productivity and performance will increase. Organizations that master virtual engagement will help transform the future of work by capturing diverse talent, enhancing productivity, and strategically reducing costs, while creating an organization that employees are more than happy to work for.Combines knowledge of digital with extensive experience in IT strategy and transformation to advise clients on all dimensions of digital, agile, and advanced analytics
Sid is an expert in the Ops practice with extensive experience in helping clients solve problems using digital, analytics, and lean Six Sigma tools.
October 18, 2019 Imagine a future where smart robots assemble products from multiple manufacturing lines by physically reconfiguring themselves on the factory floor. Security drones handle tedious tasks ranging from monitoring for intruders to validating employee parking. Autonomous vehicles transport parts not only between buildings, but also across the country. And factory inspections are performed remotely from a thousand miles away.
Just a few years ago, these were impossible dreams reserved for the realms of science fiction. But with the arrival of 5G connectivity, combined with advances in artificial intelligence (AI) and cloud computing, these dreams are becoming increasingly attainable for today’s manufacturing organizations.
The hype is intense. With data speeds slated to be 25 times faster than today’s 4G networks and lag reduced to virtually zero, 5G appears to promise unending opportunities to strengthen connectivity and digitization—both within factories’ four walls, and beyond them at every step along the entire value chain.
But which potential applications deserve manufacturers’ attention? Five show particularly strong potential for boosting factory productivity:
Cloud control of machines —For decades, factory automation has relied on programmable logic controllers (PLCs) that were physically installed on (or very near) the machines they controlled, and then hard-wired into computer networks to ensure precise, reliable control under extreme conditions. If 5G consistently meets its performance promises, the PLC could be virtualized in the cloud, enabling machines to be controlled wirelessly in real time at a fraction of the current cost.
—For decades, factory automation has relied on programmable logic controllers (PLCs) that were physically installed on (or very near) the machines they controlled, and then hard-wired into computer networks to ensure precise, reliable control under extreme conditions. If 5G consistently meets its performance promises, the PLC could be virtualized in the cloud, enabling machines to be controlled wirelessly in real time at a fraction of the current cost. Augmented reality —Factory workers are no strangers to performing complex maintenance and control tasks, often guided by standard operating procedures (SOPs) in paper manuals, videos, or—in some cases—even augmented reality. But instructions streamed over 4G networks can be unreliable due to bandwidth constraints, and fail to deliver the required levels of quality without stuttering. 5G promises not only the streaming of high-quality instructions on the shop floor, but also stutter-free augmented reality that can guide people, step by step, through each individual motion they need to make. This will allow shop-floor workers to undertake advanced tasks without waiting for specialist engineers or incurring costly machine downtime. The best knowledge and work instructions can therefore be shared with all workers exactly when they need it, building worker skills more quickly, safely, and effectively than ever before.
—Factory workers are no strangers to performing complex maintenance and control tasks, often guided by standard operating procedures (SOPs) in paper manuals, videos, or—in some cases—even augmented reality. But instructions streamed over 4G networks can be unreliable due to bandwidth constraints, and fail to deliver the required levels of quality without stuttering. 5G promises not only the streaming of high-quality instructions on the shop floor, but also stutter-free augmented reality that can guide people, step by step, through each individual motion they need to make. This will allow shop-floor workers to undertake advanced tasks without waiting for specialist engineers or incurring costly machine downtime. The best knowledge and work instructions can therefore be shared with all workers exactly when they need it, building worker skills more quickly, safely, and effectively than ever before. Perceptive AI eyes on the factory floor —Cameras are already common in modern factories to monitor processes and security. However, their use is limited to focused applications and often requires workers to monitor video feeds. 5G will allow the streaming of data in real time to the cloud, and the use of live video analytics. For example, a security camera could see a disturbance, identify if there is an imminent threat or danger, and dispatch a drone or alert a worker to investigate. Alternatively, the same security camera could provide a more efficient mechanism to measure cycle times and monitor process deviations.
—Cameras are already common in modern factories to monitor processes and security. However, their use is limited to focused applications and often requires workers to monitor video feeds. 5G will allow the streaming of data in real time to the cloud, and the use of live video analytics. For example, a security camera could see a disturbance, identify if there is an imminent threat or danger, and dispatch a drone or alert a worker to investigate. Alternatively, the same security camera could provide a more efficient mechanism to measure cycle times and monitor process deviations. High-speed decisioning —The best-run factories rely on vast data pools to make decisions—with inevitable delays as data is collected, cleaned, and analyzed. 5G speeds up the decision-cycle time, allowing massive amounts of data to be ingested, processed, and actioned in near real time. In several heavy industries, for example, manufacturers have been able to sell excess energy back to the grid when machines aren’t running and prices are favorable.
—The best-run factories rely on vast data pools to make decisions—with inevitable delays as data is collected, cleaned, and analyzed. 5G speeds up the decision-cycle time, allowing massive amounts of data to be ingested, processed, and actioned in near real time. In several heavy industries, for example, manufacturers have been able to sell excess energy back to the grid when machines aren’t running and prices are favorable. Shop floor Internet of Things—The addition of sensors to multiple machines means factories are creating more data than ever before. Transmission through wired networks is expensive to scale, and Wi-Fi networks can quickly get congested—as anyone who has tried to connect to public Wi-Fi networks can attest to. 5G has the ability to support high connection density with tens of thousands of endpoints, thereby truly enabling the use of industrial data at scale.
These technologies are all still at an early stage of testing, but the pilots undertaken to date are encouraging. Long-term, one of the most intriguing effects may be on the humans who work alongside 5G. Far from creating a world of lights-out, human-free factories, industrial 5G appears more likely to allow people to move away from tasks that have previously been considered dirty, dull, and dangerous. Instead, people’s focus will shift to capturing the value made possible by the vast data harvests that 5G will enable—and that 4G could not reliably and seamlessly support at scale.We are now on the verge of the fourth industrial revolution, and business leaders have to rethink their strategies from end to end. Christian Greiser explains how BCG is partnering with companies around the world to reimagine how they approach operations in today's complex environment.A blog post by Brad Podraza, managing director, Deloitte Consulting LLP and Alec Kasuya, senior manager, Deloitte Consulting LLP
Advanced digital technologies are—and will continue to be—critical for shared services operations. A strong 90 percent of respondents to Deloitte's biennial 2019 Global Shared Services Survey agree or strongly agree that increasing digital capabilities is fundamental to achieving SSC objectives. Automation and analytics are playing a crucial role in delivering the next wave of value for shared services centers (SSCs), and as we move into the next decade, SSCs are set to evolve in ways we haven't seen before.
Increasingly, SSCs are shifting from being a "provider of what they ask for" to a generator of business value, especially as they play more of a role in strategic and interactive-heavy areas like customer service, sales and marketing support, and procurement. The overall findings fall into four major categories:
Digital adoption : Global business services (GBS) organizations are adopting digital rapidly (cloud, robotics, or single-instance ERP solutions have been implemented by more than 85 percent of respondents). They get it—this is a way to position themselves as catalysts for enterprise-wide digital transformation.
: Global business services (GBS) organizations are adopting digital rapidly (cloud, robotics, or single-instance ERP solutions have been implemented by more than 85 percent of respondents). They get it—this is a way to position themselves as catalysts for enterprise-wide digital transformation. GBS organizational structure : As organizations scale up, GBS organizations and GPO implementations become more prevalent, and the largest organizations overwhelmingly leverage GBS operating models (70 percent for companies with >$25B in revenue)
: As organizations scale up, GBS organizations and GPO implementations become more prevalent, and the largest organizations overwhelmingly leverage GBS operating models (70 percent for companies with >$25B in revenue) Cost efficiency : GBS organizations are increasingly expected to provide higher values at lower cost. Hence, cost-efficient measures like automation are top priority for GBS strategy and investments.
: GBS organizations are increasingly expected to provide higher values at lower cost. Hence, cost-efficient measures like automation are top priority for GBS strategy and investments. Location strategy: The largest global companies surveyed are driving delivery through mature markets—in India, Poland, the Philippines, Malaysia, and Costa Rica—while implementation of on/near-shore models (closer proximity to HQ) are a notable part of companies' location strategy.
In summary, we're seeing companies make big investments in SSCs. More SSCs are putting stock in automation and analytics, and we're seeing organizations use automation to reduce or eliminate transactional work. Ultimately, the data shows the realization of two predictions made in the 2017 Global Shared Services Survey report: knowledge-based processes are the growing function of SSCs and they'll do it with the help of automation and analytics.
In the earlier 2017 report, we concluded that "knowledge-based processes were on the rise." Analytics continue to play a central role in SSC's and GBS organization's business strategies. But how exactly are SSCs using analytics in 2019? Around 61 percent of SCCs we surveyed perform at least three of these six analytics processes:
As expected, global SSCs are more likely to use data analytics to gather and aggregate enterprise data (59 percent) as compared to regional SSCs (35 percent). Scale in data matters.
In 2017, when commenting on where digital technology adoption within shared services centers was heading, we heralded, "Here come the robots." The 2019 report confirms: For most SSCs, robotic process automation (RPA) has moved from being nice-to-have to a must-have. Since 2017, the number of companies that have implemented at least one end-to-end process automation has increased nearly eight-fold, with 63 percent of companies today having automated one or more end-to-end process (for companies with revenue greater than $15B, that rises to 75 percent), compared to only eight percent in 2017.
What's more, 88 percent of respondents say they plan to increase their use of robotics in the next 3-5 years, and most SSCs (53 percent) are planning to increase the use of robotics significantly.
What impact is automation having and expected to have? Around 47 percent of survey respondents reported achieving 10 percent or more in cost savings. In terms of productivity, 47 percent anticipate achieving 20 percent or more productivity increase from future RPA investments. Additionally, nearly two-thirds of respondents expect future investments in RPA to reduce or eliminate business process outsourcing and/or offshore SSCs.
Today, only 16 percent and 11 percent of respondents indicate leveraging artificial intelligence (AI) and cognitive technologies, respectively, within their SSCs. We can expect that SSCs will increasingly harness these technologies to enable them to move even faster with greater precision, to pinpoint truths that improve decision-making, and to create more beneficial customer and stakeholder experiences. All this will help further position shared services as a true driver of enterprise value.
To learn more about the state of Global Shared Services Centers, download the 11th biennial edition of the report.Fundamentally, a bot is software—a unit of capacity, a digital worker. Yet it cannot be managed like just another software application, especially when deployed by the dozens, hundreds, or even thousands. Effective digital workforce management will depend on insights from at least five key areas:
Bot performance. After a bot is deployed and work assigned to it, how will you know if the work has been completed? Is the bot delivering expected results? What happens if it gets stuck mid-task? Visibility into bot performance will be important—visibility over and above technical status that many of the vendor tools provide today.
After a bot is deployed and work assigned to it, how will you know if the work has been completed? Is the bot delivering expected results? What happens if it gets stuck mid-task? Visibility into bot performance will be important—visibility over and above technical status that many of the vendor tools provide today. Automation program performance. Beyond individual bots, how is your automation portfolio performing overall? Many organizations focus simply on the "bot count" without monitoring the efficacy of the investment. Important, high-level metrics across the portfolio should include hard and soft dollar returns on investment, full-time employee (FTE) savings, transaction volumes, automation utilization, and maintenance-related results.
Beyond individual bots, how is your automation portfolio performing overall? Many organizations focus simply on the "bot count" without monitoring the efficacy of the investment. Important, high-level metrics across the portfolio should include hard and soft dollar returns on investment, full-time employee (FTE) savings, transaction volumes, automation utilization, and maintenance-related results. License management. As your bot workforce grows, how will you level the workload across the bot population? Optimizing a digital workforce without necessarily having to scale licenses and structure involves visibility into license utilization rates for the RPA program overall, by functional area, and according to prescribed time periods such as by month or hour.
As your bot workforce grows, how will you level the workload across the bot population? Optimizing a digital workforce without necessarily having to scale licenses and structure involves visibility into license utilization rates for the RPA program overall, by functional area, and according to prescribed time periods such as by month or hour. Bot-human interaction. How will you gather input from human workers to make improvements to automation? Effective bot management should include a feedback loop whereby information about automation initiatives is shared with "the business" and they, in turn, provide insights to help troubleshoot bot issues and elevate bot performance to the next level.
How will you gather input from human workers to make improvements to automation? Effective bot management should include a feedback loop whereby information about automation initiatives is shared with "the business" and they, in turn, provide insights to help troubleshoot bot issues and elevate bot performance to the next level. Service management. For companies that use a centralized automation services model to manage bot deployment and operations, how will service levels be measured and reported on? Can service utilization and performance be tracked to identify improvement opportunities?
Visibility into, and management of, digital workforces is an emerging imperative. Tools are being developed to create visibility and governance over automation portfolios. But the bottom line is that you can't effectively manage a digital workforce as if it was a collection of apps. Bots are more like their human counterparts than software applications, so a leading practice for automation programs will be a digital labor management strategy that includes capturing, analyzing, reporting, and acting on a range of data—digital exhaust—being generated by your bot and human workforces.
Developing such a strategy and properly equipping your automation team to execute on it deserves more attention than it may be getting today.February 8, 2019 It’s something every candidate wonders about: the staffing process. How will I be paired with a team serving clients? How much say will I have in the process and outcome?
It can seem like a daunting, mysterious process until you go through it once or twice. Allow us to open the lid and explain how it really works by answering some of the most common questions we hear from applicants and new hires like you.
At McKinsey, we use an office-driven staffing model, focused on helping you build the skills, find the mentors, and strike the balance you need to succeed. Your preferences, goals, and values, and our clients’ needs will be considered every time.
When you join our firm, you’ll be paired with a professional development manager (PDM) and a formal mentor, called a Development Group Leader (DGL). These two supporters will be based in your home office/practice. They’ll guide you through staffing each time you’re looking for a new opportunity. Before you start at the firm you’ll meet with them to discuss your goals and aspirations. What do you want to learn? What types of colleagues would you like to work with? Where would you like to spend your weeks? You’ll repeat this process each time you get ready to begin a new engagement.
Early in your tenure, your PDM and DGL will encourage you to explore: topics, problem types, engagement durations, team structures, people (with different leadership styles), etc. They’ll pair you with leaders from your office or practice who will help you connect locally and become your foundation. They’ll strive to staff you in your home city at least some of the time to reduce the nights you spend away from home and help you develop the expertise and network you’ll need to serve local clients throughout your career. They’ll absolutely expect you to give input on engagements so together you find opportunities that fit with your development goals and values. They’ll also take clients’ needs into consideration as they build engagement teams.
As you advance at the firm, you’ll take more and more ownership over your staffing, but you’ll never have to go it alone. Your PDM and DGL will always be there as sounding boards, launch pads, and advocates – no matter how your interests, development goals, and lifestyle needs evolve over time.
We hear several concerns from candidates during recruiting. Here are some of the most commonly raised myths, set straight by our colleagues around the world.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Richard, associate, Operations Excellence Program, Chicago: “My experience has been that it’s somewhat difficult to get staffed internationally. To join my current engagement team in Asia Pacific (led by partners from Asia and the US), I had to show I have critical functional expertise that was not available from a local colleague. It took lots of planning, so I had plenty of time to prepare. My PDM and mentors checked my willingness multiple times to make sure this was really what I wanted. The partner leading the work made sure I understood the pros and cons to this undertaking, so I could make an informed decision; then, he spent time helping me develop a travel plan that would work for my family. My wife and daughter accompanied me to Asia during the engagement, so we enjoyed wonderful weekends at the Singapore F1 Grand Prix, Singapore Universal Studio, and Shanghai Disney.”
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Swati, engagement manager, Mumbai: “During my second year as an engagement manager, I needed a break. I enrolled in ’Take Time’ to spend a month pursuing my personal passions and priorities. At the same time, a new engagement was starting at one of my clients. The project team wanted to staff me immediately. I decided to continue with my personal plans, but I worried I was disappointing my clients and colleagues. I was completely wrong. Not only did my mentors understand my need to focus on my family, friends, and health, they created opportunities for me once I was back, rejuvenated and ready to rock and roll.”
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Aniket, associate, Operations Excellence Program, Chicago: “I joined McKinsey in July 2017. In early August, I suffered an acute stomach issue. After losing 30 lbs. in three weeks, and being put on a very restrictive diet, I knew I could not travel for a while. My PDM supported me by helping me find an internal knowledge development effort that allowed me to work from home. She checked in with me weekly to make sure I was recovering and still receiving enough intellectually stimulating work and coaching. Being staffed on this engagement ended up helping me develop a very strong foundation in digital operations and Industry 4.0, which I’m now using to help clients.”
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Diego, business analyst, Lima: “When I joined the firm, I was worried I’d have to staff myself. It’s been completely different. I’ve worked closely with partners, senior consultants and the staffing team to find engagements that would help me develop. One of my goals was to work with a diverse set of colleagues; in my three years at McKinsey, I’ve teamed with people from all continents, with areas of specialization in six industries and in four functions.”
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
YuanYuan, associate, Shanghai: “I came to McKinsey to explore industries beyond my background in consumer goods and marketing. My first engagement, however, was very similar to what I’d done in my previous job. I was a bit worried that I’d be trapped in this area. I shared my concerns with my PDM and DGL who reassured me I wouldn’t be forced to specialize. It turned out that doing something I was familiar with at the beginning was very good for my development since I could hit the ground running and focus on building my consulting tool kit. Afterwards, I got the opportunities I wanted to explore consumer-facing industries, which were way more diverse than I even imagined. I optimized the customer’s experience at a major retail bank and re-designed a non-profit education organization based on consumer insights. If anything came along I didn’t want to do, I was always free to say no and choose other opportunities.”
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Abby, associate, Singapore: “Before I went on maternity leave, I wasn’t sure whether I wanted to come back to consulting and travel leaving my little one at home. However, the transition back to work was much easier than I thought it would be. I started back in a role in the Client Development Hub, a non-client facing function, that allowed me to work from home. This helped me gain exposure to the leaders focused in consumer industries in Singapore, which led to an opportunity to join a local engagement team. With the support of my PDM and team, I was able to serve the same client for 12 months on different topics. I continued to hone my consulting toolkit and never felt like I wasn’t learning or growing. With the help of my PDM and DGL, I’ve achieved the best of both worlds: meaningful, challenging work and time at home with my son every day.”
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Mina, associate, Belgrade: “Before I joined, a lot of people asked me if I was afraid of where I might be staffed. I might have been anxious, but I’ve always had a big say in the opportunities I accept. The range of options McKinsey provides is extremely broad, which means each consultant can find whatever she or he prefers. Chances are, you’ll find several people here who share your passions and style. I sought out client work that would let me explore and found an engagement based in my home office that took me to three continents. That was perfect for me. Other colleagues have stayed closer to home or focused on varying the people with whom they work. There’s no right or wrong way to make your own path in McKinsey.”Intercompany accounting, the recording, and reporting of internal financial activities is a complex system that involves not just accounting functions, but also treasury, tax, and controllership. Recent transformations to the business and financial landscape are introducing cross-function challenges into an already complicated environment—from globalization forming multi-national value chains to more regulatory scrutiny and widespread tax reform.
The tax reform act of 2017 is one of the many significant disrupters transforming the accounting process and challenging financial institutions. When we surveyed attendees during a Deloitte Dbriefs 2016 webcast, only 3.1 percent were specifically concerned with reducing fines, penalties, or unintended taxable events. In just a few years, wide-sweeping tax reform has changed the game. It may not have been top of mind then, but it’s a challenge likely on a lot of minds now.DevOps has also always been about continuous learning. As enterprises big and small matured their processes and became proficient at automating infrastructure and build processes, they started to address the next bottleneck: testing and security. Instead of handing off builds to testers or scheduling security audits that often resulted in rework, they started shifting testing and security left. Many mature enterprises have now implemented automated tests, security scanning, and analysis tools in their build process. Builds are forced to fail if various performance and regression tests fail or if security and coding standards do not receive an acceptable score from the code scanning processes. These advancements can lead to faster development, fewer meetings, higher productivity, and higher morale.
Organizations that have entered years three through five of their DevOps transformation often shift their focus from IT automation to IT transformation. They begin addressing the next level of bottlenecks: Process, compliance, and support. Shifting these bottlenecks left requires strong leadership because this is where significant shocks to organizational structures and culture occur.
At virtually any major DevOps event today, the conversation focuses largely on culture and leadership. Becoming a high performing organization is not a technology project. It is an exercise in leadership, organizational change management, and culture transformation. Any organization can automate infrastructure and IT processes. Very few enterprises seem to have the chops to undertake effective transformation.Sometimes a relatively small investment can lead to the development of a product or process that benefits a company, an industry, or even society as a whole. The three-point seat belt, for example, is a simple strap of nylon webbing that protects drivers and passengers from being injured in an accident. This innovation helped to transform safety standards in the automotive industry and has saved millions of lives.
Similarly, the pharmaceutical industry is focused on ensuring the safety of its customers and the effectiveness of its products. Drug manufacturers use numerous pharmacovigilance (PV) processes and systems to make sure their portfolio complies with government safety standards. PV is the practice of monitoring the effects of a drug after its release to identify previously unreported adverse reactions.
Some manufacturers are taking PV to the next level by making modest investments to automate processes. This can help drug makers draw new insights from safety data to reduce PV costs, improve product efficacy, and discover new combinations and cures that—like the three-point seat belt—could benefit their company, the pharma industry, and society.
Numerous industry and marketplace trends are challenging existing PV systems and processes,2 driving some pharma companies to consider more efficient and cost-effective ways to produce robust safety data and mine it for high-quality information. Deloitte recently surveyed senior executives from mid- and large-cap life sciences companies that have global portfolios of innovative therapies. We wanted to learn more about the industry’s PV practices and find out what they expect for the future. For example, some survey respondents said they are using (or considering) automation to help reduce case-processing costs and improve signaling. Here’s a closer look:
Case processing: Driving cost out of case processing was cited as the primary goal among 90 percent of our survey respondents. Case processing can account for 40 percent to 85 percent of PV budgets. Moreover, case volumes are growing at a rate of 10-15 percent per year. 3 Some manufacturers are outsourcing, taking advantage of scale, and moving aggressively to automate case processing. Survey respondents expect automation could lead to an average annual cost savings of 30 percent per Individual Case Safety Report (ICSR).
Gaining cost control over case processing, while maintaining compliance and enhancing patient safety, depends on a company’s ability to automate more of these activities. Investments into automation can increase the productivity of case-processing teams significantly. At scale, the range can be as much as 300 or 400 annual ICSRs per full-time equivalent, to 1,000 or 2,000 ICSRs per FTE. Among productivity drivers are native automation and “bolt-on” tools that can reduce the effort required to perform duplicate checks, speed up coding activities, and streamline narrative writing. However, there is limited capability to automate away entire stages within case-processing (as opposed to discrete sub-parts within stages). Further, end-to-end case automation, even for relatively simple cases, is even further from a functioning production capability, despite a number of proofs of concept being tested.
Driving cost out of case processing was cited as the primary goal among 90 percent of our survey respondents. Case processing can account for 40 percent to 85 percent of PV budgets. Moreover, case volumes are growing at a rate of 10-15 percent per year. Some manufacturers are outsourcing, taking advantage of scale, and moving aggressively to automate case processing. Survey respondents expect automation could lead to an average annual cost savings of 30 percent per Individual Case Safety Report (ICSR). Gaining cost control over case processing, while maintaining compliance and enhancing patient safety, depends on a company’s ability to automate more of these activities. Investments into automation can increase the productivity of case-processing teams significantly. At scale, the range can be as much as 300 or 400 annual ICSRs per full-time equivalent, to 1,000 or 2,000 ICSRs per FTE. Among productivity drivers are native automation and “bolt-on” tools that can reduce the effort required to perform duplicate checks, speed up coding activities, and streamline narrative writing. However, there is limited capability to automate away entire stages within case-processing (as opposed to discrete sub-parts within stages). Further, end-to-end case automation, even for relatively simple cases, is even further from a functioning production capability, despite a number of proofs of concept being tested. Signaling: Survey respondents see a broad range of opportunities to improve their signal processing and investigation maturity. Half of respondents say they plan to expand these capabilities. As pharma companies drive toward true safety management, short-term signaling investments are likely to focus on visualization and longer-term efforts related to data integration as well as tool and process improvements. Using safety information to tie back into the discovery process remains a gap due to limitations with existing signal detection and management systems. The better the data quality and consistency, the better the signal detection. The ultimate goal is predictive signaling.
Later this summer, Deloitte will release a publication that examines why and how pharma companies are investing in automation and advanced analytics. We will show how they can gain process efficiencies, free-up resources to perform higher-value activities (e.g., benefits-risk evaluation and management, signal investigation, and real-world evidence analysis), improve quality assurance, and maximize return on their PV investment. The paper also will show that even greater gains are possible if companies buckle up and expand their technology and analytics use to create a PV system that focuses on benefit/risk management and proactive surveillance across the entire product lifecycle. Like the three-point seat belt, this approach may benefit pharma companies, the life sciences industry, and society as a whole.
Request a copy of our paper or contact us to learn how Deloitte is helping our clients to achieve their vision of a transformed pharmacovigilance system.
3. According to Deloitte analysis of the survey responses. The 10-15 percent is based on historical case volumes from FDA, available at the FAERS website: https://fis.fda.gov/sense/app/d10be6bb-494e-4cd2-82e4-0135608ddc13/sheet/7a47a261-d58b-4203-a8aa-6d3021737452/state/analysisThis blog is managed by Deloitte AG, a company registered in Switzerland with registered numbers CHE-101.377.666, with a registered office at General Guisan-Quai 38, 8002 Zurich, Switzerland.
Deloitte is committed to protecting your information by handling it responsibly and safeguarding it using appropriate technical, administrative and physical security measures.
We may collect or obtain information about you that you provide to us, that we obtain from third parties or that is publicly available, or which we infer from the way you interact with us.
We may process information about you to email you relevant blog posts, event invitations and content pieces (such as reports) that are related to the Deloitte tax blog.
For more details on how Deloitte handles and shares your information and for details on your rights and how to contact us, please click here.Advises leading organizations on how to strengthen their talent-management capabilities and build an HR function that operates as a true strategic partner and value driver for the business
July 22, 2019 Recruiting top talent, improving performance management and retraining the workforce were top priorities for one tech company.
Leadership, including a new CHRO, realized the answer to their main concerns required moving to a more agile HR model and, consequently, creating levels of excitement and motivation previously absent in the organization.
Top HR talent formed a pool of "internal consultants" to support business priorities, dedicating purpose-built teams to answer the need in a cross-discipline fashion, then disbanding to work on the next priority. Employees seeking to join this pool numbered three times those accepted and one-third were outside the HR department, reflecting broader enthusiasm for the new model—which is now being adopted elsewhere in the company.
In a well-managed agile transformation, results spur employee engagement across the organization and a faster response to emerging priorities. An agile HR model enables the allocation of resources to top business needs, generating these outcomes:
Critical talent initiatives are completed faster with better outcomes and greater visibility of value delivered. In one instance, the time required to deliver a new regional sourcing strategy was 75 percent faster than before.
HR staff can focus on generating clear impact while developing a broad base of skills. Our research indicates a 20 percent boost in employee engagement scores by using an agile model.
A more flexible pool of resources typically drives a smaller overall resource level in HR, more fully utilizing those already in place and increasing productivity through agile project delivery techniques. When a European bank deployed this model, HR realized productivity of nearly 25 percent.
A centrally managed pool of HR professionals permits visibility and control over initiative development and deployment, eliminating the siloed approach typically found in traditional HR organizations.
At a foundational level, an agile organization can scale dedicated resources rapidly to propel progress on key initiatives. This has immediate relevance to HR’s mission: Driving business value through talent.
“Run” activities: HR systematically applies the same processes every time; standard processes run repeatedly by specialists.
HR systematically applies the same processes every time; standard processes run repeatedly by specialists. “Build” activities: HR seeks to improve programs, capabilities and talent initiatives via a new learning program, high-potential development pathway or sourcing strategy—all ripe for agility.
The “standard” HR organization model usually possesses three pillars: Centers of Excellence (COEs), HR business partners (HRBPs) and operations/shared services. “Run” and “build” activities can get mixed up with the first two, so an agile HR model focuses on these areas by answering two questions:
How many HR COEs comprise expertise-driven specialists, and how many concentrate on supporting execution and operations? A handful of people may provide cutting-edge expertise, but an agile staffing model generates stronger execution. Of embedded HRBPs/generalists, how many grasp the value agenda for the area they support, and how many furnish the “arms and legs” to adopt initiatives and respond to generalist questions? An agile HR model delivers more flexible staffing.
The flexible pool typically pulls from both groups: generalists that bring greater focus on how to engage business leaders for maximum impact, and junior COE resources that bring some specialized knowledge of best-practice solutions. Working together, agile HR teams offer a mix of business and HR knowledge, along with domain expertise that drives creative solutions. Simultaneously, key skills for everyone in the pool are more flexible problem-solving and initiative leadership.
Here’s how a European bank employed the agile model: It moved half of its HR resources into the pool of inner consultants working on bank priorities. It kept its COE and HRBP group, and its HR professionals’ pool supported these areas as business priorities emerged.
Exhibit We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Numerous issues must be addressed, when establishing an agile HR model, that require solid planning and change management within and outside HR. This sparks some near-term disruption, but organizations pioneering the model demonstrate that the benefits of transformation cement it as a core component of next-generation HR.A blog post by Katie Glynn, senior manager, Deloitte & Touche LLP and Anastasia Traylor, senior manager, Deloitte & Touche LLP
A manufacturing company faces a federal grand jury investigation involving intercompany cash transfers related to its tax planning.
An insurance company is forced to restate its financial results stemming from its failure to eliminate certain intercompany transactions related to variable-interest entities.
An offshore drilling company is levied fines and penalties due to untimely and incomplete filings of financial statements in a foreign jurisdiction
The costs of a fragmented, manual, and non-standardized intercompany transaction processing and accounting can be significant. It is a process that has typically evolved over time “by default” as opposed to “by design;” but an evolving financial environment and digital transformation have been a catalyst for organizations to rethink, restructure, and redesign the intercompany accounting process. Tax reform, growing regulatory scrutiny in the US and local jurisdictions, and an increased focus on operational efficiency offer a challenge and opportunity for companies to optimize the intercompany accounting process to reduce risk of regulatory and statutory non-compliance, provide for effective tax planning, and achieve a more standardized, sustainable, and cost-effective operating model enabled by technology.
Before we tackle the concepts of redesign and technology-enabled transformation, it is helpful to first highlight the components of the end-to-end intercompany accounting process and the leading practices that may align with a company’s multi-disciplinary intercompany-focused objectives from the perspective of controllership, tax, treasury, and the overall vision across a broader organization.November 11, 2019 As automation and artificial intelligence dramatically change the nature of work, employees must fine tune the social and emotional abilities machines cannot master. To encourage this behavior, employers must adjust the ways they assess, educate, train and reward their workforce on soft skills such as collaboration, communication and critical thinking.
Our previous post demonstrated the value of developing and rewarding soft skills, considering the impact of automation and AI on the workplace of the future. But what exactly are soft skills, and how can organizations meet these needs?
Soft skills, which are commonly defined as non-technical skills that enable someone to interact effectively and harmoniously with others, are vital to organizations and can impact culture, mindsets, leadership, attitudes and behaviors. These skills fall into the following categories:
Advanced communication and negotiation skills Interpersonal skills and empathy Leadership and management skills Entrepreneurship and initiative-taking Adaptability and continuous learning skills Teaching and training skills
A key difference among today’s large-scale skill shift and those in the past—including the transformative transition from agriculture to manufacturing—is the urgency for workers who exhibit these capabilities.
Reskilling at scale is a concern and priority for 80 percent of C-suite executives worldwide, according to a McKinsey survey. Reskilling significant portions of the workforce within the next 5-10 years will be required—tens of millions of mid-career, middle-age workers, particularly in advanced economies—with the development of soft skills a key element.
Developing required soft skills and ensuring employees, and in turn organizations, are set up for success isn’t as simple as popping in a training video. Instead, companies must change their employees’ processes and behaviors—a much harder task.
Assessment is an important first step. Sizing the soft skill gap proves particularly challenging, since they typically lack systematic evaluation and certification mechanisms. HR departments must be equipped with a framework that codifies soft skills and defines their respective evaluation criteria.
For example, several European firms are employing “stepping stone” initiatives to build a digital platform to help workers evaluate their soft skills, know their strengths and development needs, gain access to specific trainings, and get certified.
Effective reskilling requires blended learning journeys that mix traditional learning, including training, digital courses and job aids, with nontraditional methods, such as peer coaching. One retail giant has distributed over 17,000 virtual reality headsets that immerse employees in unfamiliar situations, such as their first Black Friday sales day, and is training them in new tech, soft skills and compliance.
People naturally operate based on incentives—they do what is rewarded. To encourage people to not only begin their soft skill learning journey but to continue with it, rewards and incentives are critical. One large advisory firm has recently implemented a series of digital badges to reward people who complete certain training sessions. Much like the progression of belts provided to martial artists, these badges serve as public recognition for others that the trainee is becoming an expert in a certain topic, thereby encouraging employees to further invest in key skills.
Given the critical need for soft skills now and in the future, training current employees is not enough. It is also crucial to ensure that new talent coming in the door is ready with the most critical skills on day one. Recruiting for soft skills can be tricky, but it generally involves structured interviews which elicit responses that include details about one’s past work and life experiences that contribute to who they are today, or situational judgment tests whereby the interviewer puts the candidate in a specific hypothetical scenario and asks how he or she would deal with it.
Employers providing soft skills training report positive impacts on their workforce, including higher productivity and improved results. As today’s skill shift accelerates, it is essential that organizations enhance and expand development initiatives for business longevity.August 17, 2020 The helix organization model, which we explored in part one and part two of this blog series, separates people-leadership tasks from day-to-day business leadership, helping organizations strike a better balance by reducing complexity and increasing flexibility, encouraging faster decision-making, and empowering employees to act.
In order to make this model a success, changes beyond the structure need to be made. The following recommendations help ensure that an organization is set up for success:
Make resource planning transparent, flexible, and focused on value The biggest advantage of the helix organization is the flexibility, which people can be shifted between value-creating areas where the organization sees the highest return on its investment. To enable this, best-in-class organizations attach this process to a quarterly priority setting process (e.g. as we see it in many agile organizations a quarterly business review “QBR”). When quarterly priorities across the value creation areas are defined, implications on resource shifts can be derived. By that value-creation leaders give capability leaders ample time to match supply to demand for skills and roles. A leading consumer goods company which struggled to compete in the market owing to slower decision making as compared to its peers achieved significant reduction in time to market by implementing the helix organization model. This organization dedicated resource allocation as one of its core priorities in the QBR at the highest level to improve its focus on value.
Create a talent marketplace Whenever shifts of resources are decided on in the resource allocation process, a transparent talent marketplace is required to staff the right people at the right time to the right topic. This requires that leaders have a detailed understanding of available human resources. Companies who do that well, have a digital marketplace, where supply and demand are listed, with a transparency on people’s profile. In larger organizations we also find new HR profiles called “Staffer,” that support the matching of supply and demand and deal with potential conflicts between value creation areas. A consumer company defined the role of a “Staffer” who staffed from skill groups to squads by matching necessary skill sets and was aligned either to a tribe or a non-tribe skill group.
Support leaders shifting their mindsets and organization’s culture Both kinds of leaders need to adapt a “we over me” mindset; value-creation leaders need to accept that management of the day to day business can work without a traditional “formal” solid people line, and need to learn how to operate in this model using other methods to align people behind the joint goal. The model also requires a stronger culture of collaboration, to align resources and business requirements in the best way, a culture of trust and partnership. Exhibit We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com An automotive company decided to take out capability managers (e.g., Head of R&D, Head of Marketing) from stage gate meetings. As a result of this, the project team members felt much more empowered to make real decisions on the process and the meetings became much faster and focused.I am currently still staffed on the first engagement I was assigned, which is a large Navy project. We now build and maintain an enterprise-level web-application used all over the world. When I first started, I was purely a functional tester, but as soon as I could, I picked up ETL testing. Now I am currently transitioning into a .NET developer role.
I was extremely nervous! When we had our project onboarding meeting, we went over a very high-level the scope of the work we do and the services we provide. Some of the technologies I had never even heard of—I felt completely out of my depth.
1. Learn as much as possible. When you get on a new project, there will be no shortage of things to learn, whether it's how the project operates, new domain knowledge, or new procedures. For example, when I first started, I spent a lot of time learning about our testing tools and methodologies, but I also had to learn the extensive change management process that was specific to our project.
2. Ask questions. It can be tough to get up to speed on a new project, but it's part of the process. No one expects everyone to know all the answers, least of all a newcomer. Asking questions of people who have been in your shoes is one of the best ways to learn what you need to know—and most of them expect it.
3. Meet people. This one does not just apply to a new project, but to Deloitte in general. Growing your network and meeting people with various skillsets can be crucial to your success at Deloitte. As you build your network, you can create available resources for any new or unknown challenges you may face.
I would say, being prepared. This might be overlooked in the day-to-day of a busy work week, but it should be the easiest to remedy. Simple things like staying on top of your calendar and setting aside time to prepare for meetings go a long way toward being professional. I dedicate time before every meeting to prepare, whether that means thinking about what I'm going to say or even reading any information provided beforehand.
Read about Manan Shah's and Courtney Newcombe's first client engagements, and check back soon for more stories!A blog post by David Linthicum, managing director, chief cloud strategy officer, Deloitte Consulting LLP
Über-mergers will be the focus of enterprises over the next three to five years. The Global 2000 wants to leverage their stock value as a currency to make key acquisitions that will take them to the next level.
Unfortunately, many of these acquisitions may not work out as planned. It’s difficult to bring together the IT systems of both companies, and synergy can take years, not months to achieve. Both the customers and investors can become underwhelmed by the progress, and the company often pays the price by falling short of expectations.
Enter the use of cloud computing and its ability to more easily merge IT systems. Cloud-based resources can be allocated as needed, and public cloud-based systems can easily work and play well with each other.
The amount of time it takes to merge and integrate systems to support an acquisition varies, depending upon the type of companies pushed together. However, the core capabilities of leveraging the cloud include:
The ability to exchange data intra-cloud. It’s faster and easier because cloud providers leverage the same cloud-native databases, middleware, and database ops solutions. Traditional approaches to inter-datacenter integration are much more problematic, and often takes more time and money when compared to the cloud computing-based alternative.
The ability to merge security systems together using a common platform. When the cloud-native security system exists on the same public cloud provider, it’s just a matter of integrating directory services, and thus identity and access management solutions. Security can be synced within weeks. Traditional legacy security integration can take as much as a year, not including planning.
The ability to deal with common data semantics. With the same notions of a customer, inventory, product, etc., there is no misunderstanding of what data is the single source of truth between the merged companies. This requires some understanding of the metadata, and perhaps some common MDM solutions. The public cloud again provides an effective common platform for all of these integration efforts.
There are many more benefits to M&A in the cloud than can be listed here. You’ll find that it’s a matter of understanding where your enterprise is at, where the company you want to acquire is at, and the potential use of the public cloud platform as a point of integration between both IT systems.Will 2019 be different from 2018? For many investment managers, yes! Those firms breaking ground on new developments will likely see contrast afforded by a new perspective. No doubt, most investment management firms still face challenges such as margin compression, regulatory change, rapid technological change, and shifting investor preferences. Just as necessity is the mother of invention, these pressures are driving firms to find avenues for growth, improve operational efficiency, and develop elegant customer experiences.
In order to achieve growth, capabilities have to improve, because the competition is stiffer in both emerging and traditional markets. New technologies, such as artificial intelligence, are being increasingly deployed in search of a competitive edge.
Many firms will choose to grow their current products and markets, but this is not to be confused with business as usual. They still have to refine, if not revamp their investment operations. While some firms might pursue incremental improvement strategies, others are expending considerable effort to improve their core investment capabilities. Since the markets are always pricing in more information—never less—active investment management firms should consider looking for ways to build deeper insights into the investment process, just to keep up.
Keeping up is important. For mutual fund managers in particular, many of the large advice-driven distributors are trimming funds from their shelves. More than 4,900 funds have been dropped from the shelves of leading distributors over the past two years.1 This shelf-space dynamic demonstrates that competition for distribution is stiffening. Differentiation and innovation help investment management firms from being left out.
To get ahead, many firms are considering expansion into China, and joint ventures and acquisitions are often part of that strategic decision. At its current double-digit growth rate, China will become the world's second largest market for investment in the next decade.2December 27, 2017 Nobody likes annual performance reviews. Even high performing employees can be demoralized by rigid or arbitrary goals. But what if you could find a way to flip it – turning the annual performance review process into a positive moment where employees feel empowered to learn and grow?
While goals have long been used as a quantitative measure for employee performance, many organizations find that the goal-setting process takes a huge amount of time and is, frankly, not very effective. However, when done correctly, goal-setting can help improve employee engagement in a way which elevates performance and benefits organizations overall, according to recent McKinsey research.
Setting goals can be as challenging as meeting them. Here are three things to keep in mind when establishing effective employee goals:
Involve employees from start-to-finish The purpose of goals is to help employees improve – naturally, it makes sense to include them in the entire process. Securing employee buy-in allows you to help develop their short- and long-term goals, and increases the likelihood that they will be achieved. Managers should jointly develop goals that are SMART (specific, measurable, actionable, results oriented and time bound). Doing so inspires commitment and allows individuals a sense of ownership in achieving their goals. Encouraging employees to set stretch goals also helps push performance and serves as a motivator for ongoing development.
Link individual goals to business objectives Of companies who have effective performance management systems, 91% say that employees' goals are linked to business priorities. The explanation is simple: employees will be more effective if they can see how their individual goals fit into the big picture. In recent years, there has been an uptick in the number of companies linking organizational business goals to functional business objectives, and converting those into team-performance goals. This encourages accountability and better performance as individuals grasp the direct impact of their performance.In March 2018 the European Commission published an Action Plan on Financial Sustainable Growth (the “Action Plan”) to help investors identify, compare and classify sustainable investments and integrate ESG criteria into their investment processes. More recently, the European Commission began the process of amending MIFID II to ensure that in future, investment managers will be required to take into account consumers’ Environmental, Social and Governance (ESG) preferences as part of the overall suitability process. The market is already seeing growing client demand for ESG products; Morningstar data shows sustainable funds domiciled in Europe showed resilience during the recent market sell-off. Driven by continued investor interest in ESG issues, the European sustainable fund universe grew by EUR 30 billion in the first quarter of 2020 compared with an outflow of EUR 148 billion for the overall European fund universe. Advisors and Investment Managers should therefore not only be on the front foot from a regulatory perspective, but also from a commercial and strategic perspective, ensuring they are able to serve their clients’ best interests.
The expected implementation date for the updated rules on suitability is March 2022. This might seem far away, however, given the expected challenges and all-encompassing nature of ESG, firms should be thinking ahead as to how they will address these key regulations into their existing process and control frameworks.
In this blog, we explore in more detail the operational and compliance challenges ESG will create for Advisors; specifically the risks and challenges in capturing ESG preferences of clients during the suitability assessment process.
The existing MiFID II suitability rules require those providing investment advice and portfolio management to obtain information on clients’ financial objectives, risk profiles, capacity for loss, as well as knowledge and experience in relation to the specific type of financial instruments being advised on. The proposed updates to MiFID II will add clients’ ESG preferences to this list.
The purpose of this regulation is to create demand for ESG products; to move to a more sustainable economy. Whilst clients’ aren’t obligated to provide any ESG preference, and factors like investment objectives must be assessed before a clients’ ESG preferences, if some clients provide a strong opinion on ESG and the firm does not have a suitable product available, consideration must be given as to whether the firm can still make a suitable recommendation for that client.
Advisors will need to review the proposed changes to regulation the surrounding provision of advice and portfolio management to ensure ‘sustainability preferences’ are captured within their suitability process. To this regard, they will need to consider the wide range of ESG factors that their clients may have a preference on which will form part of their overall recommendation.
Defining ESG issues can at first appear daunting, given for many it is unchartered territory. Fortunately, the starting point can be aided by a number of existing frameworks and principles
ESG needs to be grounded in materiality. For example, what is considered a material set of environmental issues for oil and gas companies is not directly comparable to textiles or consumer products. Identifying the material ESG issues facing underlying assets should be the first consideration for Advisors. The Sustainability Accounting Standards Board (SASB) outlines where they consider relevant ESG issues as material to different industries, including example metrics that can be used for monitoring performance. SASB is used by many as a guide for determining material ESG issues – recently a prominent institutional investor announced it would use selected SASB KPIs as a method for engagement and stewardship.
Advisors should also consider the UN Sustainable Development Goals, and their associated targets for 2030, as part of understanding definitions of ESG or sustainable. Climate change action is one of seventeen key focus areas globally agreed to achieve sustainable development. The World Economic Forum, appreciate this ‘new age of materiality’ for ESG has been working toward standardising ESG metrics used by companies, that will support investors decision making based on ESG performance.
Finally, firms should consider the key activities outlined within the EU Sustainable Finance Taxonomy to determine a variety of ESG preferences. To this end, incorporating ESG will provide a new set of product governance challenges when firms decide on the range of investments that they can advise on. Collecting appropriate data on ESG products and monitoring this on an ongoing basis in itself will be another key challenge for firms.
One of the main challenges for firms will be effectively embedding ESG considerations within their suitability process. Many may argue that suitability requirements are already overly burdensome for clients, and adding further requirements on ESG preferences risk making the process overly lengthy and complex, ultimately jeopardising customer engagement. It is therefore important that firms consider the customer journey in its entirety, and, as we will explore in this blog, it is not as straightforward as one might perceive.
Let us consider the key steps within the suitability process by taking an Advisor focused view. We will explore the key considerations and challenges that may arise as ESG is incorporated into the process, and call out some key impacts that firms and their Advisors should start to consider.
Before asking a client what their ESG preferences are, Advisors will first need to ensure clients understand what is meant by ESG in clear and simple language. This may include describing the difference between the ‘E’, the ‘S’ and the ‘G’ and what sort of factors are considered under each heading.
Firms should consider whether they would need to verify or otherwise test client responses with regards to ESG. In the same way Advisors have to assess clients’ knowledge, experience and understanding of investment risks associated with the advised products, firms may wish to consider whether they should do the same for ESG. For example, a client who misinterprets ESG might limit what products the advisor considers for them. In future years, if the Advisors recommendation has not achieved the desired outcome for the client, it could give rise to a suitability related complaint.
Client responses could fall across a spectrum of attitudes and preferences for ESG for Advisors to consider. This could range from clients having no ESG preference to clients having very specific preferences towards achieving an impact that aligns with a particular Sustainable Development Goal (SDG), otherwise known as Impact Investing. This is illustrated below:
Advisors also need to be aware that people’s attitudes to ESG factors may change over time. Client preferences in response to world events and topical issues at the time of assessment will likely influence their responses. Striking the right level of granularity in the questions asked will therefore be key, too niche or too detailed could limit investment choice or lead to portfolio rebalances over time; too high level and firms risk not capturing a client’s actual ESG preferences.
When making a recommendation, Advisors need to be clear how they have considered the client’s ESG preferences for each financial instrument recommended. In particular, suitability letters should contain an explanation on whether, or how, clients’ objectives have been achieved by taking into account their expressed ESG preferences. To do this, Advisors need to have clear consistency between the internal categorisation of ESG products and external marketing information for ESG products. Embedding the suitability process with product governance oversight will be key to successful implementation.
One other key concern is around fee transparency and the potential conflicts of interest that could exist between firms and clients. Many ESG products are, by nature, more costly than their non-ESG equivalents and this could create conflicts where funds or strategies are labelled as ESG in order to charge higher fees. To this end, ESMA set out in its technical advice that firms should have in place appropriate arrangements to ensure that the inclusion of ESG considerations in the advisory process does not lead to mis-selling practices or misrepresentations and do not damage the interest of the client. Or, as ESMA describe it, “an excuse [for a firm] to sell its own-products or more costly ones, or to generate unnecessary churning of clients’ portfolios, or by firms misrepresenting products or strategies as fulfilling ESG preferences where they do not”.
Firms will need to consider any limitations of how particular ESG preferences may affect uptake of model portfolios and investment strategies, and, ultimately whether the clients’ objectives can be met where the client has expressed strong ESG preferences.
The current process for periodic reviews of suitability requires firms to provide an assessment of suitability of any recommendations they provide to the client, where they hold an ongoing relationship. For many, periodic reviews will include ESG as a consideration for the first time, reaching a population of existing investors who might have never expressed their ESG preference.
This may present a number of challenges for Advisors, including how they obtain client engagement on a new topic when clients have had long standing relationships; or how the process would account for any portfolio transitions to more ESG friendly assets without impacting the risk exposure and objectives for the client.
The impact of ESG will be wide ranging and require careful planning in the run up to implementation. Suitability is just one aspect of the ESG requirements however, other impacts to additional areas such as product governance and conflicts of interest that deserve equal attention. Firms will look to their ESG change programmes and impact assessments to highlight these areas in further detail, however in the meantime, we have set out below some high level questions for Advisors and firms to take away and consider when implementing ESG into their suitability process.
Deloitte has supported the mainstreaming of sustainability within the investment system by leading and actively participating in every critical framework, taskforce and committee that is used and relied on by investors. We regularly publish thought pieces on how sustainable finance has grown and is still evolving.
Every day we work with investment management clients, around the world, supporting their approach to sustainable finance through six key areas:Though major crises may inflict significant economic damage, they can also inspire innovation. From digital connectivity to diversity, this issue of Deloitte Review explores innovations that organizations can put to use both now and in the future.Coleads our Organization Practice in Asia, developing the talent and leadership that organizations need to thrive; leads our work across China on infrastructure, sustainability, and public-sector issues; and works extensively with cities and major developers to plan and deliver integrated, sustainable urban developments
Coleads the Organization Practice globally and is head of McKinsey’s OrgSolutions group, helping clients organize in an integrated way by applying analytics methodologies and tools to improve culture, talent, change management, agility, and leadership
April 22, 2019 Leadership development interventions often lack strategic rigor, and the results show—only 10 percent of CEOs strongly believe their leadership development initiatives have a clear business impact.
For organizations to develop successful strategies requires leaders who are trained to think critically about where to compete and how to break down big-picture strategies into the smallest, most granular components. To break through requires real rigor and data-driven analysis to identify pockets of opportunities invisible at an aggregate level.
Leadership development programs, however, are rarely as rigorous. Too many organizations focus on broad, generic leadership competency models that apply a one-size-fits-all approach. One organization we know held a workshop to help leaders foster a “more global mindset”—with little discussion on why a global mindset was valuable for the company strategy in the first place or what participants should do differently in their daily work.
When leadership development links to specific context and strategy, however, outcomes improve significantly. Organizations that are successful at this are 8.1 times more likely to focus on the most critical leadership behaviors linked to their performance objectives, compared to those that are not successful.
Too many organizations focus on broad, generic leadership competency models that apply a one-size-fits-all approach
How, then, can you identify the most critical leadership behaviors to propel performance? There are four key steps:
1. Identify the context of the organization and the leadership behaviors that matter. Every organization resides in a unique context, and the specific leadership behaviors that enhance performance objectives must be identified with rigor. Multiple lenses apply here, including industry, ownership structure, strategic objectives, geography and organizational culture.
For example, an oil and gas company might emphasize operational discipline and safety while a Private Equity-owned company might emphasize quick decision-making and a bias for action. One lens we always apply is that of organization health and recipe, which can be measured quantitatively and has a clear link to performance. Organizational health measures the ability of an organization to align around a common vision, execute effectively against that vision and renew itself through creative thinking. Our research shows that organizations at different stages of health require different leadership behaviors to be effective and transition to higher levels of health and performance.
2. Crystalize leadership aspirations in a tailored leadership model. This model—sometimes called leadership competencies or values—typically includes 3-6 overarching themes, each comprised of several specific underlying skills and/or behaviors.
For example, a conglomerate embarking on a new strategic direction was focused on customer centricity, addressing disjointed cultures across its operating companies, and constructing a leadership pipeline. As a result, the organization developed a tailored leadership model with six themes, all of which supported the strategic aspirations. The explicit focus on a handful of specific and tailored leadership behaviors ensured that participants saw the program’s immediate value in their daily jobs, with an average program rating of 9.3/10. At an organizational level, the leadership program contributed to a 13-percentage point increase in leadership effectiveness and a 14-percentage point increase in overall organizational health.
3. Pinpoint the 3-5 behaviors that matter most. We consistently find that leadership development initiatives hit obstacles when they try to change too many things at once. Organizations cannot address the whole leadership model at once and must prioritize. In practice, it is individuals who must begin doing things differently on the job and developing sustainable behavioral change can prove challenging.
4. Identify the difference between the leadership the organization requires and where it stands today. This is the concrete gap across the 3-5 priority behaviors that the leadership development program should fill. Sometimes called “from-to” shifts, they serve as an objective measuring stick for program success. It is critical the behaviors are defined in detail, as they will ultimately drive the design of the program.
Few successful organizations operate with a vague notion of strategy. Similarly, it pays for organizations to pinpoint specific leadership behaviors required based on their context and to ensure that leadership development efforts are laser focused on addressing them.
Defining the critical leadership shifts that matter to performance is the first of four core principles we outline in McKinsey’s new book, Leadership at Scale. Our next blog post in this series will explain why organizations need to engage a critical mass of pivotal influencers during leadership development programs to ensure the change effort sticks.This blog is managed by Deloitte AG, a company registered in Switzerland with registered numbers CHE-101.377.666, with a registered office at General Guisan-Quai 38, 8002 Zurich, Switzerland.
Deloitte is committed to protecting your information by handling it responsibly and safeguarding it using appropriate technical, administrative and physical security measures.
We may collect or obtain information about you that you provide to us, that we obtain from third parties or that is publicly available, or which we infer from the way you interact with us.
We may process information about you to email you relevant blog posts, event invitations and content pieces (such as reports) that are related to the Deloitte banking blog.
For more details on how Deloitte handles and shares your information and for details on your rights and how to contact us, please click here.Walking into an office as a new hire [after new hire orientation and training] was so much different than coming in as an intern. It was intimidating, but mostly it was so exciting because I came in with a completely blank slate and a yearning to prove myself. I remember coming in at 8:00 AM and wondering if I was too early or too late. Luckily, I was joined by fellow new hires and experienced professionals eager to answer questions about what to expect from Deloitte. After completing about three hours of training and filling the day with networking activities, I remember walking out feeling energized, hopeful, and eager to learn over the next few months.What was your first client engagement?
I was working on an enterprise resource planning (ERP) system integration. The scope of our work involved the configuration and testing of an external tax engine to successfully process and calculate tax amounts on transactions in dozens of new countries. The scope was global, and I was able to learn firsthand the complexity and data wrangling capacity required by tax.
As a staff level on this engagement, I was heavily involved in the efforts of configuration in the tax engine, the subsequent testing of these configurations, as well as the documentation. Working across systems also allowed me to be heavily involved in the creation of report specifications for blueprinting the data that flowed between systems.
Absolutely! It is difficult to know how to feel when you are not quite sure what to expect on your first project. This project required me to travel every single week—something that put me outside of my comfort zone. Despite this, however, I was lucky enough to have a team that was supportive and made me feel at ease. This is something that I have found to be a pattern at Deloitte—even though the work is challenging, the people are talented and very willing to mentor.
Something that would have helped me is knowing the importance of taking initiative. By this, I mean seeking out ways where you can be useful, and not just waiting for a senior team member to give you a task. Members of a project team are extremely busy, and it is not always easy to find tasks for inexperienced staff. If I knew how much of a difference it would have made, I know, I could have been more helpful on my first engagement and could have learned how to excel technically and professionally.Problem solvers and creative thinkers. Engineers and new business builders. Put your talents to use where opportunities are limitless and every day makes a difference.
Whether you’re an experienced professional or a recent graduate, working with McKinsey could be a challenging and rewarding next step in your career.Has a passion for capability building with deep expertise in lean and green operations and the use of advanced analytics in operations; experienced in successful large-scale operations-transformation programs
April 15, 2019 To improve, organizations must consistently seek out and solve their problems—an insight that underpins lean management’s emphasis on root-cause problem solving (RCPS). Indeed, companies that have used RCPS to build a problem-solving culture that lasts are able to avoid continuous firefighting by effectively preventing fires from starting.
But RCPS takes discipline and patience, which some leaders resist: a manager may be reluctant to use this model if she’s convinced that she has already identified an “operational solution.” Nevertheless, persuading her to join her team on a problem-solving journey can help uncover a more effective and sustainable set of solutions—most importantly by including the people who know the problem best: shop-floor employees. Their perspective often shows that the initial idea would not have addressed the problem’s real causes, and would have met with a lot of resistance from the people charged with implementation.
Ops 4.0 technologies are making it easier to overcome that resistance and invigorate root-cause problem solving performance. What follows is a non-exhaustive overview of how different technologies (italicized) could be applied in each of the five RCPS elements (exhibit).
Exhibit We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
The rise of advanced analytics and business-intelligence applications allows companies can detect many more problems than in the past, and in a more effective way—so long as they have sufficient internal support to interpret the output. Examples include fraud detection in banking and insurance, as well as deviations from normal operating conditions of equipment in manufacturing plants. For the latter, the increased availability of high-frequency, high-precision sensors, together with the rise of the Internet of Things provides companies with larger data sets from which to identify problems.
Once the problem is defined, root causes are often identified via the five-why methodology. Instead of using the traditional colored sticky notes to facilitate this exercise, companies can now use interactive whiteboards incorporating speech-to-text or handwriting-to-text algorithms, together with high-quality touch commands. Moreover, the whiteboards can link to data warehouses, thereby enabling self-service analytics or even machine-learning algorithms for performing the analyses required in confirming or rejecting potential root causes.
Augmented- and virtual-reality applications can help designers’ creation process become even more productive. Faster iterations between the drawing board and a more real-life representation shorten lead times toward final design. Rapid prototyping and 3D printing can accelerate this process even further by bringing intermediate versions of the solution to life.
Once a solution has been designed, it is crucial to test its efficiency and effectiveness. The increase in computing power enables companies to perform extensive computational simulations. Using digital twins helps organizations create virtual mirrors of their operations, allowing them to test ideas more realistically before implementation.
The digital communication and collaboration platforms that are now in widespread use can often be linked with interactive tools such as digital whiteboards, minimizing the time teams spend on documentation so they can instead focus on the creative parts of problem solving. Having past records of problem-solving sheets available at only one touch avoids solving the same problem all over again.
The above list shows how the ancient art of root-cause problem solving can take shape in today’s environment. The question for most organizations is how to start, especially with technologies that can sound like science fiction. A learning center designed to replicate an actual, digitally enabled working environment can provide the first step, helping people experience the impact these technologies can achieve in a practical and realistic setting.Two months ago, I was on a panel at the SCOPE Summit in Orlando where we discussed the role digital technology could play in improving clinical-trial recruitment and retention. During the session, my group predicted that pharmaceutical companies would eventually incorporate more telemedicine visits into clinical trials and rely on internet-connected medical devices to conduct tests and gather digital data. At the time, I anticipated the transition to remote/virtual clinical trials was still a few years off. I was wrong. The COVID-19 pandemic is likely to push this timeline from years to months.
Last month, the US Food and Drug Administration (FDA) issued guidance that would temporarily allow researchers to use virtual visits, telephone interviews, and remote monitoring to collect data for clinical trials where possible.1
Clinical trials often require patients to make regular visits to a clinical site, which tend to be located in large medical institutions or hospitals and involve face-to-face meetings with clinical staff. Safety risks tied to the COVID-19 pandemic—combined with stay-at-home orders in most states—are preventing patients from traveling to investigational sites. Moreover, some patients and clinical staff have been quarantined after becoming infected by, or exposed to, the virus.
A March 23 article in STAT noted that biotech and pharma companies with market values of more than $300 million are running more than 120 Phase 3 clinical trials. Topline data readouts were expected before the end of the year. However, many trials are now struggling to recruit and retain patients, and most ongoing trials have been delayed. Some hospitals that had been hosting clinical trials are now busy responding to COVID-19 patients. As a result, many biopharma companies now have to consider incomplete patient data due to missed or delayed clinic visits.
Some trials for therapies that treat life-threatening conditions such as cancer are more likely to move forward, as are potential treatments for COVID-19. As of the end of March, more than 300 clinical trials related to the virus were either recruiting patients or preparing to recruit.2 Many of these trials are taking place in China, Korea, and some European countries hard hit by the disease.
Here are five things pharmaceutical companies should consider when evaluating existing or future clinical trials:
Conduct a risk-based portfolio analysis: Pharmaceutical companies should evaluate their portfolio of studies, conduct a risk-based assessment for dealing with the impact of COVID-19, and document a contingency plan. Many of our pharma clients have made the difficult decision to delay any new trials that aren’t deemed life-threatening or where an effective therapy already exists. They have also paused ongoing trials due to missed visits or incomplete data. For critical studies, they are working with their institutional review boards and regulators to determine which tests or processes can be conducted virtually, including telephone calls with patients or video visits via the internet. They should also determine if Bluetooth-enabled devices could be used to remotely gather patient data without requiring the patient to travel to the clinical site. Determine if trials can be relocated: Clinical trials that were taking place in hot spots might need to be relocated to other regions that haven’t been hit as hard. Rather than requiring a patient to travel to a large hospital, alternate sites (local clinics, laboratories, imaging centers) near the patient’s home could be an alternative. Home health agencies might also be used to help keep patients at home. Home health aides can travel to a patient’s site, draw blood, listen to lungs, and perform tests that the patient can’t do alone. Evaluate the potential of virtual visits and digital tools: Health concerns and travel restrictions related to the virus are likely to keep patients from volunteering for clinical trials or staying in existing clinical trials. They might be more willing to participate in trials if some visits can be done remotely. Companies should evaluate their protocols to determine what can be done virtually and what must occur in a clinical setting. Many of our clients are evaluating various technologies for telemedicine visits. They are also trying to determine how to leverage connected medical devices to capture patient data. During this assessment, it is critical to consider data privacy and security concerns as well as global regulations and the cultural impacts of remote visits. Consider partnerships: The outbreak has created additional logistical challenges in getting supplies delivered to investigational sites or directly to patients. Trial sponsors are trying to figure out how a patient would get their drugs if they can’t travel to the trial site and how to furnish tests that require specialized medical equipment (e.g., x-rays or CT scans) if the patients can’t go to the hospital. Several pharmaceutical companies are looking at forming new types of partnerships. For example, they might work with a retail pharmacy chain that can make investigational drugs available to clinical-trial patients locally. Another option is to train and enable local imaging centers to conduct tests that would typically be done at a hospital. Determine how to manage missing data and deviations: It is inevitable that patients will miss visits, have events occur outside visit windows, or withdraw from clinical studies. This can result in protocol deviations and missing data. Trial sponsors should develop processes and plans to manage those issues and decide what to do with incomplete data sets. Data collected remotely will likely need to be assessed in new ways. Sponsors should update their contingency plans with these process changes and update their data-analysis plans accordingly.
It feels like a year has passed since the SCOPE conference in February. In that short amount of time, the world has changed. Pharmaceutical companies that had expected to digitize clinical trials over the next few years are looking at weeks or months instead. At this point, the technology and infrastructure needed to push clinical trials into the virtual world might not be fully ready. For example, there are privacy concerns that should be worked out before patients and clinicians can conduct visits over the internet. During the months ahead, I suspect regulators will evaluate experiences, determine what works, and update the guidance. Once the industry, regulators, and patients see the benefits of remote clinical trials, I believe it will be difficult to go back to the way things were.
1. Coronavirus (COVID-19) Update: FDA Issues Guidance for Conducting Clinical Trials, FDA, March 18, 2020
2. Global coalition to accelerate COVID-19 clinical research in resource-limited settings, The Lancet, April 2, 2020It is well known that COVID-19 pandemic rapidly sent millions of people to work from home (WFH), which created an immediate challenge for many organizations – providing secure system access to employees. However, the less visible and more challenging transformation that also occurred was the sudden requirement to digitize processes, including previously paper-based transactions, in-person meetings, business travel, and other “normal” day-to-day operations.
Rapid digital transformation has enabled organizations to respond and thrive during the pandemic. A May 2020 blog post by the World Economic Forum stated “the transition to a new model for supply chains will be underpinned by a rapid and wholesale digitization of the paperwork that accompanies global trade.” However, this transformation has also introduced new risk into business operations – and it is important for organizations to understand and mitigate those risk as we enter into the “Next Normal.”
Some organizations had already begun the digitization journey before the pandemic hit, providing them with a head start. For example, companies that were already focused on collaboration technologies before COVID-19 were in the strongest position to maintain steady business operations when social separation and work-from-home (WFH) became new realities. Likewise, those with robust security mechanisms in place, such as sufficient VPN licenses and multifactor authentication, were better positioned to transition to virtual working while protecting sensitive information. And organizations that increased their internet and network capacity before the pandemic found it easier to connect to remote employees, customers, suppliers, partners and other stakeholders.
As one might expect, companies with bandwidth constraints prior to the coronavirus pandemic had a difficult time in the WFH environment, as did those with inflexible legacy systems and processes that could not keep up with user demand. For example, old government systems running COBOL had severe capacity problems as millions of citizens filed claims for social assistance. These older systems can’t be migrated to the cloud quickly, so IT departments were stressed finding “workarounds” to the problem. Other problems arose in cases where there was no pre-existing mobile strategy. For example, most call centers operate out of a central location with employees using desktop computers. Due to a shortage of available laptops, some call centers had no choice but to send desktop computers home with employees so they could work remotely, which led to implementation delays and interrupted operations.
Technology Preparedness - This includes the adoption of virtualization and cloud technology. Whether it’s servers, networks or desktops, virtualization enables organizations to dynamically scale their IT resources up or down as needed, while also providing centralized management and control. Virtualization can also enable more efficient use of existing IT resources, which generates greater return on investment.
While this has been an IT trend for several years, the increasingly widespread adoption of cloud continues to generate strong results. Migrating data to the cloud gives companies the scale, flexibility and redundancy to keep IT systems running effectively, even during massively disruptive events like a pandemic. It helps reduce the costs of hardware, power, firmware upgrades and on-site support, because these become the responsibility of the cloud provider. Software-as-a-Service (SaaS) is a great example of how moving applications to the cloud gives simplified, scalable and more reliable access.
Improved Cyber Security including Identity and Access Management (IAM) – WFH has obliterated many remnants of the traditional network perimeter, and with it the concept of perimeter security, where virtual “fences” keep the bad guys out. Identity has become the new paradigm of enterprise security – if you can ensure that only the right resources are accessed by the right people doing the right things, then you have a more secure environment. Modern IAM systems provide flexible authentication that enables people to work from home or anywhere else. And, with many companies announcing they plan to maintain expanded WFH policies beyond the pandemic, IAM has become the foundation in the modern secure working environment.
COVID-19 can be thought of as a harbinger indicating where organizations need to focus in order to thrive in the future with far more agile and resilient business processes.
Technologists alone cannot make digitization initiatives successful. Organizations can take a holistic view and consider many aspects of digitization, including:
Re-envisioning controls and testing – As more processes become digitized, it is logical to concurrently consider how control processes can also be digitized and automated. Building in more automated control processes at the beginning will allow companies to more efficiently and effectively monitor digitization risk while potentially reducing costs and time associated with compliance activities.
– As more processes become digitized, it is logical to concurrently consider how control processes can also be digitized and automated. Building in more automated control processes at the beginning will allow companies to more efficiently and effectively monitor digitization risk while potentially reducing costs and time associated with compliance activities. The ability to re-engineer processes – Before digitizing a process, it is important to evaluate that process to determine if it can be reorganized and re-engineered to deliver a better business result. Otherwise organizations risk digitizing flawed processes. This requires much broader thinking than simply ramping up bandwidth or installing new software.
– Before digitizing a process, it is important to evaluate that process to determine if it can be reorganized and re-engineered to deliver a better business result. Otherwise organizations risk digitizing flawed processes. This requires much broader thinking than simply ramping up bandwidth or installing new software. Proper funding – While investment is needed to get digitization projects underway, investments will be under scrutiny during the current uncertain business climate. Executives will likely need to show the projected value of a digitization initiative when stating their case for more funding, pointing out both short-term and long-term benefits.
– While investment is needed to get digitization projects underway, investments will be under scrutiny during the current uncertain business climate. Executives will likely need to show the projected value of a digitization initiative when stating their case for more funding, pointing out both short-term and long-term benefits. The right talent – Effective digital transformation requires expertise that spans both technology and business. These qualified professionals should be able to understand the functionality that was valuable in old processes, the benefits of creating new processes, and how technology can make it happen.
– Effective digital transformation requires expertise that spans both technology and business. These qualified professionals should be able to understand the functionality that was valuable in old processes, the benefits of creating new processes, and how technology can make it happen. Flexibility – Certain digital controls may have been relaxed during COVID-19 in order to speed up implementations and get WFH employees online quickly. This can open up new risks, so these controls may need to be re-applied over time to their proper levels. However, any process controls should be flexible enough to accommodate unforeseen requirements in the Next Normal, to avoid the fire drills caused by the coronavirus pandemic.
Finally, to thrive in the Next Normal, organizations should consider conducting risk assessments of digitized processes and take appropriate actions to remediate any identified security gaps. These assessments should also be a foundational element of future digital transformation initiatives, so the proper controls can be implemented from the beginning.
COVID-19 has turned digitization from a “nice to have” to a “must have” for many organizations, forcing them to adapt and modernize quickly in order to keep their operations running. While digitization may seem like a daunting task for some organizations, the pandemic has made it clear that sound business strategy demands identifying digital transformation opportunities and getting those initiatives underway quickly.
However, speed of transformation cannot come at the expense of risk, or the entire initiative can cause more harm than good. It is critical that cybersecurity and other risk factors be considered in the design stage of digital transformation initiatives, so the new digitized process does not weaken the overall risk profile of the organization. The good news is, all of this is readily achievable, and when done properly, it will make organizations much better positioned to thrive as they emerge from the pandemic into the Next Normal.​An organization’s biggest potential talent source may be its own people. But why do so many organizations find internal talent so hard to access?
Organizations have historically focused on external recruiting to find people for new roles, but with growing skill shortages and low unemployment rates, they are now finding that acquisition alone isn’t enough to access the capabilities they need. To fuel growth, organizations need to more effectively tap their current workforce to identify and deploy people with the required skills, capabilities, motivation, and knowledge of the organization, its infrastructure, and its culture. Creating better programs to facilitate internal mobility can pay off in multiple areas: growth, employee engagement, and business performance.
As talent markets get tighter and the world becomes more connected, a major new trend has emerged from our research: the need to improve internal talent mobility to more effectively move people among jobs, projects, and geographies. This year, internal talent mobility has become a C-suite-level topic, with 76 percent of our survey respondents rating it important and 20 percent rating it one of their organization’s three most urgent issues.
It’s not hard to understand why. For many organizations, their biggest potential source of talent is to access the enterprise’s own workforce and internal talent market. Surprisingly, however, that market is often undervalued and even overlooked, and many organizations find it amazingly difficult to access. The sad and maddening reality is that employees generally find it easier to find new—and more attractive—opportunities in another organization than to explore and move to new roles at their current employers.1 In this year’s Global Human Capital Trends survey, more than 50 percent of respondents told us that it was easier for employees to find a job outside their organization than inside (figure 1), a situation that leaders would do well to address.
Organizations have many reasons for starting to explore internal mobility in earnest. Hiring people with critical skills is highly competitive; workers who want to reinvent themselves don’t necessarily want to leave their current employer; internal mobility can be a way to embed collaboration and agility into an organization’s culture, which is one of the key attributes of becoming a true social enterprise; and agile organizations and career models dramatically improve employee engagement and commitment. Ingersoll Rand, for example, developed a robust internal career program to help employees reskill themselves for new positions within the organization, and invested in an interactive, analytics-based technology solution that allows them to explore and access alternative roles and career paths across the company. The result: a nearly 30 percent increase in employee engagement.2
Another major driver for internal mobility is the need for many organizations to globalize their operations as they expand into the fast-growing economies of Asia, the Middle East, and Africa. Schneider Electric, one of the largest French manufacturers of electrical systems and components, changed its structure from being a Paris-based, centralized operation to having four global headquarters: one in France, one in the United States, one in China, and one in India. The company now develops and markets products in each of these geographies, requiring the organization to create a culture of mobility, diversity, and inclusion. By creating four headquarters, the company can now offer roles in all four places that were available in only one location before, which increases both the need and the opportunity for employees to develop and grow into new roles. Schneider is now investing in new technology solutions to create more mobility options for its expanded organizational talent markets around the world.3
The shift toward flatter organization models also creates a greater need for internal mobility. As organizations start to operate in teams and networks, managers are realizing that open access to the diverse skill sets, backgrounds, and experiences held by the organizations’ own people is essential for success. To staff projects and programs as they grow, team leaders have to find expertise throughout the network, which is difficult if the organization lacks an active and open internal mobility process.
Although internal mobility is a high priority, it’s not easy to do well. Only 6 percent of respondents told us they believe they are excellent at moving people from role to role; 59 percent rate themselves fair or inadequate (figure 2).
One reason internal mobility is difficult is that most organizations are modeled around hierarchical structures: systems that people enter at the bottom and spend years working their way up to increase their influence, impact, and rewards. But while organizations have spent decades building career and promotion models to help people move up the pyramid, that’s not the same thing as having a vibrant, easy-to-navigate internal mobility market and culture across the entire organization. Only 32 percent of this year’s survey respondents believed that their organization’s employees have opportunities to move between operating divisions. Forty-nine percent of respondents, the largest proportion, identified the lack of processes to identify and move employees as a top-three barrier to internal talent mobility (figure 3). Siloed organizational models make it hard for managers to look for talent outside their own fiefdom, and block employees’ views into opportunities elsewhere in the enterprise.
What’s more, incentives are rarely set up to encourage hiring from within. Unless hiring managers are actively encouraged and rewarded for hiring internal candidates, they may pass over existing employees looking for development. Equally problematic, an internal candidate’s current manager may resist other departments’ or managers’ efforts to recruit the person unless incentives are in place to encourage managers to develop subordinates’ skills and support their growth. Indeed, 46 percent of this year’s survey respondents told us that managers resist internal mobility. Team leaders who are rewarded for producing results but not for promoting internal mobility have no reason to welcome the prospect of losing a high-performing team member—creating an obstacle to mobility, no matter how hard HR promotes mobility programs.
Culture is also a barrier in many organizations. Seventy percent of respondents told us that talent mobility expectations, the culture around talent-sharing, and decision-making around mobility were inadequate or only fair at their organization. Technology and systems around internal mobility, too, are often lacking. Forty-nine percent of respondents told us that they have few, if any, tools to identify and move people into new internal roles. Forty-five percent said their employees lacked visibility into internal positions. And in our conversations with clients, many HR leaders tell us that employees find it easier to quit and be rehired than to change positions within the organization because of the lack of systems to enable and promote internal moves.
Are the problems worth overcoming? Our respondents think so. Beyond looking at internal mobility to fill open positions, our respondents cited several other strategic business reasons for urgently focusing on this issue. Thirty-eight percent are looking at internal mobility to build better leaders, 31 percent cite the need to expand the business, and 32 percent believe mobility is required to increase employee engagement.
At one global engine manufacturing leader, encouraging internal talent movement stems from a firm belief that learning through experience is extremely powerful. One employee we spoke with said that this emphasis makes the company a “playground for learning” and praised “the number of cross-functional moves that take place and how open leaders are to considering high performers for any number of assignments regardless of their technical background.” Not surprisingly, enabling these experiences not only provides learning opportunities, but also raises employee engagement.4
Other organizations that have made substantial investments in internal mobility are also seeing these investments pay off. To take a well-known example, AT&T has spent hundreds of millions of dollars since 2013 on upskilling its employees, both by providing direct education and professional development programs and through tuition assistance. The program’s goal is to fill existing openings with people already at the company, and by that measure, it is succeeding: From January to May 2016, upskilled employees filled half of all tech management jobs and received almost half of the available promotions.5
A global bank offers another illustration of the types of talent market and mobility initiatives organizations are exploring and launching. The bank is building a new function for internal mobility that integrates talent acquisition with career mobility and takes an enterprisewide view and scope. Not only are internal mobility initiatives moving beyond new programs and processes, but leaders’ mindsets are changing to view the company’s entire workforce as a talent market that allows for multidirectional careers. This, in turn, is influencing how leaders think about operating models and organizational structures as internal boundaries become less important and enterprise teams and internal capability markets increase in importance and impact.
Companies like these have caught on to what is becoming more and more self-evident: Internal mobility is a driver of growth in today’s digitally powered, highly competitive global economy. The numbers tell the story: When we looked at the fastest-growing organizations (those growing at 10 percent or more compared to the prior year) in our survey, they were twice as likely to have excellent talent mobility programs than organizations that were not growing at all, and more than three times more likely than organizations whose revenues were shrinking.
As organizations reexamine how they approach internal mobility, they need to address a fundamental issue: Internal mobility today is governed by a set of (often unwritten) norms that are outdated and need to be fundamentally recoded for the future needs of today’s workers and organizations (figure 4). It is only through this reinvention that organizations may be able to unlock the potential hidden within its existing workforce.
Not surprisingly, the earliest adopters of this shift have come from the technology industry. Spotify and Facebook are leading examples. At Spotify, internal mobility has become such a core cultural element that employees take on a new role, on average, every two years.6 And at Facebook, employees and managers have conversations about career progression with internal mobility understood as an accepted element.7
Internal mobility, in short, can be a major source of critical talent and competitive advantage. To do it well requires investment and a focus on culture, infrastructure, and incentives—but it’s an investment well worth considering for leaders looking for ways to bridge the talent gap. In an economy where outside talent is becoming more and more difficult to find and attract, looking within can make the crucial difference between struggling and succeeding.Every organization already has some form of vulnerability management. But often it is not immediately related to DevSecOps. This is understandable as traditionally the use of security tools and monitoring of the IT landscape is often positioned with the security team. DevSecOps brings the security tools and monitoring to the development teams themselves. This means that the traditional vulnerability management needs to be extended or copied into the development teams. But since there is a different way of working, it calls for a different approach.
Our DevSecOps model shows various tools that can be leveraged in a DevSecOps pipeline. All these tools provide output; information that is new for the developers that work with those tools. All this information needs to be interpreted and adequate actions need to be taken. But how to interpret it? When is something bad, really bad, or not bad at all? And does action mean drop all your work and fix it, fix it next week, or just put it on the backlog for later?
The security team, developers and product owner need to work together and think about this. Depending on the nature and purpose of your application some vulnerabilities might be acceptable or not. And mitigating actions can be simple of complex. All these things need to be considered and balanced out with the costs and business priorities. For this there should be a clear and flexible vulnerability management process, to bring together the tools and people, as well as the developers and the security team.At the beginning HR has played a crucial role in managing the COVID-19 response at an organizational level. HR has been the driving force in keeping the workforce and organization engaged, productive and resilient. This situation has illustrated the true value of HR and has proven the importance of investing in flexible and robust HR processes and structures. As shocking as the COVID-19 crisis is, it also introduces a rare opportunity for HR to rebuild and take the lead in driving organizational stability and strength. Now that we are past the respond phase, HR needs to materialize on this opportunity: the time has come for HR to reimagine not only its own future, but also the future of the business/enterprise (see here for the full story around the Future of work: Redefining work, workforces, and workplaces).Massive scope: During this phase, there is a lot of excitement about the world of possibilities with RPA. Processes are selected based on how easy is it for humans to execute the process. 80% of the work is deemed suitable for automation just because it is rules-based. There is little comparison of what constitutes rules based decision-ing for humans versus RPA (e.g. Jon versus Jonathan may be ok for humans to action but typically not ok for Robots).
Huge savings: Industry “benchmarks” are used to estimate the size of the prize, with anecdotal evidence from single data points and article headlines used to justify the initial cost-benefit estimates. Savings of 50-60% and program return on investment in the first 6 months are not unusual.
Easy to implement: There is a strong belief that RPA programs are really easy to implement. This is partly driven by advances in user interfaces on the RPA tools and desktop recorder like functionality used in most demonstrations and Proofs of Concept. The roles in the RPA program are mainly business focussed – typically Business Analysts, with some doubling up as RPA configurators/RPA developers and project/program manager(s).
Missed roles in the operating model: As the first few project are nearing go-live, multiple roles emerge with team members asking the question “who’s responsible for that”? Typical examples are – who would oversee actual running of these Robots updating schedules and resource allocation based on changes in demand? Who would tweak/fix/modify them when business processes change “slightly”, IT applications have an unplanned change e.g. batch jobs are cancelled for a week requiring different interpretation of the data presented on the user interface?
Underestimating IT environment complexity: Using the assumption that Robots are simply rules based humans, initial RPA projects typically overlook the complexity and idiosyncrasies of interacting with various target applications. Some of IT application require only one log on and log off during the day, others are the opposite. Some are built for browsers that the RPA tool doesn’t support natively leading to longer build times and requiring a more robust design. Finally, there are implications on upstream and downstream systems that underpin the target applications which need to be considered in the Automation build.
Using RPA to cover for process gaps: RPA is sometimes incorrectly used to address operations pain points related to broken processes e.g. lack of standard operating procedures, low levels of documentation rather than challenges around scale, operational risk, seasonality, speed for mature, well documented processes. This leads to longer design times, “discovery” of new business scenarios during testing/pilot, reduction in scope of what can be automated using RPA and rework of Automation build – leaving the stakeholders frustrated, increased costs and lower benefits
Phase 3: Eyes wide open – “RPA requires structured, cross functional effort with specific focus on foundations”
Industrialised RPA framework: Development of a Robotics Operating Model (ROM) is critical to scale process automations. The ROM needs to clearly define new roles, accountabilities and controls specific to development and use of RPA. The RPA build requires a new Robotics Delivery Lifecycle and a new Robotics Support Lifecycle. Both of these are similar in some aspects but quite different in others from the typical software delivery and support lifecycles.
Robust Robotics platform: The RPA platform is only as strong as the underpinning platforms it relies upon. These include but are not limited to the virtualisation platforms, the networks and hardware infrastructure that host the Virtual Desktops that the Robots use to interact with the target applications. Any gaps here will result in slow robots resulting in missed OLAs/SLAs, typically mitigated by increasing resource requirements or adding more bots but this results in higher run costs. An inadequate platform also causes robots refer more business transactions to human workers which in turns reduces benefits from Automation.
Cultural change readiness: Implementing RPA at scale requires a change in the organisational culture at many levels. First and foremost, the business needs to prepare for the workforce implications both in terms of roles that are no longer needed as well as the new ones that are going to be needed. Secondly, RPA needs to be seen as a lever in Operations Excellence which means fundamentals such as waste elimination, process standardisation and simplification cannot be ignored. Finally, for RPA to scale it may be business led but it also needs to be technology (IT) driven – after all Automations are a hybrid of process and technology.
RPA programs can be a huge success and scaled RPA capability is not a pipe dream. However, organisations need to realise that their human workforce is a lot more adaptable and forgiving than their robotic counterparts. Building out a Robotic work force requires a lot more operational discipline, a technology platform to match, and much greater collaboration between the operations and technology teams.
In the next post, we will share our battle-tested tactics to advance quickly and with less pain to Phase 3.June 17, 2019 You might think that advanced industry—a sector characterized by research and development and use of artificial intelligence and other breakthrough technologies—also optimizes the way its R&D organizations work. But continual business and technology trends in advanced industries (AI) have triggered fundamental challenges that require advanced industry innovate in its approach to R&D.
Just consider the three major R&D hurdles automakers confront in designing autonomous cars: more complexity and functional interfaces across projects, especially involving interlinks between software and hardware; amplified change and ambiguity in customer demands; and tighter interaction with an increasingly diverse ecosystem. As a result, decisions take too long, milestones are missed and standard operating procedures are delayed, siloed and fragmented. R&D staff stay in task force mode, and collaboration and job satisfaction diminish.
Early agile models in advanced industry R&D departments are delivering significant impact. We’ve seen a doubling of the time spent on value-add work, speedier decision-making, a 30 percent rise in productivity, increased engineer motivation and enhanced responsiveness to customer demands.
Sidebar Designing flying taxis: Is agile the key to innovative R&D? Many research and development (R&D) teams find themselves held back by a traditionally siloed structure in a rapidly changing environment, particularly in heavy industries. We connected with James Arnold, head of design systems and head of process excellence at Lilium—a European company developing the world’s first electric vertical take-off and landing jet—for a first-person perspective on what an agile R&D department looks like when starting greenfield in a highly innovative industry. Arnold and his team recently completed a successful first field test of its all-electric five-seat aircraft and hopes to launch a fully operational flying taxi service in select cities by 2025. Question: You are a small start-up exploring a very futuristic technology. How are you approaching innovation, and how has experimentation played a part in the process? Arnold: The history of the development of our aircraft is one of experimentation and iteration. From the very start, our founders worked with physical prototypes to test and demonstrate ideas, and as the company has grown, we have developed many prototypes in increasing levels of complexity. This kind of experimentation—and working towards something that can be tested and learned from—is essential for innovation. Q: Can you talk about the positive social and environmental impact of this unique mode of transportation? Arnold: We like to think about the “radius of life.” When you can travel five times faster than you can by typical ground transport, your horizon for commuting also increases by five times. Five times the radius gives 25 times the area and 25 times the possibilities. Or you can gain that time back for yourself and your family and create a big increase in wellbeing. Congestion and ground-level pollution will drop dramatically; cities will become cleaner, greener, quieter and safer. Q: What characteristics were critical in putting together your R&D team? Arnold: Research shows the impact of diversity, in terms of outcomes and the positive effect on team interactions. We have people with 30 years of experience working alongside undergraduate interns. We have people from different industries and cultural backgrounds. To benefit from this, we also need people who are open and ready to learn and try new ideas. Q: How do you manage collaborations to incorporate cross-functional teams for effectiveness? Arnold: We build our main cross-functional teams around the product breakdown structure; each major aircraft system has a dedicated team. Each team is established from the start of the program and is co-located, with a single day-to-day leader from the systems engineering team. We believe there's a huge increase in effectiveness and efficiency when sitting together vs. trying to collaborate virtually. Q: How are you looking at scaling the R&D unit? Arnold: Our goal is to make the foundations, processes, systems, mindsets and skills scalable. This means continuously challenging and improving things like our onboarding process for engineers, day-to-day collaboration and data management. It’s also important to expect and embrace the changes that scaling brings. Different structures and approaches are better for different sizes of teams, and it’s OK to change! Q: How is agile part of the equation for your team? What principles have been key? Arnold: One of the original principles of the Manifesto for Agile Software Development—the progenitor of the “agile” concept—is simplicity. Our whole architecture is designed to be extremely simple, and we drive this down into the detailed design of every part. We also work in short, iterative cycles that come to some sort of end product that can be evaluated. The objective is to learn quickly and efficiently, with a short lead time. Q: The hallmark of agile is to continually evolve. How do you ensure ongoing changes happen while still protecting the agile culture? Arnold: Due to our extremely fast team growth, we have a slightly different problem. Change is happening and will continue at a breakneck pace for several years. We work to protect and build on our engineering culture but also allow evolution and new people to bring new ideas. To take advantage of this, it’s important to have and reinforce core principles that give a framework but are not too rigid. Sometimes you can embed these principles into processes, but that’s not enough—there needs to be a huge and continuous effort to reinforce the right mindsets.
So, what comprises a more effective agile organization that sparks cross-functional collaboration, quick decisions, fresh ideas from anyone, flexible shifts of priorities and resources, and a place that attracts talent drawn to rewarding and fun work?
We can look to other industries such as banking, energy and telecom because they have faced similar issues. For instance, when one banking institution moved to a model where small teams follow a joint purpose and enjoy full end-to-end responsibility, they significantly improved cross-functional collaboration, time to market and customer satisfaction while moving to No. 1 employer of choice from No. 12 two years prior.
From these other industry pacesetters, advanced industry can take agile mindsets, principles and values while tailoring practices and tools to their own R&D realities. If an R&D organization truly wants to change how it operates, it needs to:
Derive promising learnings from pilots for organizing agile teams and make necessary changes to its “backbone” system, such as budgeting and work allocation processes and alignment of plans and priorities.
We do see some winning practices in selected “frontrunner” R&D departments in advanced industry as they pertain to structure, process/technology and people dimensions.
Structure: Create small, stable e2e teams that are accountable and possess a shared purpose instead of organizing by competencies. When priorities change, shift the task, not the people. People should work and sit together in teams but retain a home base within their discipline (e.g., electronics). They assume responsibility for managing common components and setting software and other architectures.
Processes/technology: Work on end products in rapid iterations and quick learning cycles, applying new testing technologies in standardized, not religious, processes. Enlist customers early. Favor more frequent and smaller decision meetings—in a way disaggregate today’s big meetings—that focus on decision-making versus status approvals.
People: Leaders change their style, e.g. visionary, focusing on coaching and problem solving and embedding ownership in their teams. That means asking them to develop their own plans and solutions and focusing on providing a clear framework, including clear interfaces and responsibilities. This requires ensuring a culture with stronger collaboration, more ownership from lower-level team members and risk assumption. Development teams also must step up. As one manager explained, “If your engineers behave as fenced-in sheep and you remove the fence, they will just continue grazing in the same place and nothing changes.”
Most advanced industry players have begun experimenting to determine where and how to apply agile, but they must scale it up for the full impact. Pilot projects prove important to learn whether a concept works, and they can boost enthusiasm. Technology trends will continue and as organizations meet these challenges, a full agile operating model will be required.A blog post by Dennis Ortiz, managing director, Deloitte Consulting LLP and Howie Stein, senior manager, Deloitte Consulting LLP.
Imagine you have a question about your subscription to a streaming service. As you search the company's website for a customer service number, a message box pops up to ask if you need assistance. You soon find that resolving your question can be done as easily as texting a friend—but the customer experience hadn't always been so fluid. The media company behind the service had grown through acquisition, building a vast product catalog with complex service processes. To simplify support, the firm deployed an intelligent chatbot—powered by artificial intelligence (AI)—to enable customers like you to self-serve through voice or text interactions with a computer.
This is just one example of how companies across technology, media, and telecommunications (or TMT) are leveraging conversational user interfaces (UIs) to meet their unique service delivery challenges. More and more, TMT customers expect the same leading customer experience from their support interactions as is delivered by the products themselves. These buyers are increasingly digital-native, with growing expectations for service and support to be integrated or adjacent to the services themselves. For example, wireless subscribers expect support options within the carrier's app, and software customers expect service on the same platform they are using from the provider. Moreover, TMT customers expect sophisticated personalization across channels, including chatbots. If their need cannot be resolved by the UI, customers expect to be transferred to a human with context on the issues and which products the customer uses.
The chatbot has evolved. Today's top chatbot platforms offer a powerful bundle of advanced cognitive technologies, including native machine learning and natural language processing and generation. Such technology can handle large datasets1 to process, evaluate, and respond to inputs, mimicking human conversation. This enables numerous customer engagement applications, including common uses such as billing support, customer authentication, and FAQ responses, and more sophisticated applications, such as technical support.
Chatbots can integrate with back-end systems to aggregate what a company knows about a customer (e.g., products, usage, and error messages) and proactively diagnose problems. For example, a wireless company can detect excessive dropped calls and proactively suggest there may be a problem in the customer's neighborhood, and a hardware manufacturer may take action based on error codes received from its hardware. Further, a chatbot can consume volumes of service records to guide a customer in troubleshooting a product.
TMT leaders leverage chatbot technology to address costly challenges that hurt customer satisfaction: Ineffective customer hand-offs, manual processes driving handle times, procedural confusion or inconsistency, etc. Others are hindered by traditional data silos that exist in TMT companies, especially relating to customer data. These firms must design cognitive programs that break silos to uncover data and insights outside their traditional IT systems, enabling them to service customers in new ways.
Chatbots are a strategic avenue for companies to begin integrating AI into their business, and the benefits can be significant. To learn more about how conversational UI and other AI-enabled technologies can help improve your customer engagement strategy, read our full article or get in touch.Dr. Suz is a social-personality psychologist and a leading practitioner of Deloitte’s Business Chemistry, which she uses to guide clients as they explore how their work is shaped by the mix of individuals who make up a team. Previously serving in Deloitte’s Talent organization, since 2014 she’s been coaching leaders and teams in creating cultures that enable each member to thrive and make their best contribution. Along with her Deloitte Greenhouse colleague Kim Christfort, Suzanne co-authored the book Business Chemistry: Practical Magic for Crafting Powerful Work Relationships as well as a Harvard Business Review cover feature on the same topic. She also leads the Deloitte Greenhouse research program focused on Business Chemistry and is the primary author of the Business Chemistry blog. An “unapologetic introvert” and Business Chemistry Guardian-Dreamer, you will never-the-less often find her in front of a room, a camera, or a podcast microphone speaking about Business Chemistry. Suzanne is a University of Wisconsin-Madison graduate with an MBA from New York University’s Stern School of Business and a doctorate in Social-Personality Psychology from the Graduate Center at the City University of New York. She has lectured at Rutgers Business School and several colleges in the CUNY system, and before joining Deloitte in 2009, she gained experience in the health care and consulting fields. A mom of two teenagers, she maintains her native Minnesota roots and currently resides in New Jersey, where she volunteers for several local organizations with a focus on hunger relief.Job search and application: The job search/application is the first touchpoint that a candidate has with an organization. Sometimes, job postings can be too tailored to organizations, leading to confusion among candidates, while deciding roles that match their experiences and skills. While providing a negative candidate’s experience, this can also reduce the quality of applicants. Alongside this, overly lengthy application processes can also deteriorate the candidate’s experience.
According to a survey, 60 percent of candidates have quit an application process because it took too long. (Erin Engstrom, n.d.). Various talent acquisition vendors have identified this as an opportunity to enhance/simplify and provide a high-touch candidate’s experience. If we look from the perspective of the candidate, an ideal scenario would be where they would be able to apply for a job, as easily as they can click ‘buy now’ when shopping online—providing only must-needed information upfront! However, sometimes this information would not be sufficient for the recruiters to weed out applicants. The balancing act is to create an application that is not front-loaded—gathering only relevant information upfront, while also being interactive for the candidate. Outlined below are two ways where technology has been utilized to generate a unique candidate’s experience during the job search and application experiences.
Job seekers are often unaware of the various roles in an organization that they may be a good fit for based on their skills and experiences. Artificial intelligence and cognitive talent management solutions can be utilized to personalize the experience and guide applicants to jobs they may potentially be best suited for within the organization. When an applicant is visiting the website, Artificial intelligence can also engage with the job seeker in personalized discussions and recommend potential job opportunities to the candidate within the organization. By providing this unique experience for the candidate, organizations are able to make a strong connection with potential employees at the very beginning of the process.
The rise of voice technologies has changed the way individuals have been completing tasks and interacting with their devices. A leading fast-food chain (McDonald's) has utilized voice recognition to provide a quicker and more interactive way for them to apply for jobs.² A job prospect can now utilize voice recognition software to answer a couple of quick questions and apply for a front-end job. Followed by which they receive an SMS link on their phone to complete their application and apply for a job. The company is envisioning this as a way to provide young people an opportunity to start entry-level careers at one of its restaurants through artificial intelligence-powered digital voice assistants. In a time, where convenience is a key market differentiator, this organization has definitely utilized it to generate a positive hiring experience!
Interviews: LinkedIn has found that 83 percent of talent say a negative interview experience can change their mind about a role or company they once liked. Strategic implementation of tools and technologies can help organizations significantly enhance the screening and interview experience of candidates. A clear and transparent interview process is a paramount priority for job seekers today. Outlined below are two ways in which an organization can drastically improve its candidate’s experience while interview scheduling and conducting the interview.
An organization can successfully differentiate its candidate’s experience during interview scheduling by reducing the amount of time spent back and forth between emails trying to identify timings that work best for interviews. Technology can be utilized to manage schedules and availabilities, book rooms, provide clear communication, etc., providing recruiters with the opportunity to focus on more strategic work. Self-scheduling interview technology can be utilized to significantly reduce interview coordination time for candidates. Once the candidate elects their chosen interview time, some leading systems can even generate notifications to the interviewers providing them with all the relevant information required to conduct the interview. Providing candidates with the opportunity to schedule interviews per their own convenience, while reducing the back and forth between themselves and the recruiter, helps generate a positive experience for the candidate.
The advent of new digital technologies and methods of collaboration has changed our ways of working. Considering our new reality and rapid increase in virtualization, video interviewing technology has been rapidly incorporated amongst many leading organizations instead of face-to-face interviews. Talent lives all over and is not restricted to the headquarters of your organization. Considering that many candidates (like talent acquisition specialists and managers) have busy schedules, in-person interviews can sometimes be difficult to conduct, while also being more expensive. This brings in the need for video interviewing software. Video interviewing software can be utilized in the form of live in-person interviews as well as prerecorded interviews. Prerecorded interviews serve as an optimal method to prescreen candidates, prior to bringing in top talent for in-person interviews. Utilization of video interview technologies as a part of the screening process provides candidates the flexibility to move through the talent acquisition process at their convenience.
Providing a positive candidate’s experience has enormous benefits to an organization not only in terms of developing a stellar brand but also in terms of measurable business outcomes. Sixty-four percent of surveyed job seekers say that a poor candidate’s experience would make them less likely to purchase goods and services from that employer.³ Therefore, a poor candidate’s experience can not only drives top talent away but also helps increase the number of unhappy customers. So, a focus on a candidate’s experience is imperative for an organization’s success.
Technology can play an important role in improving the candidate’s experience during their talent acquisition journey. Treating candidates well helps enable the organization to find the top talent and stellar candidates, including those who weren’t right for one role, but were the best fit for another or will reapply again in the future.
Bhawna Bist is a senior manager in the Workforce Transformation practice of Deloitte Consulting LLP, specializing in the Future of Work and talent acquisition transformation. She has more than 18 years of cross-industry and consulting experience advising global organizations and leading strategic transformation programs.
Aarushi Gandhi is a consultant in the HR Transformation Advisory practice of Deloitte Consulting LLP based out of Canada with experience across talent acquisition transformations, HR roadmap and org design, and workforce experience and process design.
¹ https://www.forbes.com/sites/zackfriedman/2019/05/22/millennials-disillusioned-future/#21317b03353e
² https://www.theverge.com/2019/9/25/20883007/mcdonalds-apply-thru-amazon-alexa-google-assistant-job-applications-ai-automationYou don’t need a business background to succeed at McKinsey. More than one-third of McKinsey consultants don’t have business degrees, and about half don’t have MBAs. Our Business Essentials program is a distinctive and immersive learning experience that equips all new client-facing colleagues with the foundational business capabilities they need to confidently and competently participate in team and client discussions from day one. It is individualized to your background and experience, and will introduce you to a set of curated core business principles and their application within the McKinsey context and frameworks through a blend of on-line modules, virtual classroom sessions and an in-person capstone event. Beyond the formal training programs, you will learn quickly by working with other McKinsey consultants on client engagements, and you will find that McKinsey has a supportive environment, with both formal and informal mentoring to promote development.
McKinsey allows you to use your legal training to make an immediate and dramatic impact. Consultants need the very skills that lead to success in law school, including strong leadership and communication skills and the ability to address multiple conflicting points of view to solve complex problems. At McKinsey, you also have the opportunity to advance more rapidly than you might in the legal profession. Whereas it can take years for new associates at a law firm to advance to a position of responsibility, new McKinsey consultants frequently find themselves directly advising CEOs and other leaders within months of joining the firm. McKinsey has a long-standing interest in attracting and retaining lawyers. In fact, Marvin Bower, the father of the modern McKinsey organization, was a lawyer, and he built McKinsey based on the professional principles he learned from his experience in law. Today, more than 250 consultants at McKinsey have law degrees. They joined McKinsey at various points in their careers—some immediately after law school and some after practicing law for years.
Consultants with master’s degrees represent a broad spectrum of experience. Your role upon beginning your career at McKinsey depends on your academic and professional background.
Generally, if you are pursuing a master’s degree and you earned an undergraduate degree fewer than 4 years ago, you will be considered for a business analyst position. If you hold a bachelor’s degree and have at least 4 years of work experience, or you completed or expect to complete your master’s program 4 years from the time you received your bachelor’s degree, you will join as an associate.
We understand that the additional training you received and the expertise you developed by attaining a master’s degree add value to your work as a McKinsey consultant. McKinsey was the first consulting firm to systematically hire consultants with advanced professional degrees outside of business; currently, more than 3,000 of our consultants worldwide hold master’s degrees in fields other than business. Often, because of their professional experience, business analysts with master’s degrees show promise immediately, putting them on a fast track for promotion to associate.
At McKinsey, consultants advance based on performance—not background or tenure—so if you perform well, you’ll be considered for early promotion. Here are some example scenarios for possible entry points to a career at McKinsey. If you are interested in the German office and hold a bachelor’s degree and completed a 1-year master’s program, you will join as a fellow. If you are interested in joining the UK and Ireland office with a master’s degree, you will typically join as a business analyst. If you are interested in a North American office and hold a bachelor’s degree and have at least 4 years of work experience, or you completed or expect to complete your master’s program 4 years from the time you received your bachelor’s degree, you will join as an associate.
Nearly 200 McKinsey consultants around the world have medical degrees. Some joined the firm right out of medical school, others after years of leading clinical departments at major medical centers. McKinsey has found that the consulting world needs many of the same attributes and skills that contribute to MDs’ success in medicine, including being intellectually curious, creative, and analytically talented. MDs bring their teams not only relevant skills but also a valuable clinical perspective that allows them to approach healthcare problems distinctively. On healthcare projects, MDs understand the context deeply from day one and can speak the language of medicine with clients and external experts.
McKinsey typically hires MDs as generalist consultants into an associate role, the same roles as their colleagues with MBAs. While most McKinsey MDs focus on healthcare over time, all McKinsey consultants, regardless of background, are encouraged to pursue a range of interests across a wide array of industries and countries. On McKinsey teams, MDs find many opportunities to contribute their medical knowledge, but the strong problem-solving and people skills developed during their medical careers are often their most important assets.
Practicing medicine can be fulfilling, emotional work. As a physician, you establish relationships with individuals and often see your influence immediately. Performing a difficult surgery, diagnosing a disease accurately, or giving hope to patients and their families can bring tremendous satisfaction. McKinsey offers a different kind of satisfaction. Rather than influencing one patient at a time, you can help shape the systems and strategies that have much broader impact. We help our clients tackle some of their toughest problems. As a consultant, you have the potential to help shape the way healthcare decisions are made—decisions that influence the care of thousands or even millions of patients. Additionally, McKinsey MDs enjoy the opportunity for learning and personal development. Through the combination of diverse and challenging client work, high-quality training programs, and one-on-one apprenticeship, McKinsey creates an unparalleled learning environment that most McKinsey MDs value greatly. Finally, McKinsey MDs greatly enjoy their colleagues; McKinsey is a diverse, talented, and engaging group of people who do their best work as part of a team.
Currently, there are more than 1,400 consultants with PhDs at McKinsey globally, and most say they came to McKinsey to broaden their horizons beyond the academic setting. As consultants, they find they can apply their problem-solving skills in new ways, work in fun and stimulating team settings, and make a measurable impact more quickly and more often. Many came from careers in basic research, where they often worked in isolation and where it can take years to achieve tangible results. As McKinsey consultants, they work through their clients’ problems in months or even weeks rather than years. To solve those problems, they work side by side with other consultants and with their clients. As in academia, the environment at McKinsey is intellectually stimulating and competitive, but it’s also ever changing and supportive. PhDs who come to McKinsey appreciate the chance to tackle a new challenge with each engagement, and they develop personally and professionally as they go, with mentoring support, on-the-job training, and more formal learning opportunities such as our Business Essentials program and leadership courses. For someone who has spent years conducting research within the same field, coming to McKinsey offers the chance to branch out—to explore new industries and new ways of thinking. Many consultants with PhDs in fields such as pharmaceuticals or high-tech go on to work in those areas, but some choose to enter industries they might never have been exposed to before joining McKinsey, including media, private equity, consumer goods, and banking.
Every McKinsey engagement demands the same qualities you need to succeed in academia: strong problem-solving skills, intellectual curiosity, and the drive to achieve results. The difference is, at McKinsey you’ll be working with and presenting your findings to business, government, or social-sector leaders. McKinsey consultants learn to solve problems quickly and make fast decisions, even when they don’t have all the information about a particular subject. Consultants with PhDs say one of the biggest challenges—and most attractive aspects—of a career with McKinsey is this shift in thinking. In the academic setting, they grew accustomed to diving deep into a subject, often spending years gathering and analyzing data. At McKinsey, consultants learn to work with the most important information, whittle a problem down to its core, and offer a solution that helps a client make better decisions, often when it’s not a clear-cut, easy answer.
Joining McKinsey would be a major career change for me. How can I ensure my success in the long term?
Consultants with advanced professional degrees outside of business are elected to partner at McKinsey just as often as consultants with MBAs. We want you to succeed, and we’ll support your growth with formal training and development programs to continually strengthen your business and leadership skills. Our apprenticeship model ensures you’ll always have experienced consultants to turn to for advice or insight. Expectations are high—McKinsey consultants handle some of the most sensitive, critical issues faced by the world’s top organizations—but they’re also clear. You’ll know your responsibilities before beginning each client engagement, and when you need help, you can turn to one of your fellow consultants or one of our 30,000 plus alumni worldwide. You’ll grow with each engagement, but you’ll be the one directing that growth. We understand that not everyone wants to become a partner. If you find another opportunity that interests you, we’ll support you as you pursue it. You’ll take the skills and knowledge you built at McKinsey with you into your chosen field, and you’ll stay connected as part of the global McKinsey alumni network.
McKinsey can enable you to build skills in new industries and functional areas as well as use and build on the skills and experience you have already gained. After building on your core consulting skills, you can choose to craft a program that leverages your background, experience, and knowledge by serving clients on topics close to your background area, or you can choose to focus your program on completely new client topics. In either case, you should be prepared to increase your knowledge base of new industries and functional topics.Whenever your organization uses a third party as a processor, there must be a data processing agreement in place. This contract, which can be integrated in the general contract with the third party, is important to ensure that both parties understand their responsibilities and liabilities regarding the processing of personal data. A clear contract negotiation and onboarding process sets the basis for a structured and successful relationship with a third party. This process should involve all the requirements, controls and procedures that are relevant to your business with regards to data protection, data use and privacy compliance. A clear contracting and onboarding process will make sure that your future contracts with third parties contain adequate privacy measures. To make sure also existing contracts with third parties contain adequate privacy measures, those could be addressed through a risk-based approach and adjusted where needed.If you have read any of my articles over the years you will know that I subscribe to the definitions of DevOps that focus on outcomes and business value, not the definitions that focus on tools and engineers. Having said that, I have frequently written that DevOps is about continuous learning and improvement and removing bottlenecks from the software development lifecycle (SDLC).
As I look back over the last 10+ years since the term DevOps was coined, I have witnessed a pattern of removing bottlenecks from the SDLC in the following order (usually):
In the early days, DevOps was mostly focused on solving the bottleneck of inconsistent builds and environments. Practitioners focused heavily on tooling and automation around the build process and infrastructure. This is the primary reason why many people think DevOps equals CI/CD, but as you will see in the rest of this article, it has moved way beyond that. CI/CD is a commodity now and an area that many organizations have solved yet are still continuously improving over time.
As practitioners beefed up their skills in perfecting the build process, they looked to solve the next bottleneck which was throwing the code over the wall to be tested. A lot of time was being wasted in the back and forth processes required to shake out the critical defects. Automated testing became a standard for the CI process from this point forward.
Most companies who have been on their DevOps journey for a few years, have a solid track record with CI/CD and automated tests in the build process and are now focusing on one or more of the next bottlenecks.
Yes, the dreaded DevSecOps term. Practitioners who removed many of the bottlenecks caused by inconsistent builds, unrepeatable deployments, and lack of test automation now look to remove the next big bottleneck which is usually security. A lot of work is happening in enterprises to involve security teams and security architects in the SDLC from the start. Security code scans are now part of many CI/CD pipelines. Security policies are being baked into cloud platforms and continuous security monitoring and alerting is becoming the new norm.
Traditional Ops is being totally rethought. We see a lot of movement around SRE (site reliability engineering), observability, platform engineering, chaos or resiliency engineering and many other modern approaches to running apps and platforms in the cloud.
Nothing says bottleneck more than governance and compliance. Many mature DevOps shops are focusing heavily on culture change in this area. Some companies are creating governance and compliance teams that focus solely on the cloud and act as a liaison back into their respected COEs (Center of Excellence) in corporate IT as a way to speed up approvals and decision making.
Another major bottleneck is problem resolution and MTTR (mean time to repair). Many companies are shifting support left, closer to the people with the proper context of the application so that problems are solved faster. This usually requires a culture shift to product centric mindset as opposed to project centric mindset and t-shaped management structures where the same manager who is responsible for building the software also owns supporting it.
While I have watched this unfold over the last 10+ years, I often ask “why aren’t we talking about architecture?” All the automation, op model changes and process improvements in the world do not solve for bad or overly complex architectures. At the DevOps Enterprise Summit in 2019, I watched a great presentation by architect Scott Havens that nearly brought tears to my eyes. Finally, someone was talking about architecture as a bottleneck and prescribing a way to address it. He discussed functional programming methods and ways to avoid or simplify complexity in systems. If you are technical and have 30 minutes, I recommend watching this video (he starts around the 7-minute mark).
I wish more architects would be more pragmatic like Scott. I have seen too many instances where architects run to microservices as an end-all be-all solution to solve all of their problems only to create a complex mess of unmanageable chaos. Microservices are only as good as the architecture they are deployed in. The same can be said for any of today’s hot new technologies such as Kubernetes. I run out of fingers and toes to count how many times I have seen teams run off and go dark on the business as they spend precious dollars and hours building Kubernetes clusters for the sake of Kubernetes, not for the sake of the business.
Microservices, Kubernetes, Cloud, AI, ML and all other hot technologies are all force multipliers and can be powerful business enablers, but all of them are only as good as the architects and the architecture for which they are designed and deployed in. Take a page from Scott’s talk and design a well thought out architecture to avoid complexity and solve real business problems.
DevOps is all about working together to build more reliable software with more agility while delivering business value. As we mature along our DevOps journey, we must focus on continuous learning and improvement while we change the way we think about systems, the way we work and the way our culture embraces change.
While we focus on our people, process, and technology bottlenecks, let’s not forget that our success can be severely limited by the complexities caused by both or legacy and new architectures. As we run to new tools and technologies to achieve our technology nirvana, let us not forget that a pragmatic architecture that limits complexity, anticipates and recovers from failure at all layers and focuses on delivering business value can be one of the best ways to remove bottlenecks from your entire SDLC.
Great architectures minimize technical debt thus freeing up staff to contribute to even more business value. Refrain from using tech for the sake of tech and start creating real business value with a focus on architecture, not tools.As the future of work unfolds, adaptable learning organizations will likely stay ahead of their competition, attract the best and the brightest prospects, and manage market movements with their customer base with more agility. Learning leaders are well positioned to lead the charge to develop an adept workforce that can not only respond to rapid shifts in markets, but also thrive in them as well.
HR professionals use virtual reality to facilitate employee training and increase retention. Sports reporters use natural language generators to automatically recap games and to highlight interesting statistics. Actuaries use cognitive computing to automatically evaluate data, compute results, and predict new patterns. Professionals across many industries engage employers in alternative work arrangements through the gig economy. This future of work is rapidly becoming reality as technology develops exponentially. Exponential professionals are those who capitalize on the shifting workplace by embracing new technology, leave behind traditional automatable tasks, and apply their uniquely human skill set to more high-value, strategic roles.
AI. Automation. Machine Learning. Natural Language Processing & Generation. New technology is rapidly disrupting and transforming the nature of work and the identity of professions by enabling humans and machines to work together, side by side. A new breed of professional is rising to navigate this shifting landscape by embracing technology, leaving behind traditional tasks, and applying a uniquely human skill set to focus on higher-value, strategic roles. Enter the exponential professional.
Is capitalism broken? Rising inequality, high profile corporate failures and the potential for technology to displace millions of workers has prompted many to ask this question. It will be part of the discussion at Davos this week, where world leaders will debate what’s holding back inclusive economic growth. They’ll also question how ready we are for the Fourth Industrial Revolution – the blurring of technology into all aspects of our daily lives – and whether businesses are doing enough to manage the impact of automation on the workforce.
Mornings are easier than ever for me. True, I need to be careful shaving around the RFID chip in my chin. That’s a small price to pay for not having to look around the house for my wallet and keys, which I no longer need because that tiny chip and biometrics lock my front door and start my car, which now drives itself. And if something goes wrong on the road and I arrive at the hospital unconscious, my RFID chip will present my medical history to emergency room doctors.
The rise of robots in organizations has resulted in two schools of thought—those who believe robots will replace humans and those who believe robots will help humans perform better.
Industry has used robots for decades. They were once confined to safety cages in manufacturing facilities, programmed to perform one task perfectly, over and over again.
The future workplace is going to require a change in organizational culture, and this needs to come from the boardroom.
Today’s interview is with Erica Volini, who is the US Human Capital leader for Deloitte Consulting. Erica joins me today to talk about the Future Of Work, the implications for organizations, organizational transformation, Digital DNA and how the employee experience fits into all of this.
Mix smart machines, businesses as platforms, and diverse teams solving complex problems, add a whole lot of uncertainty, and you have a recipe for the future of work. Jeff Schwartz ’87, a principal at Deloitte, discusses how leaders can navigate fast-approaching opportunities and challenges.
By 2025, cognitive technologies — that’s robots, AI, machine learning and automation — will replace 7% of jobs in the U.S. By 2033, economists predict AI could convert 30 percent of full-time jobs today into augmented services completed through a collaboration of human and automated labor.
Your organization, like most of those we see, is probably already incorporating contingent workers in your talent mix, and likely seeing year-over-year increases in the number of contingent workers in your workforce.
We recently sat down with Josh Bersin, the Founder of Bersin, to discuss where he believes the future of work is heading towards, and what the most important aspects to consider within that would be.
The head of one of Australia’s biggest professional services firms believes public negativity and misconceptions are preventing Australia from fully embracing automation. Deloitte chief executive Cindy Hook, who also heads a Business Council of Australia committee looking at the workplace, says business and government “need to change the narrative” that automation, robotics and digitisation will eliminate jobs, “because that’s not the case”.
As organizations navigate technological and societal shifts, corporate boards will have a critical role to play. Diversity of thought—and of people—will be more vital than ever to ensure that boards are considering different perspectives and exploring challenges from every angle.
What skills are essentially human? It’s a question that many HR professionals never thought they’d need to answer. But with the advent of AI, robotics, sensors, and cognitive computing, that’s what every HR professional should be asking—because the future of work is here.
On Tuesday, I participated in a panel discussion hosted by the Organisation for Economic Co-operation and Development (OECD) on the rapidly evolving workforce and the role business can play in navigating these changes.
We are living in an age of disruption. More than 50 years after the formulation of Moore’s law – which holds that computing power doubles on capability every 18 to 24 months – technologies such as artificial intelligence (AI), mobile platforms, sensors, robotics, and social collaboration systems are becoming more pervasive before revolutionizing the way we live, work, and communicate.
As I prepared for my time in Davos, I spent some time thinking about what the biggest takeaways will be. Clearly, based on the recent buzz over the past year, the future of work and how to navigate it is on many people’s mind. The fact is that we are already living this future and to be successful in the next three to five years we will all have to embrace constant change.
The world of work is rapidly changing as we deal with new technologies, AI, generational changes, and a more interconnected organization. What are HR’s mandates in this new world? Moreover, how can HR add value in organization design, driving new models of leadership, driving engagement, and improving organizational culture?
The phrase “Future of Work,” has become a buzz word. (I found 48 million Google hits on the phrase.) There are are suddenly hundreds of conferences, books, and articles on the topic, covering everything from artificial intelligence to robotics to income inequality and contingent labor.Digitization in companies is advancing more and more. Even though processes are increasingly being carried out electronically, logistics service providers often receive their orders outside the transport systems - often still via analog channels. This increases the effort required on the part of logistics service providers to record shipment data.
In order to optimize the yard planning, staff utilization and operational processes, an increasing number of clients is asking their logistics providers to book dedicated time windows to pick-up and deliver goods. The booking of the time windows usually needs to take place 24h before pick-up/delivery. The booking itself causes additional effort for the logistics providers and reduces efficiency. In addition to that, the flexibility to plan the pick-up/delivery tour is reduced which can negatively affect the utilization of the available loading capacity.
Customers are increasingly demanding reliable transparency on the status of shipments from their service providers. This requirement presents logistics companies with an enormous challenge. On the one hand, the recording of the conventional barcode by warehouse personnel is time-consuming and therefore inefficient. On the other hand, additional information, such as temperature or vibrations, must be transmitted to the customer more frequently. Current transport systems are often not suited to provide this type of information.
In the event that companies do not transmit their shipment data electronically, the data must be recorded by the service provider. This entails the risk of incorrect information being recorded, which is even increased by the existing shortage of skilled workers and outsourcing. In addition, shipments cannot be reloaded as long as the shipment data has not been recorded. In reality, this repeatedly leads to delays in operational processes.A blog post by David Cutbill, partner, Deloitte & Touche LLP and Beth Kaplan, managing director, Deloitte & Touche LLP.
Many US publicly-traded companies that operate on calendar fiscal years are now expected to include leases on their balance sheets as of January 1, 2019. As public companies implement the new lease accounting standard and private companies continue to prepare for the January 2020 effective date, Deloitte pulled together a group of industry executives to take part in a special Dbriefs to answer questions and discuss their lease accounting compliance efforts.
Guest panelists, Anne Bernath of American Airlines Inc., Tiffany Moseley of Valero Energy Corporation, and Todd Sears of Walmart Inc., shared their thoughts on the new lease accounting standard, including lessons learned during implementation and some of the near- and long-term actions companies are taking to prepare for reporting and improve overall operational efficiency.
Take a look at our summary of highlights and insights from this special edition Dbriefs and listen to our Green Room podcast for a deeper dive discussion with additional insights from our guest panelists.SAPinsider says that a little more than half of SAP customers planning SAP S/4HANA investments are opting for either new implementation or system conversion.2
Those choosing a new implementation typically want to eliminate custom programs, shed ineffective practices, and drive more standardization around best practices. Organizations that implemented SAP when they had simpler business models, different competitors, and a less demanding customer base find this approach allows for remodeling to support productivity and growth. It also lets them start afresh and keep their ERP clean.
Those choosing system conversion usually want to preserve some of their custom environments and have business models that have not evolved. They see this as a lower-cost path, one that could require less change management. This approach is often used by companies that completed SAP implementation within the last five to seven years. These companies don’t need to transform, but they want to take advantage of the SAP S/4HANA digital platform.
For many SAP customers, a new implementation or system conversion can be combined with a third implementation option: leveraging SAP Central Finance.
SAP Central Finance allows companies to deploy a single instance of SAP S/4HANA Finance and then integrate some or all their financial and operational processes back through that instance. A company’s current SAP or non-SAP financial systems don’t need to be converted and can remain in their existing environments.Leads our agile work in Central Europe and our Enterprise Agility Center in Budapest and helps institutions across industries to shape growth strategy and transform themselves in the digital age
October 5, 2020 In previous research, our colleagues have outlined the importance for agile organizations to create both stable and dynamic practices. A periodic business review, prioritization of different activities, and alignment across organizational units (frequently called tribes) are often together referred to as Quarterly Business Reviews (QBRs). QBRs can be the cornerstone of an effective agile organization, linking overall strategic direction to agile organizational units and team-level backlogs.
When done well, QBRs can bring immense value to an organization by creating vertical and horizontal alignment. However, inefficiencies often occur due to limitations in the ecosystem around the QBR—even if the narrowly defined process is done well. There are five reasons behind these suboptimal operations:
QBR ownership: The QBR and the broader ecosystem surrounding it are at the heart of an agile organization and must have a proper owner. This role spans three main activities: managing the QBR process, ensuring proper content quality, and continuously improving the QBR. A dedicated squad is required during QBR cycles, combining agile, IT, finance/budgeting and strategy expertise, and a strong and respected leader. Broad dependency alignment: During the QBR process, these units set Objectives and Key Results (OKRs) and plan what they will deliver to achieve them. Ideally, a substantial portion of the unit backlog can be delivered autonomously by the owner of the group, while a smaller fraction requires broader alignment. The QBR should serve as a forum to understand those dependencies and resolve them while not making the process highly technical and administrative. For instance, one LATAM company organizes a quarterly fair where each unit leader presents its initiatives and all other leaders are responsible to challenge them and understand potential dependencies. Traditional budgeting: Agility brings a paradigm shift in the logic of budgeting. Instead of projects, agile organizations use cross-functional teams as budgeting units. Agile organizational unit leads must assume resources are relatively fixed, and their job is maximizing impact, generated via prioritization. This is important, because if agile organizational units are subject to traditional project and business case-based budgeting logic, then QBRs cannot function properly. If fully agile budgeting is not realistic in the short term, companies can opt for a hybrid approach. For example, a leading bank uses QBRs to review budget status against delivered business results—and potentially make adjustments in a transparent and fast way during the QBR meeting, if circumstances require. KPI and OKR misalignment: OKRs are among the most fundamental elements of QBR logic, used by many organizations to set aspirational targets with motivating narratives to rally people behind a common vision. In the QBR, these units must define OKRs from strategic company aspirations. Yet, organizations often struggle to draw a connector line between the newly introduced OKR concept and end-of-year key performance indicators (KPIs). A Western European bank defined the value driver KPIs for each agile organizational unit and derived OKRs that helped to achieve these relatively fixed end-of-year KPIs. Disconnect from IT processes: In an ideal agile environment, agile organizational units can release standards and an IT architecture vision. This is rarely the case in large corporations due to legacy architectures and monolithic systems. Given that planning for major monolith IT systems often requires 12+ months, QBRs often need to co-exist with IT release planning. One European telco solved this by synchronizing the timing of IT release planning with QBRs, and then used them as a complementor forum—refining and breaking down the upcoming portion of the high-level IT roadmap.
Building proper QBR practices and enabling the ecosystem takes time and effort. However, once these pain points are addressed, the QBR can truly act as the nerve center of the organization, transmitting key impulses and strategic signals.Global process owners (GPOs) are individuals who own an end-to-end process across functional silos, geographic and business unit boundaries. The role has become increasingly common, in line with the development of global operating models and the concurrent evolution of the process model.
While GPOs have arguably been successful in bringing about gains in process efficiency and effectiveness, there may be opportunity for GPOs to add enterprise-wide value. Companies are pushing to manage global business services as a single organization and are leaning towards a service delivery model that has fewer global locations rather than more regional ones.
In coming years, GPOs will have the opportunity to play an important role in enhancing how global business services organizations partner with the overall business. With the right level of management support, GPOs can greatly help in aligning the organization better, changing detrimental behavior, and reinforcing the overall culture and brand in the organization.Intercompany transaction processing at global financial institutions has historically been passed over in favor of other finance initiatives. These decisions were generally founded on:
Global financial institutions are experiencing escalating pressure from downstream challenges caused by legacy complex and manual intercompany processes. These challenges include increased regulatory scrutiny due to apparent data quality issues and reporting inconsistencies, as well as bottom-line tax impacts from the meaningful changes brought on by tax reform. These challenges stem from increasingly granular regulatory data required to satisfy reporting requirements for regulated entities and the challenge of satisfying these requirements with numerous disparate systems and siloed intercompany processes. Additionally, tax reform, while complex, also provides opportunities for companies to analyze their tax footprint in alignment with broader business objectives. These factors are causing financial institutions to revisit their intercompany transaction processes, seeking opportunities for automation, optimization, and enhanced governance.
We previously discussed a new framework with leading practices for the intercompany accounting process and optimization that offers a road map to reimagining the end-to-end process informed by our proprietary intercompany maturity model. To implement a strategy that can align with a company's focused objectives, it is necessary first to address the unique challenges facing the intercompany accounting transaction life cycle at financial institutions.August 21, 2019 From the early 1970s to the mid-2000s, demand for electric power and natural gas in North America outpaced the growth in invested capital. Regulated gas and electric utilities were therefore stable and profitable. They earned reliable returns and were also able to keep customer rates down, satisfying both customers and regulators. These positive conditions, however, also meant that utilities didn’t need to be as efficient with their capital as other capital-intensive industries, such as metals, mining or oil and gas.
Now things are different. Since 2008, there has been no electric load growth in North America. Thirty-three states and several Canadian provinces have actually registered declines, thanks largely to greater efficiency and lower industrial demand. For gas utilities, higher efficiency in home heating and insulation has contributed to stagnating demand. Nevertheless, utilities still need capital, to upgrade aging infrastructure and to make investments in flexibility, resiliency, and functionality. According to Global Market Intelligence, capital expenditures for major North American electric and gas utilities have risen 7 percent a year over the past five years, with transmission and distribution (T&D) accounting for about 60 percent of the total.
At the same time, regulators are pushing back against rate increases. In 2018, they approved only 38 percent of such requests, compared with 52 percent over the previous nine years. Regulators in North Carolina, Virginia, Kentucky, and Massachusetts, for example, rejected requests for rate increases to fund utility grid modernization. There is a growing gap, then, between the amount of money needed to maintain and upgrade North American grids, and what regulators are allowing utilities to charge to raise that investment.
Given these constraints, utilities need to use their capital more productively. They do have options. Among them: aligning capital plans to strategic priorities; focusing on the minimum technical solution; applying lean-construction techniques; and using advanced analytics to make asset-management decisions.
In this article, we discuss each of these options, and suggest questions leaders can ask themselves to determine whether they are using their capital as productively as possible.
Aligning capital plans to strategic priorities: Utilities need a rigorous capital planning and risk-assessment process. This starts with developing a common understanding and quantification of the most important risks. In practice, different asset classes and planning groups often have different views of what matters most; as a result, utilities’ capital plans often miss the mark. Done right—that is, by focusing on the biggest risks and rethinking where dollars are spent—we estimate that utilities can deploy their capital as much as 20 percent more efficiently.
One gas utility achieved this level of impact after doing a thorough evaluation of the roughly $3 billion in capital projects planned for the next three years. The utility created a consistent record of the rationale and scope for each project; this understanding enabled it to figure out which projects mattered most and to spend accordingly.
The types of investments utilities need to make are changing. For example, as more investments are made in supervisory control and data acquisition, automation, analytics, and grid modernization, information technology (IT) needs to support these efforts. Under typical capital-planning approaches, however, IT investments are often left to the end, and then get squeezed for funding. Implementing a planning process that shows regulators the trade-offs between core power systems and supporting infrastructure is an important first step to establish which projects utilities should pursue, in what order.
How has spending evolved over the last five years in different asset classes, such as poles, transformers, IT, and analytics?
Focusing on the minimum technical solution: It is relatively easy to re-think the business case, design, and scope of a project in the early stages. One way is the “scrub.” This is a process in which a cross-functional group of experts ask structured questions and scrutinize the project’s scope and design to identify ways to develop it more cost effectively.
Project scrubs are common in unregulated, capital-intensive businesses that are seeking the “minimum technical solution”—meaning the lowest-cost design that meets current and likely future objectives. The context is somewhat different for utilities, because they have a wider set of stakeholders, including regional transmission organizations, regulators, customers, and municipalities, with varying priorities. Finding the minimum technical solution provides a way to assess whether project add-ons, such as upgrading substation breaker designs or replacing equipment not yet at end of life, are worthwhile. At one utility, a series of project scrubs before design and construction identified 15 percent savings on $400 million of annual spending on large, complex projects in the transmission organization. The effort also identified more than $50 million in large projects that were no longer needed.
Applying lean-construction techniques to capital projects can deliver planned work for less, and additional work within the same budget. Lean-construction techniques have a proven track record in other industries, as well as in utility operations and maintenance (O&M), but they have not been widely deployed in utility capital projects. One reason is that once regulators approve a project budget, the utility has little incentive to cut costs. Another is that utilities make greater use of outside contractors, rather than in-house crews. Lean techniques for field execution, such as daily huddles (Exhibit 1), and tracking and monitoring unit productivity, should be standard practices, but are not.
Exhibit 1 Exhibit 1: Huddle boards can be a useful aid for daily structured conversations. We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Lean techniques should also be applied earlier in the project planning process. “Pull planning” is one example (Exhibit 2). In this process, a cross-functional team starts with the commissioning date of a project and identifies the critical dependencies, such as permitting, rights of way, and design. Then it establishes milestones against each critical component, with clear accountability. In one transmission organization, the pull-planning team found in its first week of work that 40 percent of projects were either not on track or the utility didn’t know if they were. By week four, that was down to less than 10 percent.
Exhibit 2 Exhibit 2: Display boards show job progress and readiness We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Ideally, lean-construction techniques should be incorporated in parallel with the capital-planning process. By using a combination of lean techniques, we estimate that utilities can cut costs 10 percent to 15 percent.
Using advanced analytics to make asset-management decisions: Making sound maintenance, renewal, and replacement decisions conserves capital and lowers the total cost of ownership. Better decisions start with the collection and analysis of data, and this is easier than ever, through the use of monitoring software, automated sensors, drones, satellites, and the improved analytical capabilities available in the market.
One utility improved the use of its data to inform asset-management decisions, leading to almost 10 percent savings in O&M and capital spending. For example, the utility analyzed the maintenance records of the breakers that were scheduled to be replaced in the following year. It found that 40 percent had never needed any attention; for these, preventive maintenance was the right choice. On the other hand, three percent of the breakers had incurred significant maintenance costs; for these, quick replacement was the better option. Though the decisions were different, in both cases, the utility optimized its spending. In general, we estimate better asset management decisions can save about 10 percent—and more if digital tools and data analytics are fully incorporated.
How has asset management decision-making evolved over the last two years, taking into account developments in technology and data?
Improving capital productivity can seem daunting, particularly since many utilities have not had to make this a priority. However, many of these options can be implemented independently and even small changes can yield significant improvements. With affordability pressures increasing and the need for investment growing, utilities have to accept that using their capital better is a matter of urgency.
Adam Barth is a partner in McKinsey’s Houston office. Sarah Brody is a consultant in Washington, DC. Zak Cutler is a partner in Toronto. Corey Hopper is an engagement manager in New York City.Since early March 2020, finance professionals have been forced to shift to a remote working environment, challenging many organizations to manage a quarter-end close with a distributed and sometimes distracted workforce. Financial services have faced challenges and are continually making adjustments to the ways they navigate these complex business challenges.
We wanted to know how it’s working, so Deloitte surveyed more than 25 C-suite professionals in banking, insurance, investment management, and real estate firms on the overall impact of remote work on the execution of the 2020 remote close. In reviewing the results, it is clear that many organizations could have a better understanding of the overall impact the remote working environment has had on the industry and how they compared to their peers in the past quarter.Someone posted an article on LinkedIn the other day claiming “Agile is Dead”. The comments that followed were more interesting than the actual article. Many people were bashing agile frameworks. It is no secret that organizations have spend a lot of money on doing agile and many times never really achieved being agile. Right now, SAFe (Scaled Agile Framework) is trending and many of my clients are implementing it. But methodologies and frameworks are nothing more than a set of guiding principles for delivering software. At the end of the day, doing agile comes down to the three things:
A framework is only as good as the people, processes, and organizational structures that use it. Silos with competing goals always trump frameworks. Each silo creates an unnecessary handoff and increases wait time. Too often, additional processes get added to deal with the interaction between silos.
Then there is the people part. I am old enough to remember when all projects managers had to be PMBOK certified which trained project managers how to follow a set of processes and procedures (framework) to navigate the waterfall methodology. When we moved to agile, all these people were retrained and became certified scrum masters. Unfortunately, they still had the old command and control, sequential mindset and most agile efforts became “Wagile” — waterfall with daily standups.
The point here is it takes much more than a few training classes or certifications to change the mindset. This is a transformation and requires an investment in organizational change management to get the value out of the new frameworks.
All the process in the world can’t fix a bad architecture. To do agile, one must have an architecture that supports being agile. Characteristics of an agile architecture include:
Service-oriented — opposite of Monoliths, the system is made up of small parts that can be deployed separately
Testable — system supports testing hypothesis with methods such as A/B testing, feature flags, chaos engineering, etc.
The more a system supports the characteristics above, the more agility can be achieved. Not all systems need to implement all of those characteristics, but each characteristic can reduce manual intervention, allow for more frequent deployments and quicker MTTR, reduce widespread system outages, and provide for better availability. It can also reduce the amount of unexpected work which is probably the biggest single issue all agile frameworks struggle to deal with.
Even if you have an agile architecture and your agile framework is being executed flawlessly, if your operations people and processes are not in alignment, the whole house of cards will come tumbling down.
There is a lot disruption in operations these days. DevOps has played a huge roll in getting developers and operators collaborating better. Operations is now being thought of earlier in the lifecycle and teams are designing for ops. Companies are reevaluating their operating models and investigating newer practices such as Site Reliability Engineering (SRE), accepting that testing in production is a good thing (if done right), moving from reactive to proactive operations, embracing observability, and much more. As we move to more agile architectures, it’s common sense that we need to embrace more agile methods of operations.
The list goes on and on. I have yet to see a framework that even mentions most of these characteristics. The frameworks focus mostly on how to manage backlogs which is important, but if the software and the operations of that software does not promote agility, the framework is not going save you.
Organizations should focus more on being agile rather than doing agile. Being agile requires more than a framework. It is a mindset and it should be applied everywhere, not just in Dev and Ops. The Security and Governance teams need to be agile. Procurement can’t take six months to procure a software product. Decisionmakers need to come to conclusions in a timely manner. Processes that take forever should be redesigned. Approvals should not take forever. You get the point.
Being agile is a cultural issue and should be treated as one. If you want to make your organization agile, adopting a framework is only one piece of the puzzle. In fact, many teams that I have seen that are truly agile use no framework at all. They do a good job of managing a backlog and they do a great job of collaborating, writing good software, automating everything they can, and recovering from issues quickly. At the end of the day, agility can be measured by customer satisfaction. If the customer is getting their demands met, the system is reliable, and issues are resolved quickly, it really doesn’t matter what framework you use.December 16, 2019 For most organizations, the clear boundaries of who is “in” and who is not are becoming blurred, and what seemed like bright line differences are now becoming like concentric circles, where the types of people and organizations working together to create value vary widely, and system participants exist along a spectrum.
Consider some vendors in a value chain ecosystem who - in every other way but being on a company’s payroll - act like employees. Are they part of the organization or external? In today’s world, perhaps the answer is not such a simple either/or. It might be more helpful to see some participants as neither at the inner core, nor fully external.
Defining the “who” matters because it can radically expand or contract your focus when evaluating whether your operating model will deliver on your strategy. We believe companies should increasingly have strategies for how they deal with “quasi-employees” and other participants in their system who are neither traditional “inner core” employees, nor fully external.
Leaders have an opportunity to take control of their ecosystems and shift from passive subjects to deliberate architects of a much broader range of participants in the organizational system. Taking a holistic, systemic approach to operating model design and including the broader ecosystem as part of the solution space can deliver real opportunities for value creation. To ensure organizations can deliver on their strategic value agenda in an increasingly complex world of opportunities, we believe leaders must incorporate ecosystem design into the operating model design process and pressure-test old boundaries, become more expansive in the scope and aspirations of the redesign, and explicitly create more flexible organizational perimeters that effectively utilize the concentric circles of people and organizations within an ecosystem.
An insightful example of this is the ubiquitous credit card company Visa ™. When the credit card business exploded onto the banking scene in 1966, the initial impact was chaotic. The systems for managing sales drafts, data entry and clearing of sales were primitive; each merchant-signing bank accepted all transactions regardless of the issuing bank, and reimbursed itself by drawing a draft on each issuing bank through the Federal Reserve system. The clearing draft was then posted to a suspense ledger while waiting for the merchant bank to send them through the U.S. mail. And that is only half of the utterly complex, siloed process that effectively led to hundreds of millions of unprocessed transactions and, ultimately, provided opportunities for criminal activity.
Dee Hock, a bank official, was involved in organizing regional committees to help address these major issues. Hock would eventually go on to found Visa™ by shifting from a passive subject to a deliberate architect of the banking ecosystem in which the credit card idea was born. While there is nothing simple about the processes and structures that had to be developed to deliver on the ultimate goal, Hock understood early on that no one bank or financial institution could own the credit card (or resolve the myriad problems it produced) and developed an idea of a self-organizing, networked organization that could evolve, organize and invent itself. Rather than design the organization, Hock came up with some basic principles of organizing that would facilitate the complex self-organization of the committees that had already been created.
When leaders let go of old paradigms and adopt new ones, it unlocks opportunities in our increasingly connected world— one where the sources of value are constantly changing. Because these shifts are constant, successful leaders will need to take an open systems view over a mechanistic view or organizations. Not only will leaders begin to better understand the current landscape, they will be empowered to make choices on what to do about it and expand value creation opportunities.
This blog post is part of a series on Organizing for the Future, which explores a set of new principles such as anti-fragility and experimentation that are becoming increasingly critical for today’s organizations as they build more creative, adaptable, and human systems.Leaders throughout industries have ambitious visions of how digitization will transform their core businesses. In service industries, the vision typically includes completely new consumer journeys enabled by comprehensive self-service, integrated omnichannel offers, and full utilization of all available data. As a result, data flows digitally in a highly automated manner, costs are lowered, efficiency and quality improve, and flexibility increases.
This vision may come true at some point. In the near term, however, it is highly unlikely that payers will be able to adopt fully paperless processes, despite the myriad problems manual document processing entails. Although many payers have taken steps to move away from paper, they have found that eliminating it is more difficult than they anticipated. Both internal and external factors have made the transition to fully paperless processes nearly impossible as of yet.
We expect that a large share of all paper-based interactions at most payers today could remain paper-based for at least the next several years. Given this, finding ways to process paper-based documents in the most efficient way possible—and to smoothly merge data from paper and digital sources—is becoming an imperative for all businesses that must process a high volume of documents from consumers, providers, and vendors. In this article, we describe an approach that payers can use to achieve these goals.
In every industry in which paper plays a significant role, manual document processing causes problems. Manual processing is slow and tedious. It requires employees to perform repetitive, monotonous tasks while adding little value, which can reduce their job satisfaction. Manual processing is also error-prone and not transparent, and thus often causes operational inefficiencies and confusion among teams. As payers expand their use of omnichannel strategies, the lack of process transparency also impairs consumer satisfaction. In addition, paper data can hinder growth, since it makes it more difficult for companies to gain insights from advanced analytics.
Given these problems, it is not surprising that pundits have predicted the demise of paper for more than 30 years. Nevertheless, fully paperless processes have yet to materialize in many businesses (Exhibit 1). Progress has been especially slow in service industries. One large German payer, for example, still uses about 100 tons of paper each year for its claims operations alone. A medium-sized European payer purchases five truckloads of paper each year just to support customer service. Yet both companies have striven to eliminate as many paper processes as possible. Why have these and other payers found it so hard to stop using paper?
Exhibit 1 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
The progress toward fully digital document processing has been hindered by a variety of factors. Internal roadblocks include general organizational rigidity, risk-averse decision making, and employees’ fear of job losses. Moreover, designing and building new IT solutions, then integrating them into existing organizational technology, is inherently complex and usually requires changes in both behavior and processes, as well as significant company investment.
Given the economic benefits of fully digital document processing, many companies are starting to find ways to overcome these obstacles. However, they have found it much harder to get around external obstacles. Payers operate within ecosystems that include partners, vendors, providers, government agencies, and consumers. Getting all these stakeholders to agree to adopt fully digital communications requires a comprehensive transformation, which for many of them entails significant switching costs. For example, providers in countries with multipayer health systems may need to adapt their claims submissions processes to account for the requirements of different payers. Many consumers may be reluctant to switch to digital self-service because health insurance is often a low-involvement product—touch points are infrequent, which gives consumers little incentive to memorize login credentials and keep their contact information up to date.
Moreover, regulations may hinder the move away from paper in many countries. Payers and other companies that deal with health data are usually subject to strict data protection laws. Security and privacy standards are not only stringent but also often tailored to the use of paper-based communication. In some cases, regulations may require a member’s signature on a form. Even if the regulations do permit two-factor digital authorization as an alternative, it is often difficult for payers to establish sufficiently secure transactions.
In short, paper-based processes endure because they are well-established in payer organizations, avoid high switching costs for outside parties, and do not require members to interact with digital platforms they may use infrequently. Because this situation is unlikely to change rapidly, payers that want to gain a competitive advantage must find better ways to handle paper while moving toward the longer-term vision of fully digital processes
Payers can generate significant value during the transition to a fully digital future by optimizing the way in which they process paper documents and other data. The consequences of suboptimal document processing are significant. Effective handling of paper is crucial because data is at the core of the payer service offer, and paper continues to be a main source of data from day-to-day operations. Furthermore, data analytics is increasingly important to support strategic decision making. Leading businesses use analytics to discover valuable consumer and operational insights; the lack of access to data in digital form makes it much harder for a payer to do this.
Fortunately, new technologies have emerged that enable more efficient processing than has been possible before, including quicker and more accurate information retrieval from paper documents. (This retrieval process is called document ingestion.) Ranging from intelligent character and pattern recognition to machine learning, the technologies have made impressive progress in recent years.
The benefits offered by these new technologies go far beyond efficiency improvements (as important as those improvements may be). Accurate, structured data is a prerequisite for many other digitization efforts, from omnichannel to analytics transformations. Automation efforts rest on good data and cannot be successful when information is buried in large piles of paper.
Digital document processing has three main phases. The first phase, document ingestion—our main focus in this paper—is the route through which incoming information on paper documents is “consumed” and then made available in a structured, digital fashion (Exhibit 2).
Exhibit 2 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
In the second phase, digital data is processed internally using automated workflows. By optimizing these workflows, data usage can also be optimized, which often avoids the need for redundant stakeholder communications (for e.g., asking consumers for the same data multiple times). By combining the data derived from paper documents with the wealth of digital data already available, a comprehensive data landscape can be established, significantly enhancing data evaluation and analytics possibilities.
In the third phase, documents are delivered to stakeholders more efficiently. Many types of outgoing communications are shifted to digital channels, and the processes required for paper-based communications are streamlined. Keeping coherent records is a crucial efficiency lever because it ensures that information is sent to the appropriate point of contact (for e.g., when billing confirmations are sent to providers).
To get digital document processing (including document ingestion) right, payers must understand and master all three phases. As part of this effort, they need to consider the full range of documents that will have to be processed. Incoming mail and other physical documents are an important source of data, but not the only one—many documents that arrive digitally can pose significant challenges if not handled correctly. Emails, for example, may require significant effort to become structured, digital data that can be processed automatically.
To incorporate the full range of documents that need to be processed, a digital document ingestion workflow typically has six steps (Exhibit 3):
, to turn paper documents—physical mail, for example—into digital images Optical character recognition (OCR) , to detect characters in the digital images and convert the output of a scanner or fax machine into digitally stored text
, to detect characters in the digital images and convert the output of a scanner or fax machine into digitally stored text Data extraction , to pull out relevant pieces of information from the OCR output and other digital sources (for e.g., email or online chats)
, to pull out relevant pieces of information from the OCR output and other digital sources (for e.g., email or online chats) Interpretation , to take effective, logical steps to transfer the information to relevant IT systems
, to take effective, logical steps to transfer the information to relevant IT systems Exception handling , to recognize errors and uncommon scenarios and provide alternative routes for their proper handling
, to recognize errors and uncommon scenarios and provide alternative routes for their proper handling Data utilization, to ensure awareness of newly available information, trigger relevant workflows, integrate data into consolidated views of consumers and providers, automate processing, and ensure data security
Exhibit 3 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Effective document ingestion cannot be established without a proper foundation. To build the best possible processes, payers need to put these critical components in place: technology, organization, and capabilities/sourcing.
Technology. Document ingestion requires effective new tools. However, it also has significant implications for the supporting IT architecture.
Introducing new technology is a pivotal element in establishing document ingestion. Although basic OCR solutions to digitize information are typically easy to implement, subsequent steps in the workflow are much more challenging. In particular, turning a large range of semistructured, or even unstructured, information into meaningful data often requires highly advanced OCR solutions such as intelligent character recognition (ICR) software, which has much higher recognition accuracy than traditional OCR software.
Once the information is made available in a structured digital format, the data usually requires further refinement before it can be processed automatically; it is because of this requirement that document ingestion goes far beyond the mere reading of information. For example, the data must be embedded into comprehensive records stored in a consistent format and find its place in comprehensive data models describing consumers and providers from a payer point of view. An event bus (a software mechanism that allows different components in an IT system to communicate with each other) must pass the information on and ensure that all relevant IT systems are made aware of the new data. Automating this part of the process often requires a wide range of application programming interfaces or robotics solutions.
Organization. Improving document-handling processes takes significant cross-functional effort, strong organizational commitment, and careful change management.
Document ingestion has important implications for a payer’s organization. At a minimum, the organization needs to establish corresponding roles and responsibilities to ensure that all steps in the ingestion process run properly. More importantly, altering the way paper is handled requires a significant change effort. Many organizations could benefit from establishing a dedicated team to act as a “digital factory” that uses a process-by-process approach to achieve organizational change in all business units and departments. Such a team is usually staffed with full-time members who operate in an agile environment with substantial management support. The digital factory builds new IT tools and processes, but also reshapes the ways different organizational units work on a day-to-day basis. The addition of cross-functional project teams with rotating personnel inside of the digital factory enables the spread of new knowledge throughout the organization.
Capabilities and sourcing. Implementing the correct technologies and processes and ensuring that the necessary changes are embraced typically require the use of both internal and external expertise.
To successfully implement document ingestion, companies need the right capabilities—they need to be able to redesign existing processes, build required technologies, run the new systems, and manage change. These capabilities can be built in-house or acquired by partnering with vendors or other organizations. In many cases, both internal and external resources are necessary.
Currently, the document ingestion industry is shaped predominantly by OCR vendors. Their solutions are a central pillar of the overall technology blueprint, but some organizations have found their products difficult to install and run. Furthermore, know-how is usually lacking outside of these specialized firms. As a result, companies often find themselves locked in with individual vendors. Strong vendor management capabilities are therefore especially important.
Sidebar Case study: digital document ingestion A large German payer enabled a large-scale digital transformation by optimizing digital document ingestion. Several factors had led this payer to believe that paper would remain a major channel for several years or more. For example, many of the providers and government agencies it dealt with were behind the curve in digital adoption and regulatory issues (including data privacy concerns) were making it difficult for the payer to move consumers to digital channels. The payer therefore decided to incorporate paper-based communication into its overall omnichannel strategy but also created a road map to help it move toward omitting paper from its internal processes. The payer started by optimizing its methods for scanning and OCR of all paper documents and then entering the digital files into a document management system. In this way, the payer was able to avoid storing additional documents in physical archives and reduced the time that many work items were in transit. These changes made it easier for employees to work from home by providing digital access to all documents and improved the company’s performance management capabilities. The payer’s second step was to create a shared-services center that would be responsible for data transfer from paper documents into the company’s core IT systems; the business units would take over once the data was in the core systems. As a result, the business units increased their efficiency through labor arbitrage and more straight-through processing. Because of the momentum generated on the business side, the payer then established a central output management system for printing and letter finalization, which allowed the business units to achieve higher quality and even greater efficiency. No letters had to be handled manually by an employee. Finally, automated data extraction was introduced to manage the transfer of data from documents into the core systems. As a result, the shared-services center gained efficiency, which freed up valuable time so that employees could focus on more consumer-centric processes, such as personalized communication.
Companies that successfully implement digital document processing—including document ingestion—often use a similar approach, which is frequently embedded in a larger digital transformation.
First, these companies identify the right technology vendors to build and run the necessary components along the full document processing value chain. In addition, they typically assess the potential of process redesign and identify the behavioral changes that will be needed throughout the organization.
Second, the companies often use a dedicated project team to put the essential IT infrastructure in place relatively quickly. Typically, they undertake an initial technical proof of concept and then start building the IT infrastructure while transforming the first end-to-end processes (for e.g., invoice processing for a group of chosen pilot providers).
Third, they scale up the effort by setting up a digital factory (as described above) and start to rotate people in and out of the effort. In addition, they begin transforming payer processes one by one (perhaps by starting with claims, then moving on to invoicing). In this way, the new technology and organizational structure of all paper-based processes at the companies are transformed.
Fourth, the companies not only use a digital factory but also undertake a dedicated change management effort to implement the digital document processing system. Employees who are used to paper-based processes and often have considerable control over process decisions typically need help in adapting to the new digital processes. The change management effort is crucial to ensure the transformation is carried out to the end because the last 20 percent of paper-based processes are usually the hardest to eliminate. Attention to change management helps give employees at all levels of the organization the ambition to fully eliminate paper.
Payers, like many other companies, are finding it difficult to realize their vision of fully digital processes. However, they can gain immediate benefits by improving their approach to digital document processing—especially digital document ingestion. This approach acknowledges that paper documents will remain a reality for some years to come but enables payers to move along the path to a fully digital future.
To be effective, digital document processes must consider the full range of inputs (both paper and digital) and cover the end-to-end workflow. To make this possible, a payer typically needs to build or acquire the required technologies and establish the necessary organizational foundation.
Payers that cannot get digital document processing right will put their other digitization efforts—and their ambitious digital goals—at risk.
In all industries, digital document processing in general, and digital document ingestion in particular, are important for core back-office functions. However, their relevance for corporate functions varies across industries (Exhibit 4). Similarly, the typical level of digital document processing maturity also varies across (and within) industries and regions. Payers and most of the stakeholders they work with lag behind most other industries in their level of maturity and thus face high switching costs if they want to move to fully digital processes.
Exhibit 4 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
New digital journeys for consumers can succeed only if they can be seamlessly integrated with paper-based processes and all required information (including claims status) is available.
Analytical modeling (e.g., for fraud detection and automated claims handling) needs to be built on comprehensive data sets.
IT architecture transformations require a comprehensive view of all digital processes and are unlikely to succeed if manual work-arounds based on poorly handled paper-based processes are present.
Unnecessarily heavy reliance on paper is expensive. Reducing the use of paper should be an integral part of any cost-cutting initiative.
Consumer service improvements are of limited use if communication based on physical mail is not handled properly.
Omnichannel implementation requires a 360-degree view of all consumer interactions, including the role played by paper-based communications.
Do not assume that all communications can be rapidly moved to digital channels, making paper superfluous. This will take time. Build IT architecture that can cope with all aspects of document processing. Digitizing the last 20 percent of documents is particularly challenging. Involve the business units as early as possible and pursue a clear minimum-viable-product logic to achieve some early successes. Establish consistent key performance indicators to monitor success and steer toward maximum value. Refrain from overinvesting in the wrong areas. Be cautious about building custom solutions. Available commercial solutions are highly advanced. Do not underestimate the effort that redesigning internal IT workflows requires. Do not overlook basic analytics capabilities—they are often more valuable than artificial intelligence (AI) approaches. However, digital document processing can create a great playing field for building AI knowledge and skills.Sweeping global forces are reshaping the workplace, the workforce, and work itself. Organizations are now rethinking their talent strategies at all stages of the employee lifecycle, vying for top talent in a highly transparent job market and becoming laser-focused on their external employment brand.
Powered by Deloitte’s Human Capital practice, Capital H blog is a forum for sharing insights on all things HR. Timely, relevant, and relatable, the blog features discussions on the HR topics and challenges facing businesses today. Check out the blog by browsing previous topics, subscribing to receive updates when new content is posted, and sharing your opinions on these top-of-mind subjects.Here is a preflight checklist of specific components to think about as you prepare for and continue down the path of ASC 842 implementation.
Make sure that your teams have performed end-to-end testing across the lease ecosystem—including data entry processes, calculations, modifications, transition, reporting, and integrations to upstream and downstream systems.
Organizations should consider the quality and approval processes to determine whether data is complete and accurate. In our experience, an efficient operating model to maintain and align both lease accounting and operational data is imperative for implementation and beyond.
There are a large number of data elements for a lease that are required to be captured, some of which exist in the lease and some that come from sources outside the lease agreement itself. Data is absolutely critical to getting this right from an accounting perspective.
Are internal controls designed and implemented, including such areas as transition accounting; interim solutions, if applicable; ongoing data maintenance; and any other new system-related internal control risks?
Making sure that the appropriate resources are available and trained can ease the transition. In addition, clearly established roles and responsibilities can help to increase the efficiency of talent. Organizational resources, such as a help desk, center of excellence, and on-site support, can also help amplify the performance and effectiveness of talent resources.
Policies around ASC 842 should be ironed out and communicated to stakeholders. Particular consideration should be given to maintenance of accounting policies to keep current with ongoing developments and interpretations.
The new lease accounting standard is a substantial change for many companies. Regular updates and communications to stakeholders are important to help investors and lenders understand the impact of the new standard.
Adoption of the new lease accounting standard will likely present immediate and ongoing challenges to the operating model, talent resources, accounting policies, new systems, and communications. While many organizations and professionals should be wheels up and ready to go, a final preparations checklist can assist organizations through the transitioning months ahead and into the first reporting deadline.
For further discussions and insights to consider as the new standard takes effect, watch the full Dbriefs webcast, Public company lease accounting: Time for the final sprint.
Following the Dbriefs, listen to the Green Room Podcast episode on the new lease accounting standard for public companies, to gain additional perspective and hear in-depth answers to ongoing questions about the implementation process, experiences with software solutions, new borrowing rates, and more.April 19, 2018 You can tell an organization has problems making decisions when you hear these complaints: The organization is “too complex,” possesses a “meeting culture,” or has “too much consensus.” “Too complex” can simply be code for “it’s too hard to get things done.” And while people often finger too many “cooks” as the culprit, we’ve seen matrix structures where, despite many people being involved, roles are clear, how things work is straightforward, and decision-making is fast and effective.
For agile organizations, getting decision-making right is critical since their foundation rests on an action-oriented decision architecture. The result: Organizations with high decision-making velocity and quality generate 2.5 times higher growth, 2 times higher profit and 30 percent higher return on invested capital, our research shows.
Still, decision-making is hard. An unclear or poorly defined process can trigger decision “churn,” where previous judgments are revisited; a “fog of accountability,” where no one is truly answerable; “death by PowerPoint,” where decision-making gets lost from too much information sharing; and bureaucratic governance.
Good decisions are often made quickly. Usually, it reflects a decision-making system designed to maximize engagement of the right stakeholders but minimize the number of decision makers, accelerate the entire process through decision execution, provide ruthless role clarity, orchestrate key points of collaboration, and streamline governance to keep meetings and approvals to a minimum.
While these can help, in many cases they don’t. In fact, more technology and more data can lead to information overload and analysis paralysis. Also, beware of big data and analytics creating a belief that decision-making can be entirely rational, thus taking emotion out of it. Emotion can be very helpful in determining what is good and desirable and what isn’t.
In fact, most “best” practices are conditional. They are good in some situations and not others. Different types of decisions require varying approaches, and advice helpful for some decisions can be terrible for others.
What’s the key to unlocking great decision-making? As we advise in “Untangling your organization's decision making,” any organization can improve the speed and quality of its decisions by paying more attention to what it’s deciding. We recommend segmenting decisions into four basic types and applying a different set of best practices for each:
Big bet: Infrequent high-stakes decisions that affect the organization broadly (e.g., mergers, acquisitions, big investments). In these instances, healthy debate among top team members is more important than data. Cross-cutting: Frequent decisions that affect multiple areas in the organization (e.g., budget allocations across products/regions, sales and operations planning, new product development). Clarity of process is more important than who gets the decision right. Ad hoc: Day-to-day decisions by individuals as part of their job (e.g., interactions with customers). An open and trusting culture with personal ownership and role and strategic clarity are more important than formal accountabilities. Delegated decisions: Day-to-day operational decisions made by a team or individual closest to the information vital to making the decision (e.g., deciding on regional or site level promotions, adjustment to local manufacturing operations). Here, clarifying delegation of authority is only half the battle; leaders need to learn how to empower and let go.
Recognizing these impediments to decision-making and targeting action against them helps improve the choices organizations make. In three forthcoming blogs, we will focus on different decision types and share tested approaches for ensuring the best results.October 1, 2019 Following the annual three-day gathering of approximately 7,000 insurance industry leaders last week at InsureTech Connect in Las Vegas, we reflect on what we heard. Five themes were clearly top of mind for most attendees.
1. Leveraging digital and analytics to reduce costs and streamline current operations. Freeing up capital to invest in growth, customer and agent experience, and other priorities gives carriers the flexibility to strengthen their long-term relevance. As a result, many carriers are prioritizing productivity and using the digital disruption in the industry to accelerate bottom-line impact.
Digital and analytics solutions have helped many carriers identify and harness opportunities to improve productivity across the value-chain, including overhauling general expenses and overhead, optimizing IT service contracts, and reducing claims losses. As innovation continues, incumbents face the difficult task of integrating these technological advances into their legacy operations and navigating an industry culture that often resists digital adoption and change.
2. Using data to enhance customer experience. Developing a leading customer experience begins with knowing your customer. In an industry hugely influenced by intermediaries, sometimes the target customer—be it advisors, end consumers, or another group—is not obvious. Once that target customer is defined, data can support determining how to most effectively understand and support them.
Data is the backbone of much of the disruption and technological advancement occurring in the industry. As a result, a focused data-architecture strategy is critical for supporting both core and digital priorities. This data strategy is also a foundational capability that many insurers overlook as they move to implement more advanced digital approaches such as artificial intelligence or robotic process automation (RPA). But maintaining and organizing data, analyzing data, and making decisions using data are the best ways to enhance and customize customer experience. When transforming customer experience, data is at the center of comprehensive, journey-based approaches to streamline processes and interactions that customers have with insurers.
With more carrier options and more commoditization across products, a leading customer experience has never been as important as it is today. Data is an integral competitive advantage to forming insights that gain customers' trust and approval, and establishing a value proposition that is tied to customer needs.
3. Insuring and managing risk. Insurers must now address an unprecedented amount of new age risk, including that from cyber, cloud computing, and autonomous vehicles, among many others. With the rapid pace of technological advancements, the scope of risks that carriers must protect themselves against (both business risk prevention and mitigation, especially regarding data protection) and insure others against (underwrite) will only continue to grow. To keep up, insurers must understand how to apply new solutions—including AI, predictive analytics, telematics, robotic process automation (RPA) or chatbots, text ingestion, and content-management systems—to analyze and evaluate their risks. Further, in the face of a significant increase in demand, they must use these new tools to determine which risks they are best suited to underwrite based on their appetite and underlying portfolio.
4. Finding growth outside the core. With a largely saturated market across life and P&C, insurers are now searching for their next growth horizon and taking a three-to-five-year view of developing new businesses. Insurtechs are expanding their influence across ecosystems, and carriers are exploring how to best use their core competencies to enter adjacent growth markets. Many carriers have created venture funds to test new growth opportunities while others have installed innovation hubs within their core operating businesses. As lines continue to blur across health, wellness, personal finance, insurance, and other industries, the ability to develop flexible capabilities and integrate with third-party platforms or application programming interfaces (APIs) is becoming essential to enabling successful growth in the near term. Over longer-term horizons, insurers are investing in internal innovation capabilities that link to continuous improvement, pursuing digital upskilling, and adopting a venture capital–style approach to evaluating opportunities.
5. Securing top-tier digital talent. With an aging agent population—our research shows the average insurance agent age is 59—and higher demand for digital and analytics talent, carriers are facing pressures to upskill and refresh their talent pools. The issue of an aging population extends beyond just insurance, with the proportion of the world's population over 60 years-old expected to nearly double from 12% to 22% between 2015 and 2050, according to the World Health Organization. While some carriers are pessimistic about finding new talent and believe that millennials and recent graduates have limited interest in insurance, others are cautiously optimistic that the creativity emerging from insurtechs, new ventures, and disruptors will attract top talent to the industry. With the evolving demands that technology is placing on the industry’s workforce, digital skills should now be considered when evaluating most roles whether they be producers, underwriters, technologists, managers, or service representatives.
It is clear that there will be winners and losers in the war for talent. Finding innovative ways to excite and retain top talent in both competitive urban markets and more fragmented rural locations will be an important differentiator over the next decade.
These topics are top of mind for most carriers as they face extraordinary innovation and disruption across the insurance industry. If the vendor pit at the InsureTech Connect expo was any indication of the future, the pace of this innovation will only accelerate. Establishing a strategic approach to productivity, data, customer experience, risk management, growth, and talent is becoming table stakes to remain competitive in an ever-changing space.May 11, 2020 Jo joined McKinsey as an associate in the Houston office in January 2020. She came through our recruitment process in the fall of 2019 while pursuing her PhD in applied physics from Rice University. We wanted to know what it was like for this former research scientist, model, actress, avid traveler and active volunteer.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
I first learned about the work McKinsey is doing in digital and analytics through a connection of mine who works out of the Houston office. I’m very interested in that type of work as well as sustainability and energy, which are also growing areas of focus for McKinsey. The nature of the work I could do at the firm and the level of impact I could achieve in these areas really drew me to apply.
I was so excited to receive the invitation to interview – this was my chance! Then my nerves started to fire. I didn’t know much about the process or style of interviews. I’m a researcher at heart, so naturally I started exploring the McKinsey Careers website for information, resources, and guidance. It’s super informative and contains great video overviews of what to expect, practice cases, etc. My recruiters, Allison and Jackie, did an amazing job of explaining what to expect. They communicated with me often, which I really appreciated.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
All McKinsey interviews contain at least two parts – a conversation about your personal experience and a case study. I took the personal experience portion as a great opportunity to reflect on my studies, career experience, most memorable achievements, and biggest challenges. I practiced sharing my stories with a couple of friends who were not very familiar with them, which helped me learn how to communicate my experiences, convey my excitement, and share my thought process about these moments with another person.
For the case portion, I did a few of the samples on the McKinsey careers website and went through a couple of practice sessions with my McKinsey Mentor and a friend from school. It really isn’t about memorizing answers or frameworks and I didn’t want to start sounding overly rehearsed in my answers, so I didn’t do too many. Instead, I focused on learning how to break down the problems and show my work and thinking.
During the time of application and interviews, I made sure to take breaks and stay active, workout regularly, and go for hikes. It was very helpful when dealing with the stress from graduation, writing my dissertation and preparing for interviews at the same time.
Of course, I felt nervous, but also very excited to learn more about the McKinsey and the Houston office and to meet interesting and inspiring people along the way. I felt more comfortable going into final rounds because I was more familiar with the process and I received very helpful, specific, and actionable feedback after round one, which I practiced incorporating into my responses.
Yes, a few things did. First, I thought there would be multiple interview type questions, and I was pleasantly surprised when my discussions felt very conversational. I was thrilled to discuss not only on my professional experience, but also my aspirations and goals.
Second, the feedback I received from practice sessions and round one interviews was very encouraging. One of my assessors called me after round one to tell me I was advancing to the next round. He started with very positive feedback and emphasized all the things I should keep doing in my next round of conversations.
Finally, I want to reassure everyone who is getting ready for interviews or considering applying that it is a standardized process and there aren’t tricky questions or curve balls. All the aspects the interview are listed clearly and comprehensively on the interview website. Interviewers are trained well and are empathetic and not critical. Multiple interviewers sympathized that it’s a long day , it’s natural to be tired by the end, it’s ok to take breaks, etc.
I received a lot of support from my recruiters and built connections with many McKinsey people during the process. I had an interview coach from the Dallas office named Hannah who helped me think through the feedback I received. She shared her McKinsey interview experience and encouraged me to, “try not to be stressed out about having the perfect interview. I made a couple of mistakes during mine. It’s really not the end of the world.” This advice significantly lowered my stress level. And lastly, I received an incredible amount of support from Southern office Women’s network. The members of this group regularly reached out to me to help address my questions and share their personal experiences. I was so impressed by the McKinsey Mentor program, I became a Mentor after I joined. Now, I am super excited to coach candidates through interviews.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
The people and the connections I built during the interview process. I really appreciated how efficient and supportive everyone was. I could see myself as part of the big McKinsey team . I was still very excited about the client opportunities , and knowing I’d work with interesting people made it all even more appealing. McKinsey’s values played a part in my decision as I felt they aligned well with my personal mores.
Jo started her career as a research scientist at Baker Hughes Oil Services. She has also been a medical products research fellow, model, and actress. When she is not working, Jo enjoys traveling, music and sports, especially hiking, playing the cello, swimming and weightlifting. She’s a PADI certified scuba diver. She spends a lot of time volunteering, especially in education by teaching for the Junior Achievement Program and mentoring through Girls in Science.Connected cars have become one of the most prominent implementations of the internet-of-things. In fact, cars themselves have become internet-of-things environments, usually with between 70 and 100 Electronic Control Units (ECUs) embedded in each vehicle. These ECUs work with sensors and other hardware units, and are connected internally by busses (a small in-car network) as well as to the outside world using mobile sim-cards. As with computers and smartphones, software has become increasingly prominent in managing vehicle functionality and has replaced many formerly hard-wired functions in classic ECUs. In fact, the growing dominance of software has helped modern vehicles become known as “computers on wheels.”
Unfortunately, software also makes vehicles vulnerable to potential cyber-attacks. According to the United Nations Economic Commission for Europe (UNECE), new vehicles include approximately 100 million lines of software code, and that number is expected to triple by 2030. In response to this trend, the UNECE World Forum for Harmonization of Vehicle Regulations adopted two new cybersecurity regulations in June 2020 – one for ECU cybersecurity and one for software updating – and they require automobile manufacturers to implement control processes across four domains:
Securing vehicles “by design,” to decrease the likelihood of risks being introduced by the technical architecture or through supply chain partners
These new regulations present a major challenge to automobile Original Equipment Manufacturers (OEMs) due to the complex and decentralized technical architecture in modern vehicles, as well as the necessary reliance on supply chain partners for software (classic OEMs have just a 10-30 percent share of self-developed software in their cars). Additionally, the cybersecurity talent shortage makes it difficult to recruit employees with the specialized skills required to assess cyber risks, implement controls and perform other mitigating activities. Also, different manufacturers are at varying stages of maturity with vehicle cybersecurity, and many will be building the capabilities required to comply with the WP.29 regulations almost from scratch.
While enforcement dates for WP.29 cybersecurity compliance may seem relatively far off – in the EU, for example, manufacturers must be able to show cybersecurity compliance for all vehicles, both new and legacy models, as of July 2024, to receive vehicle type approval (the deadline is two years earlier for newly developed car series). This is a significant challenge given the development cycle of new models, which is typically around three to four years. In other words, engineers developing new models for 2022 or 2024, when the regulations are in force, are already into their development projects and must now retrofit cybersecurity into their designs.
There are several key challenges automobile manufacturers are facing today as they work to move their manufacturing, supply and aftermarket processes to WP.29 compliance:
The most fundamental question automobile manufacturers are dealing with right now is: “Who owns these new WP.29 requirements?” Typically, engineering owns the automobile design and manufacturing process, but the IT department (more specifically, the CISO) owns cybersecurity. IT and engineering have been crossing paths for some time in the automobile industry – with the convergence of operations and information technology networks, and with an increasing number of ECUs and digital capabilities in vehicle designs.
To reconcile ownership of the new regulations, most manufacturers are either making the CISO the point person for WP.29 cybersecurity compliance, or creating a new role in the engineering department (Chief Product Security Officer being a commonly used title). Either way, establishing clear ownership is an important first step to addressing the new WP.29 cybersecurity and software update requirements. However, this is just crossing the first organizational hurdle as departments that typically work in their own silos urgently need to cooperate to assure cyber secure vehicles. These departments include R&D, cybersecurity, IT, quality, procurement, aftermarket, and more.
Cybersecurity is different from other vehicle quality processes, because software components must be tested much earlier and more often than other vehicle hardware components. (You can test a hardware system by driving millions of miles with pre-series/pre-production cars – this will never be a successful approach with software because by the time those cars are available, it’s already too late.)
To achieve sound cybersecurity practices, the automotive supply chain needs to be differentiated between hardware and software. The software part needs to work like a professional technology company for software development. Software is currently developed through a combination of internal development organizations and tier-1 suppliers. To incorporate cybersecurity processes that enable WP.29 compliance, OEMs will need to develop new processes that not only change how software is developed, but also evolve relationships with those tier-1 suppliers.
When the vehicle goes away – responsibility stays. Under the new regulations, manufacturers are responsible for cybersecurity measures across the entire vehicle lifecycle. As a result, the aftermarket duties of OEMs to sustain cybersecurity for their fleets represent a cost and profitability risk. And, they need skilled people to manage the fleet’s compliance in the aftermarket. As might be expected, current aftersales organizations are not prepared for this brand-new challenge. These factors require the creation of new teams to manage these processes, and staffing these teams will be difficult amid a cybersecurity talent shortage.
Acquiring the right expertise may also require enlisting the help of external assistance. At the strategic level, consulting organizations with a strong focus on the automobile industry can provide expertise in WP.29 regulations to help manufacturers build their compliance programs. At the tactical level, specialists in penetration testing, cyber secure software design, software update management, fleet monitoring and other cybersecurity disciplines may be required for software security assurance.
As mentioned above, automobile manufacturers typically outsource software and ECU system development to supply chain partners. This introduces significant complexity into WP.29 compliance, because those partners now must adhere to secure coding and testing practices that ensure the software installed in vehicles is cyber secure.
These challenges will require a realignment of the relationship between manufacturers and their computer technology supply chain partners. Manufacturers will need access to source code, and will also need to implement rules around which tools and technologies are used to develop the software. Ideally OEMs and their software suppliers work with one source code (including free and open source software, or FOSS) repository, which contains just cyber- and quality-approved source code modules. All of these new rules and requirements will need to be detailed in revised contracts, which today only define software/hardware functionality requirements, not WP.29-specific cybersecurity requirements.
Manufacturers will also rely on their software suppliers to deliver updates for the life of the car, which creates ramifications for the business model around selling cars. They will need to develop ways to finance the update process, so they do not defray profit margins over the life of the car.
Deloitte is currently engaged in WP.29 cybersecurity projects with more than 10 international automobile manufacturers. Based on this experience, the following initial steps can help automobile manufacturers move in the right direction toward WP.29 cybersecurity compliance:
Conduct a readiness assessment. By assessing the current status of their organizations against the requirements of the WP.29 cybersecurity framework, manufacturers can identify the staff, capabilities and procedures they will need to put in place to achieve compliance.
By assessing the current status of their organizations against the requirements of the WP.29 cybersecurity framework, manufacturers can identify the staff, capabilities and procedures they will need to put in place to achieve compliance. Set up an internal UNECE cyber readiness program. The readiness assessment should provide the information required to design an effective readiness program. When implemented, this program will enforce the controls, procedures and reporting required for WP.29 cybersecurity compliance
The readiness assessment should provide the information required to design an effective readiness program. When implemented, this program will enforce the controls, procedures and reporting required for WP.29 cybersecurity compliance Do a deep dive into ongoing vehicle projects. The ultimate nightmare for manufacturers is to build a car they can’t sell. To avoid this, conducting a comprehensive review of vehicles in the development pipeline will identify any potential WP.29 issues before production begins.
The new WP.29 cybersecurity regulations will have a fundamental impact not only on the automobile supply chain and manufacturing process, but also on automobile manufacturers’ after-market support requirements and the business model for selling cars. Complying with these requirements may seem daunting – but it is achievable if manufacturers take a methodical approach that starts now. And, as automobiles become increasingly reliant on software for everything from entertainment to safety and suspension options, it is likely less costly to implement more secure software development and update processes now, than it would be to respond to and remediate a serious cybersecurity incident later.The client sought help from McKinsey in coordinating the relationship of its middle-market line of business with its risk management group. This association was characterized by ineffective and inappropriate commercial-credit decisions, portfolio- tracking methods, and metrics. Loan charge-offs exceeded normal expectations, and our client made little or no economic profit on significant portions of its middle-market credit portfolio after full-loading all costs.
McKinsey began by examining the client's loan portfolio to determine sources and concentrations of risk. This required analyzing the pipeline to gauge the credit outlook and determining the organization's appetite for risk along each dimension. McKinsey then detailed the end-to-end process across sites including time, cost and quality. To accomplish this, the team identified sources of variation, modeled the end-to-end economics, established appropriate trade-offs, and mapped roles and responsibilities.
The next step was to benchmark the client's competitive position and customer requirements by assessing current performance and the performance of likely market entrants. McKinsey synthesized its results and developed recommendations that identified opportunities to reduce risk and/or costs and enhance customer satisfaction. McKinsey also clarified roles and responsibilities between the middle-market line of business and the risk group.
McKinsey's plan established a risk strategy and management framework that was integrated with the client's overall strategic business objectives. McKinsey helped the client streamline the credit process, resulting in an expected loss reduction of $15 million in the first year. The client's improved focus on origination quality and reduced charge-offs was expected to boost return on capital by 3 percent over 3 years.I entered the pharmaceutical sector 32 years ago as a clinical research associate. In all that time, there has been surprisingly little change to the way biopharmaceutical companies and contract research organizations conduct clinical trials. While digital technology is widely available to the general population, it generally has not made its way into clinical trials. Most trials continue to use paper-based processes, which can make the process slow and inefficient.
Drug manufacturers might spend $2.6 billion to bring a new drug to market, according to a recent estimate from the Tufts Center for the Study of Drug Development. Every day that a new drug isn’t on the market could translate to $1 million dollars or more in lost revenue.1
During a recent keynote presentation, I outlined some of the challenges and potential rewards involved in moving to virtual clinical trials. Most of the attendees—who were from the largest biopharmaceutical companies—were interested in learning about the complexities of conducting virtual clinical trials and wanted to hear how their peers are approaching the process. While there was an overall feeling that virtual clinical trials represent the industry’s future, even the largest and most technically advanced organizations are just beginning to dip their toes into the digital waters.
Some pharmaceutical companies have been somewhat reluctant to move to digital clinical trials because they assume regulators will not support it—even though companies running pilots with digital technology have found that regulatory agencies are open to novel solutions. Some large technology companies, which have limited experience in life sciences and generally aren’t held back by perceived regulatory barriers, are leading the charge toward virtual clinical trials. While some pharma companies are concerned about the role these new entrants might play, others appear to be anxious to work with them. Along with offering innovative technologies, tech companies might also bring new perspectives to clinical trials.
One of the primary benefits of virtual clinical trials—for pharmaceutical and medical device companies—is the potential to improve recruitment. Our research and client experience suggest that digital transformation can be a complex and resource-intensive undertaking, but the rewards can be significant. By making the recruitment process more efficient, clinical trials could get patients enrolled more quickly, which can reduce the time it takes to bring a new product to market. While patients should be at the center of our universe, we really don’t make it easy on them when it comes to clinical trials.
Consider this: A typical patient travels an average of two hours each way to participate in a clinical trial. After parking, the patient typically has to sit down and complete a variety of forms, undergo tests, and wait for the doctor to become available. Given this enormous time commitment (and possibly time away from work), it’s not surprising that only about four percent of eligible cancer patients participate in clinical trials—that percentage is even lower outside of the US.2 As a result, recruiting patients for clinical trials tends to be highly competitive, and the tiny pool of potential participants can make it impossible to recruit a representative sample. To make matters worse, an estimated 40 percent of people who sign up for a clinical trial wind up dropping out before it concludes.3 This can waste time and money for pharmaceutical companies, researchers, and patients.
Patients might be more willing to accept the burden of a clinical trial if they don’t have to commit as much time. By digitizing processes, patients can fill out forms and complete some medical tests at home or at a more convenient location. Further, some of the monitoring could happen remotely. For example, a diabetes patient might use a digital blood glucometer at home that the doctor can read virtually.
Improving clinical trials could improve the return from R&D for pharma, medical technology firms, and the contract research organizations (CROs) that conduct research studies. A wide range of digital tools could transform traditional clinical trials. These include:
Cognitive computing and machine learning: Information clustering and deep learning can make it possible to solve previously intractable problems.
Information clustering and deep learning can make it possible to solve previously intractable problems. Predictive-Interactive analytics: Aggregated real-time data views can be constructed on agile data lakes, with algorithms, thresholds, workflows and alerts.
Aggregated real-time data views can be constructed on agile data lakes, with algorithms, thresholds, workflows and alerts. Internet of Things (IoT) and mobile health: Wearable medical devices, always-on sensors, and consistent IoT connections can make it possible for a continual flow of data between patients, doctors, and researchers.
The availability of wearable devices makes it possible to gather vast amounts of patient data in real-time and allow patients to participate at home or at the point of care. A patient connected to a digital device might generate one million data points in a single day.4 Ten years ago, by contrast, an entire clinical trial might have generated one million data points. Moreover, data are coming from sources including clinical and patient-reported outcomes, mobile apps, social media, electronic health records, and wearable devices. As a result, physicians and researchers now use a wealth of data to understand how their patients are living with an illness and what might be done to improve their care. These richer data sets can also provide better insight into the effectiveness of a drug or device.
Regulators recognize the value of virtual clinical trials in improving safety. For example, instead of receiving one reading once a month, digital devices can generate a continuous flow of readings, which could provide a much clearer picture of a drug’s safety and perhaps effectiveness. From a safety perspective, the US Food and Drug Administration has acknowledged that data collected digitally can be analyzed more quickly, which can improve the safety profile of a new product. During a presentation early this year, former US Food and Drug Administration (FDA) Commissioner Scott Gottlieb called digital technologies among “the most promising tools we have for making health care more efficient and more patient-focused.” He noted that real-world data gathered from wearable devices, electronic health records (EHRs), and even social media can “expand the sources of evidence that we can use to make more reliable treatment decisions.”5
Though virtual clinical trials have clear benefits, they also face challenges. If the patient population is elderly, participants might not have much experience with digital devices and could be reluctant to participate. Some patients might not be comfortable with collecting and transmitting personal health information electronically. Companies need to incur upfront costs to move to a digital platform.
Clinical trials exist so that we can ensure the safety of new therapies and medical devices for patients. However, there seems to be a growing sense of excitement among pharmaceutical companies that want to become a part of the digital world.
PS: If you happen to be attending this year’s DIA conference, please stop by booth #1855 in the exhibit hall—we will be featuring a virtual clinical trial demo.
1. A Tough Road: Cost To Develop One New Drug Is $2.6 Billion, Policy and Medicine, March 21, 2019 (https://www.policymed.com/2014/12/a-tough-road-cost-to-develop-one-new-drug-is-26-billion-approval-rate-for-drugs-entering-clinical-de.html)
2. Despite pressing need, survey finds most Americans unlikely to enroll in clinical trials, Memorial Sloan Kettering Cancer Center/ScienceDaily, May 2016. (www.sciencedaily.com/releases/2016/05/160523105038.html)
3. https://www.advisory.com/research/oncology-roundtable/oncology-rounds/2016/10/why-patients-dont-enroll-in-clinical-trials
4. Surmounting eClinical Data Volume and Diversity, Applied Clinical Trials, March 1, 2018 (http://www.appliedclinicaltrialsonline.com/surmounting-eclinical-data-volume-and-diversity)
5. Speech by Scott Gottlieb, former commissioner of the US Food and Drug Administration, January 28, 2019 (https://www.fda.gov/news-events/speeches-fda-officials/breaking-down-barriers-between-clinical-trials-and-clinical-care-incorporating-real-world-evidence)Automation has underpinned growth of industry for hundreds of years. From automation of physical tasks in manufacturing to automation of digital processes in recent decades.
Historically, automation was more prevalent in operational areas, that is, in performing tasks that didn’t interact directly with the customer (e.g. robots that make stuff). As technology became more accessible to consumers over time, so did the ability of customer facing processes to be automated (e.g. ATMs).
With digital technology and machine learning, more customer interactions are being automated and we are now seeing rapid increase in algorithmic decisions on customer experience. Every day we interact with algorithms – from ordering pizza to booking a flight, from settling a dispute during online shopping to travelling on elevators with no buttons – each has a profound impact on our experience as consumers and our day to day life.
These innovations have allowed new industries to emerge and allow society to benefit from new products and services. Most of the industry dialogue, however, on the topic of automation has been one sided – either focusing on cost reduction or opportunity expansion. We rarely see an examination of the harmful side of automation, and what are appropriate levels of automation.
Algorithmic processes and automation can have both positive and negative impacts on customer experience as well as on society generally. We categorise impact of automation on customer experience in three broad categories:
In this category of automation, customers benefit from faster service, flexibility of when they can access the services, receive relevant and engaging communication from service provider. In other words, things improve for the consumer. Examples include convenience of online shopping or ordering a taxi.
The supplier of service also benefits from efficiencies through automation and improvements in customer engagement.
In this category, customers face increased complexity in interactions with the supplier and slower overall process due to time spent on finding the right information or reaching an officer for assistance resulting in an overall frustrating experience, or both.
Typically, this is a result of an algorithm being designed for “normal” customer scenarios, that is, an algorithm designed for when things run well. But when a customer’s need falls outside the “normal” range e.g. when there is a problem, such an algorithm can result in an overall poorer experience.
Think of calling a utility company when there is a problem. In this “exceptional” scenario, trying to navigate through an automated system can be frustrating and having a manual process and/or a real person to interact with can vastly improve the customer experience.
In this category of automation, the supplier of service faces risk of customer disengagement and complaints.
In some industries, consumers have formed negative perceptions of customer experience to the extent that some companies are using their customer service call centre capability as a means of differentiating themselves from the competition (e.g. an insurance company advertising “a real person will pick up the phone when you have an accident”).
In this category, customers face harmful impacts of automation through privacy intrusions, unfair discrimination in automated decisions or other actions that may fall below community standards.
This may be unintended e.g. when the automation behaves in unexpected ways. For example, an algorithm based recruitment may result in unintentional discrimination against certain groups during the recruitment process.
In this scenario, the supplier or service provider faces compensation liability, regulatory actions and damage to brand. For example, banks have faced regulatory intervention on algorithm-based lending to borrowers who could not afford to pay back the loans.
Since this category of automation has the greatest harmful impact on consumers and society, it has resulted in public scrutiny in recent years and increasingly we are seeing legislation introduced internationally on holding companies and their officers accountable for decisions made by algorithms and automated systems. Examples include GDPR Right to object and automated individual decision-making, Principles of Accountability raised by ASIC and a recent discussion paper on Australia’s AI Ethics Framework.
How to build algorithms that enhance customer experience and comply with corporate and social objectives?
1. An algorithm should be designed and implemented in a way that meets objectives of the supplier as well as customers and society. Is there clarity of purpose of the automation project from corporate, customer and social perspectives?
2. There should be a clear understanding of value created through automation. For example, while some things are suited to automation others are inherently best served by a human (e.g. the barista that makes fabulous coffee).
3. There should be a tangible improvement in user experience, and not relying on improvements at face value from vendors’ marketing material. Improvements should be verified through field and lab experiments.
4. Algorithm should be designed to handle both “normal” and “exceptional” user scenarios and should have the ability to prompt human intervention when needed.
5. There should clear human ownership of an algorithm. Accountable persons should be empowered with full understanding of an algorithmic process and have control over its actions.
6. Regular testing and maintenance should be performed on the algorithm to check whether it is behaving within expectations as well as whether the system continues to be fit for purpose over time.
Deloitte Business Algorithms has developed a process for designing, implementing and monitoring algorithms that enables human ownership of algorithmic outcomes – “Human in the Loop” (HITL) – which requires human cognisance, ownership and sign-off that algorithmic output is consistent with corporate and social objectives. We help organisations articulate corporate and social objectives, design human-centered customer experiences, use quantitative and qualitative tools to develop intelligible algorithms, apply behavioural science expertise to encourage desirable behaviours and provide certification of algorithms.Digital transformation can be, well, transformative, but I’m hearing rumblings from some people I talk with that their digital transformation initiatives aren’t living up to their promise. They talk to me about budget overruns, unmet expectations, and technology integration problems. There’s an old saying that goes, “If you don’t know where you’re going, any road will get you there.” It applies perfectly to digital transformation.
Back in the day, technological transformation at a company happened maybe once, twice in a decade. It took months—sometimes years—to implement a change. Think process moving to client-server from the mainframe and shudder. Today, though, change comes at you fast—almost daily—and as the pace of change will only accelerate, it’s time to step back and realize that transformation can no longer be managed in silos. Instead, it’s critical to deal with transformation strategically and holistically, and embed transformation into the strategy of the organization.
Silos have been a thorn in the side of IT forever. IT processes and projects are often implemented on a one-off basis that satisfies the needs of the sponsoring department or business function and not the entire system or enterprise as a whole. Even with the rise of DevOps, it’s still too easy to be narrowly focused, because there’s still a lot of, “Well, we’ve always done it this way.”
It’s also just sheer lack of insight. Many people don’t understand the effects of siloed work to begin with, and these effects are magnified when the work is part of an enterprise digital transformation. Transformation is ongoing; it never stops. At any given time, there may be one group transforming for cloud, another for machine learning, another for IoT, etc. The work one group does will almost certainly impact the work of others. When the transformation is managed in silos, the changes become just as fragmented and ineffectual as the original processes that spawned them.
There’s a better way. As I said in the opening, it’s essential to look at transformation holistically, to embed it in the strategy. That means making it a strategy itself. To do that, you need to acknowledge that one-offs don’t work. They’re usually just plasters that cover a sore spot. Instead, it’s critical to understand that the pace of business is transformation. Every day, all the time.
To meet those 24/7 demands for change, it’s essential to put a structure around the transformation process, to make it repeatable and sustainable, sure, but more importantly, to make it the air your organization breathes—to embed it in the very fabric of the organization.
That’s a mouthful, but here’s what it looks like: it’s people, it’s process, and it’s technology—integrated to build a transformative whole that works with change, but more importantly, welcomes it and thrives on it. Each technology project should have transformation user stories being worked on each sprint so that the pace of organizational and process change moves at the same pace as the pace of technology adoption.
So how do you get there? The journey will be different for every company, but there are a few key steps you can take. First, look at your people. What people do you have? Where are they? What skills do they have? What skills do they need to achieve your transformation goals? Answer these questions and put the right people in the right place along with a training, recruiting, and retention plan.
Next develop a plan to assess and manage change—at the top level of your organization. This is the holistic, strategic part I talked about earlier. The plan should be based on the precept that change is constant and pervasive, and that, almost without exception, a digital transformation in one business function or department will ripple like a rock in a pond.
That ripple effect is why step three is crucial. For transformation-as-strategy to work, the idea and thrill of transformation must be embedded into the culture of the company. Everyone has to be on board, to understand that change is a fact of life that should be embraced, not feared. They should live for change. The cultural ethos of the organization should reflect the fact that transformation is continual, and processes and technologies should be implemented with how they affect the organization as a whole in mind.
Individually, people, process, or technology will never solve all your business problems. It is the three combined moving at the same speed toward shared goals that will have the greatest impact on success as we move into the digital age. If you make transformation a core strategy, embed it in your organizational culture, and include it in your project budgets, you just might be able to wrangle those people, processes, and technologies to get more out of it.Deloitte Asia Pacific FS Technology Lead Partner Clifford Foster outlines the trade-offs needed between how technology-driven innovations raise customer expectations, offer new sources of revenue, and transform the competitive landscape, and how enterprises’ extensive IT infrastructures and systems enable them to run their existing businesses, with a wide range of products and channels to support.
When moving into the future, these existing assets can be an advantage or disadvantage. To determine next steps the questions to ask include:
Organisations have to figure out how to harness these existing IT assets and capabilities to meet their current needs, while positioning their businesses for the future. They need a clear, executable, strategy on how to leverage and integrate emerging market services into their offerings quickly and smoothly; while continuing to meet regulatory and broader stakeholder requirements.
The organisation will need to implement technology and practises that isolates the core systems in the IT environment. These core systems can be wrapped as interoperable nodes that interact with other business system nodes, to deliver functions that are vital to the operation of the business.
Although this may not seem to be too different to the IT environment that it has today, it has created untapped potential waiting to be exploited to the benefit of the organisation and its stakeholders.
There is value in the nodes. But even more value in the network that connects these nodes within the organisation. A core network provides a clean and secure gateway for connecting nodes within the organisations and external nodes or services external to the organisation. This allows internal teams, as well as chosen third parties, to innovate and implement new ways of working.
As with Metcalfe’s Law, the more nodes isolated within the IT environment, the greater the potential value to the organisation. This facilitates the flow of data, rather than restricting it to islands of information at the edges. For example, by generating new business insights from data in flight through the network, with data-at-rest in the core nodes you can provide, monitor, and action events at the heart of your business.
Exploiting the potential of the core and core network requires a new set of skills, management and governance. Combinations and intersections become more important than single data points.
The enterprise should clearly consider its technology and information management operating model by considering what capability is needed to:
The organisation’s that are best able to exploit the digital core will position themselves for a future whereby the value and assets within the enterprise can be rapidly combined with new market services to deliver unprecedented value to shareholders.Anna joined our Warsaw office as an experienced hire after working in finance for several years. While completing her bachelor’s and master’s degrees—both in finance—from Wrocław University of Economics in Poland, she also completed her CFA program, paving the way for her to work almost exclusively within our financial institutions group. She speaks four languages, which is useful given her love of international travel. Outside of work, you’ll find her skiing, sailing, or attending the theater.
Hi everyone! I've spent the last 6 months working on a pretty intense, yet truly rewarding project. Our client has set ambitious goals that required a team with wide range of newest competencies. From day one, I've been working hand in hand with a very large, international and very diverse group of colleagues specializing in digital solutions, advanced analytics, UX and UI design, implementation etc.
Team dynamics has been great, we spent a lot of time working closely with the client, travelling and meeting in person. Three weeks ago, the situation changed due to the COVID-19 outbreak, and like all other teams in the firm - we had to reorganize the way we work. As the manager on the project, I immediately thought: multiple client meetings planned, all our equipment left in the team room, fifty people on the team suddenly need to work remotely... How will we manage that?
Thankfully, the firm already had multiple solutions in place, the technology and tools were all there - we just had to make good use of them. Our team works Agile, and there are many applications enabling virtual work. I connected with our Agile teams in China who shared advice on what worked for them. One of the firm's strengths is undoubtedly the global knowledge sharing and our Chinese colleagues helped a lot.
We now use an online Kanban board, stay in touch using Teams, and continue our scrum ceremonies virtually. Our clients have also switched to remote work, so overall I am happy to see that despite challenges we can maintain delivering to our client at the same level as always.
My initial fear was that given lack of in person interaction, maintaining strong team bonds will become challenging. We are staying as connected as possible, though. We are trying to have individual 1:1 calls and also find time to connect informally. We recently arranged an online team dinner with charades, which was a lot of fun!This blog post has been adapted, based off a talk given at the 2018 Lean Agile Systems Thinking Conference and shared at a couple of Melbourne based meetups through the year.
Over the past 12 months there have been a number of bold, public and notable announcements and changes (ANZ, Bankwest, Telstra to name a few) to Australian organisations looking to think, work and organise themselves differently.
However transformation or change, of any kind, is hard. Especially when this change is so fundamental to the core of how organisations, and the people within them, operate.
Yet only 11% of organisations feel confident in their ability to get it right. Source: Deloitte Global Human Capital Trends Survey 2017
94% of business leaders think that ‘agility and collaboration’ is critical to their organisation’s success. Whether that be in an attempt to be more purpose driven, more focussed on customer needs, creating greater alignment and transparency around priorities, or reinvigorating and creating a great workplace for their employees.
Companies will have either seen the benefits of agility and collaboration in their own organisation and want to replicate this at scale, or have observed what their competitors are (or are not) doing and deciding to act.
A need to change will stem from either an ambition to constantly change and innovate – however, this is often culturally deeply embedded as a part of the organisational fabric. Organisations like Zappos, Netflix, Amazon do this naturally.
Or from a more traditional burning platform, where the result of not changing may result in more dire consequences for the organisation. This is particularly prevalent in industries or organisations adversely impacted by disruption or changing external environmental and market forces. This is evident with the digital impact on telecommunications, the royal commission into banking, and the rising cost pressures on utilities providers.
In an effort to become more agile and adaptable, are these organisations focussing on what really matters?
The goal should not be ‘to do or become agile’. It should be about delivering a better outcome for their customers.
Here are five suggestions to think about, before considering adoption or launching any kind of transformative agile change.
Most organisations recognise the need to be more customer-obsessed, however few understand what is required to become customer-obsessed.
It was now almost fifty years ago that Peter Drucker said “There is only one valid definition of business purpose: to create a customer. The customer is the foundation of a business and keeps it in existence.”
However most internal practices within an organisation do not have line of sight to an end customer and often service internal needs.
If you are able to create alignment within a team about who the customer is, what matters to them and why you are trying to serve them – that is a good start.
While the commercial drivers that support running any business (revenue, cost, compliance, etc.) are important, setting short to medium term goals focussed on changing customer behaviours as a leading indicator is critical.
Set goals that promote introducing small changes directly to customers, to validate if you are doing the right thing. This naturally favours a more hypothesis-driven approach to validating customer needs.
Being able to quickly shift or respond to customer behaviour, will support longer-term decision making about where and how to invest time, effort and money.
The role of a leader in an adaptive organisation often represents a shift in how they would have lead organisations to-date. There is a noticeable change from the Leader as the expert, to the Leader as a servant.
Without proper support and coaching, they may struggle to adapt to the changing nature of what their teams need from them. To best support these leaders, be specific and measured about what they do and do not need to do.
There is no cookie-cutter playbook or method for successful agile adoption. The context in which each organisation plays in will also vary (the same as every individual team).
Enter into this change with an understanding of the current parameters, constraints or deliberate choices about what matters to the organisation and what can or cannot be shifted.
Openly discussing and assessing on a sliding scale where your organisation currently sits and where they would like to be, across a range of dimensions (example below), will help shape what your adoption or change might look like.
Having agreement on what dimensions can be impacted and to what benefit is incredibly powerful in order to gain alignment to the common goal and purpose, and useful to manage perceptions and communications of the direction the organisation is heading.June 17, 2019 You might think that advanced industry—a sector characterized by research and development and use of artificial intelligence and other breakthrough technologies—also optimizes the way its R&D organizations work. But continual business and technology trends in advanced industries (AI) have triggered fundamental challenges that require advanced industry innovate in its approach to R&D.
Just consider the three major R&D hurdles automakers confront in designing autonomous cars: more complexity and functional interfaces across projects, especially involving interlinks between software and hardware; amplified change and ambiguity in customer demands; and tighter interaction with an increasingly diverse ecosystem. As a result, decisions take too long, milestones are missed and standard operating procedures are delayed, siloed and fragmented. R&D staff stay in task force mode, and collaboration and job satisfaction diminish.
Early agile models in advanced industry R&D departments are delivering significant impact. We’ve seen a doubling of the time spent on value-add work, speedier decision-making, a 30 percent rise in productivity, increased engineer motivation and enhanced responsiveness to customer demands.
Sidebar Designing flying taxis: Is agile the key to innovative R&D? Many research and development (R&D) teams find themselves held back by a traditionally siloed structure in a rapidly changing environment, particularly in heavy industries. We connected with James Arnold, head of design systems and head of process excellence at Lilium—a European company developing the world’s first electric vertical take-off and landing jet—for a first-person perspective on what an agile R&D department looks like when starting greenfield in a highly innovative industry. Arnold and his team recently completed a successful first field test of its all-electric five-seat aircraft and hopes to launch a fully operational flying taxi service in select cities by 2025. Question: You are a small start-up exploring a very futuristic technology. How are you approaching innovation, and how has experimentation played a part in the process? Arnold: The history of the development of our aircraft is one of experimentation and iteration. From the very start, our founders worked with physical prototypes to test and demonstrate ideas, and as the company has grown, we have developed many prototypes in increasing levels of complexity. This kind of experimentation—and working towards something that can be tested and learned from—is essential for innovation. Q: Can you talk about the positive social and environmental impact of this unique mode of transportation? Arnold: We like to think about the “radius of life.” When you can travel five times faster than you can by typical ground transport, your horizon for commuting also increases by five times. Five times the radius gives 25 times the area and 25 times the possibilities. Or you can gain that time back for yourself and your family and create a big increase in wellbeing. Congestion and ground-level pollution will drop dramatically; cities will become cleaner, greener, quieter and safer. Q: What characteristics were critical in putting together your R&D team? Arnold: Research shows the impact of diversity, in terms of outcomes and the positive effect on team interactions. We have people with 30 years of experience working alongside undergraduate interns. We have people from different industries and cultural backgrounds. To benefit from this, we also need people who are open and ready to learn and try new ideas. Q: How do you manage collaborations to incorporate cross-functional teams for effectiveness? Arnold: We build our main cross-functional teams around the product breakdown structure; each major aircraft system has a dedicated team. Each team is established from the start of the program and is co-located, with a single day-to-day leader from the systems engineering team. We believe there's a huge increase in effectiveness and efficiency when sitting together vs. trying to collaborate virtually. Q: How are you looking at scaling the R&D unit? Arnold: Our goal is to make the foundations, processes, systems, mindsets and skills scalable. This means continuously challenging and improving things like our onboarding process for engineers, day-to-day collaboration and data management. It’s also important to expect and embrace the changes that scaling brings. Different structures and approaches are better for different sizes of teams, and it’s OK to change! Q: How is agile part of the equation for your team? What principles have been key? Arnold: One of the original principles of the Manifesto for Agile Software Development—the progenitor of the “agile” concept—is simplicity. Our whole architecture is designed to be extremely simple, and we drive this down into the detailed design of every part. We also work in short, iterative cycles that come to some sort of end product that can be evaluated. The objective is to learn quickly and efficiently, with a short lead time. Q: The hallmark of agile is to continually evolve. How do you ensure ongoing changes happen while still protecting the agile culture? Arnold: Due to our extremely fast team growth, we have a slightly different problem. Change is happening and will continue at a breakneck pace for several years. We work to protect and build on our engineering culture but also allow evolution and new people to bring new ideas. To take advantage of this, it’s important to have and reinforce core principles that give a framework but are not too rigid. Sometimes you can embed these principles into processes, but that’s not enough—there needs to be a huge and continuous effort to reinforce the right mindsets.
So, what comprises a more effective agile organization that sparks cross-functional collaboration, quick decisions, fresh ideas from anyone, flexible shifts of priorities and resources, and a place that attracts talent drawn to rewarding and fun work?
We can look to other industries such as banking, energy and telecom because they have faced similar issues. For instance, when one banking institution moved to a model where small teams follow a joint purpose and enjoy full end-to-end responsibility, they significantly improved cross-functional collaboration, time to market and customer satisfaction while moving to No. 1 employer of choice from No. 12 two years prior.
From these other industry pacesetters, advanced industry can take agile mindsets, principles and values while tailoring practices and tools to their own R&D realities. If an R&D organization truly wants to change how it operates, it needs to:
Derive promising learnings from pilots for organizing agile teams and make necessary changes to its “backbone” system, such as budgeting and work allocation processes and alignment of plans and priorities.
We do see some winning practices in selected “frontrunner” R&D departments in advanced industry as they pertain to structure, process/technology and people dimensions.
Structure: Create small, stable e2e teams that are accountable and possess a shared purpose instead of organizing by competencies. When priorities change, shift the task, not the people. People should work and sit together in teams but retain a home base within their discipline (e.g., electronics). They assume responsibility for managing common components and setting software and other architectures.
Processes/technology: Work on end products in rapid iterations and quick learning cycles, applying new testing technologies in standardized, not religious, processes. Enlist customers early. Favor more frequent and smaller decision meetings—in a way disaggregate today’s big meetings—that focus on decision-making versus status approvals.
People: Leaders change their style, e.g. visionary, focusing on coaching and problem solving and embedding ownership in their teams. That means asking them to develop their own plans and solutions and focusing on providing a clear framework, including clear interfaces and responsibilities. This requires ensuring a culture with stronger collaboration, more ownership from lower-level team members and risk assumption. Development teams also must step up. As one manager explained, “If your engineers behave as fenced-in sheep and you remove the fence, they will just continue grazing in the same place and nothing changes.”
Most advanced industry players have begun experimenting to determine where and how to apply agile, but they must scale it up for the full impact. Pilot projects prove important to learn whether a concept works, and they can boost enthusiasm. Technology trends will continue and as organizations meet these challenges, a full agile operating model will be required.Many years have passed since Agile has become a household name globally in IT. Large organisations which previously worked in very traditional ways have now been on the journey to achieve Agility for many years. This journey has typically commenced at the grass roots in software development teams, and then has scaled up to multiple teams using agile to run large programs.
Agile has now widely been recognised as a way-of-working that enables you to define, plan, and execute against outcomes. This wider recognition has resulted in the demand for the application of these ways-of-working outside IT in business functions, such as Marketing, Sales, and Legal. With the repeated success of agile achieving faster, smarter, and cheaper customer outcomes, large enterprises have realised the need to adopt these ways-of-working across the full organisation which we call Enterprise Agility.
In this blog post, we explain why Enterprise Agility is needed to remain competitive and what Agility means at the Enterprise level.
A volatile market with innovative competitors focusing on the customer and leveraging new technologies has created pressure on existing players
The need for Enterprise Agility is driven by the current VUCA (volatile, uncertain, complex and ambiguous) market dynamics. Competitive pressures against large organisations across industries are increasing. Contributing to these pressures and the change in these market dynamics is disruption from global innovators, particularly through start-up organisations which are able to compete in new ways. They are achieving this by pinpointing lucrative / niche segments and combining these with a customer first focus and new technologies. This is lowering the barrier to entry allowing start-ups to compete at scale with traditional large corporates.
Traditional ways of the past will not stack-up against the new goal of the customer for 21st century organisations
Not only is the competitor and technology landscape changing, so are customer demands for a better, more personalised service.
With the rise of digitisation and the global economy, this has changed the information customers now have access to. This means the goal for organisations now also needs to change. No longer can an organisation prioritise their shareholders needs over their customers. They can no longer offer an average service or customer experience and see no broader impact outside that single customer. They can also no longer take months or years to provide customers with the products and experiences they want. The customer needs to be at the heart of everything they do. As the below slide presented by Steve Denning at the inaugural business agility conference in New York 2017 shows:Agile and Design Thinking are complementary. Design Thinking is a human-centred approach to defining and solving problems, which encourages innovation and creativity in the problem solving process. Design Thinking is particularly well-suited to situations where the problem itself is not clear, advocating a strong focus on problem definition, problem shaping, and requirements clarification. Likewise, Agile methods embrace uncertainty and are appropriate for projects where the requirements are subject to change.
While Design Thinking is a solution-centric approach, it also places great emphasis on having a clear articulation of the problem. For Agile projects, the backlog is where the functional requirements of the system under development are captured, and the quality of those requirements is a significant factor determining the success of the project.
A pairing of Design Thinking with an Agile mindset and method can occur across the lifecycle of a project, from Initiate to Release. We will explore three examples of how to elevate your Agile with Design Thinking:Project Management processes are maturing with more and more projects being delivered successfully. According to the Project Management Institute[1], a lack of project sponsorship continues to be the number one reason why projects fail. Scope creep continues to be an issue coming in at number two, with number three being a lack of capability in value delivery.
Organisations embark on large complex transformation journeys to achieve breakthrough performance, support acquisitions or comply with regulatory obligations to name a few. These journeys are time-boxed, budget dependent and face ever-changing risks, including regulatory, competition and resource capability. Ways to increase the likelihood of project success and value delivery include project governance, management and use of better practice delivery frameworks such as PRINCE, PMBoK, Waterfall and Agile.
Agile continues to be a topic of growing importance in project management, with 71 percent of organizations now reporting they use agile approaches to their projects sometimes or more frequently than in the past[2]. Two out of every five projects use an agile, hybrid or blended agile approach[3] and some of the agile methodologies now in use are Scrum, Lean and Kanban.
No single delivery framework fits every project and agile methodologies need to be adapted to suit project needs.
Kanban is a popular framework used for software implementation. This point of view captures the use of Kanban to deliver large and complex projects.
"Kanban" is the Japanese word for "visual signal" and was developed as a scheduling system by an industrial engineer at Toyota to improve manufacturing efficiency and just-in-time manufacturing.
It requires real-time communication of capacity and full transparency of work. Work items or tasks are represented visually on a Kanban board that helps to keep everyone on the same page. This can be tracked on a physical wall or digitally. The simplest Kanban boards are physical boards divided into vertical columns where teams mark up a whiteboard or wall space and place sticky notes/cards on. These move through the workflow of Do, Doing or Done phases and demonstrate progress. Digital boards allow teams that do not share a physical office space to use Kanban boards remotely through tools such as Jira, Slack and Trello.
In 2018, a leading organisation was de-merging from its parent division to create an independent top 30 ASX-listed company, representing Australia’s largest ever-corporate transaction. Part of the scope included the setup of a new Treasury operating function including operating model, bank accounts, payments, interest rate risk management, hedging, and accounting, recruitment of its key resources and rapid implementation of a new and critical Treasury Management System.
A market leading Software as a Service solution was chosen with 19 weeks for implementation. From a system perspective, this would encompass and support capabilities such as integration with four banks and existing technology platforms, third party financial and market data systems and a supplier finance facility to start with.
Given the 19-week delivery timeline, principles such as transparency, collaboration, leadership, understanding, and agreement were required between the business and IT teams to achieve successful delivery of the new treasury system. Aside from the development of standard project management components, it was necessary to establish a methodology for effective collaboration, transparency of information and communication of change across the multiple stakeholder groups involved.
The Kanban methodology was chosen for this purpose and physical wall was setup in a dedicated project room with co-location of business, IT resources to deliver the system under the aggressive timeline (see Figure 1 below).
To commit to these timelines, activities and tasks from the integrated project schedule were developed in to a backlog and then prepared based on delivery priority into columns on the wall moving from left to right in the form of sticky notes highlighting a 3-week view and tracked daily. These sticky notes (see Figure 2 below) were assigned to team members with an end-date and then moved from ‘do-doing-done’ during the plan, design, build, test and deploy phases.
Daily stand-up and iteration reviews were performed to support the body of work underpinning the Kanban methodology and highlight updates to tasks, risks/issues and dependencies making every team member from the project, business or IT co-own the wall. This level of engagement, collaboration and transparency helped to maintain clear channels of communication and continue the delivery momentum. This also assisted in feeding information to the Program Management Office and provided and appropriate layer of first line governance and controls for the project.
The visualization of the work that Kanban established underpinned the interpretation of the to-be world, provided focus on continuous delivery, reduced re-work, quickly resolved risks, issues and dependencies and drove the successful delivery of a Minimum Viable Product in an aggressive timeframe.Organisations are experiencing disruption at an unprecedented pace. Enterprises hesitant to embrace ambiguity in the past, now want and need to be agile enough to meet evolving customer, technology, and market dynamics.
However large, traditional organisations are struggling to keep pace. They have typically built-up significant internal complexity over a number of decades, which is slowing or preventing them from change. Examples of this complexity are:
Different operating cadences across core business functions causing misalignment and slow go to market
Multiple layers of command and control style hierarchy creating bureaucracy and an inability to deliver change quickly.
To keep up with the constant change required, it’s a challenging juggling act to quickly reconfigure strategy, up-skill or hire new people, update process, protect existing business, and create new propositions, all on an ongoing basis.
There are some local, recent examples of traditional organisations, such as ANZ 1 and Bankwest 2, looking for new ways to design their internal ecosystem. These organisations have used Spotify as a source of inspiration.
We believe that having a tailored operating model, with a foundation built on empowering network based, sticky, multi-disciplinary teams is paramount.
Also ensuring that these teams have the right skills and capabilities with the required supporting infrastructure to enable creativity and productivity to be unleashed is essential for success.
Our previous blogs have looked at our definition of Enterprise Agility 3 and why it is a business imperative, as well as, how you can start your journey 4. In our third edition of our Enterprise Agility series, we will discuss our key agile operating model design principles.
Conway’s law states that “organisations which design systems … are constrained to produce designs which are copies of the communication structures of these organisations.” 5
The replication of complex and matrixed structures, based on internal process compliance doesn’t deliver what customers ultimately want or need.
Projects are too often launched without actually addressing the true customer need. Moving human centred design closer to the problem, rather than the solution is a great way to challenge the norm.
Having teams focused on the customer journey and experience ensures that, rather than mimicking complex internal structures, teams are organised around delivering value to the customer.
For example, ING had squads within their Mortgage Services tribe that focused on the search engine and another on the mortgage application. Both aligned with the overarching customer outcomes which the tribe was responsible for delivering. 6
The greater the alignment to a customer strategy, and the more autonomously these teams can deliver outcomes against that strategy, the better.
When multiple lines of business or functional areas follow different timelines, release windows or cadences – the ability to coordinate at scale becomes challenging.
This is most commonly the case across areas that may have constrained resourcing (e.g. legal, change, finance), or where there may be added complexity or longer lead times (e.g. technology, operations, security).
Organisations need to develop an operating model which can support delivering change multiple times per day, planning every fortnight, and changing direction at least every quarter, if appropriate.
Our guiding principle is to adopt a common cadence across all involved parties to make it easier for teams to plan or pivot based on shifts in strategic direction.
As the role of leaders changes from being less about operational decision making, to servant-leading and empowering teams – the need for complex matrixed structures diminishes.
Employees closest to the work need to be allowed to make real decisions, and be accountable for them. Management need to either get out of the way, or step-in and proactively remove the blockers which prevent teams from going faster.
Focusing less on antiquated and lengthy governance processes and adopting a build, measure, learn philosophy enabling rapid experimentation and lean start-up techniques is a fast way to ensure you’re working on the right things.
When change is enacted with greater frequency and in smaller packages, it naturally minimises the scale of what could go wrong.
Our guidance is to allow employees to experiment and test solutions; but do so by time-boxing the design and experimentation process in order to quickly make a decision whether to pursue, pivot or perish an idea.
Your enterprise agility journey doesn’t necessarily need to begin with a re-designed operating model or new organisation structure.
However three design principles that you need to consider in your operating model are shifting the focus of teams towards the customer, aligning to an organisational cadence, and removing layers of bureaucracy and focusing on operating lean.
Without these, large organisations will continue to face challenges in keeping up with the pace of change and leap frogging their competitors.Data from an OECD study reports that 15% of Australian graduates are overqualified for their jobs[1], working in fields which do not require a degree. Meanwhile, the World Economic Forum is advocating that traditional learning is leaving graduates without the skills they need to contribute in the workplace.[2]
Increasing HECs debt and a workforce skills gap presents complex problems for many stakeholders. Co-Founder of LinkedIn, Allen Blue states that “many members of the global workforce can’t keep up with the shift in skills required for jobs”[3]. Given the heavy focus on traditional knowledge such as literacy, numeracy and recall skills in assessments, it is no surprise that students are lacking the 21st Century skills they need to succeed.
21st Century skills are traits that are universally applicable and in-demand in the modern era. As relevant and important as technical skills are, adapting to new ways of working by leveraging the characteristics and behaviours which make us uniquely human will give us an edge over AI.
Skills frequently rated by the World Economic Forum as important for 21st century workers include[2]:
Firstly, whose responsibility is it to ensure students graduate with the necessary skills for today’s workforce? More broadly, how do employees continually maintain relevant skills despite a rapidly changing workforce?
The answer to both may be found through a thoughtful balance of traditional technical skills and newer, more human-centric ways of working. Many of these 21st century skills are uniquely human, and learning to solve the problems of others through transdisciplinary group work is one way to develop these skills. The practice of human-centred innovation could also offer a safeguard for the future as it requires advanced communication skills, and demonstration of empathy, creativity, and adaptability.
These previously under-prioritised skills will become ever more crucial with the rise of robotics and AI. Predictions by the Committee for Economic Development of Australia indicate that almost five million jobs are likely to be replaced by artificial intelligence in the next twenty years[4]. Others, such as the founder of China’s Sinovation Ventures, Dr. Kai Fu Lee, suggest that jobs which utilise the characteristics of creativity, complexity, dexterity, empathy and compassion will not be replaced by AI[5]. Regardless of the resulting conclusion, it is undisputable that the future of work will be very different, and it’s difficult to clearly determine how.
The best we can do for future generations is to equip them with the versatility and resilience they need to adapt to the rapidly evolving work environment – a monumental challenge which poses more questions than answers. Perhaps AI will become a self-inventing, self-constructing, self-improving and empathetic force, replacing the societal structures we know today. One can only speculate. Until then, we can do some self-evaluation and self-improvement of our own by asking, ‘how can we each ensure that we’re prepared to navigate the challenges ahead?’
[1] https://www.telegraph.co.uk/education/2018/09/11/almost-one-three-graduates-overqualified-job-major-report-finds/
[4] https://www.ceda.com.au/News-and-analysis/Media-releases/More-than-five-million-Aussie-jobs-gone-in-10-to-15-years
[5] https://www.forbes.com/sites/forbesbusinessdevelopmentcouncil/2018/08/13/three-trends-on-the-future-of-work/#10540c1b60a4Before joining McKinsey, Aaron worked at several other consultancies, as an independent consultant, and served as a research associate at the Institute for Behavior Resources. He has a PhD in social and organizational psychology from Columbia University, where he specialized in organizational dynamics, culture, human-resource management, leadership effectiveness, and strategic change.
Aaron, who writes frequently about organizational topics, has published many articles in McKinsey Quarterly and elsewhere. He is a member of the master faculty of the Change Leaders Forum and of the Organizational Agility Forum , which he helped establish. He has also led McKinsey’s thinking on organizational health and was on the teams that developed the Organizational Health Index (OHI), OrgLab , and Influencer.
Much of Aaron’s work focuses on helping large distributed organizations to achieve growth, innovation, productivity, and organizational agility. He serves clients across several industries, including agriculture, biotechnology, chemicals, energy, financial services, and healthcare.
Aaron counsels leadership teams as they transform their organizations to improve performance, organizational health, speed, and agility. He is also an expert on organizational design, corporate culture, leadership development, team effectiveness, capability building, and transformational change.
“Decision making in your organization: Cutting through the clutter,” McKinsey Quarterly, January 2018
“Reimagining how life sciences work will be done in the next normal,” McKinsey & Company, October 2020
“Reskilling in the age of COVID: There’s no better time than the present,” blog entry, McKinsey & Company, October 2020
“Unleashing sustainable speed in a post-COVID world: Reshape talent,” blog entry, McKinsey & Company, September 2020
“What 800 executives envision for the postpandemic workforce,” McKinsey Global Institute, September 2020
“Unleashing sustainable speed in a post-COVID world: Rethink ways of working,” blog entry, McKinsey & Company, September 2020
“The need for speed in the post-COVID-19 era—and how to achieve it,” McKinsey & Company, September 2020
“Four considerations for helix success beyond structure (part three),” blog entry, McKinsey & Company, August 2020
“What does a helix reorganization look like? (part two),” blog entry, McKinsey & Company, August 2020
“Become flexible and speed up with a helix model (part one),” blog entry, McKinsey & Company, July 2020
“Ready, set, go: Reinventing the organization for speed in the post-COVID-19 era,” McKinsey & Company, June 2020
“To emerge stronger from the COVID-19 crisis, companies should start reskilling their workforces now,” McKinsey & Company, May 2020
“Leadership in a crisis: Responding to the coronavirus outbreak and future challenges,” McKinsey & Company, March 2020
“Busting a management myth: empowering employees doesn't mean leaving them alone,” blog entry, McKinsey & Company, February 2020
“What it really means to lead more effectively through empowerment,” blog entry, McKinsey & Company, February 2020
“Improve your leadership team's effectiveness through key behaviors,” blog entry, McKinsey & Company, January 2020
“How companies can help midlevel managers navigate agile transformations,” McKinsey & Company, April 2019
“Leading agile transformation: The new capabilities leaders need to build 21st-century organizations,” McKinsey & Company, October 2018
“Houston Astros: winning the World Series with advanced analytics,” blog entry, McKinsey & Company, September 2018
“Building the critical foundation of an agile organization,” blog entry, McKinsey & Company, February 2018A couple of years ago, larger organizations focused solely on implementing agile projects in which they tried to leverage benefits from agile methodologies to deliver better results, with higher quality and a faster time-to-market. These days, the discussion has moved on: More and more organizations are thinking about transforming the entire enterprise into a product-centric organization to bring business and IT closer together and deliver more value directly to the customer.
Several organizations have already started on their journey or are planning to do so. Before deciding to embark on such an endeavor, it is important to evaluate whether agile is the right solution to achieve the organization’s goals. Otherwise, the risk of being stuck in a long-term transformation without direct benefits is likely to be high. Having agreed on the urgency of an agile transformation, we usually find ourselves discussing with our clients all the diverse dimensions that need to be considered for such a journey.One of the reasons that doing agile transformations is difficult is that there is no one formula for how to do it. The starting point and context for each organization’s journey toward agility is different.
Our cross-functional agile tribe recently brought together executives of more than 50 organizations from across financial services, healthcare, software, retail, chemicals, industrials, advertising, manufacturing, and advanced industries for our inaugural Agile Day in New York. The event included multiple speakers who shared their companies’ experiences, a panel discussion on the pitfalls of agile, and breakout how-to sessions aimed at helping companies drive agile at scale. What we heard is that although every organization’s story is different, five common factors seem to underpin all successful agile journeys:
Bold vision and clear commitment communicated from the top. This may sound obvious, but it’s critical to success. In almost every journey we heard about, leaders said they invested most of the first months of their programs in helping the organization’s biggest influencers understand the vision. Everyone has to see that there is no going back to the old way of working. “People need to know what’s in it for them, and they need their questions answered,” said the CEO of a British financial-services firm. That’s when you can also point out the downside of the status quo. Building trust this way is key. “You can’t hide behind slides—you have to be real with people,” he said. Use agile to implement agile. Healthy agile teams continuously learn and challenge themselves to be more mature. “Don’t be afraid to fail, don’t punish failure, and don’t even think of it as failure,” advised the CIO of a US insurance company. Teams should not expect to get to the end in one step. Rather they should celebrate their experimentation, and that includes celebrating the bumps in the road. Go beyond technology. Successful agile transformations address every aspect of the organization. As the chief digital officer of a Latin American bank described it, “You can’t do just one thing.” You can start with technology, if that’s preferable, but eventually an agile transformation has to touch all parts of an organization, including HR and marketing and finance. End-to-end, the entire organization has to embrace agility. Engage your leaders. You need them to champion the cause of agile transformation, Agile Day speakers said. Part of doing that is for leaders to move away from giving directions and instead ask, “What do you think?” As the CIO of a multinational bank put it, “You have to arrive at answers by asking questions.” It’s a collaborative method of problem-solving that has to be reinforced with role modeling and the right performance assessments. Agility is about empowering and trusting in a self-leading team to figure it out, speakers at Agile Day said. This means top leadership needs to look for opportunities to strengthen teams, remove roadblocks facing them, and improve their performance. People first. This also may seem obvious, but getting the best talent is truly a delicate balancing act. You have to move quickly or you’ll lose the right candidates to other employers. At the same time you need to be especially sure that any person you hire is truly the right fit for your culture. “You may have to adapt policies,” said the chief product officer at an HR solutions company that allowed its agile team to make offers in less than 24 hours, rather than the company’s usual six weeks.
It’s not easy, but agile transformation is worth it, as we heard from the success stories recounted at our Agile Day. It can lead to all sorts of improvements: faster time to market, significant cost reductions, customer-centricity across all functions, reduced waste, and a generally healthier and more successful culture.
The author would like to acknowledge Somesh Khanna, Marcus Sieberer, Aaron De Smet and Krish Krishnakanthan for their contributions to Agile Day and this post.Jak skutecznie skalować pracę zespołów zwinnych w dużych organizacjach? O tym, między innymi, rozmawialiśmy pod koniec października z naszymi kolegami z niemieckiego Deloitte, którzy podzielili się praktyczną wiedzą i doświadczeniami ze swojej pracy z wykorzystaniem metodyki Scaled Agile Framework (SAFe). Przy okazji poprosiliśmy o krótki wywiad specjalnie dla czytelników naszego bloga „Zwinne organizacje”.Traditionally, leaders have been encouraged to dynamically reallocate capital to the most pressing and attractive opportunities. This focus remains today, but many companies face a challenge: human capital is now the scarcer of the two main capitals. Companies that manage talent with the same rigor they do financial capital, treating it like the precious resource it is, typically see better results. They reallocate talent to high-value areas and push talent management to the top of their growth ...April 9, 2020 I’m an agile coach in McKinsey’s Gurugram office. I joined McKinsey in 2012 as an operations engineer, providing support for Oracle, MySQL and other relational database management system (RDBMS) technologies. From there I expanded to the reliability engineering group, where I was responsible for product management, change management, problem management and onboarding new applications.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com Agile coaching session (before COVID-19)
McKinsey has given me great access to tech learnings both internally and externally. In my operations engineering technology role, I learned additional RDBMS technologies, including MySQL and DB2 and NoSQL systems like Apache Cassandra and the Neo4j graph platform. I also worked on automation projects using Ansible, Python & Shell Scripting.
In 2017, with the support of my managers, I decided to try my hand at becoming an agile coach and scrum master. I’m now a certified scrum professional, scrum master and product owner, certified agile leader and Kanban system designer. I’ve led more than 10 agile squads in development operations, product and client services as a scrum master. Now, I’m a leader in McKinsey’s agile group.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
We have a saying here, which I find rings true: Make your own McKinsey. It means that within the firm you can explore opportunities and build your own path based on the work that excites you. We have the opportunity here to learn and experiment with disruptive tech languages, platforms and methodologies.
In my current role, I serve as an agile coach to squads around the world, leading them to follow data-driven visualization approaches to problems, past patterns and new opportunities. I also mentor and coach scrum masters through designing and executing virtual and in-person workshops and training programs.
I don’t limit my methods to scrum. I am inspired by Liberating Structures techniques, lean processes and design thinking. I also love using Kanban’s practices like visualizing and managing workflow to establish predictability.
The leadership at McKinsey has been very supportive. I have had mentors who helped me in my journey, and I’ve mentored others in turn. I enjoy the people at McKinsey, the culture and the inclusive environment that the company fosters. Every day, I work with colleagues at all levels within McKinsey, with different technologies and in many geographies and time zones.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com Bhangra performance (before COVID-19), a Punjabi folk dance form with my McKinsey group “Bhangra Jammers”
I am happy to have found groups of like-minded people within McKinsey. I perform Bhangra, a Punjabi folk dance form with my McKinsey group “Bhangra Jammers” at McKinsey events like Values Day. I’m involved in the corporate social responsibility team, I serve as the Go Green Team board member and I’m part of McKinsey Toastmaster’s club, which promotes communication, public speaking and leadership.
Based in Gurugram, India, Gurbrinder is an agile coach with our internal Technology & Digital team. Prior to joining McKinsey, he was a Java developer focused on insurance and telecom projects. Gurbrinder earned his bachelor’s in technology from Guru Gobind Singh Indraprastha University in New Delhi. Outside of work, he volunteers with charity groups for causes including women’s issues, children with special needs, pollution and blood donation.1. Transparency: As one of the basic three pillars of scrum, raising constant visibility and tangibility is vital. It sets the foundation for good decision-making. A collective view of the strategic progress that factors in all interdependencies will make organizations more aware of emerging events, risks and issues but also potential synergies between existing initiatives. This can be achieved by commonly using Kanban boards, strategic backlogs and sprint plans as basic tools. Further, monitoring activities and feedback loops supplement the understanding whether the organization’s initiatives are aligned with the strategic vision.
2. Continuity: Since Agile Strategy is using an incremental approach, strategic initiatives are divided into various, manageable sizes fitting into one iteration. In doing that, each part builds on the previous one leveraging new attained insights and learnings. For instance, an initiative that usually takes one year can be divided into four to five pieces (each for one sprint). This helps organizations to build strategies from different angles using these new insights and increases momentum on a frequent pace. The same applies to the overall governance of agile strategy management: in a retrospective at the end of each iteration, conclusions for identified improvements are evaluated. Consequently, this promotes a relentless optimization of strategy planning and execution. This stands in contrast to traditional plan-build-run approaches, where the delivered outcome, such as organizational changes, can only be verified at the very end.
3. Consistency: This feature goes hand-in-hand with the previous one: after each sprint, the outcomes can be verified and measurements for the next steps investigated. By releasing a steady stream of strategic artifacts (initial and ongoing outcomes of initiatives), organizations can build and maintain sustainability as well as predictability. This has two benefits. Firstly, short-term and long-term needs can be addressed more effectively. Secondly, strategic plans are not treated like single artifacts anymore but as growing strategies that are continued and optimized. Closely interlinking (re)design, execution, monitoring and adaption can help achieve this as part of the strategy development and execution process.
4. Flexibility: The main motivation behind adopting an Agile Strategy framework is the ambition to adjust and adapt more quickly towards the strategic impact of changing environments. After each iteration, it is either to pivot or to preserve: by conducting regular reviews at the start of each iteration, the value contribution of an achieved strategic artifact is evaluated against the present situation. Practitioners can either continue to work on it or they can stop and tackle more critical matters that have emerged in the meantime. The same applies to any new risks or issues that need to be solved beforehand. Previous initiatives hereby will be set back to a strategy backlog until the next iteration. Not only does this iterative proceeding defy the rigidity and flaws of traditional strategic management. It centers the view on business value and increases the focus on managing strategic initiatives in a predefined time.
5. Feasibility: Unlike tremendous planning activities, dynamic decision-making methods such as hypothesis-driven and scenario-based planning help to explore and test complex and uncertain environments. They lead to repetitively new assumptions or selective options until a fitting solution has been narrowed down. One level beyond, experimentation-based ‘trial and error’-activities, piloting and data-driven automation procedures lead to alternative conclusions that can change a previously anticipated status quo immediately. In any case, organizations need to familiarize themselves with an insight-driven ‘Fail and Learn fast‘ mentality in order to increase the success rate of strategic realization.
6. Engagement: Organizations are advised to empower self-organized, interdisciplinary strategy teams dedicated to put these strategies into practice. They should consist of senior managers representing all affected organizational areas – business as well as IT – who are committed to shape and contribute to strategic discussions. In doing that, they maintain a mutual exchange of information between Top Management and the engaged staff. Latter provide their subject-matter expertise and consult the strategy team on the feasibility of planned initiatives. The Top Management oversees that the strategic team adheres the strategic direction while promoting the team in its autonomy. In the end, this encourages a higher dedication by all involved parties including a broad knowledge base for decision-making and an increased buy-in from all relevant stakeholders.Wouter is a life coach, with certification from the MMS Worldwide Institute, and has coached more than 20 senior executives and board members on making the personal changes needed to lead their companies’ transformations. He writes frequently on organizational topics and is a leader of McKinsey's Organizational Agility Forum .
Wouter is a leader of McKinsey’s agile organization work. He has deep experience in serving global high-tech companies and technology functions in other industries as well as cross-industry experience in agile operating-model design and transformation.
Wouter has led several large-scale transformation programs for clients, helping them achieve sustained improvement in both performance and organizational agility. These programs focused on strengthening mind-sets and capabilities from the leadership team to the front line while delivering improved performance. He believes strongly in integrating hard measures to boost operational and financial performance with soft skills, such as self-awareness and effective teamwork.
“Rethinking the boundaries of your organizational (eco)system,” blog entry, McKinsey & Company, December 2019
“How to select and develop individuals for successful agile teams: A practical guide,” McKinsey & Company, December 2018February 5, 2018 Across industries and regions, the concept of organizational agility is catching fire as companies scurry to deal with rapid change and complexity. Yet, achieving the ability to reshape themselves quickly is proving elusive for most.
The findings of McKinsey’s first global research study of agile organizations underscores the difficulties in achieving their desired nimbleness. But it also illuminates that getting agile right delivers substantial rewards ranging from efficiency improvements and improved customer satisfaction, to faster time to market.
We cast a broad net in our research, and it delivered some major surprises in identifying key success factors for becoming agile. Among them:
1. An organization must excel at all the 18 identified key practices to achieve agility. Our research finds that doing a few of the key practices well is not enough, all 18 must be embraced. The 18 include some basic elements – such as standardizing ways of working and sharing access to unfiltered data – and several more advanced techniques, such as having an open talent marketplace where people move regularly between roles and teams. You must address the holistic set of levers to scale organizational agility across most or all of an institution.
2. Speed is central to becoming agile, but so is stability. Organizational agility requires a core set of organizational elements that don’t change a lot, such as a platform to build and launch fast, dynamic capabilities. Even if your company is stable, you need to determine how it is stable. Most global enterprises possess the wrong type of constancy; instead of a launching pad for dynamism, most big companies today have stable elements that are bureaucratic “speed killers,” such as rigid organizational structures centered on hierarchy and control.
The research identified six stable, foundational practices among the 18 key elements upon which to build and scale agility, such as a shared vision and purpose that establishes a North Star for the entire organization.
3. An organization must deal head-on with the No. 1 agility challenge: culture and leadership mindsets. They surpass insufficient resources, lack of leadership commitment and system limitations as the biggest barriers to becoming nimbler. To solve them requires abandoning many basic assumptions about how organizations can and should work, including that senior leaders must maintain control. Letting go of control is vital to becoming agile.
Amazon’s CEO Jeff Bezos gets it. In a 2016 letter to shareholders, he maintained that the company must treat every day like it’s Day 1. “Day 2 is stasis. Followed by irrelevance. Followed by excruciating, painful decline. Followed by death. And that is why it is always Day 1,” he wrote. To keep that Day 1 energy, he says, requires being extra fast on making decisions, even if they must later be reversed or are made without having full information. And, he said, senior leaders must feel free to disagree with a decision, although they must fully commit to it if they’re outvoted.
Understanding these three insights from our research into how to become agile will especially benefit organizations starting or still in the early stages of their journey to agility. In subsequent blog posts, we will explore other essential ingredients for achieving an agile organization, including a deeper examination of the 18 practices considered essential to adopt.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
March 16, 2020 Throughout my career, I’ve experienced how agile methods improve workstreams and deliver tangible results firsthand. I spent time as a scrum master, digital product owner, agile trainer and a tech strategy consultant at Accenture.
One day, a new job alert popped up on my LinkedIn: Agile Coach at McKinsey’s Warsaw office. My father worked at McKinsey 20 years ago, so I read McKinsey’s posts and blogs about agility to learn more about their work in the space. During the entire recruitment process, I had great support from McKinsey recruiters, who coached me and helped me land the job.
McKinsey approaches agility differently. We go right into the boardroom and make agility a priority for the client’s entire organization, not just one department. Agile isn’t an experiment here, it’s a long-term business practice.
Day to day, I help large organizations shift to agile workstreams to create lasting change. Some of the organizations I work with use agile in segmented departments, and we help take that company-wide. The most rewarding part is working alongside people across the company who are experts in their fields, building a strong team, and making this change a success.
Agile work at McKinsey explores a variety of methods and frameworks. We use practices from agile approaches like SAFe, LeSS, scrum and Kanban and tailor our methods to each situation. For higher-level steering, we bring OKRs into the mix and institute quality planning structures like those many Silicon Valley tech companies use.
I’m working on a very cool project right now for a large apparel company. We’re using agile methodologies to connect the company’s planning and logistical operations to improve the company’s processes. As a loyal brand customer, it’s a dream come true to work alongside these clients and bring agility to their business.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Working at McKinsey is amazing because of the people. I have the chance to work with remarkable, smart and kind people from different backgrounds from all over the world. Even when I’m the only person in a t-shirt in a room full of suits, I feel welcome and appreciated for the expertise I bring to the table.
I enjoy McKinsey’s focus on people and communities within our offices, within our 4.5K+ global tech community and within our practice of 100+ agile coaches. Through the agile community, I can connect with colleagues worldwide when I need support during a project. We have in-person meetups, where we get to know each other on a more personal level, share our experiences and discuss the future of our role in the firm. I always look forward to these meetups and we always have great fun.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Tomasz is an agile coach based in Warsaw, Poland. Prior to joining McKinsey, he was an accredited agile trainer and a senior tech strategy consultant at Accenture. Tomasz earned his bachelor’s in finance and accounting at Kozminski Academy in Warsaw and his master’s in international management at Warsaw School of Economics. He is certified Scrum Master, Product Owner, DSDM practitioner and Kanban Management Professional. In his free time, Tomasz enjoys spending time with his wife and kids and keeping up with the latest blockbuster action movies.As the business impact of the COVID-19 crisis mounts, leaders in every industry are moving urgently to protect employees and build resilience. Governments are mobilizing to safeguard citizens and manage the economic fallout. Immediate action is critical, but leaders must also embrace a new agenda—one aimed squarely at what comes next.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.Enterprise agility was desirable and is now becoming essential. Agility across a whole enterprise combines speed and stability; helps role clarity, innovation, and operational discipline ; and can produce positive outcomes for organizational health and performance. Although the beneficial outcomes of agility are widely recognized by executives, those considering an enterprise-wide agile transformation are questioning both the potential of such an undertaking and the outcomes they should seek.
What should executives focus on, and what might they expect to change? Some data are emerging to help with answers. We analyzed the impact of enterprise-wide agile transformations as part of our worldwide agile-research effort. We analyzed 22 organizations in six sectors, and our preliminary results identified three main outcomes of agile transformations: improved customer satisfaction, employee engagement, and operational performance. These make up what we call the “agile impact engine.” The benefits are mutually reinforcing and produce a fourth outcome: improved financial performance (Exhibit 1). Exhibit 1 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
The agile impact engine forms a framework for assessing potential gains by examining in more depth those organizations that have successfully completed agile transformations (see sidebar “A word on our research methodology”).
Sidebar A word on our research methodology To create the ‘agile impact engine,’ we collected outcome data on 22 companies across six sectors that completed agile transformations at the business-unit or enterprise level (excluding organizations that implemented agility solely at the team or squad level or within just one function). We measured the level of agile maturity (the extent to which a company operates in an agile manner) before and after the transformation. This allowed us to check if the transformation had successfully increased the level of agility and to weight the improvements observed in the outcome metrics. To measure agile maturity, participants rated a set of statements capturing agile behaviors across five dimensions—strategy, structure, processes, people, and technology—on a scale from one to five. We compared the change in agility maturity as a result of the transformation with the change in outcome metrics to understand how agile maturity might drive company outcomes. When conducting our research, we encountered three main challenges that influenced our sample size and the outcome metrics considered: the limited number of enterprise-wide cases that are currently sufficiently mature, given the pioneering nature of such full-scale transformations
the lack of a single measure of impact—impact depends on industry, and measurements need to be taken across a combination of metrics, given the complexity of impact
the difficulty in tracing the impact of marginal output (for example, additional product features resulting from more agile development) on financial results
Although these results seem highly desirable, there are three caveats. First, the extent of the gains depends on the starting level of enterprise agility, since, naturally, those starting with lower baselines experience more change. Second, significant gains are found only where agility is implemented successfully, holistically, and with high ambitions for performance improvement. Finally, the 20 to 30 percent improvement in financial performance may not register as profit and loss, as organizations make strategic decisions about removing cost and reinvesting in growth and capabilities.
Before we look closer at the potential impact of agile transformation, it’s important to build a shared understanding of how we define and understand the topic.
Agile organizations can quickly redirect their people and priorities toward value-creating opportunities. A common misconception is that stability and scale must be sacrificed for speed and flexibility. Truly agile organizations combine both: a strong backbone or center provides the stability for developing and scaling dynamic capabilities.
This backbone binds structural stability (standard operating procedures) to cultural stability (shared purpose, direction, and values); it also supports dynamic capabilities (for instance, fluid changes to strategy and team setup) in order to respond quickly to fast-changing conditions.
Sidebar How agile are you? Understanding your company’s agile maturity today is an essential step in shaping your journey to enterprise agility. Curious to find out your company’s agile maturity? Take our 20-question survey in the paper’s appendix.
To balance flexibility and stability, organizations can implement choices in five dimensions of the agile operating model (Exhibit 2). The extent to which an organization has implemented these agile elements represents their level of agile maturity (see sidebar “How agile are you?”). To reap the fullest benefits of agility, companies should implement any operating-model changes across all five dimensions.
Exhibit 2 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Few organizations have completed a full transformation across all dimensions of the operating model at the enterprise or business-unit level; most still work at team-level agility. However, we see a growing interest in scaling agility from pilot projects at the team level to implementation across larger parts of the organization. With this in mind, our research included only those agile transformations at the enterprise or business-unit level.
Although the five dimensions seen in Exhibit 2 provide a clear path to implementation and how to assess the level of enterprise agility, they offer no guidance on how to measure the impact of enterprise agility. The danger here is using the table to measure the ruler rather than the other way around.
We tracked a broad set of outcome metrics during agile transformations and saw that organizations use a unique set of metrics depending on their sector, customer type (for example, B2B or B2C), and transformation objectives (Exhibit 3). However, we can broadly synthesize the key outcome metrics into the four categories that compose the structure of the agile impact engine shown earlier:
Exhibit 3 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Clearly, different organizations undergoing agile transformations will tend to emphasize apposite outcome categories. For example, those in our sample who needed to recruit talent focused more on employee engagement, whereas those in financial distress concentrated on financial gains and those facing competitive pressure valued customer satisfaction.
Section 2 How much do your customers love you? Agility has the potential to improve the customer experience by up to 30 percent
Using enterprise agility to meet rapidly changing customer needs can result, unsurprisingly, in a better customer journey. In the cases we examined, agile transformations resulted in an uplift in customer satisfaction and engagement of between ten and 30 points.
An obvious driver of this impact on customer experience is the shift toward an obsession with the customer; this is key for all agility. During an agile transformation, customers move to the heart of the organization, and the “North Star” (a shared purpose and vision across the organization) invariably centers around customer needs.
In fact, the North Star is essential to an agile transformation, since it informs all decisions and missions and provides a language shared across the organization. For example, Amazon’s North Star is, “We seek to be Earth’s most customer-centric company.” Amazon’s four guiding principles, of which one is “customer obsession rather than competitor focus,” further emphasize this purpose.
During an agile transformation, customers move to the heart of the organization, and the “North Star” invariably centers around customer needs.
Another element that enhances customer satisfaction is a flexible network of teams (one of the five trademarks of an agile company). In a successful agile transformation, the teams need to operate with high standards of alignment, accountability, expertise, transparency, and collaboration, all in service of the customer.
The impact of these standards on customer satisfaction becomes clear when we consider the complicated pathway that new product ideas took at an Asia–Pacific telco in its preagile state. As Exhibit 4 shows, new ideas to meet customer needs went through countless handovers between departments with different customer value propositions and incentives. This resulted in frequent delays and, consequently, low customer satisfaction. During the company’s agile transformation, it moved to a cross-functional setup of its digital-consumer business, with 18 squads taking end-to-end accountability for different outcomes within the new digital hub. As a result, customer satisfaction increased by 35 points.
Exhibit 4 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Section 3 Do your employees really care? Agility leads to a potential 20 to 30 percent improvement in employee engagement
A second area in which the impact of agility is clearly visible is in employee engagement. The organizations in our sample experience a 20- to 30-point improvement in engagement in an agile environment, compared with a nonagile environment. This change was seen whether engagement was measured by employee willingness to recommend their workplaces or by internal employee-satisfaction surveys.
Several factors could explain the impact of agility on employee engagement. Most fundamentally, in the nonhierarchical organization of cross-functional teams, employees have the opportunity to develop a strong sense of autonomy, mastery, and purpose. These have a positive influence on employee satisfaction and engagement, as evidenced in previous McKinsey publications and extensive research, including that compiled in Daniel H. Pink’s Drive: The Surprising Truth About What Motivates Us (Riverhead Books, 2009).
An agile transformation encourages these three motivating factors, as illustrated by a telecom operator from Asia–Pacific. The company launched an enterprise-wide agile transformation, with improved employee engagement as a leading goal, alongside increased customer centricity and faster time to market. Throughout the transformation, the company’s operating model went through an overhaul. They transformed its hierarchical and multilayered organization structure into a simple, three-layered approach consisting of a leadership squad, 18 tribes, and approximately 200 autonomous squads.
Autonomy was embedded by creating small, cross-functional teams with full end-to-end accountability for specific missions and products. Mastery grew from its need for people who could apply knowledge across a broad range of situations while having deep knowledge in one area. The new setup recognized individuals for their technical skills and allowed growth in expertise, not just a move into management with a multidimensional contribution model.
Sidebar What is the difference between a key performance indicator and an objectives-and-key-results metric? A key performance indicator (KPI) is a metric used to measure the performance and track the health of a business, and it usually refers to an ongoing activity. A mature organization will track many KPIs but conceptualizes them as levels to maintain, not necessarily targets for change during the period of measurement. Setting objectives and key results (OKR), however, allows companies to focus on aligning its objectives for change and monitoring progress toward those objectives during the period of measurement. The objectives, based on the overall company road map and strategy, get revisited regularly as the team or organization evolves. There may be an overlap between a KPI and the OKR framework if a KPI aligns with an objective that a change in the KPI could accurately measure, but this is not necessarily the case.
Finally, purpose was created through an inspiring North Star translated in clear goals and missions for each squad in the organization. Concrete tools such as objectives and key results (OKRs) allowed the North Star to act as a common language between distributed and autonomous teams (see sidebar “What is the difference between a key performance indicator and an objectives-and-key-results metric?”).
As a result, employee engagement scores in most of the agile tribes now significantly exceed levels seen even in many of the iconic digital natives, allowing the organization to attract top talent in the market and strongly outperforms its peers in this area.
It makes sense to want happy, motivated, and engaged employees. There is a strong connection between employee engagement and efficiency metrics (such as speed of issue resolution), as well as between employee engagement and customer satisfaction. And the contribution of such employees is widespread. Moreover, it should come as no surprise that high employee engagement scores attract better applicants and support organizations in the war for talent.
Sidebar Mini case study: Purpose in the public sector An example of the impact of a purpose orientation comes from a European public-sector defense organization. One senior leader commented, “In order to overcome organizational inertia, we focused on crafting a ‘North Star’ vision and redesigned our previous hierarchical structure into purpose-based teams. We really wanted our staff to feel part of this transformation, so [we] focused from the start on cocreation and listening.” This enabled the organization to set priorities for each team, make “health checks” to identify pain points and strengths, and facilitate early employee buy-in. Overall, the organization became more responsive to change, and its employee engagement increased by 20 points.
When measuring the impact on employee engagement of agile transformations, it is important to track changes over time. Any transformation can initially provoke excitement across both agile and nonagile parts of the organization. Equally, parts of an organization may experience a subsequent decline in engagement when they encounter obstacles in nontransformed parts of the organization.
The HR director of such a fully agile organization expands on the powerful impact purpose and autonomy had on the large improvements in employee engagement :
[Without purpose and autonomy], you’re in a world where people come in to work, they do their little bit, they go home, but they may have no idea where that fits into the big scheme of things. Agile puts direct ownership and real-time accountability with the squad so that they have absolute clarity about where it all fits now. That’s where the engagement comes from—employee engagement goes off the chart because people have richer jobs, they’ve got a broader perspective, and they’re focused on solving problems. They don’t feel like hamsters—they feel like they’re part of a squad that’s on a mission.
Operational-performance metrics vary by sector. Common examples in our sample include time to market, planning time, issue-resolution speed, predictability, and raw product output, among others. These can fit broadly into three categories: speed, target-achievement rates (TARs), and other industry-specific metrics. Our research shows that implementing an agile transformation can unlock an improvement of 30 to 50 percent in these metrics.
Two specific factors—enhanced visibility and understanding of objectives and improved team dedication—are dominant here:
Agile units have more visible expectations of their tasks (by having strategy expressed in OKRs, team-level milestones, and deliverables). They are also clear about their current performance (by using real-time key-performance-indicator dashboards). Adjustments can occur quickly. Tasking dedicated teams with particular outcomes reduces the need for handovers (for example, sending a customer from department to department or handing off an unfinished product to another team) and the waiting time, thereby increasing efficiency.
Using agility, organizations can increase the speed of decisions and product development, as well as shorten the time between the conception and release of a product (known as time to market). They dream of a setup that allows them to stop trailing their competitors and to move to the forefront of product development.
Implementing an agile transformation can improve operational-performance metrics by 30 to 50 percent; enhanced visibility and understanding of objectives, as well as improved team dedication, make a difference.
This happened to a telecom player in our sample. As a result of the company’s new, agile setup, it could respond to its competitors’ new-product releases within one week, as opposed to several months: it cut time to market by as much as 70 percent. Overall, our research indicates that agile transformation can reduce time to market by at least 40 percent.
This is also relevant for B2B companies, or parts of B2B companies, in which speed can have a large impact on capital expenditure. An oil and gas company, for example, wanted to reduce the time it took to plan and design a new oil well. The health and safety implications of drilling rely on a variety of technical skills and require large capital and time expenditure. By creating one co-located team of engineers from the completion, drilling, geoscience, and petroleum teams, as well as supply-chain and commercial specialists, the company halved the time required to plan and design its wells and increased quality by reducing handovers.
Finally, in service operations, speed can drive significant gains in productivity and customer satisfaction, as we have seen in many instances of agile transformations of customer-service and back-office activities.
Another operational metric that shows significant improvement after agile transformations is the TAR. Capture 70,000 customers of a goal 100,000 new customers, and the TAR is 70 percent. Whereas most traditional companies struggle to meet their targets (falling below the 100 percent rate), all agile companies in our sample, bar one, surpassed their targets: rates ranged from 90 percent to 140 percent. The 140 percent TAR was at a European bank that outperformed its objectives despite deteriorating market conditions. That said, outperforming targets is not always desirable. Predictability of performance is crucial in accurate forecasting for strategy and resources. Agility allows organizations to adjust their forecasts and targets up and down in a timely manner.
There are many industry-specific operational metrics that illustrate the benefit of agility. For one Australian liquefied natural gas producer, increasing the amount of gas produced per employee was a key operational metric. By applying agile methodologies, such as shifting technical middle managers to “doers” and creating semiautonomous operating assets, the producer was able to raise overall gas production by 5 to 10 percent. However, with a significant reduction in full-time-equivalent hours by means of these methodologies (and by reducing its organizational layers to four), the overall increase in the volume of gas production per employee went up by 70 to 80 percent.
Although successful agile transformations lead to impressive operational improvements in the long run, a dip in operational performance is common during the initial phases of the transformation. This is the result of employees and the organization adjusting to new ways of working. For example, at an Asian telco, senior leaders mentioned that performance—measured by time to market and achievement of performance targets—initially dipped after implementing new initiatives (sprint-based operating rhythms and newly cross-functional squads). But after three months, performance surpassed the company’s preagile level.
Can improvements in customer satisfaction, employee engagement, and operational metrics (such as speed) as a result of agile transformation translate into financial uplifts? Whereas almost all the organizations in our sample tracked productivity gains and cost savings, few systematically looked at revenue or margin uplift, citing difficulties in baselining the pretransformation state. This led to the data overemphasizing cost savings; nonetheless, we have qualitative evidence of revenue-based improvement as a result of agile transformation.
Although cost savings is seldom the primary objective of an agile transformation, it is a natural consequence of the improved operational performance and ability to provide the same outcomes with fewer people. The internal and external costs savings identified in our sample ranged from 20 to 30 percent. Importantly, in several cases, companies reinvested part of the savings to capture new business opportunities—meaning these savings did not register as part of profit and loss.
For example, a Latin American bank decided to go agile in one of its discrete business units. By applying a “no middle managers” rule; reducing the number of layers to three, from seven; dedicating squad members 100 percent to the transformation; and removing the silos between the business and IT functions, it saved 30 percent of its internal full-time-equivalent employees. The bank identified all these employees as new capacity and redeployed them to new roles within the agile company.
Our research so far shows that the prize for agility at the enterprise level is a significant boost in multiple organizational outcomes; we have summarized the maximum potential in our agile impact engine. The findings hold true for successful agile-transformation implementations across sectors and geographies. As the pressures mount to find innovative ways to remain competitive in today’s rapidly changing environments, agility is no longer just desirable but becoming essential.
To continue building our fact base, in coming months, we will extend our research on agile maturity and key performance indicators (including financial results) across industries and over time.Where are you today? Given the growing popularity of agile over the past number of years, especially within IT and recently emerging for business areas like Marketing, Sales, etc., there are likely to be pockets of agile within your organisation. These learnings are important to capture and will feed into your understanding of the current state enterprise agility spectrum. The current state view will provide a rough indication of how much change will be required.
Where do you want to get to? To determine where your organisation would like to get to starts to define the choices and decisions that will be required. Based on the examples across culture, people, leadership, governance, strategy, structure, policy, ecosystems and technology in the spectrum, there is a clear contrast between how a classic/traditional organisation works vs. a high performing agile organisation.
As an executive leadership team, clear decisions need to be made on the set of guiding principles that will define the ways-of-working for the organisation across these core themes. These principles should be universal. However, the application of these principles will vary as a one-size fits all execution approach will not work consistently across all areas of the business (e.g. core customer/product business units vs. shared functions like HR, Finance, Risk, Procurement).
Lastly, the accumulation of the previous 3 steps will set you up to create a clear, simple and purpose-driven story that will drive your change narrative. It is essential that all individuals in the organisation, including the executives at the top, new graduates / recruits, and individuals who have been with the organisation for years, are able to articulate with conviction, strength and a sense of urgency the case for change.
The case for change needs to be balanced with the benefits of the change (enabler of your strategy through embracing the art of the possible and solver of current challenges) and the investment required to get there in people, process and technology. There needs to be a recognition that you will ‘slow down before you speed up’, and clarity on how success will be measured iteratively on the way.
All 4 steps are important to work through, yet the most fundamental for your success is to ensure that there is leadership sponsorship, alignment and prioritised focus. An evolution towards Enterprise Agility, regardless if it commences from within IT or from the Business, will result in a complicated mess, with both leaders and team members feeling frustrated, and likely end in failure, if there is minimal or no visible, active, or aligned leadership.
Moving beyond the phase of Ideation, an Enterprise Agility journey continues in an iterative and incremental way – in the true agile spirit. Committing and delivering on small actions as an organisation, team, and individuals, at all levels, is fundamental to the approach. Measuring outcomes along the way will be your guiding light. Remember, there will be feelings of resistance, fear and discomfort at the start, and during ‘the emotional journey to creating anything great.’ It will not be easy to change. But, if your organisation doesn’t change, how else will you respond to the ‘change is the new norm’ world that we live in today?April 9, 2020 I’m an agile coach in McKinsey’s Gurugram office. I joined McKinsey in 2012 as an operations engineer, providing support for Oracle, MySQL and other relational database management system (RDBMS) technologies. From there I expanded to the reliability engineering group, where I was responsible for product management, change management, problem management and onboarding new applications.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com Agile coaching session (before COVID-19)
McKinsey has given me great access to tech learnings both internally and externally. In my operations engineering technology role, I learned additional RDBMS technologies, including MySQL and DB2 and NoSQL systems like Apache Cassandra and the Neo4j graph platform. I also worked on automation projects using Ansible, Python & Shell Scripting.
In 2017, with the support of my managers, I decided to try my hand at becoming an agile coach and scrum master. I’m now a certified scrum professional, scrum master and product owner, certified agile leader and Kanban system designer. I’ve led more than 10 agile squads in development operations, product and client services as a scrum master. Now, I’m a leader in McKinsey’s agile group.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
We have a saying here, which I find rings true: Make your own McKinsey. It means that within the firm you can explore opportunities and build your own path based on the work that excites you. We have the opportunity here to learn and experiment with disruptive tech languages, platforms and methodologies.
In my current role, I serve as an agile coach to squads around the world, leading them to follow data-driven visualization approaches to problems, past patterns and new opportunities. I also mentor and coach scrum masters through designing and executing virtual and in-person workshops and training programs.
I don’t limit my methods to scrum. I am inspired by Liberating Structures techniques, lean processes and design thinking. I also love using Kanban’s practices like visualizing and managing workflow to establish predictability.
The leadership at McKinsey has been very supportive. I have had mentors who helped me in my journey, and I’ve mentored others in turn. I enjoy the people at McKinsey, the culture and the inclusive environment that the company fosters. Every day, I work with colleagues at all levels within McKinsey, with different technologies and in many geographies and time zones.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com Bhangra performance (before COVID-19), a Punjabi folk dance form with my McKinsey group “Bhangra Jammers”
I am happy to have found groups of like-minded people within McKinsey. I perform Bhangra, a Punjabi folk dance form with my McKinsey group “Bhangra Jammers” at McKinsey events like Values Day. I’m involved in the corporate social responsibility team, I serve as the Go Green Team board member and I’m part of McKinsey Toastmaster’s club, which promotes communication, public speaking and leadership.
Based in Gurugram, India, Gurbrinder is an agile coach with our internal Technology & Digital team. Prior to joining McKinsey, he was a Java developer focused on insurance and telecom projects. Gurbrinder earned his bachelor’s in technology from Guru Gobind Singh Indraprastha University in New Delhi. Outside of work, he volunteers with charity groups for causes including women’s issues, children with special needs, pollution and blood donation.It was a Saturday morning. I was standing in line at a coffee shop, thinking about flow, as I often find myself doing when waiting in line. I reached for my phone to pass the time (while stuck behind a constraint in the cafe’s system of work) and sent the tweet above*. This tweet went, relatively-speaking for me, viral, breaking in to triple digits of likes and retweets. It seems to have struck a chord.
If you want to do an Agile Transformation, don’t. Focus on Better, Value, Sooner, Safer and Happier and you will end up transforming to have agility.
This is the first of a series of posts, where I’m going to share a number of anti-patterns and corresponding patterns. It is worth noting that everything is context dependent. An anti-pattern for one scenario might be a pattern in another context. That said, I believe that the anti-patterns to be presented are applicable in the majority of contexts.
This is based on lessons learnt through doing including learning from failing. Along with many talented people, we’ve been servant leaders on better ways of working (the application of agile, lean , DevOps, design thinking, systems thinking and so on) across a large (80,000 people), old (300+ years old), global, not-born-agile, highly regulated enterprise, with personal experience of delivering change with an agile mindset, principles and practices since the early 1990’s, about a decade prior to the Agile Manifesto, when the term ‘lightweight processes’ was used. The anti-patterns and patterns are also based on learnings from the community, from other horses (rather than unicorns) on similar journeys, as we are all at a turning point in the Age of Digital.
A capital ‘A’, capital ‘T’ Agile Transformation, from the perspective of an employee, infers involuntary, mandatory change being done to you, whether you like it or not.
The capital ‘T’ denotes that you have to change and the capital ‘A’ denotes how you are going to change. Both of these words carry baggage.
Not surprisingly, this triggers fear and resistance for many reasons, including loss of control, uncertainty, changing habits, fear of failure, fear of incompetence, more work, change fatigue and ‘better the devil you know’.
From an evolutionary perspective, depending on the messaging of the why and depending on how the change is approached, and in particular for those with a fixed mindset, change drives a fear of survival, which leads to resistance and less rational thought as the primitive brain takes over.
Looking at autonomy, purpose and mastery, as per Daniel Pink’s Drive and that human motivation is primarily intrinsic for knowledge work, two of the top three motivators have been taken away. There is a lack of autonomy (you have to do this thing) and a lack of mastery (you’re a beginner again, possibly after a long career). If the why is articulated as cost reduction or profitability, meaningful purpose is also removed, taking away all three categories of human motivation.
“The problem with the amygdala and its fight-or-flight response today is that it sets off alarm bells whenever we want to make a departure from our usual, safe routines. The brain is designed so that any new challenge or opportunity or desire triggers some degree of fear. Whether the challenge is a new job or just meeting a new person, the amygdala alerts parts of the body to prepare for action — and our access to the cortex, the thinking part of the brain, is restricted, and sometimes shut down.” (One Small Step Can Change Your Life. The Kaizen Way, Dr Robert Maurer, 2014)
This evolutionary fear of change is also seen in loss aversion, which is people’s tendency to prefer avoiding losses to acquiring equivalent gains. This evolutionary tendency to loss aversion further cements people’s desire to maintain the status quo.
“Humans may be hardwired to be loss averse due to asymmetric evolutionary pressure on losses and gains: for an organism operating close to the edge of survival, the loss of a day’s food could cause death, whereas the gain of an extra day’s food would not necessarily cause an extra day of life.” (Loss aversion, Wikipedia)
Agile should not have a capital A unless it is at the start of a new sentence. Agile is not a noun. It is not a trademark. You can’t buy Agile In A Box (really, you can’t). By the very fact that agility is optimal in complex contexts, where the What and the How is inherently unknowable in advance, where acting in the space changes the space, there cannot be a one size fits all solution. It is about exhibiting agility, being agile not doing Agile. It is first and foremost a mindset that informs every single deliberate decision and automatic reaction.
The capital ‘A’ Agile mindset leads to the Agile Industrial Complex. It leads to a number of anti-patterns, such as the imposition of practices on people and to certification schemes with questionable value. We don’t want agile for agile’s sake or DevOps for DevOps sake. This can lead to local optimisations where the expected business benefits, end to end, do not materialise.
There is a need to focus on Why are we doing this and what the desired business outcomes are. Then agile, lean, DevOps, Design Thinking and so on are bodies of knowledge, they are tools in the toolbox, to achieve those outcomes, applying what works in your unique context and continually improving through experimentation.
First, as well articulated by Simon Sinek, start with why. There should be a clear and well communicated Why for the organisation of the need to change ways of working, why constant improvement is needed, with nuanced context-sensitive and relevant definitions of why for the any sub-organisations within the parent organisation which may have their own cultural norms, history, folklore and legacy ways of working.
The ‘why’ should be more than profitability, shareholder returns or stock price. As per the article ‘The Irrational Side of Change Management’
Research shows that when employees are asked what motivates them the most in their work they are equally split across five forms of impact: (1) society (2) customer (3) company (4) team (5) the individual.
“What the leader cares about (and typically bases at least 80 percent of his or her message to others on) does not tap into roughly 80 percent of the workforce’s primary motivators for putting extra energy into the change program.”
Teal organisations, the most evolved, are driven by a higher level purpose. This is echoed in ‘Drive’ by Dan Pink, where people are motivated by a transcendent purpose. Ensure that the definition of why has a higher level purpose and covers society, customers, company, team and the individual.
From there, identify high level, thematic desired outcomes. Start with what does awesome look like, what is the current reality and what are the obstacles. Next, derive, prioritise and theme outcomes which get you to your state of awesomeness.
For us, our desired outcomes are described as Better Value Sooner Safer Happier, each of which is measurable.
Value => context specific unique measures per quarterly Business Outcome (e.g. customer Net Promoter Score increased 10 points, reduced carbon usage by 10%, increased gender diversity by 15%, increased lending to small and medium firms by £100m, reduced Risk Weighted Assets held on balance sheet by 20%, etc.)
Sooner => Flow => Lead Time, Release Cadence, Flow Efficiency. Be wary of becoming a feature factory. Reduce Lead Time and spend more time with the end users, refactoring and innovating.
Safer => GRC Control Compliance (e.g. InfoSec, Know-Your-Client, Data Privacy, GDPR type mandatory requirements). Speed & Control. Agile not fragile.
Ultimately, it is all about Flow. This needs balancing measures, as anything can be done badly, so that it is not Flow at the expense of quality, happiness, safety or value.
On a regular cadence, a one pager is sent to senior leaders with measures for the above, including vector measures, the rate of improvement. Everyone can see everyone else’s data. In addition, a real time dashboard with drill down is available.
The scope is the whole organisation, to enable business agility. It is Incremental and Disruptive, Exploit and Explore. It is equally aiming to delight customers in existing markets and to delight new customers in new markets.
Then, for the reasons above, rather than doing a capital ‘A’, capital ‘T’, Agile Transformation for the sake of agile and framing it as such, and commence the rollout of a set of prescriptive practices or a prescriptive framework, frame the change around the Why and around the improvement in the identified Outcomes.
This appeals to intrinsic motivation, it is asking people to bring their brain to work, to understand and internalise the mission, and in an empowered manner to take personal ownership for working out how to achieve the desired outcomes. Agile principles and practices, Lean, DevOps, Systems Thinking, Design Thinking and so on are tools in the toolbox, and are supported with training, coaching and psychological safety in a context sensitive, not one-size-fits-all, pull-based not push-based manner.
*this has been slightly adapted from the original tweet to represent the current Business Agility narrativeAs organizations adapt to the ongoing COVID-19 crisis, their agile teams can be a real source of competitive advantage. Such teams are typically well suited to periods of disruption, given their ability to adapt to fast-changing business priorities, disruptive technology, and digitization.
But the abrupt shift to remote working in response to the coronavirus has challenged the typical approach to managing agile teams. Traditionally, such teams thrive when team members are co-located, with close-knit groups all working in the same place. Co-location allows frequent in-person contact, quickly builds trust, simplifies problem solving, encourages instant communication, and enables fast-paced decision making. And while we know from experience that agile teams that have worked remotely from the start can be as effective, the sudden transition of co-located teams to a fully remote approach can reduce cohesion and increase inefficiency (Exhibit 1).
Exhibit 1 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
The good news is that while it takes real work, much of what leads agile teams to lose productivity when they go remote can be addressed. In fact, if the necessary technology is in place, a talented remote team can deliver just as much value as co-located teams. Assuming a firm’s IT function will handle the organization’s technology, we’ll focus here on the kinds of targeted actions agile leaders can take to sustain their people and culture and recalibrate their processes.
Remote work for agile teams requires a considerable shift in work culture. Without the seamless access to colleagues afforded by frequent, in-person team events, meals, and coffee chats, it can be harder to sustain the kind of camaraderie, community, and trust that comes more easily to co-located teams. It also takes more purposeful effort to create a unified one-team experience, encourage bonding among existing team members, or onboard new ones, or even to track and develop the very spontaneous ideas and innovation that makes agile so powerful to begin with. And these challenges are complicated by the unique circumstances of the current health crisis. Teams working from their living rooms or their dining-room tables are often sharing that space with children or other family members also working remotely.
Teams already operating remotely before the crisis are less likely to struggle, given their ability to handle ambiguity without losing focus and to concentrate on outcomes over processes. But many teams that just switched to a remote way of working are facing new challenges, which may require revisiting team norms, cultivating morale, and adapting a team’s approach to coaching.
Virtual whiteboards, instant chat, and videoconferencing tools can be a boon to collaborative exercises and usually promote participation. But they can also require teams to reconsider existing norms and agreed-upon ground rules.
Some challenges may require team members to adjust to the tools themselves: team members should be generous with one another in offering practical support on navigating virtual tools—such as help formatting or recording presentations or informing the host about any technology issues. Teams need to get up to speed quickly on visual management and virtual whiteboarding and tailor established ceremonies into standard virtual routines. New ground rules for communication may be needed to keep people who are interacting virtually from talking over one another. For example, something as simple as asking each speaker to “pass the ball” by calling out the next presenter by name can help.
Other team norms may also need to be revisited—and revised. On an agile team, everyone needs to take responsibility for capturing spontaneous ideas and putting up blockers to avoid losing them. When using virtual whiteboards, for example, teams need to make extra effort to capture the collective view, especially in larger remote teams. That will help avoid ambiguity and confusion in individual priorities. Similarly, when brainstorming in person, it’s easy to organize and reorganize sticky notes in columns on a whiteboard. That’s not always something that’s easy to replicate using virtual-collaboration tools.
And while teams should put a premium on personal productivity and allow time for it, they may also need to make a conscious point of allowing themselves and others to have more personal interactions. For example, some teams will leave a video feed turned on for longer periods of time; this conveys visual cues that aid in coaching and collaboration and helps team members maintain a face-to-face relationship.
Importantly, teams need to be respectful of personal choices. Working from home blurs the lines between professional and personal lives. Team members may feel added stress about the impression they create on video, whether because of the appearance of their home workspace, interruptions from young children, or even family members sharing the same workspace. Teams should accept these limitations and interruptions graciously—and team members should feel free to set their own boundaries around scheduling and use of video.
Many of the kinds of activities that nurture morale for co-located agile teams—such as casual lunches, impromptu coffee breaks, or after-work social activities—are not possible in a virtual environment. Team members should encourage one another to introduce their pets and family members and to show any meaningful items in their working space. Working remotely, teams need to make a more conscious effort to be social, polite, precise, and tactful—to ensure everyone feels just as safe contributing remotely as they did in person.
For many teams working remotely, some approaches to cohesion and comradery have grown quickly familiar. At one bank in the United States, for example, one agile team established virtual happy hours. Squad members join a videoconference call for a half-hour every week, sharing the beverage of their choice and talking about whatever comes up—other than work. Another team uses a website that generates quick and easy surveys. A designated team member (usually one appointed by the scrum master) sets up each poll with trivia questions to test team members’ knowledge of one another. The whole activity takes under ten minutes, is easy to do, and winners get bragging rights. These activities might sound silly, but they’re also fun—and a useful way of supporting morale and shaping a shared experience virtually.
Agile teams working remotely may also require a more deliberative focus on empathy, openness, respect, and courage. For example, team members may need to remind themselves to create and receive communications with a collaborative mindset and always to assume the best possible motivation from their colleagues. This practice is important to agile teams in general but to remote agile teams in particular, given how easily electronic communications can be misunderstood. For example, an agile team at one retail company has an explicit agreement that team members will always assume that the contributions of others are made with positive intent. Especially in written interactions and brief chat messages, the agreement observes that a comment that may seem appropriate to one team might not seem so to another. Assuming positive intent can create a safe space for team members to play a role as custodians of the culture, flagging such comments and negotiating new rules for collaborating. The person who flags an inappropriate comment can bring it up with the person who made it directly or with the scrum master to resolve it. Or if needed, a small group could stay on the line after a stand-up meeting to discuss. To ensure that team members feel psychologically safe to voice their concerns, one US insurance company conducts an anonymous biweekly survey to solicit input. Tribe leaders and scrum masters use the survey to take the team’s pulse—for example, on whether they’re feeling overworked, how motivated they are, how many things they are being pulled into each day, whether and how processes are working, and what professional-development concerns they might have. The scrum masters and tribe leaders then agree on a benchmark goal and identify a list of two or three tangible actions to take over the coming weeks to improve—which might include visible teamwide actions or more personal one-on-one conversations. All of these are good practices even in a co-located setting, but they become even more critical in a remote setting.
With coaching, agile teams should aspire to model remotely everything they would have done in person—but more frequently, given the abruptness of the switch to remote format. If you would do one-on-one coaching over coffee, try doing it remotely—while actually having coffee over video. Encourage all team members to turn on their video and actively monitor body language during group meetings, especially those in the role of coach.
At one US insurance company, for example, coaches observed meetings while scrum masters led them. Then the two got together afterward to compare notes, and the scrum master followed up with team members individually. Coaches also increased the frequency of feedback—with a regular cadence that included a short meeting every day or every other day. Some even kept a chat window open during ceremonies, to give people they were coaching real-time feedback. Coaches would also host open meetings, so that team members had an informal forum to seek impromptu support on an as-needed basis.
The challenge for remote agile teams is that they’ll be tempted to try to replicate exactly whatever has worked for them in a co-located setting. But what worked in the office setting won’t always work remotely—or isn’t always necessary. The trick is to work backward—start with the outcomes you were getting in the office and modify your scrum ceremonies as appropriate (Exhibit 2). It’s all about adapting to the situation rather than sticking to a guide.
Exhibit 2 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Consider breakouts, for example. Group meetings that use certain video-chat forums can allow large groups to break up into smaller ones for discussion, just as they’d do in person. At one US insurance firm, agile team members joining the virtual group late sometimes found themselves in an empty chat room because everyone else was in a breakout. Their teams were taking more time than they took during in-person meetings to cover the same ground. And they would often return to the general group without having assigned a spokesperson. In person, they’d have had a host or group of hosts going back and forth to different breakouts to check progress, direct latecomers to the right room, and then call everyone back to the main room. They soon realized that in a virtual meeting, they’d need someone performing those same logistical functions. Teams may need to adapt their norms to let individual team members jump in as support, which isn’t possible in a live setting.
Remote work may also require new ceremonies. For example, keeping teams aligned with organizational objectives can be even more challenging. This is easier for teams working together in person, where they can lean more heavily on organic interactions. But working remotely requires more purposeful and structured communication. To navigate that, agile teams at one company adopted biweekly division-wide meetings to identify and agree on objectives for the following weeks.
As performance stabilizes and teams grow more comfortable with working remotely, they may eventually be able to trim down the ceremonies and make them more organic. When an agile team at one insurance company first transitioned to remote working, team members found it necessary to double down on backlog-refinement sessions and documentation because the output of conversations was getting lost. Over time, they’re seeing more organic conversations and collaboration and are beginning to refine ceremonies so that they’re more lightweight.
Agile team processes are fairly informal when working in person, and there’s little need for capturing notes and documenting agreements. Conversations are organic and in real time. Take morning stand-up meetings, for example. This is the daily huddle that keeps teams informed, connected, and aligned—and in person it usually takes 15 minutes of discussion. Teams make decisions with everyone in the room, so there’s little need to record them.
Working remotely, teams may need to consider a different approach to documenting team discussion—producing a so-called single source of truth to memorialize agreements. This can then be kept in a single shared workspace. A remote stand-up can be more involved than an in-person one, depending on a team’s cohesiveness and its maturity. If team members don’t all participate in the event—or if there’s a risk that they’ll be distracted during the call—then it’s important to calibrate the process to the context. The right approach is likely to be team specific, depending on team maturity and existing norms. Others might find it sufficient to simply submit their notes to a shared online workspace, with a bot to collect and compile everything for the records.
Similarly, most agile teams find that the importance of keeping their backlog clean, up to date, and well documented increases when working remotely. A user story inadvertently left active would be a minor matter for a team working in the same room, because a team member could quickly confirm its status verbally. But working in a remote setting, team members might work on a story for hours before getting an alert that it should have been closed.
Asynchronous communication, such as messaging boards and chat, can be effective means to coordinate agile teams working remotely. In fact, we have already seen some teams replacing certain traditional ceremonies with asynchronous communication. For example, a team in a services institution has replaced some of the daily huddles by a dedicated messaging channel to which team members submit their updates and identify impediments to further work. This has the benefit of allowing team members to raise red flags at any point during the day, and it serves as the registry of concerns that have been raised and addressed.
Note that asynchronous communication needs to be used carefully. Teams that grow overly reliant on asynchronous channels may see team members feeling isolated, and the trust among them may suffer.
A remote-working arrangement creates new challenges to keeping agile teams motivated and avoiding burnout. Working in isolation is hard for any person, but particularly for agile teams accustomed to face-to-face communication and frequent interpersonal engagement. Multitasking and home-based distractions also take a toll, depending on how things are set up.
But approaches to keep team members engaged aren’t unique to agile teams, even if the imperative may be more acutely felt. At one US financial institution, for example, a scrum master realized that staring at a video screen for more than a couple of hours was draining without the dynamic interaction of an in-person workshop. Her solution? For longer meetings, she began to schedule in a ten- to 15-minute exercise break every 90 minutes—with a shared videoconference tool to recommend different exercises.
The core mission of leadership stays the same, whether co-located or remote. But leaders need to be more deliberate when engaging with customers and teams, especially when you have limited in-person interaction. Leaders in this context can be anyone on the team, whether product owners, scrum masters, or even a developer demonstrating leadership. Working in the same location, agile team leaders often empower teams to push work forward. Working remotely, they need to be closer to—and more proactive at—guiding their own team members.
They also need to be purposeful at engaging external customers and stakeholders. They must be transparent and reassuring in their communication about team performance and objectives. The tools and approaches can vary (Exhibit 3). But the individuals and interactions should be the main consideration. Leaders need to show, in their tone and approach, that everyone is in this together.
Exhibit 3 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
At one insurance company, for example, the product owner does five-minute individual check-ins with her team members throughout the week, asking if there’s anything she can assist with or any problems she can help trouble shoot. She’s also scheduled sessions with customers and stakeholders every week, in addition to the usual sprint ceremonies, to see if there’s anything more the team should be doing to get their feedback. Too much communication can overwhelm people working remotely with emails and instant messages. So it’s worth putting extra emphasis on making sure they feel heard without overwhelming them further.
The abrupt shift to a remote-working environment was a dramatic change that particularly affected agile teams. The hope is that these changes won’t be permanent. But for now, teams can reinforce productivity by taking a purposeful approach to sustaining an agile culture and by recalibrating processes to support agile objectives while working remotely.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.It is an exciting time to be part of HR. Right before our eyes, HR is transforming into ways of working never seen before. The 1990s are well behind us and it’s fair to say that at most enterprises HR now has a strategic role in leading the business. This is a blessing, a challenge, and the biggest opportunity to create value that HR has ever experienced. As HR has moved into the boardroom and solidified its role in the C-suite, visibility to business imperatives is much clearer for HR and the opportunity to shape those imperatives from a workforce angle is greater than ever. In return, leaders are expecting that workforce programs evolve more rapidly and drive greater, measurable value.
These new expectations drive HR leaders to look outside organizational walls, learn from other functions, and import leading practices that will enable HR to travel at the speed of business, make data-driven decisions, and deploy workforce programs that enable the business to win over the workforce and customers.
The seemingly never-ending quest continues: How do HR organizations, which are aspiring to enable their businesses and people to excel, operate? And, how do the latest insights about becoming exponential HR connect with, complement, or replace the array of practices that have come before in the forms of Lean, design thinking, strategic planning, and agile? These new expectations drive HR leaders to look outside organizational walls, learn from other functions, and import leading practices that will enable HR to travel at the speed of business, make data-driven decisions, and deploy workforce programs that enable the business to win over the workforce and customers.
Irrespective of methodologies, HR must accelerate its pace to effectively deliver on the workforce priorities at the speed of business today. This demands laser-sharp attention to delivering work outcomes that impact business imperatives. HR should architect solutions that elevate the human experience and apply advanced, digital technologies to generate insights and partner machines with humans to help generate value.1
HR leaders are drawing from the methods of lean, design thinking, strategic planning, and agile to break away from traditional operating models and achieve work outcomes in an integrated way that enable HR teams to unlock previously unrealized value when applying each method independently.
We observe HR organizations integrating methods as they work toward evolution—perhaps even revolution—of how HR operates. Although integrating methods may not be the result of an intentional effort and, instead, the blending of practices learned and borrowed over the years, the result may be to fuel an HR organization that consistently focuses on outcomes to achieve sustained results. Four key, interdependent components are coming together, as shown in the visual below:Michael leads Deloitte Consulting LLP’s Learning Consulting practice in North America. He focuses on working with global clients on building high-performance businesses that drive growth and optimization through talent and learning. Prior to joining Deloitte, Michael led the Learning Strategy business for a Big Four firm and was the head of training for a major online retailer in the UK. He has more than 20 years of experience leading key programs at market-leading clients, including running the learning and change management office for a top-tier merger in the Financial Services industry and driving learning transformation for a global brand in the food and beverage industry. Michael has presented at the Chief Learning Officer annual conference and has won learning program awards with his clients. He also lectures on learning at NYU School of Continuing Education.Few IT organizations—or enterprises—can make the leap to agile in one fell swoop. Here's how to make the journey step by step, realizing benefits at every stage.
More customer value, faster development times, greater responsiveness to market changes, better employee motivation, higher user satisfaction, and lower costs. The lure of benefits like these often motivates IT organizations to investigate agile methodologies, widely believed to be able to deliver such positive outcomes. However, transforming a traditional IT shop to an agile one is rarely easy or quick, and it can be even harder to extend the agile philosophy to functions outside IT to become a truly “agile enterprise.” Our experience shows that many agile initiatives get stuck in implementation, failing to deliver the hoped-for benefits. Why?
One big reason is often the approach to agile transformation. Many leaders adopt a mindset that envisions an orderly transition from one stable state to another, seeking to move the entire IT organization to agile in one fell swoop. However, such an approach rarely yields the desired results. Instead, we have often observed that more-successful agile initiatives break with traditional ways of thinking to begin the journey with selected parts of the IT organization. This alternative mindset accepts a certain degree of instability and uncertainty during the transition to agile, and allows ample time for the IT organization as a whole to adapt (in essence, applying agile principles to the agile transformation process itself). Once agile practices are well-established in portions of IT, they can be expanded to other teams, and eventually to other functions within the broader organization, so that the entire enterprise supports the IT organization’s efforts to operate in an agile manner.
There is no way around the observed fact that a wholesale agile transformation usually takes time. Indeed, it can take up to 10 years to go from a traditional IT organization just getting started with agile to an entire enterprise where agile ways of working are part of the culture. But that is no reason not to start. We envision a four-stage transformation process in which every step along the way can deliver benefits—and where each step can be accelerated by taking certain specific actions (figure 1). Below is our guide to cultivating agility in an organization, from small beginnings in the IT department to its adoption across the entire enterprise.
At the first stage, the traditional IT level, the predominant operating model follows a “plan-build-run” approach. This model calls for each team within IT to focus on a certain activity that it and it alone performs. The planning team defines the strategy, processes, and governance mechanisms; the build team is responsible for all change initiatives, which are conducted with waterfall methods; and the run team focuses on IT operations. Process frameworks such as ITIL are often used, defining stage gates at which the most promising initiatives are selected and given resources and budget to continue.
To introduce agile methodologies into an environment like this, leaders can identify one or more projects or groups to manage separately from the prevailing plan-build-run model. This may mean implementing agile approaches for a specific project, or it may mean identifying a relatively self-contained group within the IT organization that can adopt agile approaches without extensive detrimental impact on the rest of the organization. The idea is to seed agile within the broader IT organization, creating a nucleus of experience and know-how in agile methodologies that can later be extended to other parts of IT.
Paradoxically, one step toward preparing an IT organization for the journey toward agile can be to establish a structured operating model for a plan-build-run approach. This step can be important for IT organizations where development occurs in an unstructured, ad hoc manner, as it allows IT personnel to become accustomed to following a defined process instead of approaching each project in an idiosyncratic way.
Another important action leaders can take to help accelerate progress out of the traditional IT level is to outsource a number of projects and encourage those vendors to use agile methodologies. The organization can hand over all IT services and initiatives related to the project in an unstructured state. The outside vendor then takes over, structuring the activities and providing services by applying standardized processes, while monitoring agreed metrics and intervening if the metrics fall outside the agreed-upon ranges. By observing the vendor’s actions, the client’s staff can learn how an agile project is managed, sharpening their ability to steer the outsourcing vendor over time.
The experience of a multinational banking corporation shows how a traditional IT organization can begin moving toward agile. Under pressure from new marketplace entrants (such as fintechs) that were often more flexible, had shorter times to market, and offered more comprehensive product suites, the company decided to experiment with agile methodologies to shorten its product development cycle. It had already outsourced most of its IT projects to vendors that followed agile methods, and the positive results from these efforts supported the business case for establishing an agile delivery model in-house.
The company decided to start the transformation in its offshore center in India to keep costs down, targeting IT executives in a specific organizational unit. Cultural differences between workers from the company's headquarters in Germany and those in India presented an initial difficulty, but after both sides reached a common understanding, the change of mindset toward agile principles—as well as the motivation to act differently—took hold. The teams in India learned agile methodologies from the overseas professionals and developed effective ways to manage multicultural teams in an agile context. Currently, the company is expanding agile practices throughout its Indian IT organization with the goal of eventually applying agile methods around the world. As a first step, the organization has refined its project approval and budgeting process so that agile endeavors are being evaluated on the same basis as classical projects.
An IT department at the bimodal IT level operates in two worlds. At this stage, IT organizations frequently have several initiatives or “digital labs” that use a broad range of agile methodologies and thinking approaches such as Kanban, lean startup, design thinking, and scrum. These digital labs operate as self-contained entities aiming to develop prototypes and minimum viable products outside of the traditional IT environment. Their goal is to deliver innovative solutions that are easy to understand by customers in the business. Meanwhile, the rest of the IT organization continues to operate along plan-build-run lines.
Tension between the digital labs and the remainder of the IT organization is not uncommon at this stage. For one thing, projects started in digital labs are difficult to complete by the classical IT organization, as the timelines for planning and implementation often differ significantly. For another, the classical IT organization tends to be skeptical of the digital labs’ agile project managers, perceiving them as lacking clarity on how to reach the final goal since the agile teams’ minimum viable products are developed in increments. The funding process also differs fundamentally between the digital labs and the rest of IT. While classical projects need up-front funding for the entire project duration, agile digital labs typically compete with each other for budget, with only the most promising developments receiving funding at each project checkpoint.
One way for a bimodal IT department to progress to the next stage more quickly is to require—not just encourage—vendors to apply agile methodologies to outsourced projects. This can deliver benefits on two fronts. First, technology companies frequently have agile resources and know-how on hand, so many vendors are able to start projects very quickly. And second, the client’s IT staff can learn about the procedures and tools of an agile way of working by observing how the vendor acts.
As an example of how digital labs can help an IT organization gain comfort with agile, consider the story of a global insurance company that had created a digital lab to gain experience with agile methodologies. The digital lab had evolved to the point where it was using agile methods to develop standardized insurance products without being technologically or culturally constrained by direction from corporate headquarters. In fact, by having experts from the insurance business work with the software developers, using journey maps to gain a customer-centric perspective, and continuously reprioritizing projects based on the end product’s envisioned value to the customer, the digital labs were able to develop more-relevant products—and get them to market more quickly—than the product development initiatives driven by headquarters.
Some time after the digital lab’s establishment, leaders decided to centralize the provision of IT services for all of the company’s products, hoping to take advantage of synergies with current and previously developed software products to reduce asset development costs. Encouraged by its positive experience with the digital lab, IT embarked on an ambitious agile transformation, establishing multiple cross-functional scrum teams in multiple delivery locations. A strong change management program enabled the scrum teams to spool up on a steady and gradual basis regardless of location.
The company intended to use the scrum teams to not only develop standardized products, but to apply agile methodologies to quickly consider and implement local requirements (for instance, to comply with specific countries’ regulations) into those products. The effort was successful. To date, the scrum teams have been able to produce more than 12 digital assets, which are live in eight countries.
The third stage, agile IT, is characterized by increased collaboration among groups and a prevailing mindset that focuses on outcomes over predefined outputs and deliverables. Typically, this stage is catalyzed by leaders who have seen the benefits of the digital labs’ agile operations in the bimodal IT phase and now want to extend those benefits to the entire IT organization. Although the biggest shift in this transition is cultural, there is also an organizational impact: Whereas a traditional IT organization organizes by process—putting together teams from multiple groups focused on completing specific tasks—an agile IT organization organizes around the product, integrating all team members into a single group striving to achieve the same outcome. The product they are working on, in essence, becomes the organizational entity to which these workers belong.
Operating as a product organization can enable the formation of stable, self-organizing, cross-functional teams across the IT organization that can be up to 400 percent more efficient than traditional IT project teams.1 Such product teams adopt an agile mindset and culture, and are thereby able to take over further development of any minimum viable products that a digital lab may produce.
Another common strength of a product-focused organization is that, as it becomes more mature, it is increasingly able to use a variety of different frameworks, such as SAFe and DevOps, that focus on different aspects of agility while still maintaining a common agile culture. The impetus for variety typically comes from the realization that a single framework cannot fit all situations equally well, and that teams could be more effective if allowed to pursue their method of choice as long as they commit to following agile values and principles. Hence, teams can use different methods, including scrum, Kanban, or even waterfall, without sacrificing the adaptability and focus on outcomes that are hallmarks of agile. (See figure 2 for a guide to deciding what kind of approach may be preferable in different situations.)
To accelerate progress to the next stage, organizations can deploy transformation teams organized in communities of practice to share knowledge and lessons learned among the IT organization’s various development teams. The use of a minimum viable design approach, in which the most basic changes are implemented first, can help to reduce the transformation teams’ need to reinvent the wheel for each new group they work with. At the same time, the transformation team should be allowed the freedom to calibrate the speed of agility adoption to each group’s needs. We recommend taking a “minimum viable change” approach in which change progresses by making small, frequent adjustments rather than all at once. This can help the transformation team quickly test its approach with each new group with which it works, and speeds up the delivery of value for the larger organization due to the small but frequent increments of change.
One multinational telecommunications company that had historically relied on classical development approaches for its core systems wished to adopt agile approaches—both within the IT organization and across the broader business—to become more responsive to the marketplace. Since the company’s mission revolves around the technology-enabled dissemination of information, it had the advantages of both an advanced technical infrastructure and a culture that was supportive of innovative business solutions. At this company, the IT organization had reached the point where it was organized around products—but the business was still split into the familiar departmental silos of finance, procurement, marketing, and so on. The company sought to extend the adoption of agile principles across these silos by promoting collaboration between business and IT. Customer journey maps—which depict a customer’s interactions with the organization, along with the related internal processes and information systems, from the customer’s own perspective—and value streams—which show the multiple customer journeys that can lead to a given outcome—were extensively used to drive collaboration. These journey maps allowed personnel in different functions to understand, for the first time, how customers interacted with the organization’s technology at various points in their experience, which helped engage functional representatives in proposing and testing improvements.
Other changes also supported the business’s shift to agile ways of working. From a financial perspective, the company went from project-based funding to an incremental approach that allowed it to provide seed funding for developing minimum viable products. In terms of leadership, executives were coached to accept failure as an option, while remaining cognizant of the need to halt unsuccessful efforts. Finally, from a technology architecture standpoint, the company was able to allow classical methodologies (primarily waterfall) to seamlessly coexist with agile methodologies by eliminating “technical debt” and ensuring that the organization’s long-term vision was reflected in the data model.
The fourth and final stage in the progression to agile is the agile enterprise stage. At this level, all stakeholders work closely with each other to increase the alignment between technology products and customer requirements. To increase collaboration, organizations create end-to-end teams that cut across functions. Further, the concept of the customer has evolved. All parties orient themselves toward serving the end customer—those who buy the company’s products or services—instead of considering the customer to be the internal business units or functions that use IT products.2 Endeavors are funded incrementally in stages rather than contractually via a fixed project budget. (In an environment with stage-based funding, a project team must continuously apply for the next round of funding, with approval contingent on delivering the desired results.3 In this way, funding is directed to the most promising intermediate products rather than to a predetermined but possibly suboptimal final deliverable.) From an HR perspective, performance management also reflects an agile way of working, with workers’ performance being measured on multiple agile endeavors rather than against the outcome of a single project.4
It can be helpful, to ease the non-IT functions’ transition to agile ways of working, to develop templates or blueprints that give examples of how they can support agile approaches. For example, the finance department can be given an off-the-shelf model for incremental funding. In this way, the functions can more quickly and easily implement the changes they need to adopt to support IT’s use of agile methodologies.
That it may take years to move through one stage to the next should not necessarily be a cause for concern. Every stage in the journey to an agile enterprise can yield benefits, although the advantages (and limitations) can differ from stage to stage (figure 3).
An important point, too, is that many different methodologies can coexist in an agile enterprise—as long as all teams commit to a joint culture based on the agile values and principles defined in the agile manifesto:5
Becoming agile on an enterprise level is a long journey that, for many organizations, is most feasible to accomplish in a stepwise fashion. Starting the journey toward agility often requires leaders to accept that the IT organization will likely experience some instability and conflict during the first two stages, when pockets of agile activity are still surrounded by traditional development culture and processes. Although each of the steps toward enterprise agility has certain limitations, each also delivers worthwhile benefits. The ultimate payoff: the potential for gaining a competitive edge through agile methods that allow companies to be more responsive to and aligned with customer demands.Belkis is one of the pioneers of agile thinking at McKinsey. With over 18 years of experience in delivering robust solutions and coaching teams, she is wholly focused on agile transformation.
An expert in agile transformation, Belkis partners with leaders in banking, healthcare, and other sectors to engender productivity and launch innovative products. Her primary mission—which has her across North America and to Europe, India, Latin America, and South Africa —entails helping large companies innovate with the agility of small start-ups.
Belkis is an experienced agile coach and practitioner with deep knowledge in building truly agile organizations across an assortment of sectors. She is an active leader in the external agile community, as well as a board member and leader of the Agile New York City meet-up, which convenes a group of 100 agile leaders in the city every month. Using the agile methodology as a starting point, she expands its impact dramatically, guiding at-scale transformations, pursuing digital strategy development, and leading end-to-end digitization initiatives. In this, she is passionate about guiding teams out of their comfort zones so they can make a transformative leap.
During her 16 years with McKinsey, Belkis has coached executives while leading major change programs. For global banks, she has worked to minimize technological risk and increase productivity through improved engineering practices—her efforts accelerated product launch time by 60 percent for a leading bank in Brazil. She has also designed centers of excellence focused on agile product management; one program for a healthcare company improved efficiency by aligning the organization around product lines.
Belkis speaks internationally at workshops and on panels, sharing insights on such concepts as talent recruitment for agile professionals, digital industry trends, and the guidance of high-performance teams.
Before joining McKinsey, Belkis led the upgrade of mission-critical enterprise systems at the New York Stock Exchange and held leadership roles with the New York City Law Department and Brooks Brothers.Our recommendation is for any large organisation in this situation, or for organisations scaling their approach beyond the team to the portfolio/program or enterprise, that the ‘right’ balance of both agile mindset and agile frameworks is best to enable success. Large organisations typically need to consider how do they evolve and do this while not putting their existing ways of working, such as legal, compliance and shareholder commitments at risk.
In this blog post, we will cover off how you can leverage both the agile mindset and principles to enable the ‘heart’ of agile, which supports the underlying culture change required to drive different behaviours, as well as, leveraging the agile frameworks to enable and support that change with ‘hard’ structure to provide a ‘freedom within a frame.’
The quest and driver to achieve enterprise agility may commence in many ways across different organisations and teams. For example, the driver may be to improve delivery speed and efficiency to deliver faster to catch up or out-pace competitors. Or the driver may be to better understand customers to meet their needs and to ensure a customer-centric focus. Or it may be a combination of both. Either way, an agile evolution and journey has begun and questions on ‘where do we start?,’ ‘what choices do we need to make – now and later?,’ and ‘how do we actually do this’ begin. The agile manifesto provides a set of values and core principles, which many of us would not disagree with and would accept as common sense. But how do you convert those values and principles into action?
At regular intervals, the team reflects on how to become more effective, then tunes and adjusts its behaviour accordingly.
There are techniques and practises provided within Agile frameworks that can be leveraged. Examples include retrospectives and prioritisation methods, which are a good starting point to enable adopting these principles. The key is to understand what others have done before to not only save time (maximise the amount of work not done) and so we can improve, do better, and apply to our context (tune and adjust).
As an organisation undertakes the journey to agility, it makes sense to take advantage of what has already been learnt by other organisations and broader industry expertise. Agile frameworks are evolving and being tuned based on the practical execution experience from a wide base of organisations.
Further examples of challenges faced by organisations which can be solved by taking guidance and leveraging some of the many agile frameworks are:Much has been written over the years about parallels between the military and large corporations. But what insights are most relevant for senior executives today in an age of agile organizations? With his long experience in the Army and then in business, Justin Maciejewski is unusually well placed to reflect on the lessons for business, as a former commander of the British Army’s 800-strong 2nd Battalion, The Rifles, during its vital peacekeeping mission in Basra, Iraq, from 2007 to 2008.
Sidebar Justin Maciejewski biography Justin Maciejewski has been the director of the National Army Museum, in London, since 2018. He spent 27 years with the British Army, including serving as commander of the 2nd Battalion, The Rifles, during its vital peacekeeping mission in Basra, Iraq. He subsequently brought his leadership experience to the commercial sector as a management consultant with McKinsey.
Maciejewski’s career in the army spanned more than a quarter of a century, taking in the years after the Falklands War, in 1982, to recent operations alongside coalition forces in Afghanistan, the Balkans, and the Middle East. It was a time that coincided with the development of a new type of leadership based on empowerment, designed to make the British Army more tactically agile and able to overcome larger adversaries through maneuvers, rapid planning, and decision making that disrupt and break down the enemy’s cohesion. This has transformed the British Army’s approach, which for generations had been based on centrally controlled, set piece battles focused on overwhelming firepower and attrition. Awarded the Distinguished Service Order for his role in Iraq, Maciejewski joined McKinsey in 2013 and was appointed director general of the National Army Museum in London in 2018.
In this conversation with McKinsey’s Rob Theunissen, Maciejewski talks about the modern army’s agile model, the balance between command and control, the importance of (good) process, and the notion of learning without blaming.
Justin Maciejewski: In the Second World War, the British Army achieved success by focusing a huge amount of resources on a smaller enemy force, then wearing them down through attrition. Battles were often very static, relying on numerical superiority. The battles were designed top down; everyone knew their place. Montgomery, the great British commander of the Second World War, called this “a tidy battlefield,” and he referred to it as the orchestra of war: one conductor conducting, with all the different instruments doing exactly what they are told to do.
As the British Army got smaller in the 1960s and ’70s, it found itself at a numerical disadvantage relative to the forces it was facing in the Cold War. Nevertheless, this culture of top-down direction continued. And in the Falklands, the British Army found that soldiers were waiting to be told exactly what to do in circumstances where casualties might have been avoided had they been more proactive. At the end of that war, people asked themselves, “Why did intelligent people sit there, waiting to be told what to do? Why didn’t they just get on and do it?”
In the late 1980s, the British Army radically redesigned the way decisions were made and how officers were empowered. A new system was introduced: Mission Command, which would now be called agile, was all about giving people the tools to make rapid decisions in order to disrupt the enemy.
In reflecting on our performance in the Falklands War, in the late 1980s, the British Army radically redesigned the way decisions were made and how officers were empowered. A new system was introduced: Mission Command, which would now be called agile, was all about giving people the tools to make rapid decisions in order to disrupt the enemy. The idea was that you could defeat a larger enemy by getting inside their decision cycle, moving so quickly that their cohesion is disrupted and they begin to fall apart.
Justin Maciejewski: In Montgomery’s army, the functions—artillery, engineers, logistics, medical, intelligence, signals, et cetera—were very powerful. In the 1980s, led by General Nigel Bagnall, the notion of integrating the functions at every level took hold. Every group was tailored for the operation that it was required to do, and functions were integrated in the volumes that were needed for that operation.
That sounds easy, but it’s difficult to do. And in order for that to happen, the army had to be much more standardized about the way it planned, the way it gave direction, and the way it cascaded intent. If you’re going to be very modular and agile about the way you allocate resources, people need to be speaking the same language.
Mission planning lies at the heart of military operations, and the army came up with seven questions, which everyone now uses across the entire organization. Once you standardize like that, you create organizations in which people feel confident to make decisions and where trust grows because people know what other people are going to do even before they come up with an idea.
The Quarterly: Standardization can feel rigid and bureaucratic—it almost sounds paradoxical alongside agility. Was that not limiting?
Justin Maciejewski: The trick is to work out what process is good and fundamental to the stable functioning of an organization—and to its consistency—and what process is bureaucratic and superfluous. Don’t throw out the good stuff when you get rid of the bad stuff; organizations that have been fossilized by bad processes sometimes try to get rid of it all.
What the army managed to do in the 1990s was to get rid of a lot of bad processes but design these very solid core processes, which everyone was able to rally around. I never saw them as constraining; I rather saw them like a trellis where a plant grows up an open frame. The effort to root out bad processes was considerable and involved significantly reducing the number of operating procedures to encompass only those activities that genuinely needed to be standardized.
For me, a good process is a process that helps someone see how to think, how to find a solution, but it doesn’t tell them what to do. It doesn’t tell them the exact answer. In other words, it’s not a tick box. It’s a framework that lets people bring themselves to the problem in a way that they know they’re not going to miss anything. It’s a support—but a support that gives them the chance to be creative.
The Quarterly: Could you describe in more detail how structure, process, and creativity work together?
Justin Maciejewski: In the old world, leaders wrote down what they wanted people to do in quite a precise way. People were given tasks that fit within an overall operation or mission. A mission today is not a set of tasks, because, in a dynamic situation, people should revert to the purpose rather than the task. Situations change; the enemy’s done something. That’s my purpose—that’s what I’m going to go after—rather than in the old system, where people would literally do their task and wait to be told what to do next.
For example, in the old world, you could say to someone, “Take and hold the bridge by midnight tonight.” In the new world, you would say, “Our intention is to cross that river. To do that, I see you securing that bridge by midnight tonight. And the reason we want you to do that is because we want to put 20,000 soldiers on the far side of that river by the close of day tomorrow.”
If you imagine that philosophy being replicated across an organization of 80,000 people at every level, it dramatically changes the performance. Everyone at every level is thinking, “What if it changes? How do I respond?”
In a business environment, people often express annual targets as percentages of growth or the amount of cost they have to take out without any real articulation of how that feeds into the overall success of the business. [What they should be saying is,] “We need you to take out this much cost because we want to put that into the R&D program for the next model that’s going to win us a new market.” It’s very disempowering to have targets without any real context of how that target fits into the bigger picture.
Justin Maciejewski: I grew up during this transformation, but I think it was a lot tougher for some of the people who’d grown up in the old army. One thing you have to be prepared to do as a leader is to give people space to fail, to let people spread their wings as leaders, and to trust them. Occasionally, they’ll get it wrong. And, when they get it wrong, you mustn’t crucify them. Because if you do, they won’t do it again, and then you have to micromanage them because there’s no other option. Watching people grow as leaders, by tripping over the first time and then getting up and dusting themselves down, is most fulfilling. As new leaders gain more experience, you can supervise less.
Leaders also need to understand that there is a tension between command and control. A commander may want to do something, but it may be impossible, and that’s where command has to be constrained by control. And there are other times when the commander knows something can be done and has to be done, and sometimes the machine needs to work a little bit harder to make it happen, and that’s where command pushes control. They are both critical to success, and that distinction between command and control is something I really came to value.
Justin Maciejewski: Once the army moved to Mission Command, much more of leaders’ time was spent up front in the creative process: “What am I trying to achieve? How do I visualize this happening? What is my mission? What am I being asked to do?” It’s about making sure everyone is clear around what’s expected of them. This gives commanders much more time away from their laptops and more time with the people they are commanding. I like to think we were all frontline people.
When we first got to Basra, we had an operations room—a control tower—that had all the screens with satellites and aircraft photography coming down and data flowing in from people on the ground on their radios. It was a huge hub of information. What I actually found was, I may have had all the data, but what I didn’t have was the fingertip feel of what was actually happening on the ground.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com Justin Maciejewski (right) sitting with a fellow soldier in the back of Maciejewski’s command vehicle in Basra, Iraq, in 2007.
Over time, I came to realize that the data was not the most important thing for me to see on any given day. I would get a much better feel for the operation by seeing the “customers”—the people on the streets—and the soldiers themselves who were doing the job. I would spend two-thirds, maybe three-quarters, of my time with soldiers at the front line, either talking to them or listening to them after an operation. I spent a quarter of my time planning.
That’s where the chief of staff in the army really kicks in. In business, the chief of staff is someone who organizes the CEO’s diary. The chief of staff in the army is an incredibly powerful figure and is literally the chief of the machine. My chief of staff bought me the time to be with the soldiers, talk to my Iraqi colleagues, or meet local leaders in Basra. The chief of staff also was able to triage the data and feed to me what I needed: “Be aware that this is happening.” A key thing [in the army] is that the system selects the chief of staff to work with the commander. When I look back now, I really appreciate how much effort went in to selecting the right chiefs of staff to work with the right commanders.
How you allocate your time, though, is only part of it. The army also invests a lot of time in training leaders to manage the mental and emotional states of the troops.
Justin Maciejewski: When a leader shows up in the army, the soldiers immediately worry that they’re under scrutiny, that they’re being evaluated. That imposes an additional burden. So when I started in Basra, my assumption was to let the guys lead. They’ve got the enemy to worry about, and they’ve got the local population to worry about, but if you show up, they’ve got their leader to worry about as well. When a leader shows up in the right way, it’s a source of encouragement; it shows you also have skin in the game on any particular day. When the bullets are flying around, it makes the point that we’re all in this together.
One day, we had a mortar attack, and a lot of guys were badly injured on the other side of the city. The day before, someone had been killed by an improvised explosive device, and someone had lost one of their legs. So we got into our vehicles, and we drove across the city to spend the afternoon with this company and see how they—a company of about a hundred people—were getting on. I just went up there, had a cup of tea, put my arm around a few people.
One thing you have to be prepared to do as a leader is to give people space to fail, to let people spread their wings as leaders, and to trust them. Occasionally, they’ll get it wrong. And, when they get it wrong, you mustn’t crucify them. Because if you do, they won’t do it again, and then you have to micromanage them because there’s no other option.
The fact that we made the effort to get up there after this attack, in the same sort of vehicles that they’d been attacked in, meant a huge amount to the guys. I came to realize that showing vulnerability and presence as a leader becomes a very important way of galvanizing everyone around a particular mission. I wouldn’t go on a mission with a leader because I was worried about that leader, but because I wanted to show that leader that I was right next to him. And that mind-set change was the most profound for me personally as a leader: seeing yourself not as an evaluator but as a supporter of the people who work for you.
Justin Maciejewski: For a meeting somewhere with, say, a tribal leader or local power broker, I would turn up with my entire panoply of drivers, communicators, and bodyguards—we call it the “commander’s tac,” maybe as many as 15 people—and there might be a jet in the air over the area. That’s saying you’re the biggest tribal chief in the area.
The vulnerable bit is when you go to a group of soldiers who are being led by somebody and say, “I would like to come out with you tomorrow.” And you don’t try and command it; you just try and be with them, to walk in their shoes. The night shift, for me, was the place where you got the best conversations, turning up in a guard tower at two in the morning and saying to a young soldier, “How are you feeling?” And they’d be honest. They’d say, “I’m scared.” One could then talk about things that we were all concerned about and how we were going to tackle them.
I’m always struck by Henry V in Shakespeare, when he goes out and walks around. That is a very profound insight of good leadership. It’s in the night, when it’s quiet or when people have got their thoughts, that you can gently get alongside them.
I think the king is but a man, as I am [. . .]. When he sees reason of fears, as we do, his fears, out of doubt, be of the same relish as ours are: yet, in reason, no man should possess him with any appearance of fear, lest he, by showing it, should dishearten his army.
Justin Maciejewski: My team was built by my predecessors: years of investment in developing the right talent and pushing it forward. So my regimental sergeant major had spent 20 years in the army, but he’d been recognized 15 or 16 years previously and had been pushed through the system to be ready when I needed him. I didn’t find him through advertising a job.
When I looked at this group of 800 people, I could see the sort of institutional investment in talent over at least 20 years—but, in reality, over generations. And it made me realize just how good the army is at getting and developing the right people. I had to remove a few people when I was there, but not many—a handful in an organization of 800—while everyone else stepped up and did what was required of them.
Talent selection is crucial, and being rigorous about it is important. I haven’t come across many organizations [in business] where talent selection is really rigorous. Often, it’s based on a good year’s performance, then you leap forward into the next job rather than really understanding what potential looks like versus performance. It could be that someone’s doing something they’re not actually ideally suited for, but, by God, they’ll be good for the next level. I think business is too quick to bring in talent rather than develop it internally. Endlessly looking outside creates a very transactional approach to people.
Justin Maciejewski: People have got to complement each other. So if you have an extrovert leader who may not be very good on detail, you need to make sure they’ve got a second in command who’s bloody good at it. You mustn’t let people pick their own teams, because what you then create is an inner circle. I’ve seen this in other armies, where commanders were allowed to move with their inner circle. And when you have an inner circle around the boss, you just create a sense of disempowerment for everyone who’s not in the magic circle of power. That creates a very fractious—and, ultimately, toxic—organization. In business, I often saw an outer circle of people who were feeling very scared and vulnerable, and I don’t think that’s the way to drive successful teams.
The Quarterly: Let’s talk about the performance dialogue, where the backbone of a culture and an organization’s true beliefs always pop out.
Justin Maciejewski: [In the army,] there’s a very mature initial conversation between the person giving the mission and the person receiving the mission around how they’re going to achieve that mission. Then there’d be a dialogue around the concerns. There’s literally a piece of paper with four headings on it, and one of the headings is “concerns,” so you can’t say, “I’ve got no concerns.” That would feel a bit weird. So it takes the fear out of alignment with your boss.
You mustn’t let people pick their own teams, because what you then create is an inner circle. And when you have an inner circle around the boss, you just create a sense of disempowerment for everyone who’s not in the magic circle of power.
At the end of the operation, there’s what we call an “after-action review,” where you review performance of that operation. And the key thing about this is that it’s facilitated by an outsider, not by the person commanding the mission but by someone who’s not directly involved in the operation—for example, someone from the intelligence staff. Generally speaking, the commander comes to that process at the end and says, “That’s really interesting. These are my thoughts, reflections. And what have we learned from this?” And then someone captures what we need to learn from it, and then that gets fed into a review of how we do an operation in the future.
When a mistake is made, you do not hang someone out to dry. Sometimes mistakes are made in battle and people get killed. If you crucify people when a mistake is made in battle, they will freeze with fear the next time they’re facing the enemy, and the consequences of that are far worse. The notion of learning without blaming is at the heart of removing fear from that process.
One thing people realize in this sort of environment is that no one is without fault. No one is invulnerable to making mistakes, because the pressures are huge. People are slow to judge because they know that tomorrow it could be them. When a mistake is made, you know it could be you. I’ve been really shocked by how much fear is used as a motivator in business—in a way that I never saw it used as a motivator in the army. People are very much in a state of fear, not because they’re being shot at, but because there’s an internal fear working in terms of how people are being evaluated and watched all the time.
Justin Maciejewski: I’ve always been struck since I left the army that the army doesn’t have just values; it has values and standards. And the reason is because it wants to help people understand what those values look like in action. So courage is a value; having the moral courage to call out something when it’s wrong is the standard.
I saw this with a young soldier who came to me and said, “Sir, my commander behaved badly in a house last night in Basra. He smashed up some furniture in a search, and it was wrong, sir.” That young soldier had the moral courage to do that.
We would spend 15 or 20 minutes, perhaps half an hour, a week talking about the army’s values—courage, loyalty, discipline—and what they actually meant. Values can be a hugely powerful thing when they’re shared across an organization, but you’ve got to invest in them. You can’t just put them on a notice board or up in an office and have that be the end of the job. In business, I think, we’re still in the foothills of how we use values in the most effective way to create healthy organizations and drive performance.
I would never call my soldiers a ‘human resource.’ They were the soldiers, the battalion, the riflemen. The term ‘human resources’ dehumanizes people.
The Quarterly: What have you observed about the way organizations in the corporate sector look at people?
Justin Maciejewski: One thing is that I would never call my soldiers a “human resource.” They were the soldiers, the battalion, the riflemen. The term “human resources” dehumanizes people.
The army is very mindful of its people because it can’t hire them in at any level. You can’t hire in someone to be a great general on the battlefield on day one. It has to nurture, invest in, and grow talent. Specialists can come in, but the core manpower has to be grown from within; the army does not use headhunters.
A lot of industry and business relies on the fact that it can just hire and fire people, so it becomes a hire-and-fire machine rather than a coaching-and-building machine. And I think that you can hire and fire your way to a certain level of performance, but by doing that, you will never build genuine teamwork and cohesion. The new approach to becoming agile in business is based on building small, tight-knit squads. That requires trust, and trust takes time. You’ve got to bind people to the idea and the purpose and, if you like, the essence of the company you’re building or the business you’re running. You’re never going to get people to go the extra mile if, fundamentally, it’s a transactional relationship.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.Since their origin in software development, Agile processes have been successfully employed in countless initiatives and within a wide variety of business settings.
Building on the original Agile approach, Deloitte’s Agile Internal Audit (Agile IA) methodology challenges both the mindset of internal auditors and their established business processes. It allows the internal audit function to focus on stakeholder needs, accelerate audit cycles, drive timely insights, reduce wasted effort, and generate less documentation.
Of course, Agile methods have only recently been implemented by internal audit departments, prompting questions about whether it is possible to adopt Agile in Internal Audit while remaining true to the IIA Standards. Additional questions about which methodologies to adopt, as well as how to customize and implement them and how Agile projects themselves should be addressed, also invariably arise.
Our Agile IA library gives you the opportunity to explore the basics of Agile IA; their compatibility with IIA Standards; and how to best adopt them to drive efficiency, efficacy, and innovation in your organization and beyond.Demand management is focused on receiving, evaluating, and deciding upon work requests. This is accomplished with prescribed points of entry for new requests, and qualifiers to prioritize them. Agile introduces two key concepts that enhance demand management, and support portfolio and results management (defined later). These new concepts are value-streams and epics. Value-streams are the ecosystem of teams that deliver against epics. Epics are large cross-cutting initiatives that deliver solutions to the end user. As more teams adopt agile across the organization, the need to define value-streams and epics is critical, to ensure coordinated planning and delivery. Incorporating these practices into demand management is essential for agile teams to plan effectively.
Portfolio management is responsible for continually assessing the performance of active programs and projects, against defined criteria. The focus is on governing the portfolio to optimize resources, such that they are fulfilling the highest priorities of the organization. One way this is achieved is funding projects, which have a specific investment amount, a defined scope, and a target delivery date. At the macro level, traditional and agile organizations will conduct portfolio management in the same manner. Even as an organization starts its journey to agile adoption, there is really no difference in how the portfolio is governed. However, organizations that achieve agile at scale may fund value-streams, allow de-centralized financial decision making within the portfolio, and continuously prioritize their backlog of activities within each agile project to adjust to changing business priorities. The implication is that the linkage between portfolio-level decisions and team-level delivery can be broken, if the change in methodology is not anticipated. As a result, PPM incorporates governing and funding of value-streams, in order to make effective portfolio-level trade-offs.
Project/program management implements controls to manage scope, financials, progress, and quality of delivery. Project status of red-yellow-green is the primary method of conveying whether a waterfall-delivered project is in control or not. Since project scope, budget, and timeline are defined at inception, the status is driven from actuals against that baseline. In contrast, the health of agile projects is seen through an analogous set of metrics at the portfolio level. Shown below are the waterfall metrics in contrast with their agile counterparts. The implication for PPM is to ensure clarity on status definitions, and what constitutes red-yellow-green in an agile context. Organizations that are adopting agile should anticipate this change, and incorporate this new set of metrics in their PPM playbook and reporting.Traditional IT was designed for stability and incremental growth based on long release cycles. But faced with unprecedented uncertainty, businesses now more than ever need their technology leaders to be resilient, agile, and future-focused.
Technology organizations are constantly trying to stay on top of new technologies, new market entrants, increased business integration, and ever-changing customer expectations that come along with a global competitive environment. There is no better example of that than the recent COVID-19 outbreak and the global rush at technology and non-technology organizations alike to adjust and adapt to an entirely new market and new way of working. This time of evolving market, economic, and social conditions is the time for transformational, not incremental, change.
Technology leaders are positioned to drive this change, as a recent report by Deloitte and WSJ Intelligence found that 50% of CEOs said their CIO or tech leader will be the driver of business strategy—more than those who named the CFO, COO, or CMO as their top partner combined.1 By reimagining their role and relationship with the business, by reorganizing to partner directly with the business and with customers, and by adopting agile and DevSecOps processes, technology organizations can lead the way in adapting to the pressures around them and creating a resilient organization ready to react with speed and flexibility to evolving global pressures and customer demands.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.This is the second post in a series, sharing a number of observed anti-patterns and corresponding patterns on the topic of business agility (aka digital transformation).We are in the midst of a Turning Point in a 50 year cycle, in the Age of Digital, as well articulated by Carlota Perez in ‘Technological Revolutions and Financial Capital’. At the time of writing, seven of the top ten firms by market capitalisation are technology companies. Less than two months ago, on 26th June 2018, General Electric, the last remaining original constituent of the Dow Jones index which was created in 1896, left the index, as it was contributing less than half a percent. In 2004, GE was the largest firm in the world by market value and only two years ago, in 2016, GE was still in the top ten. This is an indication of how we are in the Turning Point, how the previous industrial incumbents are shrinking and how firms with new business models and new ways of working, leveraging significant shifts in technology have become the new dominant forms of human organisation.
In sharing the anti-patterns and patterns, it is worth noting that everything is context dependent. An anti-pattern for one scenario might be a pattern in another context, in particular based on the current cultural norms of an organisation. That said, I believe that the anti-patterns to be presented are applicable in the context of the majority of large, old, bureaucratic, global enterprises (horses rather than unicorns).
They are based on lessons learnt through doing including learning from failing. Along with many talented people, we’ve been servant leaders on better ways of working (the application of agile, lean , DevOps, design thinking, systems thinking and so on) across a large (80,000 people), old (300+ years old), global, not-born-agile, highly regulated enterprise, with personal experience of delivering change with an agile mindset, principles and practices since the early 1990’s, about a decade prior to the Agile Manifesto, when the term ‘lightweight processes’ was used. The anti-patterns and patterns are also based on learnings from the community, from other horses (rather than unicorns) on similar journeys.
The Kubler-Ross Curve originated from psychiatrist Elisabeth Kubler-Ross’s work on grief, published in 1969. It has been found to be valid in the majority of situations relating to change and we have repeatedly observed this pattern to hold true via feedback from colleague surveys.
The bigger the capital ‘T’ Transformation, the bigger the change curve. If embarking on one large, broad, Transformation, expect an almighty big and deep dip in the curve. The bigger the dip, the harder it is to climb out of and the longer it takes. Given that some firms are facing an existential threat, there may not be sufficient time to climb out of that big dip.
In large, diverse, regulated, multinational organisations, where the cultural norm is most likely to be control or competence based, a capital ‘T’ Transformation with a big dip in the curve, will make the journey a harder and more challenging one. There will be a greater degree of denial, frustration and anger. The change stands a higher chance of cultural tissue rejection, with more ammunition for those averse to change. Things will get significantly worse before they get better.
For organisations that take this approach, with a broad scope, where people leave as a Project Manager on a Friday and rejoin as a Scrum Master on Monday, and in some cases need to reapply for their new role, the chances of genuine, embedded, internalised, long lasting, successful change which leads to improved business outcomes, over cargo cult behaviours and new labels on existing ways of working, are greatly lowered. As per this post, this drives fear, which drives a lack of action and resistance.
When starting out on transforming ways of working, increasing business agility, embarking on a ‘digital transformation’, it is hardest at the beginning. The antibodies to change are strong, there are vested interests at stake, the impediments to better ways of working and flow will be at the their highest, there will be the most amount of dependencies impeding flow, understanding is low, the force is strong with cognitive biases with no anecdotal stories or hard data from the organisation to challenge them and this is Yet Another Transformation (time to put your head in the sand and let it blow over). An analogy is skiing. It’s cold, painful, slow and hurts when learning to ski. It’s hardest at the beginning, uses up the most energy, when snow ploughing. Break past that, and once able to parallel turn, enjoyment goes up, speed goes up, energy usage for the same distance and time goes down, it becomes fun and addictive. Does it make sense to have a large number of people all snow-ploughing at the same time, on poor quality snow, in an environment not yet set up for skiing, bumping into each other, without enough ski instructors to go around?
Furthermore, large, old, bureaucratic, traditional organisations have a limited capacity and a tolerance with which they can change over time. Organisations have a limited re-learning velocity. Re-learning requires organisational unlearning, which is harder than learning from a clean sheet. Behavioural science studies show that cognitive overload is a major theme in rejection of change. Cognitive reasoning is finite and easily depleted. According to research by Dr Wendy Wood, approximately 40% of decisions that people make everyday are not decisions, but are habits and the majority of these habits in going from a traditional to a new way of working, need to be unlearnt.
“The thoughtful intentional mind is easily derailed and people tend to fall back on habitual behaviors. Forty percent of the time we’re not thinking about what we’re doing. Habits allow us to focus on other things…Willpower is a limited resource, and when it runs out you fall back on habits.” (source)
Where the change has not been internalised and embedded, where it is forced across an organisation in a broad manner, it is like one large elastic band, as soon as a leader mandating capital ‘T’ Transformation moves on, the organisation (people’s habits and codified processes) snap back into previous ways of working. It takes 3 to 5 years, best case, for a large traditional organisation to develop a new muscle memory. And then there is no end date to continuous improvement. For more on this topic, see Barry O'Reilly’s book Unlearn (Nov 2018).
This approach is also not living its own values or applying its own principles. It is not applying an agile mindset to increasing business agility. It is big batch, big bang and big risk. It is approaching change in a manner counter to the change being asked of colleagues.
I propose a corollary to this which is that “processes, control points and standards expand based on the number of audit and control staff employed”. This is in an uncontested space (i.e. in the absence of a group of people focussed on optimal ways of working)
Parkinson goes on to say that “the number employed in a bureaucracy rise by 5–7% per year irrespective of any variation in the amount of work (if any) to be done”.
He cites two factors: (1) “An official wants to multiple subordinates, not rivals” and (2) “Officials make work for each other” and he gives the British Colonial Office as an example. In the nearly twenty years from 1935 to 1954, looking only at peacetime years, the average rate of growth of employees at the Colonial Office was 5.89% each year (within a narrow range of 5.24% to 6.55% p.a.), whilst the British Empire shrunk by 76% from 17 to 4 million square miles in the same time period. The size of the Colonial Office was inversely proportional to the size of the the Empire.
“It would be rational, prior to the discovery of Parkinson’s Law, to suppose that these changes in the scope of Empire would be reflected in the size of its central administration. But a glance at the figures shows that the staff totals represent automatic stages in an inevitable increase. And this increase, has nothing to do with the size — or even the existence — of the Empire.” (Cyril Parkinson, 1955)
As large, old, enterprises, with years of organisational scar tissue and 100 year old ways of working are going to be at the highest level of inefficiency and bureaucracy that their revenues can (or perhaps in the Age of Digital, cannot) support, this is one reason why it is sub-optimal to take that organisation and apply a scaled agile framework across the whole organisation in one go.
It is important to descale the organisation, to descale the work, before scaling agility (not scaling capital ‘A’ Agile, which is doing not being).
Instead of a big bang transformation, with one big dip in the curve, achieve a big outcome through early, often and small slices of value.
Pursue evolutionary and continuous transformation aligned to outcomes, linking together a series of smaller change curves. Start in areas which are naturally receptive, the natural champions. The dips are not as deep, the learning and feedback is quicker, there is less risk and the champions, who have been trying to do this despite the firm in the past, are best placed to beat a path through the organisational jungle, likely with a growth mindset and personal resilience.
This approach is in line with the Kanban Method principle “Agree to pursue incremental, evolutionary change”. As time goes by, I have found myself to value David J Anderson’s Kanban Method principles and practices more and more, in the context of business agility, at all levels from strategy to the team.
Hence, don’t take a large team working in a traditional manner, on a traditionally developed product (whether IT or not) and apply revolution all in one go. Apply an agile mindset to the rollout of agile. Achieve big outcomes through (1) small teams, (2) small investments and (3) small slices of value, supported with capability building, training and coaching as well as help to remove organisational impediments. Identify where there is ‘elephant carpaccio’ which can be delivered, when starting out with a traditional waterfall team, likely as per Conway’s Law, with a monolithic system. Eventually there should be no elephant in the room. Leaders should ensure that there is a psychologically safe environment for experimentation and learning.
By way of an example, I’m aware of a scenario where there was a team of about 100 people who had multiple multi-year failed attempts to deliver business value in a waterfall manner. Following this, with the appointment of a leader who had a track record of successful delivery, a team of five was created, working with agile principles and practices. Within 12 weeks, there was a product in the hands of customers, in a production environment, solving a customer need and providing much needed learning and feedback. From this point on, the team size didn’t grow to be above three teams of nine or fewer people each, despite expanding significantly in scope in terms of the business lines supported, due to the success in the first business line.
Taking the original 100 people and applying a frog march of mandated certification, re-applying for your job with a different title and a cookie-cutter approach would not have addressed the inherent bloat at the time (it’s not a 100 person problem, in fact 100 people is a large part of the problem), would not have internalised the change so that it comes from within thus building a learning organisation, is not optimised to context, is costly and does not maximise business outcomes and customer delight.
For large organisations, and the approach that we have taken, where there are multiple business units (each one large enough to be standalone company in it’s own right, and in fact used to be, with their own culture and folklore), the ‘achieve big through small’ approach can be taken concurrently (whilst limiting Work In Progress) in a fractal manner. Each business unit pursues a limited series of small change experiments starting in fertile soil, with a small central Centre of Enablement (CoE) providing servant-leadership support and dealing with bubbled up organisational impediments. An agile mindset is applied in terms of empowerment and not being prescriptive on the How (within guardrails and a common vocabulary). This in turn can be done at the sub-BU level, and so on. The leads from each business unit come together weekly as a virtual team. Applying an agile mindset, all of the virtual teams of BU or sub-BU leads are agile team sized (single digits). It’s quick to spot common organisational constraints and allows for swarming on alleviating the constraints.
A mistake that we’ve made in the past has been to start at the team level and go sideways (more teams), along with the top level support. However, even with specific targeted training, this can fail to engage one or more levels of middle management, also known as the Frozen Middle or more kindly, the Pressurised Middle, as there is not always a clear role to play in the change. This is a common characteristic in any culture change in large organisations and is not a reflection of the people, it is a reflection of the situation they are in and how people in these roles are engaged.
A personal learning, when starting small, from a people perspective, is to have a vertical slice of an organisation go first. The leadership team is team #1. With the existing structure, have a vertical slice of that org volunteer to go first, including leaders at all levels, preferably natural champions, with as few dependencies on other teams as possible. Ideally this will be value stream / product / service aligned, not a role-specialisation alignment, such as just the BAs or just the Engineers or just the PMs. Middle management at as many levels as there are, have an explicit role, coaching and being coached on continuous improvement in ways of working, as per the Toyota Coaching Kata and with multiple-level portfolio Kanban being adopted to focus on visualising and limiting work in progress.
Then scale agility (not capital ‘A’ Agile) sideways, at a sustainable pace, working towards the organisation becoming a network of interdependent services. Go for more slices of the organisation, which are value stream / product / service aligned, supported by a small BU Centre of Enablement, providing coaching, training, shared learning, clearing the path for the teams. Pursue incremental, evolutionary, outcome-oriented, continuous transformation.
This doesn’t mean that scaled agile frameworks are not used. It is up to each team and area to decide what works best for them. Each framework is a valuable body of knowledge and can be a good departure point. In some cases they can provide a common vocabulary and in all cases it’s about trying what works in your unique context, with a focus on better business outcomes (as per my previous post). We aim to avoid framework fundamentalism, preferring to be Omnists. For more on this topic, see Dan North’s excellent article on SWARMing.
Again, at the beginning it’s the hardest, as the rest of the organisation is not set up for Continuous Everything. Several years in and good progress has been made by supporting functions (GRC type functions, InfoSec, Compliance, Audit and so on) also working in a way which supports small and often, conversation over a contract, with multidisciplinary long lived small teams, value stream aligned and in a context-relevant not one-size-fits-all manner.
To help amplify the learning, the overcoming of impediments, and adoption of better ways of working, we have an Exemplar Community. There are benefits of membership, such as additional training, external speakers, shared learning and prioritisation on the pull of the virtual andon cord. You don’t need to be exemplary to join, it is voluntary and there is a psychological contract in that teams agree to strive to become exemplary, jumping in with both feet, with a focus on measurable business outcomes (not activity or output). Consistently these teams exhibit far superior outcomes (for example 23x fewer production incidents on average), provide hard data as to benefits for the critics who are swayed by hard data, provide storytelling for emotional buy in and via cellular mitosis are able to spread better ways of working.
UK GDS have taken a similar path. To quote Adam Maddison, ex-Head of Agile Delivery at GDS from Agile Cambridge 2016:
“At GDS we absolutely haven’t ignored scaling frameworks. We’re quite happy to use features from those frameworks if they truly deliver value. But we are absolutely not wedded to any methodology or framework. We will always adapt features to our own use.”
In both the case of GDS and in our context, the ‘big’ in ‘achieve big through small’ is articulated via the Roadmap, which articulates Strategic Objectives and quarterly Business Outcomes on long lived value streams / products / services. These in turn are broken down into small vertical slices of value, like layers of an onion, as outcomes not activities and delivered via Continuous Everything. Achieving big outcomes through many small steps and continuous learning.
Work towards the organisation becoming a network of interdependent long-lived services, with high cohesion, low coupling and customer-centricityOctober 25, 2019 “If you’re not reinventing your business every five years, you risk losing relevance,” says Neal Larkin, a design associate partner in McKinsey. “For businesses to stay competitive today, they’ve got to be thinking that way.”
“With technology moving so fast, there’s no time for inaction. We’re about doing,” explains Ari Libarikian, a McKinsey senior partner and a global leader for Leap. “Many companies spend a lot of time thinking and talking about their digital future. Leap is all about getting them there quickly by building something new based on the parent company’s strengths.”
Leap teams feature a mix of business-building experts, including specialists in analytics, design, and tech. Most of these colleagues have launched their own successful businesses before joining our firm and understand the capabilities a business needs to survive and thrive.
“From day one, we build for our work to endure,” explains Ari. “The goal is to build and train a new muscle for our clients, who will then sustain and further strengthen it long after we are gone.”
To date, Leap teams have led over 200 business builds, many in less than 12 months. Ralf Dreischmeier, a McKinsey senior partner and a global leader for Leap, explains that Leap’s way of working plays a major role in this success. “We co-locate with our clients and use an agile model to move quickly, while bringing the benefits of a start-up to a corporate environment.”
“Think video on demand for sports but cooler,” says Clayton O’Toole, a McKinsey partner in our Strategy & Corporate Finance Practice. That’s how he describes the over the top service he and his team built with a multinational media conglomerate that launched earlier this year in Asia.
According to Clayton, only about 25 percent of consumers in a national market were paying for sports content, while over 50 percent considered themselves passionate sports fans. So, Leap worked with our client to seize that opportunity, building an entirely separate streaming business that leverages all of the parent company’s sports rights.
The Leap team worked closely with the media company across content selection, pricing and packaging, tech-vendor selection, legal requirements, and talent sourcing. Extensive customer research through deep structured interviews meant the new product’s prototypes and wireframes reflected what customers really wanted.
“The way you engage with sports should be very different from how you watch movies and TV,” explains Eleni Watts, a McKinsey associate who spent 15 months as chief of staff to the company’s CEO. “With sports, you have the ability to deliver unique and interactive features with a greater degree of personalization.”
Testing and iterating with customers helped the team fine tune service features like in-game catch-up highlights and a ‘no spoilers’ mode.
It’s all added up to a winning game plan. The streaming service is on an exciting growth trajectory so far, having already reached 15 percent of the client’s subscriber base in just six months since launch.
For a 175-year-old financial institution, becoming the first agile and design-led bank in a regional market meant Leap had the chance to create entirely new customer experiences. Call center frustration gave way to online banking satisfaction, 10-day lending approvals were cut to three minutes, and opening an account became a 30-minute appointment instead of a three-to-five-day ordeal.
“We were working in an area where design thinking and agile practices had yet to be used in any industry,” says Neal. “So embedding this way of working was an exciting challenge.”
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com Leap partnered with McKinsey’s Digital Academy to build and pilot a capability-learning program that would turn 20 employees into design thinkers.
Over the course of 12 weeks, the Leap team partnered with McKinsey’s Digital Academy to build and pilot a capability-learning program that would turn employees into design thinkers to serve customers in new ways through new digital channels.
By 24 weeks, the team had shadowed and coached over 200 employees and established 13 agile teams. They also worked closely with HR to create and source talent for new roles like user experience designers, engineers, and data scientists.
“We were focused on making design part of the culture,” says Neal. “This means putting the customer at the center of the problem you’re trying to solve, understanding how to do customer research and map out user journeys, and having the technology in place to build minimum viable products.”
The digital transformation helped the bank surpass $10 billion in profit. Having now captured a 40 percent market share, the bank is poised to solidify a number one position in the market.
For years, the lending market was one of the main sources of revenue for a European bank, but recently that space has become increasingly competitive. So, the bank turned to Leap for help.
We built them what McKinsey senior partner Mieke Van Oostende calls a “speed boat,” a digital-lending business for small and medium-sized enterprises. “We had a ton of freedom to move really quickly and test and play in this project,” says Mieke.
Ideation sessions helped shape the product, a clickable prototype brought it to life, and customer tests guided development. “We defined a cadence of work built on agile,” adds Fernando Figueiredo, a McKinsey associate partner. “This allowed us to move fast and keep improving the product.”
We weren’t working as traditional consultants. Our roles were more like entrepreneurs bringing varied skillsets together. Mohcine Ouass McKinsey associate partner
The team worked as one unit in one location over two-week sprints. Daily check-ins ensured close collaboration between disciplines, particularly tech and design. “We weren’t working as traditional consultants,” says Mohcine Ouass, an associate partner. “Our roles were more like entrepreneurs bringing varied skillsets together.”
After six months, the digital lending business was live; it had customers and 40 full-time employees. With its 15-minute loan decisions and cash delivery in less than a day, the digital lender has earned the highest net-promoter score in the market after just a year and a half.Take a look at those new, ultra-successful companies that have, seemingly, come out of nowhere. They may have started on a shoestring budget, with a skeleton staff, but they have the potential to scale rapidly, and almost infinitely, and to grow exponentially. They do things that older, more traditional companies sometimes can’t. Things that traditional companies wish they could do. They tend to respond to market demands more quickly. Their customer base is growing, while those of traditional companies may be on the decline. In many cases, influencers hawk products from these new companies.
Why? Because they are what many old-guard companies are not: they’re agile. Both traditional and new companies can anticipate changes in markets, but the difference is the newer, more agile companies can change direction quickly and seize opportunities. They often operate with higher margins and shorter lead times at earlier stages in their business lifecycle. Further, they can increase or decrease their tech footprint with growth or contraction and launch platforms and systems in new markets. Finally, they can manage their support systems from a single console anywhere in the world.
So, how do traditional companies deal with competitors they may not even see coming? They become perfectly scalable. And they do it quickly, before their competitors achieve the size and scale to dominate their sector. Here’s what that perfectly scalable enterprise (PSE) looks like. A PSE uses technology to leverage access to excess market capacity, align cost structures with growth, and efficiently use scarce resources to achieve economies of size and scale.
PSEs automate everything they can. They limit the impact of poor decisions and capture growth opportunities. PSEs also focus on avoiding waste and outsource wherever possible. Their financial resources are well-managed, and they target wide-moat competitive advantage plays to drive and sustain success.
PSEs can also launch digital products and services at a global scale with faster time to market. They use data-driven insights to enhance their agility, and minimize upfront capital investments, sunk costs, and technological obsolescence. Simply put: they epitomize enterprise agility.
How do companies become perfectly scalable? First they reimagine their business in a world powered by advanced technology. They redefine competitive barriers, realign partner networks, promote an innovation-based culture, and strive for operational and financial efficiency and flexibility.
For instance, a US-based health insurance startup leveraged the cloud to innovate by scaling its business and guiding customers towards better care by helping them more closely track their health. The company built and deployed its new cloud-based, HIPAA-compliant health insurance platform and analytics solution in less than three months.
They have been able to easily manage enormous usage spikes during open enrollment season, disrupting incumbents, and demonstrating the ability to scale to meet demand—and do it with a lean team to continually deliver value by better meeting business needs and improving the customer experience. The platform also afforded members to realize superior outcomes while reducing the associated cost of health care.
Clearly, the cloud is a key strategic choice that underpins the capabilities of a PSE and can help transform their business, and PSEs know that. PSEs value speed to market as a competitive differentiator, and they know that the cloud is the engine for that. It connects. It improves. It evolves. It integrates—at speed—enabling PSEs to start scaling quickly.
PSEs leverage the cloud to enhance their inorganic growth strategy. With cloud-based technology, they can acquire, integrate, and divest businesses more easily—and they can increase enterprise agility and simplify transformations—all keys to disruption. To that end, PSEs with an eye toward future M&A opportunities use cloud-based solutions to reduce future integration or divestiture costs, increase post-deal transition flexibility, enhance business agility, reduce risks, and facilitate a quicker exit when it’s time.
PSE’s use the cloud to make their technology operations more effective. They automate to drive improved productivity, increase accuracy, minimize waste, and enhance business results. PSEs use cloud-based automation technologies to improve operational spend and time-to-market by employing methods and tools that drive improved business outcomes—things like DevOps, self-service, auto-provisioning, integration platforms as a service, continuous integration and continuous development (CI/CD), microservices, and containerization.
PSEs also understand that deploying cloud solutions provides a quicker route for disruptive innovation, because it allows them to focus resources on finding solutions and delivering value, rather than engaging in capacity planning, procurement, and commoditized infrastructure management.
For example, a US-based financial services startup used the cloud—deployed by a lean team—to create an innovative, massively scalable securities trading app with strong built-in security and compliance features that supported hundreds of thousands of users at launch.
The app has disrupted the industry and is successfully competing with incumbents by offering no-fee securities trading capabilities, supported by a highly-scalable IT footprint. The startup is further exploiting the cloud to grow their online business, deliver and update their mobile trading app, securely store customer information and trading data, and perform advanced business analytics.
The bottom line? The competitive landscape is challenging. New, nimble companies are entering the market faster, with the latest technologies at their disposal—and potentially with little to no technical debt to prevent them from making significant strategic moves domestically and globally. Essentially, they are starting off as perfectly scalable enterprises.
Because they’re perfectly scalable, they have many choices—and limited downside if it doesn’t work out–which sometimes happens. Technology is a great equalizer, and acquiring the technology to become more flexible and scalable is critical to success. Getting smart on the cloud is a sound strategy to get perfectly scalable.In this episode of the McKinsey Podcast, Simon London speaks with McKinsey senior partners Sherina Ebrahim and Shail Thaker on how companies can use agile practices to transform their organizations. An edited version of their conversation follows.
Diane Brady: Hello, and welcome to the McKinsey Podcast. I’m Diane Brady. Even before the COVID-19 pandemic, agility was a hot topic. Some companies came into the crisis with agile practices, and let’s just say that others have had agility thrust upon them. But what does it really mean to be agile, and how can companies use those practices to transform their organization? Simon London finds out, speaking with senior partners Sherina Ebrahim, who works in New Jersey, and Shail Thaker, who’s based in London. Here’s Simon.
Simon London: So let’s just define our terms because this is a hot topic. This is a topic one reads about quite a lot. But Shail, why don’t you take a first whack at this. How would you define agile?
Shail Thaker: That’s a very good question to start with. So agile started life as a set of working practices in software development that were really focused on ensuring that product development was done in a customer-focused way—so end-user centric, heavily iterative. All of those things that a lot of people associated with agile at a working-practice level. And we’re in a very exciting time now where those working practices are being scaled up. Not just scaled up in IT, but actually scaled up across entire organizations.
And we are ending up with organizational constructs that look and feel quite different to what a lot of us grew up with over the past 30 years. We’re in a sort of tipping point now, where a lot of companies, a lot of entities, are looking at themselves and saying, “Well, is there an opportunity for us to organize in a different way? How do we organize in a different way to get a different outcome, particularly to increase external focus, adaptability, speed, raw cycle time?”
Agile is, at its core, in its simplest, a set of almost team-based working practices. If you ask me, “What is agility at an enterprise level?” I’d say it’s the scale-up of that in a meaningful way across entire organizations.
Simon London: So maybe, Sherina, just double-click on that. When we’re talking about at an organizational level, what are some of the things that you’re going to see on the ground that would define an enterprise or an organization which is becoming agile in that sense?
Sherina Ebrahim: I think the one thing that also is really important to think about when we think about agile organizations is to remember that it’s not only about what we would typically think about as organization structure.
To really become agile, it’s very much around mindsets and behaviors and really adopting a very different way of working. And so, I was just actually having a conversation yesterday with someone who said, “Well, we have cross-functional teams. It sounds basically the same as what agile is.” And it’s not. If you have a truly agile organization, you have groups of people who are singularly focused on what we would call a mission or a value driver or task, however you want to define it.
And the right groups of people are brought together to accomplish that. So if it’s about coming together to launch a new product, the people from insights and R&D and marketing and supply chain will all come together into a squad or a team. And their job is to say, “Instead of launching a new product in three years, how do we do it in six months?” How that’s enabled is not just to say, “We came together,” and then gave them a task. It is giving them the room to make decisions quickly. It is giving them the autonomy to pull in the right people when they need them, so that they can get the right insights at the right time. And they can actually make choices to move faster than what our traditional, hierarchical, matrixed organizations will allow them to do.
If you’re on a team, you feel quite empowered. You feel like you have an end goal. Everyone on the team, no matter what part of the organization you come from, is incented on that end goal—not what my function or chapter expects of me. Sherina Ebrahim
If you’re on a team, you feel quite empowered. You feel like you have an end goal. Everyone on the team, no matter what part of the organization you come from, is incented on that end goal—not what my function or chapter expects of me, but we’re all driving against the same goal in the same time.
Simon London: Right. Now then, I think an interesting question is, how many organizations are really trying to go big on this? Because I think, as you say, there are a lot of organizations that say, “Well, we have cross-functional teams.” Or there are certain parts of the organization—typically, software development to begin with, but other things as well—that are trying to work in an agile way. How many organizations would you say are really going big and trying to do this at enterprise scale?
Shail Thaker: I think we have to be a little cautious around what we define as going big because the end blueprint of what one company may look like in its fully agile state could look and feel quite different to another, right? And that depends highly on industry contacts, the specific portfolio you have, a whole bunch of things—not least the legacy and sort of historic baggage that a lot of organizations have.
Now, if you asked me how many have an ambition to do this at scale, we’ve done recent survey work across a broad spectrum of companies, across industries, that says 70 percent of companies in some shape or form are piloting agile now.
It is a big difference from running agile pilots to actually feeling comfortable that version one of whatever your agile operating model is, is in place. And with that, it’s not “I’ve done my architecture; now I can sit back and breathe,” but it is having an ambition to say, “I’m not just doing it in IT. I’m not just doing it in these shiny, new digital areas. I’m not just doing it in these particular business units.”
Almost use system thinking to say, “I can have individual teams that work in very much the way that Sherina described earlier. But actually, I need a backbone that supports them. I need an HR system that enables people to move around. I need a finance system and a budgeting system that allow me to resource reallocate. I need to have career paths defined for people.” So I think there are a lot of companies—I would argue even to say most companies—that are experimenting.
And then I think there are a handful of companies around the world who have done it at enterprise scale successfully.
And interestingly, those aren’t the biggest companies. Actually, the ability of some small and midsize companies to move very quickly on this agenda, where this is actually quite existential for them—you do this or you die—or indeed, they have the ability to mobilize the entire organization against this mission: those are where we see some really, really interesting case studies.
But the things that come out of them are that you are getting happier customers, you’re getting a productivity uplift, and you’re getting happier employees with improved engagement. So it’s a long way of saying, “How many companies are trying? An awful lot are trying.”
Simon London: But there are an awful lot—maybe, like we said, 70 percent based on survey work—that are either on that journey or have an ambition to go on that journey.
Sherina Ebrahim: And I think there are maybe two other things to consider. The ones that we see moving faster along that journey are the ones who, in many cases, have to. It’s a do-it-or-die kind of thing.
And that’s maybe a little bit alarmist. And we see that, for example, in the financial-services industry and places where the external environment is changing so fast, such as digitization—how consumers are using technology and interacting with that industry. So you actually have to change in a way that is faster to respond to what’s going on—meeting the needs of consumers. There’s another slew of industries, whether it’s consumer or healthcare, coming right behind as well. So I think that’s one reason that accelerates people through the journey.
The other, I would say, is leadership. There are definitely companies that are not quite on the cusp of “we really must change.” But the CEO or a business-unit leader has recognized the power of what this could be and has started to take the organization on a journey, albeit maybe slowly, trying to really build the muscle in order to get there first.
Shail Thaker: I mean, there are some fairly talismanic examples that are high profile. So I would argue, in the banking sector, you could pick many banks. But the most publicly known is obviously ING. If you look in the telecom sector, Spark in New Zealand is a great example of leadership-led transformation.
And you could argue that, in the pharmaceutical world, Roche has been taking a real leadership stance but with a very different angle around creating agile leaders and what that means. And the list goes on. I would say those are still companies that are on a journey.
Sherina Ebrahim: Just to add in other industries, I think we are seeing it with Walmart, which is in a very different industry that is starting to see benefits of using that methodology.
Simon London: And then there are companies that were sort of born agile, like Spotify, which is one of those sorts of talismanic examples of a company that’s just done this almost since the very beginning.
Shail Thaker: Absolutely. And that’s where, when I refer to the historic baggage of companies, if you’re talking about a 100-person start-up, these working practices, particularly if it’s a tech-enabled company ...
If you’re talking about a 60,000-, 70,000-person organization that is across 80 countries and has been operating in a matrix with very well-established norms, then [becoming agile is] more of a journey. Shail Thaker
Shail Thaker: It’s absolutely the most efficient and effective way of working in small groups. If you’re talking about a 60,000-, 70,000-person organization that is across 80 countries and has been operating in a matrix with very well-established norms, then that’s more of a journey.
But I would argue, that is also where a ton of value-creation potential is, because those are the companies that were built based on a simple premise: the matrix is a great structure for leveraging skill—and frankly, being the 800-pound gorilla and stomping on your competitors.
Alright, that is a wonderful construct for that. It is not a great construct if you have to move at speed. And that’s where, as I think Sherina referred to—whether it is external regulatory pressures, whether it is shifting consumer behavior, whether it is challenge of incumbents by disruptors—this imperative around speed comes in.
Sherina Ebrahim: And what’s interesting about it is, if you think about a spectrum of “born digital,” typically, they start small and can do everything that Shail just described. And on the other end of the spectrum, we have very large global companies—highly matrixed, functional.
What’s interesting is that the challenge is sort of just an area of gray. So we have already talked about how a large organization just starts to think about changing, really think about moving to an agile organization, with the right backbone.
What you see as start-ups scale themselves is that they start to run into the same questions, because you can’t just keep running like that as you get bigger. So they, too, then have to ask, “Well, what’s the backbone that I need to put in place in order to continue to work in this way?”
If you think of agile as an outcome of a particular setup where you’re putting the Lego bricks around which bits are dynamic and which bits need to be stable ... start-ups have a ton of dynamic, not a whole lot of stable. Incumbents: huge amounts of stable, not a lot of dynamic. Shail Thaker
Shail Thaker: But also, if you think of agile as an outcome of a particular setup where you’re putting the Lego bricks right around which bits are dynamic and which bits need to be stable for me to be able to deliver speed and be nimble and all that good stuff, start-ups have a ton of dynamic, not a whole lot of stable. Incumbents: huge amounts of stable, not a lot of dynamic.
So it’s the different ends of the spectrum, but as Sherina says, the convergent, the equilibrium point, for these—there’s a lot of cross-learning to be had.
Sherina Ebrahim: Yeah. And I think the other thing I would add is that, oftentimes, one misconception is that agile is just to “do what you want.” And it’s not, actually. It’s systematized. It’s a pretty structured way in which to work.
And so, this notion of what should be stable and what should be dynamic is really an important distinction that people should think through, because the stable enables people to come to work. They know the framework that they’re working in. They know their role and what might be their career path. And they know where their home is, if you will. And the dynamic is actually ways of working in which you can bring different people together so that they can quickly get something done and then move on to the next one.
And a pretty important success factor, I would argue, is the notion of dynamic resource allocation, which larger, more stable companies are not used to. They're used to yearlong planning cycles, budget cycles, but to be much more agile, you have to think about quarterly.
And so, it sounds easy when you say, “dynamic resource allocation.” There are reams of proof that it actually is a value-creating driver. But it’s a very hard thing to change—especially if—you’re not used to it at all.
Shail Thaker: I think, to dig into the point around dynamic resource allocation as an example of the types of things that are different, there’s absolutely a hardwiring piece. Finance organizations are not built to move money around. We don’t have the management information systems that allow us to track.
We don’t have the forums and meeting cadence and business calendar that free up enough time to make real trade-offs. We haven’t trained leaders to have the right discussions around this. But sitting above all of this is also a massive change in management mindset.
We have an entire cadre of leaders. I will paint this in black and white, just to point out the extremes: “I have been successful as a leader because I was given my budget, and I delivered or overdelivered on my budget.” That is very different from an enterprise-leadership mindset, which is essentially, “We’re all in service of a mission.”
To do that, I accept that, if things change, the budget I thought I had, the financial and human capital, can and should be reallocated. And that is a massive shift from “my number and budget commitment is my bond as a leader, and that is my commitment to the enterprise too.” I am now a participating leader in service of a mission.
Sherina Ebrahim: So in Shail’s story, for example: if you’re incented on making your budget, that’s what you’re going to do. Whereas if you think about an organization that’s agile, you’re not incented on your function. You’re not incented on your box. You’re incented on the purpose, the mission, which is very clearly tied to the value creation of the company. That changes the entire mindset and behaviors of the people. Again, easy to say. Not very easy to flip the switch when you’ve grown up in an organization.
Simon London: So let me just pick up on a term you used earlier, Shail. You talked about a blueprint. That implies to me an overall mapping of the different elements of this end state that you want to get to. Just double-click on that for us. What are the elements in the blueprint?
Shail Thaker: I think the blueprint is quite a key step in a company’s journey. It’s not always the first step, but it is a key step. Companies can start by piloting. But without a 60 percent, 70 percent view of how all the building blocks come together in the enterprise level, it’s quite hard.
And that’s why we think a blueprint is important. Now, what is in a blueprint? You don’t do agile for the sake of it. Your agenda around applying agile working practices is strongly linked to the ability to create value.
And that refers to which parts of your business system actually could create more value by being faster or more adaptable and, indeed, which ones could create more value by having more dynamic resource reallocation. So it’s almost through this value-creation lens that you look at your business.
Shail Thaker: And you identify nodes. So there are bits of your business for which agile working practices are massively relevant and create a huge opportunity. There are, frankly, other bits which don’t matter so much, and agile’s not going to transform them, because they are actually steady, consistent. Now, they play an important role in the system. But the blueprint first identifies these nodes of value. Where is agile going to make a difference?
Sherina Ebrahim: People will say, “We want to become agile.” And so, I think, you have to ask, “To what end and where?”
Sherina Ebrahim: And if you are not clear on that—and again, it seems very simple, but people are not clear—it really isn’t a critical underpinning of success as a starting point.
Shail Thaker: Yeah, absolutely. So let’s take step one of the blueprint as understanding where value is created by the application of agile working practices. The second piece is, “If I have those, I have a set of options of almost dynamic Lego bricks”—that's a visual I use.
And you may think that agile working practices equal a cross-functional team. The reality is, that’s not at all true. There are plenty of working models that contribute to agility—by the way, going all the way back to lean working practices and some quite old-fashioned but very relevant concepts.
There are quite a few more Lego bricks than you might think. The step two of the blueprint is, you apply these dynamic models and choose the right model for the right node of value to create the most value, right?
And once you’ve got that right, it’s great. You have almost a patchwork. Then you have to think, “What’s the minimum backbone I need to put in place to actually get the system working?” And it’s important to think of the backbone in this blueprint as something other than the organizational units you currently have. Often, it could be shared vision, common career path—think job descriptions.
It’s actually thinking expansively about the backbone in the system that holds the system together. As an enterprise leader, you can take a step back and say, “Am I comfortable that this is all building to an end point that makes sense?”
Simon London: So three steps I’m hearing. Number one, really figure out and agree as a leadership team where value is created to your application of more agile working practices—where could it be transformative?
Number two, what are the working practices we’re going to apply, where? And to your point, it’s not always just one thing. It’s not like everything’s going to work on a scrum basis.
And then third, what are the more stable elements? What is the backbone? What are the enablers that we’re going to need to allow us to scale this? Is that right, broadly?
Sherina Ebrahim: And the one thing I think is implicit in your number one, when you said the leadership team really has to be clear on the vision, the implicit value is that the leadership team really understands what they’re about to embark on. And so, what kind of scale or vision of transformation are they thinking of?
That doesn’t mean they have to know today that we want to become 70 percent agile or whatever it is. But they do need to have a sense of, “What are we trying to accomplish if we go down this journey?” Because just doing one or two pilots here or there, that might get you something.
But if you have a bigger vision, if you’re trying to turn the company or a part of the company in a different way, being clear on what that is and how they will have to lead in a different way is actually a very important thing for them be very aligned around.
Shail Thaker: I mean, we look at the success factors, and it’s also the failure modes. And one of the biggest is actually ambivalent leadership commitment. It’s really easy to sit back and say, “Look, I’ve got a whole bunch of pilots going on. We’ll sit back and see how they turn out.”
The reality is, after a while, you can create a huge amount of value in a localized agile pilot. But to some extent, it’s like entropy. You’re shifting the complexity to a new set of interfaces. And you rely on the energy and enthusiasm of the people to sustain that pilot.
That is not indefinite. So pilots can run out of steam, and organizations can lose their window, because agile becomes a dirty word or a failed-pilot word in the organization. And it’s not about learning; it’s actually just that thing we tried a few years ago. So you can’t pilot your way to scale. At some point, leadership has to commit. At some point, there will be—particularly when it comes to the backbone—a switching of how the organization is wired, and that takes commitment.
Shail Thaker: Yeah, well, I would say it’s not so much a leap of faith as an understanding of what the consequences of this are going to be for the organization and you as a company.
Simon London: And the consequences are profound, if you’re going to do it at scale? That’s the point.
Shail Thaker: It’s a transformation, and it is very, very different from how organizations operate today. But that is not to say that the people who are operating our organizations today are irrelevant to the future organization. It’s just that you have to be signed up for the journey.
Sherina Ebrahim: Yeah. I think that’s a really important point, Shail, because I fundamentally believe—and obviously, I’m biased—that whether it’s five years down, X years down, every organization is going to have to embody some components of agile.
The external world, the consumer environment, is just moving in a way that means we have to change. And so how do you actually move from what are fairly monolithic organizations today—everyone has their role, everyone has their function, et cetera—to one where everybody really embraces that it’s actually quite different and dynamic and it will continue to change? That is the point. So how many of our clients, our companies, today go through reorganization number one? And then before that one’s just finished, you’re on to reorganization number two.
Because you’re trying to get it right in terms of what you need to respond. And if you actually get it right from an agile perspective, you will never have to do a reorganization, because that is the fabric of how you work. You should be able to shift and change. And maybe today you work in a stable part of the business, and tomorrow you’ll be on an agile team. If you can just sort of paint that picture, it’s quite different from what it is today.
And therefore, to your point, it’s quite a shift. But at the same time, as you’re on that journey, it’s really important to make sure that people come along, understanding where they are and their place in the organization as well.
Shail Thaker: And to build off that, as we go back to the mindsets and why is this sometimes difficult, there is a perception—and I’ll use the word “perception”—of risk around this, because it feels like moving from classical command-and-control systems to much more decentralized systems. Now, the reality of the risk versus fully accounting for the cost of doing nothing has to take into account that this isn’t throwing all the pieces in the air. It’s actually quite a regimented but different way of working. So there’s that piece around risk that is quite important: around getting this sort of mindset shift.
And the second is, you’re talking about redefining how people value themselves and value impact in businesses. So I am in a system where, if I do well at my job, I’ll also get a pay raise, but I’ll get a new title. And with that new title comes more people. And I manage bigger and bigger things.
One of the outcomes of more fluid resource reallocation and really focusing almost the body mass of the organization around the biggest priorities is that you don’t have as large of a management layer in between. And that delayering is quite disorientating for people who say, “But hang on, if I’m great at my job, there are all of these roles that I could’ve got into.” So this links to some of the things like incentives or career pathing. How do you reward, recognize, and give people progression in a world that is fundamentally more dynamic? So these are all the types of challenges.
Simon London: This underlines for me a couple things. Number one, why it’s transformation if you’re going to do it at scale, because it has to touch all of these: systems, mindsets, processes—I mean everything. And the other thing is, what you’re talking about there again is backbone in a way, isn’t it? Thinking about rewards, career progressions, different roles, and having fundamentally different ways of being recognized for impact compared to a traditional organization.
Sherina Ebrahim: Absolutely. I think it’s to make it really real. For many current employees, it’s very much tied up in how they value their own self-worth, right? My title, my number of people. And so, as you say, I think the backbone parts are all of those things.
And what’s interesting is, the younger employees of today actually prefer to work in a much more fluid, more information-based environment. That’s how they grew up, right? And so that’s also going to play into this as organizations grow.
I think what we haven’t touched on enough, as you think about the backbone, is processes. So this implies that quite a few processes actually have to change, right? One we already touched on was how do you think about budgeting—resource reallocation, right? That needs to be reengineered.
Simon London: Yes, because if you’ve got a plodding budgeting process, you’re not going to be able to allocate capital in an agile way.
Sherina Ebrahim: Technology infrastructure underneath it to help you do it dynamically, right? That’s one of the barriers today: the system doesn’t allow you to be that fast. So budgeting is one of them. You’ve already talked about career pathing and career planning. To some, it’s blasphemous to not necessarily know in three or five years where I should be going. And people have to get comfortable with some of those things—again, not in all parts, but in how to live in a world that has some of these other things. So I think some are going through transformation, and some processes will stay the same.
Shail Thaker: Yeah, company carpools. There’s going to be a whole bunch of background stuff that speed and adaptability will not impact in any shape or form.
Sherina Ebrahim: Right. Not everything will change. There are some that will need to, and many others will stay the same.
Shail Thaker: There is an important clarification. It is absolutely true that the younger generation of workers adapt to this. They’ve sort of grown up in this environment and are adapting to it a lot more quickly, and it’s natural to them.
That is not to say that, irrespective of age, engagement doesn’t go up. So when we look at what the data shows, it’s not that the younger workers are really happy working this way, and the older workers find it terrible. It’s that teams, irrespective of age, see massive increases of engagement. I’m talking about 20 points, 20 percentage points plus, right? So people enjoy working in this as long as the rest of the system allows them to do it and does not massively penalize them or make their life considerably complicated.
Simon London: I was going to ask a devil’s advocate question, actually. I mean, the younger generation adapts to this easily—big generalization, but a lot of younger people, particularly having come into the workforce in the last ten years, have been forced to do gig work, and gig work is almost a form of agile outside any organization. Are we talking here in some way about bringing gig work inside?
Shail Thaker: The gig economy has come up now. I would say “forced” is a very strong word. So that sense of compulsion when we talk about the gig economy is always dangerous territory to get into.
But absolutely. The facts are that there is an element of flexibility and an element of uncertainty on what you’re going to be doing on a day-to-day basis. What I would say is, there isn’t one element of the gig economy, which is uncertainty of income. And actually, that sort of uncertainty stretches so far.
But you still have the security of being part of a mission, right? And this again becomes part of the stable backbone. There are elements of purpose, elements of mission, and elements of security that sit around this way of working that actually allow people to step away from a lot of the insecurities of the day-to-day work in a big company that are negative. It frees up a lot of the positive energy, which is where we see the uplift.
Sherina Ebrahim: I completely agree. I think it’s very important to reinforce this notion of security, for lack of a better word. It’s not necessarily job security as we know it today. But we do know the fundamental fabric of the company that you’re working for and what they’re trying to do, how they’re trying to do it—whether it’s processes, how you’re treated, the ways of working.
And so, yeah, I may not know exactly today that tomorrow I’m going to be in a different mission. But I know that’s how I work. And that baseline of security, which all people want, is one that’s an important thing not to miss. Otherwise, it feels like it’s a bit of a free-for-all, and it’s not.
Shail Thaker: I’ll play devil’s advocate back to you, which is to say that, ultimately, the reason we see the engagement scores go up in the way they do is a greater sense of fulfillment: a greater sense that an individual worker’s time is spent on things that are more value adding, plus a greater connection to a mission that feels more relevant.
Those are things that far outweigh almost the comfort blanket of the old way of doing things, with “I know exactly where I fit into the big system.” So the devil’s advocate back would be, yes, there are elements of the gig economy. But the engagement scores of the outcome show that one of those factors significantly outweighs the other.
Simon London: So I think a takeaway for me out of this conversation is that I assumed that to do agile, you had to be sort of doing squads, scrums, chapters, guilds—the bunch of core processes that you just have to do if you’re going to claim to be doing agile. It sounds like, actually, as this is scaling across different industries and different sectors and different companies, it’s more heterogeneous than that.
Sherina Ebrahim: Absolutely. It’s definitely more heterogeneous than that. And I think the way to think about it may be to walk away from all the terminology and the vernacular. There are just core concepts in different ways of working, as we’ve talked about.
There’s, whether we call them tribes or squads, the right people coming together to accomplish a mission. There’s what we would call self-managing teams, who sort of run themselves. There’s flow-to-work models.
There are a number of different models. And even when you do things that have a construct, which many call tribes, squads, or chapters—frankly, people are starting to use the terminology that works for them—I would try not to get caught up in the language but to ask, “What are the principles around ways of working that really help unlock the value?”
Shail Thaker: There are two things that have been particularly important, I think, when I’ve worked with companies on this. One is really defining for your company how the Lego bricks come together. And that’s which of the Lego bricks are most relevant, because you don’t want to create a whole bunch of additional complexity by doing things in a different way, in a different part of the organization to achieve the same end. And then the second piece is how you solve for an individual team, but that blueprint piece is really, really important.
Simon London: Let’s discuss how you begin. Let’s say, as a management team, after doing an offsite, you’re beginning to think, “We’ve got to go for this.” How do you start?
Sherina Ebrahim: I think there are a couple things, at least, if you’re that management team. When you say, “We’ve got to start,” I would ask that first question on our blueprint, “Agile to what end? Where is the value creation? What are we trying to get to? And over what period of time?”
And in that decision, I would actually make sure you, as a team, really understand what it looks like for both the management team and the mindsets and behaviors, how you have to lead, and what that might imply from an organization perspective.
I think once you get your mind wrapped around that—and it doesn’t have to be perfect, but you need to get at least in the right zip code, if you will—then you can take one or two or three of those value-creating levers and say, “What might we actually start to pilot or try within the organization?”
But then really know that it is a bit of a proof of concept. It’s not a pilot in the sense of “we want to try it and let it go.” It’s, “How do we want to prove some of these things to build conviction for ourselves and the organization?” And then know that, at some point, you’ll want to, as Shail said before, think about how to flip the switch and start to scale.
Shail Thaker: The one thing I would add is there is no substitute to going and actually seeing a company that’s done it. Like, because we can talk about this. You can see it on a page; you can do a workplace.
Until you actually see the deployment of this at any form of scale, go and talk to leaders who have done this before and what their journey has been like. That needs to be pretty high on the list of to-dos for the leadership team you described, because it’s great that they all held hands and said, “We’ve got to do this.” But unless they really know what “this” is or what it could be, it’s meaningless.
Sherina Ebrahim: Yeah, it’s actually step one before you have that conversation. To have a sense of what you’re starting to embark on, go see.
Simon London: This sounds negative, but the failure-modes question is often very revealing. So what are a couple of failure modes that you see?
Shail Thaker: One, I would say, is one we talked about a lot: leadership conviction. And if that leadership conviction isn’t there or you allow the proliferation of pilots but don’t have the convictions of leadership ...
The second piece is the blueprint. You let leaders who have the conviction do things in their own way. If you don’t define enough guardrails around what the way will be—the right, scalable way—then you won’t get any practices scaling up sufficiently to warrant the backbone change.
The third one is, you hope to pilot your way to scale. And actually, as a result, you don’t design the backbone.
The fourth one is capability building. We have talked a lot about this being a massive shift in capabilities, at an individual level but also at an institutional level—both the rewiring of processes and also giving people the skills to thrive in this new way. This is, for most organizations, going to be an unprecedented way of working, an unprecedented capability-building challenge, because you’re talking about a large number of people needing to learn how to do things.
Simon London: At a lot of organizations, in the same way that it used to be the Six Sigma Black Belt world, now you’ve got to have agile coaches.
Shail Thaker: And then the final one I think I would add is actually, look, this is a transformation. And that means some of the classical transformation tool kit is very relevant. But also, some of it isn’t. So thinking that in the classical organizational design, where I’m going to lock myself up with a small program of people in a room I’m going to design and architect, I’m then going to execute for a period, and bang, we’re going to have day one and hit a new structure. Really understand it’s a transformation, and take the right elements of the transformation tool kit that are relevant for what you’re trying to do.
Sherina Ebrahim: Doing the hard work to change the underlying culture, mindsets, and behaviors is a pretty big failure mode. Not doing enough of it. There is such a thing as not quite failing but not quite achieving the promise of agile. And what I mean by that is, I think we’re seeing more and more people recognize a need to do it.
But sort of reading the book, hiring maybe one agile coach or something says, “We’re going to change the labels. We’re going to make some teams. And we’re going to check the box for agile.” No way. Right? Really, you can’t just surface-level get there. You have to do the deeper work.
Sherina Ebrahim: I encounter a number of people who say, “Oh, we’re agile,” and then you ask the leadership team, “OK, you say you’re agile; what does that mean?” Ten people around the table will give you ten different definitions. “It means we have open space. It means we have three teams.” That’s something I would guard against. If you’re going to do it, really do the deep work. And it’s not a little bit of work to do.December 9, 2019 There is a lot written about automation these days and some of it can be daunting. From fear of robots taking over our lives, to automation being a threat to jobs, AI is creating impenetrable skills gaps and employee resistance to change.
First, we believe there will be more than enough work to go around. Our research shows jobs gained and changed by several automation and labor trends will outweigh jobs lost in the 2016-2030 period. Companies will certainly need to ensure that the effect of jobs loss is mitigated with retraining initiatives, and we are already seeing several companies leading the way in developing skills for adjacent roles.
Second, the nature of work and the workplace will evolve in ways we believe can positively influence employee motivation. This strikes us as a good thing, since other than maybe sleep, we will spend a greater share of our lives working than doing anything else. Here’s why work may be more motivating in the near future:
Automation will strip away the dull and the dangerous, paving the way for more engaging work and learning. Very few total jobs are going away entirely—indeed only one percent of jobs are made up of activities that can be fully automated; parts of jobs are what’s changing. That said, automation technologies, including RPA, artificial intelligence (AI) and physical robotics, have the ability to displace a third of the current activities in over 60 percent of all jobs. The activities automation is best at including predictable and physical work, data collection and data processing. As automation strips away the rote and mundane, what remains for employees to tackle are heuristic tasks—the complex, creative tasks on which humans outperform machines. Surveys show that workers see automation as an opportunity to free up their time to make meaningful contributions, which they find more rewarding. Work redesigns alongside automation promote more team-based and agile ways of working. Because jobs are changing, companies are using this shift as an opportunity to redesign business processes and workflows in a way that enables humans to work effectively alongside machines. Many are also reconfiguring their overall design and workspaces to promote greater collaboration and less hierarchy, resulting in more team-based set-ups and agile ways of working. In turn, employees have greater autonomy to shape their day-to-day, and develop a greater sense of mastery and purpose over their contributions, which increases their motivation to drive the work. Accordingly, a New Zealand telco saw over 30 pts eNPS gains after forming Agile teams—exceeding digital natives and thus enabling to attract the best talent. Automation drives increased need for social and emotional skills in the workplace. For centuries, organizations have asked human labor to act like machines. Now, technology allows for automation to be much of this work, and what’s left is asking human labor to do what is truly human. Along with higher cognitive skills, finely tuned social and sophisticated emotional skills—creativity, innovation, advanced communication, negotiation, leadership, adaptability, empathy—will be in greater demand to drive these more complex activities. As these connections-based skills increase, so does deep human interaction. A multinational technology company has experienced strong growth in the last 12 months by leveraging learning and empathy as critical assets for unlocking innovation and external partnerships.
Together, we believe these shifts in the workplace have the potential to drive significant improvements in employee motivation. Self-determination theory sheds light on how to get employees to become autonomously motivated without prodding and continuous monitoring to do work. The theory posits that there are three broad needs that, when fulfilled, cause us to want to perform a behavior: need for competence, autonomy, and relatedness. We recommend organizations bring employees on the journey in helping them understand what’s in it for them, and pay close attention to how employees’ feelings of competence, autonomy and relatedness are shifting to tap into higher engagement and performance – and ultimately, higher work and life well-being.You are an expert, an advisor, and a coach. You’re experienced with a variety of agile topics, ranging from frameworks (Scrum, Kanban) to engineering practices (TDD) and DevOps. You advise clients on the best way to adapt these practices to their day-to-day. You’re a hands-on coach to teams and leaders, helping them understand the role they play in a high-performing agile team.
You’re a teacher, practitioner, and evangelist. You use your expertise to teach others how to build products and solutions with tools like storyboards, backlogs, user stories, and acceptance criteria.
You’re comfortable working with different levels of an organization, from a mobbing session with development teams to discussing organizational changes with the C-suite.To thrive in today’s dynamic marketplace, organizations need to deliver at speeds greater than the pace of disruption. A fundamental change in mindset and ways of working is essential to respond and deliver profitable outcomes. Agile transformations in large organizations are extremely challenging and generally underestimated by executives. Deloitte brings its services across advisory, implementation and operations to enable business agility. We challenge organizations to reach beyond the mechanics of agile to focus on outcomes enabled by agility–to deliver better value, sooner, safer and happier.Leads our agile work in Central Europe and our Enterprise Agility Center in Budapest and helps institutions across industries to shape growth strategy and transform themselves in the digital age
October 5, 2020 In previous research, our colleagues have outlined the importance for agile organizations to create both stable and dynamic practices. A periodic business review, prioritization of different activities, and alignment across organizational units (frequently called tribes) are often together referred to as Quarterly Business Reviews (QBRs). QBRs can be the cornerstone of an effective agile organization, linking overall strategic direction to agile organizational units and team-level backlogs.
When done well, QBRs can bring immense value to an organization by creating vertical and horizontal alignment. However, inefficiencies often occur due to limitations in the ecosystem around the QBR—even if the narrowly defined process is done well. There are five reasons behind these suboptimal operations:
QBR ownership: The QBR and the broader ecosystem surrounding it are at the heart of an agile organization and must have a proper owner. This role spans three main activities: managing the QBR process, ensuring proper content quality, and continuously improving the QBR. A dedicated squad is required during QBR cycles, combining agile, IT, finance/budgeting and strategy expertise, and a strong and respected leader. Broad dependency alignment: During the QBR process, these units set Objectives and Key Results (OKRs) and plan what they will deliver to achieve them. Ideally, a substantial portion of the unit backlog can be delivered autonomously by the owner of the group, while a smaller fraction requires broader alignment. The QBR should serve as a forum to understand those dependencies and resolve them while not making the process highly technical and administrative. For instance, one LATAM company organizes a quarterly fair where each unit leader presents its initiatives and all other leaders are responsible to challenge them and understand potential dependencies. Traditional budgeting: Agility brings a paradigm shift in the logic of budgeting. Instead of projects, agile organizations use cross-functional teams as budgeting units. Agile organizational unit leads must assume resources are relatively fixed, and their job is maximizing impact, generated via prioritization. This is important, because if agile organizational units are subject to traditional project and business case-based budgeting logic, then QBRs cannot function properly. If fully agile budgeting is not realistic in the short term, companies can opt for a hybrid approach. For example, a leading bank uses QBRs to review budget status against delivered business results—and potentially make adjustments in a transparent and fast way during the QBR meeting, if circumstances require. KPI and OKR misalignment: OKRs are among the most fundamental elements of QBR logic, used by many organizations to set aspirational targets with motivating narratives to rally people behind a common vision. In the QBR, these units must define OKRs from strategic company aspirations. Yet, organizations often struggle to draw a connector line between the newly introduced OKR concept and end-of-year key performance indicators (KPIs). A Western European bank defined the value driver KPIs for each agile organizational unit and derived OKRs that helped to achieve these relatively fixed end-of-year KPIs. Disconnect from IT processes: In an ideal agile environment, agile organizational units can release standards and an IT architecture vision. This is rarely the case in large corporations due to legacy architectures and monolithic systems. Given that planning for major monolith IT systems often requires 12+ months, QBRs often need to co-exist with IT release planning. One European telco solved this by synchronizing the timing of IT release planning with QBRs, and then used them as a complementor forum—refining and breaking down the upcoming portion of the high-level IT roadmap.
Building proper QBR practices and enabling the ecosystem takes time and effort. However, once these pain points are addressed, the QBR can truly act as the nerve center of the organization, transmitting key impulses and strategic signals.September 23, 2019 As we’ve discussed extensively, agile organizations operate in fundamentally different ways to traditional organizations (see our previous articles here and here). But what is the role of the leader in this new open, empowered organization?
In traditional organizations, the focus of leaders is to maximize value for shareholders. To do this, they play the roles of planner (developing strategy and translating it into a plan); director (assigning responsibility); and controller (making sure everyone does what they should to minimize variance against the plan).
Today’s complex business environment calls for a new approach to leadership. This approach must focus on co-creating meaningful value with and for all stakeholders, expanding beyond shareholders to include customers, employees, partners and our broader society. In an open system, everyone must win. Otherwise, they’ll simply go elsewhere.
This new style of leader must play four new roles: visionary, architect, coach and catalyst. The traditional roles, while still available to leaders when needed, become woven into the way people work.
As visionaries, leaders shape the emergence of a clear, compelling purpose and vision – a North Star – that resonates throughout the organization and beyond. They don’t arrive at this in the boardroom. Rather, they emerge it from the organization by observing and listening to people throughout the system, offering ideas for consideration, and integrating others’ perspectives with their own original thinking. As visionaries, leaders also work with teams to translate the vision into measurable outcomes that empowered teams can work towards.
With clarity on what is to be accomplished, leaders act as architects. Rather than developing plans, leaders take on the more sophisticated role of designing the organization as an open and empowered system, able to continually plan, execute, and adjust flow of resources across shorter working cycles in pursuit of its North Star. They favor a deeper examination of the system designs at the core of the organization, creating space to re-imagine how products might be produced, or how sales might be generated. This requires letting go of limiting assumptions and beliefs in order to allow new forms of business and organizational models to emerge.
As people are empowered to achieve organizational goals, they need to develop greater business acumen, learn to think more strategically, and deepen their ability to collaborate. Capability building—of mindsets, knowledge and skills—becomes a critically-important area that leaders need to address.
They do this through encouraging a wide range of formal and informal learning initiatives, and evolving a culture of learning throughout the organization. They create environments where it is comfortable to experiment, where people feel equally good about discussing what went well and what could go better. They also build coaching into their team interactions by asking more questions than prescribing solutions, and seeking multiple perspectives to expand the solution space.
As catalysts, leaders unleash energy throughout the system. They do this in four primary ways: remove roadblocks that prevent empowered teams from bringing ideas to reality; foster connections across the organization; help people connect what they’re working on to the organization’s vision and aspiration; and finally, encourage an inclusive and welcoming environment of wholeness, where people can bring their authentic selves to the office, work in energizing and sustainable ways, and pursue the full range of their personal and professional aspirations.
Collectively these four roles aggregate into a very different and more powerful kind of leadership. Leaders – and the teams they lead – find this new approach far more energizing and effective, as it unleashes the full passion and potential of people to deliver impact and value.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.Serves clients on a broad array of topics ranging from strategy to organizational design and transformation across industries, including consumer goods, retail, and fashion; leads our organization design work and helps companies through multiyear organizational transformations, focusing on bringing operating models in line with the realities of the markets, strategic shifts, and other success factors
August 24, 2020 The majority of organizations still use a hierarchical model, where each role is carefully documented and cemented through a system of boxes and lines. In this paradigm, accountability gets buried in the depth of complex organizational structures. With businesses and government agencies alike facing unprecedented disruption, having the flexibility and speed to quickly make decisions and get work done has never been more important.
Digging out from under the many management layers and antiquated hierarchies may seem impossible, but it’s not. Some organizations have successfully “unstructured” to become fitter, flatter, and faster, unlocking massive value. Many organizations are experimenting with dynamic operating models, such as the “helix” model and the agile “network of teams,” enabling them to move at the pace of change around them. This blog post highlights what these organizations have done right and what others can learn from them.
Radically flatten the structure to minimize layers and increase speed Cumbersome management layers are the enemy of speed and agility. Leaders should throw out the old rules about the most effective ratios for spans and layers. In a highly digitally enabled world—where bosses are there to empower and enable their employees, not micromanage them, we see often spans as around 1:30. Even the largest organizations shouldn’t have more than six layers; in truly agile organizations, we often see only three layers. Build a flexible, dynamic network of teams to tackle rapidly evolving problems Whether a global pandemic or some other crisis, organizations of all kinds are faced with emerging, fast-moving disruptions in their industries. They need to be able to stand up and dissolve agile teams quickly, easily, and effectively—and with minimal requirements on leadership time and resources. Provide a stable home base for employees to ensure long-term career development The helix model has gained traction recently. Its key idea lies in disaggregating the traditional split of management tasks into two distinct parallel lines of accountability. The capability line is organized in stable skill-pools, where managers are responsible for the long-term care, development, and training of employees. The value creation line, made up of the highest-priority initiatives, is where employees work on a day-to-day basis. The value creation manager ensures that people know what to do on a day-to-day basis. Empower the ‘edges’ to ensure leaders have access to the best information and rapid innovation The organizational structure of the future is designed to ensure that critical people close to the front lines—therefore to the customer or constituent and the product or service—have a voice and are heard. These people typically are close to where value is created or where risks are borne. Empowering these employees to speak up and get involved often requires a cultural shift and close collaboration with the leadership team. Delegate clear decision rights to lowest possible levels Effective decision making is one of the most important elements of the post-pandemic organization. The flattened structure can accelerate decision making by minimizing unnecessary management layers; ensuring people are clear about their roles, responsibilities, and decision rights; and empowering the front lines to make decisions within guardrails.
For the new structure to be effective, other enablers must be present. For example, leaders should ensure the organization has an effective performance management system, clear strategic planning and resource allocation processes, a transparent and dynamic talent marketplace, and a corporate center that facilitates long-term performance and organizational health.
Organizations should build on the momentum gained from their response to the pandemic and ensure their organizational structures are set up to enable and supercharge their strategic goals—not hold them back.
This blog post is part of a series on Organizing for the Future, which explores a set of new principles such as anti-fragility and experimentation that are becoming increasingly critical for today’s organizations as they build more creative, adaptable, and human systems.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.The ability to deliver in a digital world is more important than ever. Businesses that once mapped their digital strategy in one-to three-year phases must now scale their initiatives in a matter of days or weeks. Agile, analytics, technology, design, and leadership capabilities are essential to enable this, however, building these capabilities can be difficult. Knowledge, skills, and behaviors must be aligned with how teams and key roles create value for the business.
We work with organizations to build these capabilities and achieve aspirations in digital and analytics. We use a broad range of learning interventions to help individuals and organizations develop foundational knowledge, mindsets, and skills on core digital, analytics, and agile topics in order to deliver measurable and sustained business impact.Agile Internal Audit (IA) has been successful in helping functions adapt to, and navigate complexity in a continuingly volatile, uncertain and ambiguous environment. An agile approach allows the function to appropriately plan by regularly re-assessing and focussing on stakeholder needs, accelerate audit cycles, drive timely insights and reduce wasted effort – in this sense it has the power to transform how we think and work, and ultimately, the impact that IA can have on an organisation. Over recent months, functions who have implemented Agile IA have noted that they have been able to quickly, and sustainably rise to the current challenges.
Better impact, quality, performance and decision making as agile teams are used to re-prioritising work based on new and emerging risks and ensuring a collaborative understanding of value and what really matters;
impact, quality, performance and decision making as agile teams are used to re-prioritising work based on new and emerging risks and ensuring a collaborative understanding of value and what really matters; Faster team delivery, reporting, response to changing risks, and closure of control issues through the use of audit sprint cycles and more stable teams;
team delivery, reporting, response to changing risks, and closure of control issues through the use of audit sprint cycles and more stable teams; Happier stakeholders and teams due to greater transparency, team empowerment and more sustainable ways of working; and
stakeholders and teams due to greater transparency, team empowerment and more sustainable ways of working; and Safer and more receptive environments for the delivery of other changes aimed at driving continuous improvement in IA – for example, the use and embedding of analytics, digitisation of IA processes, resourcing, planning, reporting, leadership structures and behaviours.
Agile IA is a way of working based on iterative development where audit requirements and solutions evolve through collaborative, self-organising teams who are focussed on delivering the most important business value and continual improvement; ultimately creating better, faster, happier and more resilient functions.
IA needs to be prepared to respond to a continually changing and complex risk environment. At its core, Agile IA is a way of approaching work and audit planning based on iterative risk assessment and value to be delivered, being focussed on collaboratively agreed greatest risks to an organisation.
With competing priorities, IA must find better ways to engage management. Using Deloitte’s Agile IA framework during audit planning, IA collaborate early and listen to feedback from key stakeholders to understand new or elevated risks in order to assess how to best support through provision of targeted assurance on the areas of greatest risk, with use of an Audit Canvas providing a powerful tool to identify areas of value for all stakeholders.
Importantly, adopting an agile approach does not necessitate greater time commitment from stakeholders. Focussed Agile IA events facilitate regular (but less intensive) interactions with stakeholders with communications designed around the things that really matter. Therefore in our experience stakeholders are very enthusiastic about agile audit approaches due to the fact they have increased involvement and engagement with the process, as well as reduced time to value benefit.
Agile audits are typically delivered in sprints of one to two weeks, with scope and tasks prioritised by value. Agile IA teams have adopted the discipline of frequent, targeted communications, both within the team and with stakeholders. A daily Stand Up event has proven to be very useful at identifying and resolving ‘blockers’ (potential delays) to progress and Sprint Review meetings at the end of each sprint create a setting for early feedback to audit stakeholders and course correction, allowing teams to hone in on what really matters and assess the value of further work.
A sprint Point of View (POV) communicates valuable insights to key stakeholders much sooner and more regularly than traditional, often long and time consuming reporting phases. Given the regular POV reporting and agreement with stakeholders on issues as the audit progresses, audit reporting becomes smoother and more efficient. In addition, as a result of improved collaboration with stakeholders, teams that make use of agile principles have reported improved stakeholder engagement and therefore better responsiveness, resulting in the business taking action to close audit issues sooner, and therefore more quickly strengthening the control environment of the organisation.
It is vital that IA leaders ensure that teams stay connected in an increasingly remote working environment. Regular team communication, such as the use of daily stand ups during sprint delivery and team sprint retrospectives, promotes closer working relationships and enables rapid identification and solution of challenges that might otherwise stifle progress, as well as encouraging a culture of continuous improvement.
Agile’s focus on stable teams also creates psychological safety and trust; producing resilient, self-organising teams who feel more connected and accountable to each other. They are used to working without being managed and function well in ambiguity, which is particularly important when remote working can lead to challenges in maintaining productivity and team wellbeing. Use of Kanban boards (a workflow visualisation tool) allows teams to self-manage their workflow as the team (and stakeholders) can see work in progress. It also enables transparency of workload between team members, helping to identify instances where team members may require support and thereby fostering a more collaborative team working environment.
Those functions who have embraced Agile have reported significant improvements in people engagement, wellbeing and morale.
In 2020, stakeholder needs in response to the COVID-19 situation presented IA with new opportunities to add more value around assurance, improve the advice they provided and increase their anticipation of risk. Many functions are considering where they need to make changes to their approaches and operating models to enable them to thrive in 2021 and beyond.
Functions who have implemented Agile IA to support audit delivery are seeing how Agile ways of working equip them with the mindset and the mechanism to deliver broader functional change. Large scale transformations can seem daunting, particularly in the context of multiple competing priorities. Applying Agile at a functional level enables the safe and efficient delivery of change by helping IA prioritise initiatives by value, deliver them over short sprint cycles and iterate and learn through continuous improvement.
Communication and collaboration are key to delivering value to stakeholders, with flexibility in response to evolving business needs an absolute must for IA. Agile IA is a way of working that has a built-in ability to pivot to rapidly changing circumstances, with strong communication and collaboration protocols established within the team as well as with leadership and key stakeholders. In 2021 functions should continue to focus on improving ways of working at all levels of their operations to help them elevate their delivery of assurance, insight and value.This is where start-ups are able to compete with large enterprises. Instead of discussing, debating and trying to convince leaders this is a great idea, they experiment! Take Spotify as an example, they see their people as innovators and provide an experiment-friendly culture, by promoting key idea validation questions such as [2]:
– what did we learn? Recommendations – what should we repeat in the future, what should we do differently, and why?
– what should we repeat in the future, what should we do differently, and why? Mysteries – which questions and problems need further investigation?
“The consequence in the business world is that start-ups who are more willing to explore new ideas systematically outflank and often demolish established companies trapped in exploitation mode”. [1]. An example of this is Yellow Cabs in San Francisco being forced to file for bankruptcy protection because of ride sharing services like Uber and Lyft [3].
Organisations are realising that they need to adopt an exploration-based approach in order to compete with start-ups. Agile, Lean Start-up and Design Thinking can be used to aid organisations through iterative and explorative based approaches or experimentation.
An experiment is a hypothesis-led and time boxed approach to testing and validating ideas or solving problems in a rapid, repeatable way. Below is Deloitte’s high-level experiment process, which is enabled by a cross-functional team of between five to nine people using Human Centred Design, Agile and Lean Start-up methods to focus on the core problem/opportunity, to iteratively create solutions, and ultimately test a hypothesis. This results in reduced time to make better informed decision on whether to pivot, pursue or stop.Agility has demonstrated its merits and can accelerate speed-to-market, enhance quality, and increase flexibility while reducing costs and complexity. Various agile methods employ various approaches to implementation, but share characteristics. In this paper we discuss:Architect: establish the key behavior shifts necessary and systematically hardwire them in the organization. This step is foundational to activate the aspiration. Our research shows that to make behavior changes stick, companies need to use an influence model with four levers: role modeling by leaders, fostering understanding and conviction by delivering a compelling change story, building the confidence and skills required to change, and putting in place formal and informal reinforcing mechanisms.
The most successful cultural transformation efforts start at the enterprise level, reengineering core business processes to embed the new cultural aspiration and behaviors. For instance, revamping the sales planning process, quarterly review management, or new employee onboarding—all of these are recurring, critical business processes that take up a significant portion of employees’ time and represent moments that matter.HR delivery in a ‘Fast to Action’ Team: A high-level insight in the ways of working, roles & governance
The F2A team is made up of a solid group of HR resources, composed to accommodate the right roles and capabilities for the solution that needs to be developed. A F2A team can deliver because of their team skillset and their complementary HR capabilities. To make their solution fit for purpose they will work in close collaboration with the business and other support functions where needed. The team generally consists of 3 different roles: Solution Owner, Ways of working coach, and the Delivery Team. The Solution Owner is the person responsible for determining which initiatives have the highest priority. The Ways of working coach focuses on the ‘how’, as he/she coaches the Delivery Team in new ways of working and effective delivery. The Delivery Team, as the name suggests, is the group of HR employees that deliver the solution and connect with the right stakeholders to ensure successful completion.
A F2A team guides their work based on the priorities listed on their ‘Solution Canvas’. This canvas contains the identified business priorities, based on conversations with key stakeholders (e.g. CEO, Business Unit Lead) and pre-defined criteria and requirements. New requests for business driven projects that were not on the Solution Canvas, will be reviewed by the Solution Owner. The Solution Owner selects the projects that will bring most business value, taking into account the availability of the required capabilities and capacity. The basis of the F2A team is that the resources stay together and do not rotate. This creates focus, commitment to deliver results, and deep expertise.
Although not always in the nature of HR, it is recommended to have clear KPIs and measurable deliverables when working in a F2A team to ensure the right outcomes are achieved. Finally, when the job is considered done, the team hands over to the business and the standing HR organization and moves its focus to a new priority. This might sound obvious, however it is only possible when the definition of ‘done’ has been clearly articulated upfront. The F2A teams exist as long as they deliver value, if not it is dissolved.Supports financial institutions around the world as they pursue a range of strategic, digital, and agile transformation opportunities and coleads agile service work in banking
Works with clients to define, develop, and implement digital solutions to succeed in an ever-accelerating world. Helps large organizations to become more agile, empower teams, create nimble structures and accelerate innovation.
May 7, 2018 Agility gets hailed as the new order for organizations striving to unlock value in an uncertain and rapidly changing market environment. But, as clients occasionally ask us, “What about its drawbacks?”
As a philosophy, agility has few tangible downsides – but relies on being applied for the right reasons, in the right places and in the right way. Done well, it delivers tremendous impact. Misused, it can trigger disruption and productivity loss.
Firstly, agile can prove difficult to get right. Typically, its new ways of working differ from what came before and it’s easy to go astray. Watch for these common pitfalls:
Copy-pasting : Agile principles are universal, but their application varies depending on the work targeted (e.g., product development vs. sales operations). Emulating someone else's model without a clear vision and deep understanding of agile can cause significant harm.
: Agile principles are universal, but their application varies depending on the work targeted (e.g., product development vs. sales operations). Emulating someone else's model without a clear vision and deep understanding of agile can cause significant harm. Partial agile: It occurs by applying agile to parts of the value chain and leaving the rest as-is; for example, handling agile product development within a traditional go-to-market setting. To achieve full benefits, agile should be executed end-to-end.
It occurs by applying agile to parts of the value chain and leaving the rest as-is; for example, handling agile product development within a traditional go-to-market setting. To achieve full benefits, agile should be executed end-to-end. Insufficient capability building : Agile succeeds when people – including leaders – possess the right set of skills and mindsets, e.g., entrepreneurialism self-management abilities. These must often be strengthened.
: Agile succeeds when people – including leaders – possess the right set of skills and mindsets, e.g., entrepreneurialism self-management abilities. These must often be strengthened. Diluted focus on performance: Self-management sometimes becomes a license for agile teams to stop planning, reporting and delivering results. However, agile requires more discipline, not less.
Self-management sometimes becomes a license for agile teams to stop planning, reporting and delivering results. However, agile requires more discipline, not less. Short-term bias: Agile software development teams must continually decide between new features and optimizing existing software to avoid technical debt. Unless managed, agile tends to bias towards overemphasizing new features at the expense of long-term quality.
Secondly, adopting agile so that it unlocks full value potential is a significant strategic investment. While structure and process changes are considerable, the most underestimated costs often relate to people and tools. Principal investments include:
Productivity loss during the learning curve : Inevitably, the first few agile development projects suffer from productivity loss (averaging 14 percent). But when agile teams conquer the learning curve, they see productivity boosts (averaging 27 percent vs. traditional teams).
: Inevitably, the first few agile development projects suffer from productivity loss (averaging 14 percent). But when agile teams conquer the learning curve, they see productivity boosts (averaging 27 percent vs. traditional teams). Leadership time spend : Agile brings fundamental changes to how an organization is run and led, especially when done at scale. Senior leadership must spend sufficient time developing the agile operating model and supporting its application (e.g., communications, role modeling new agile behaviors).
: Agile brings fundamental changes to how an organization is run and led, especially when done at scale. Senior leadership must spend sufficient time developing the agile operating model and supporting its application (e.g., communications, role modeling new agile behaviors). Potential loss of key employees : Agile unavoidably disrupts the status quo and requires significant adaptation from employees, especially middle managers. Be prepared to lose employees who want off the agile train.
: Agile unavoidably disrupts the status quo and requires significant adaptation from employees, especially middle managers. Be prepared to lose employees who want off the agile train. New talent management systems and approaches: These rank among the hardest aspects to tackle, often requiring surprisingly large investments to talent management and HR systems. This can include investing in capability-building programs, elevating branding and value propositions to attract the right talent, changing compensation bands and structures, and reimagining career paths and individual performance management, among other things.
These rank among the hardest aspects to tackle, often requiring surprisingly large investments to talent management and HR systems. This can include investing in capability-building programs, elevating branding and value propositions to attract the right talent, changing compensation bands and structures, and reimagining career paths and individual performance management, among other things. Improvement of the technology infrastructure : Heavily tech-dependent companies must often invest time and resources up front to enable agile, e.g., reducing technical debt and automating process steps such as testing. In the short term, this will reduce resourcing for new feature development.
: Heavily tech-dependent companies must often invest time and resources up front to enable agile, e.g., reducing technical debt and automating process steps such as testing. In the short term, this will reduce resourcing for new feature development. Employment of temporary capabilities: A sure way to fail is to adopt agile without enough people who’ve done it before and know what good looks like. These capabilities are often scarce in-house and need to be contracted at a premium (e.g., agile coaches, consultants, contract hires).
Agility can have large impact – but only if done properly for the right reasons. It’s not a "silver bullet." The most successful agile adopters employ a well-aligned, situation-specific strategy that weighs the investment against expected benefits.Your responsibilities will range from shaping strategic product designs to managing and transforming agile teams - working with Fortune 500 companies to native digital start-ups.
In this role you will be a part of a highly collaborative team who are adept at solving complex digital problems, combining unparalleled business knowledge with a world-class agile development process. You will be a part of cross-functional units to design, build and deliver new and exciting capabilities for our clients - with the emphasis on creating the foundation for rapid and effective implementation of systems that maximize value from day one.
Your goal will be to disrupt the way companies and organizations work and increase organizational agility for innovation, helping our clients scale agile in their organization is key to succeed at this. To be successful in this role you will need to have strong communication skills to coach and mentor teams and leaders on Agile values and principles. You will be comfortable structuring a large-scale Agile transformation with uncertain or changing constraints.
You will also coach clients on a variety of digital topics including product management, design thinking, engineering culture, and DevOps, and you'll engage with consulting teams as a “do-er” and actively problem solve, create content, and facilitate training as required to best serve our clients.September 24, 2018 Organizational simplicity. Fast execution. Clear responsibilities. Fluid teams. Agile planning practices. Companies in every field are rushing to make these organizational changes to compete in today’s marketplace. But one industry that has been lagging more than most – heavy industry – is using innovative ideas borrowed from the tech sector to bolster performance and respond to increased environmental rules and the need for further cost savings.
What one global chemical company is doing to create agility in its R&D operation offers an inside look at the beneficial impacts such organizational makeovers trigger for not just this industry, but others as well. The company believed it could speed project execution and save a bundle in the process via its 100-plus member process-improvement R&D team.
Projects that once took months to move from idea to initiation now just take days and, in general, are 75 percent faster. Rapid coaching of the R&D team sparked daily improvements. Delegated decision-making replaced the common “hurry up and wait” culture. A seismic benefit: The first agile R&D team doubled its productivity while – in just five weeks – it identified $150 million in potential annual savings. Since then, identified savings have more than doubled as more R&D teams have made the transition to agile.
Projects that once took months to move from idea to initiation now just take days and, in general, are 75 percent faster.
As the backdrop, most R&D team members were chemical engineers with PhDs who spent much of their time alone in their respective offices. Many knew their plant’s front-end processes but had no clue about its back-end troubles. Interaction with internal business customers – and each other – was inadequate, leading to delays and rework. And their time was split across multiple projects that led to inefficient multitasking and lack of accountability.
The transformation developed through the department leaders, who handpicked team members, making sure the team reflected different age groups and behaviors. Everyone got a brief training on the agile concept.
The team applied Scrum – an agile methodology developed by the tech industry for rapid, iterative software development with a “test and learn” mindset. It adopted one-week “sprints” to identify high-value process improvements in the plants, and each week, it held reviews with internal business customers to iterate end products. Accountability was instilled through complete team ownership of the project and peer pressure. Plus, the team got instant feedback about performance.
This was also essential to meet the team’s personal needs. They were used to working independently with vastly differing schedules. We set a 9 a.m. to 3 p.m. schedule for Monday to Thursday to account for personal needs such as child drop-off and pick-up, and Friday was open for them to handle non-project related work. But importantly, during 9 a.m. to 3 p.m. Monday to Thursday, they were 100 percent dedicated to the Scrum team with no exceptions.
Of course, challenges exist that can stymie success. Principally, leaders and employees must develop new mindsets and capabilities that can differ markedly from before. And leaders must manage on output – defining the goal – rather than input, or giving the task.
Highly agile leaders and teams realize that change is constant and adopting to a turbulent global environment is part of the future. Understanding the realities that organizations need to adapt again and again means having intentional, proactive approaches to change. Continually scanning the organization’s environment, viewing challenges with fresh eyes and a willingness to rethink past assumptions, is the path forward to future success.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.Serves clients on a broad array of topics ranging from strategy to organizational design and transformation across industries, including consumer goods, retail, and fashion; leads our organization design work and helps companies through multiyear organizational transformations, focusing on bringing operating models in line with the realities of the markets, strategic shifts, and other success factors
Advises leading global companies in the consumer industry and other sectors on how to optimize organizational design and operating models to improve performance and culture, and boost organizational agility
August 19, 2019 When done well, an organizational redesign fosters improved strategic focus, higher growth, better decision-making and more accountability.
However, a McKinsey survey revealed that only 30 percent of organizational redesigns are successful in terms of achieving overall objectives and improved performance. That means a daunting 70 percent of transformations fail.
Why? In the design phase, meddling by too many cooks often obscures the vision of a future operating model. Accommodating multiple opinions means the design becomes fragmented and vulnerable to individual pain points. Resources can get tied up in tasks that don’t add real value, unnecessarily prolonging the process.
More than 80 percent of executives have gone through an organizational redesign at their current company. They know that a transformation is a marathon. But to get to the finish line, it pays to do implementation sprints. That means taking a simpler, iterative approach; learning as you go; and correcting course more frequently. Under this approach, concept development and implementation are linked, running in parallel.
One high-end retailer, for example, faced difficulties with its siloed culture when redesigning its operating model and online assortment strategy. A series of focused two-week meetings, led by cross-functional teams, helped to foster a common view of what needed to change. The quick implementation of changes led to an impressive increase in its online assortment from 30 percent to more than 70 percent in just three months.
Be bold: Set a clear and ambitious target that will help you substantially transform your organization and let it guide your future operating model. Slim it down: Create a simplified first version of your envisioned end-state that will still deliver a significant amount of impact in the first phase of implementation. Prioritize change initiatives: Don’t kick off all new initiatives at once. Instead, be clear about how the initiatives will be sequenced and how they relate to one another. Conduct implementation sprints: Kick off the implementation in short design-test-apply cycles. Adapt and hone when needed: React to requirements that emerge during the transformation and course-correct whenever needed. Keep your eye on the ball: Stay focused on the actual end product: a truly transformed organization, not a perfectly designed plan. Embrace constant reality checks and adapt the plan accordingly. This helps to concentrate resources on those areas that contribute the most value.
Change is not easy, and the odds are hardly in any transformation’s favor. But tackling the root of the problem by simplifying the design and using a pragmatic approach—through implementation sprints—will boost the likelihood of success.
While we all aim for perfection, we should not do so when designing a new operating model. Sometimes complex concepts, which theoretically are superior to simpler plans, don’t get implemented. Instead, they can draw attention and energy away from more fundamental changes and delay the entire transformation.Agile is one of the hottest management trends for companies across industries, and with good reason. This approach, which encourages collaboration, responsiveness, and ownership, has helped to transform different parts of an organization and generated significant performance improvements. Over the past decade, leading companies have applied agile methodologies to IT, software development, project management, and delivery organizations. All of these functions have volatile processes with multiple inputs and high uncertainty, which made them natural candidates for agile.
To date, companies have been much slower to implement agile in operational functions, in part because executives assume these areas are ill suited for this approach. Customer care, for example, has less uncertainty than other functions, with plenty of repeated tasks and requests. Prevailing wisdom has been that rigid control is necessary in customer care to increase efficiency. Accordingly, this function has long focused on execution and used lean and Six Sigma to improve performance while standardizing interactions and investing in tools to guide service agents in their interactions.
However, the human element of customer care introduces variability and unknowns: customers increasingly demand service tailored to their needs and want their requests resolved without being transferred multiple times. What’s more, the imperative to become more customer centric and adapt to changing customer preferences now calls for introducing new elements from agile.
Agile has tremendous potential to revolutionize customer care and unlock the value of frontline employees, who represent a huge untapped resource. By empowering agents through an agile approach, organizations can infuse customer ownership and creative problem solving in customer care. Early adopters have already achieved impressive results in their contact centers, increasing first-call resolution and efficiency while lowering operational costs. A combination of agile best practices and a sustained investment in culture change can position organizations to capture similar benefits in their customer-care functions.
Currently, many customer-care functions are pursuing a traditional approach focused on standardization. Contact centers often resemble automotive factories, in that leadership carefully plans and orchestrates every step. Due to this top-down dynamic, contact centers have typically been siloed functions, with agents who have adopted a reactive, transactional mind-set. In today’s customer-centric environment, the step-by-step customer-care model is insufficient to resolve today’s more complex customer inquiries. Therefore, a fresh approach—one that harnesses the collective knowledge of frontline agents—is critical to delight and surprise the customer.
The agile methodology, as deployed in IT and product development, is not completely suited for customer-care functions, but it can be adapted in several ways to significantly boost customer experience.
Ownership. A major challenge in classic care organizations is that tasks and competencies are very scattered. With training, agents can quickly resolve simple requests, but they must typically forward complex ones to more skilled agents. The result is that, in many organizations, the first-call resolution rate hovers around 40 percent. Indeed, customers of major companies often complain about being stuck in the organization or being dropped after the third transfer.
Over the past decade, companies have incorporated digital to resolve standard requests within customer care. Yet many of the tasks left to agents are more complex, so a different approach is required to provide excellent service. Taking a page from pure agile methodology, a team or department gets ownership of a certain customer group and is entrusted to take care of all their needs. The team is also responsible for a customer’s satisfaction, revenue, and associated costs of service.
Self-managing. The agile way of working, with a focus on self-managing teams, can help customer care attain the next level of performance improvements. Teams and departments are guided less by input variables (such as average handle times and utilization) than by common targets (such as customer satisfaction, total revenue, and waiting times). Through daily performance discussions and the freedom to adjust processes and care strategies, the team can provide better quality care.
Capabilities and team. Customer-care functions must build capabilities in their frontline organization to more effectively provide end-to-end care. Experts that have previously handled more complex requests, for example, are being integrated into agile customer-care teams or serving as coaches on the floor, joining calls as needed. These cross-functional teams can resolve more than 95 percent of customer requests during the first contact, preventing a negative experience or multiple handoffs.
Enablement. When customer-care agents are part of the resolution process, it accelerates learning; and the combination of experts with frontline agents creates a culture of knowledge and learning. One of the better-known industry examples is US telco T-Mobile, which has a model called “team of experts.”
Agile routines. Most customer-care organizations conduct performance reviews, but they are focused on evaluation and payment rather than joint learning opportunities. Introducing agile routines as biweekly reviews enables teams to assess their achievements and performance of the previous period and decide on priorities to work on for the next period. In addition, teams can implement daily, 15-minute huddles to track progress during the past day. These structures help the team embark on a learning journey that is dedicated to serving customers more effectively and addressing their personal needs.
Leading companies have already applied agile approaches to the initial steps of the customer journey. However, these stages are only a fraction of overall interactions, leaving tremendous potential for improvement (Exhibit 1). Capturing this value requires the entire organization to adopt agile principles and coordinate its collective efforts.
Exhibit 1 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
For customer care, agile principles represent a unique approach: customers are served end to end by empowered agents who work in self-managing teams. Two case studies demonstrate how agile can be used to radically change customer-care organizations in different industries.
T-Mobile was struggling with very low first-call resolution and high customer dissatisfaction. Its agents were often forced to forward calls through the organization to try to address issues, resulting in too many handoffs and declining customer satisfaction. The telecom company recognized that revamping its first point of contact with customers would be a crucial step toward achieving better outcomes. The steps the company took involve multiple elements indicative of an agile methodology.
Executives call their approach “TEX,” for the team of experts that focuses on resolving the requests of their customers and building a personal emotional connection with each customer. These teams, which include a mix of customer-service agents and specialists, implement a collaborative approach to efficiently handle more complex requests. Calls are accepted by the general customer service agents, called “experts.” In the event they are unable to resolve the issue, they bring in a specialist. This approach has two effects: the customer’s request is resolved, and the expert embarks on a learning journey. Thanks to this structure, agents can often resolve similar requests on their own in the future.
At the same time, digital tools are applied to automate standardized tasks so that agents are freed up to innovate, and the specialists are available to collaborate with agents to troubleshoot, share their knowledge, and debrief after calls. Once a week, specialists and agents participate in upskilling sessions where they highlight best practices. Classic team leads are replaced by coaches to ensure sufficient time for development, and administrative tasks are pushed to a support team linked to the department head.
While in the past agents addressed the full range of customers and requests, T-Mobile’s new method allocates a fixed group of customers to a set of agents across several teams. The designation creates greater ownership: in most care strategies, agents who transfer a customer might not come into contact with that individual again. With this new approach, agents know the customer will come back again if they can’t resolve the root cause of the issue. This setup combined with the team’s “profit-and-loss ownership” create incentives for performance on metrics such as revenue, total cost, and customer satisfaction.
In addition, this system combines classic contact-center principles, such as routing and workforce management, with all five agile elements, enabling T-Mobile to significantly outpace its existing customer-care efforts on several key performance indicators: first-call resolution increased by 14 percent while net promoter score rose by nine percentage points. And in a reflection of the efficiency and visibility that TEX promulgated, the contact center reduced the number of times customers were transferred by 70 percent. The new approach has also had an impact on employee morale and talent retention: the emphasis on engagement and teamwork among the squads led to a 40 percent drop in employee attrition. In this way, T-Mobile turned a challenge into a competitive advantage.
A financial services provider faced a different challenge: its contact center was taking too long to resolve requests—sometimes as much as eight weeks. One reason for this poor customer service experience was that the provider had not designated an owner of the customer journey, which created siloed functions that were focused on tracking their own performance metrics without regard to overall goals. To remedy this situation, the provider aimed to streamline processes and reduce the number of requests that had to be handled by specialists, who were sometimes overwhelmed by the volume of issues that crossed their desks.
The application of agile principles led the provider to create self-managing, end-to-end teams composed of customer-care agents with colleagues from other relevant functions (Exhibit 2). Serving as single points of contact, these teams took ownership of issue resolution. This streamlined process improved customer engagement and significantly reduced the number of internal handoffs. To strengthen connections with customers, the provider coached agents to treat requests as if they were coming from personal friends. The provider also aligned performance metrics with the end-to-end customer journey to better track the ability of the team to resolve issues.
Exhibit 2 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Establishing ongoing communication and teamwork across the contact center benefitted both customers and the provider. In just 12 months, customer satisfaction increased by 20 percent, while contact-center costs fell by 30 percent and employee satisfaction rose by 10 percent. The increased visibility also reduced unnecessary rework by approximately 60 percent. The provider used the success of the pilot to roll out the new customer-care model to locations in nearly a dozen different countries.
The agile playbook is well established, thanks to its success in other functions such as delivery organizations and project management. Still, the unique dynamics of customer care require companies to tailor plans for implementation and scaling. Customer-care executives should seek to integrate four best practices into their agile strategies.
Identify customer-care functions for selected pilots. The initial pilots should be concentrated in a discrete area of customer care—for example, around a product line or specific region. The process of mapping customer journeys end to end can help agents think about how their engagement at any given touchpoint contributes to a positive customer experience. The top priority when evaluating candidates for pilots should be to ensure that agents can get as close to the customer as possible. Companies must also determine how best to cluster their teams, as this composition has a direct impact on performance.
All of these decisions share a common goal: to empower employees and give them the perspective and support to think more proactively and creatively about customer interactions. In some contact centers, teams have more flexibility in rostering and staffing plans and eventually transfer part of the profit-and-loss authority to individual teams.
Create an agile culture and mind-set. Since contact centers have traditionally been highly structured, with a command-and-control management approach, moving agents from a purely executional stance to a more engaged, problem-solving mind-set is critical. In an agile contact center, everyone needs to work together and support one another. Employees who may have become used to the standard ways of working may need a compelling reason to adopt a new approach; a clear change story can be the stimulus.
In addition, the physical layout of a contact center can send strong signals about the need to embrace collaboration. At one European contact center of a major telecommunications company, all of the employees who served specific customers were located on one floor with an open seating plan. Specialists were a visible presence, walking the halls, sitting next to agents, and sharing feedback on issues and how to resolve them. These measures serve to make call centers less anonymous and reinforce team spirit.
Prepare for the global rollout in waves. To scale successful pilots, companies must pay special attention to preparing employees for the shift to agile in advance, since selecting the right people to lead the rollout is crucial. Indeed, companies want to put at the vanguard people who are well respected by their peers and can be effective evangelists for agile. And by modeling the desired behaviors, these leaders can reinforce the collaboration and dialogue necessary to provide better service to customers. T-Mobile, for example, had a competition to choose people to participate in the effort. Executives should also reach out to internal work councils to ensure they are on board and understand the new opportunities that agile can offer to motivated workers.
In addition, companies should upgrade their workforce to ensure they have the capabilities to excel in agile. Professional development and training programs can address the hard skills, but it’s just as important to create an environment that helps employees gain the soft skills of teamwork and mentoring.
Go live and then improve continually. The beauty and challenge of an agile approach is that to be effective it must adapt to changing customer needs. Since the contact center has nearly constant engagement with customers, frontline workers will be the first ones to detect emerging issues, recognize trends, and then develop and test new ways of working to address them. Above all, teams need to remain flexible and be open to recreating themselves on a regular basis.
By keeping teams intact, companies can benefit from institutional knowledge and help to maintain morale among workers, who will take pride in having end-to-end responsibility for a product or region. Companies might need to invest in reskilling for agents in certain product segments or regions, depending on evolving customer preferences.
In the coming years, customer expectations will continue to evolve—likely at an accelerating pace, making the quest to please customers ongoing and continuously changing. Agile can not only improve customer-care outcomes in the near term but also lay the organizational foundation to respond quickly to shifting customer preferences. The prize is simply too big to ignore—not just more satisfied customers but also higher-performing customer-care organizations and happier employees.The financial industry, with its legacy systems and processes, continuously demands more projects with a fast time-to-market conversion. Therefore, digitalization has become a driver to revolutionize the industry. Companies disseminate information about products and services, processes or customer behavior in electronic form. The products and services themselves are digital. Furthermore, the speed and power of these digital structural changes is often underestimated. Traditional banks are clearly late adopters when compared to other competitors (e.g., Digital Banks) or industries. It is then in their best interests to implement innovative digital solutions to remain relevant and not lose the connection to either complementary third-party product offerings or competitors.
The banking sector, with long-term projects (over one year), is facing a tremendous change within the next 3 to 5 years. This time of transformation is a major strategic challenge for the executive management of every bank –probably the biggest in recent decades. This sustainable transformation and development ranges from the front office to the back office across every department. Professional and personal requirements as well as qualitative competences required from the employees raise are steadily increasing. Above all, high levels of IT competence and IT affinity are becoming more and more important to all employees and executives. The complexity of IT and the growing security requirements of the digital age are enlarging the number of software solutions, business apps and platforms that support the business. Active cooperation between management and IT consultants is a practical idea to properly adapt and integrate security and business processes.We previously explored tribal culture and planning, where the move towards ‘Agile Finance’ was seen as a move towards a ‘do it once and do it right’ environment. Pivoting our focus now to agile budgeting and the tools that support flexible forecasting, we first observe the process of costs estimation for IT projects (the birth place of agile). Exploring these examples helps to distil the ingredients that enable cost preparation and forecasting flexibility, and then explore how these can be applied to bridge the current IT Finance gap.
For CFOs looking towards change, the questions remain: How do we best prepare the organisation for the future? How do we derive value and create benefits?
There are no easy answers and the change for each organisation is unique. Essentially, the organisation’s design must be sufficiently robust to manage the known challenges of today, and the unknown challenges of tomorrow. To achieve this from a budgeting and planning perspective, it is important to address the perceived tensions between strategic long-term planning and short-term agility, as well as the relevance of shorter budget cycles for seemingly long-term commitments.
The first point to make is that, within the right structure, an agile finance function allows an organisation’s longer term vision, planning and budget forecasting to be shared more effectively through teams and in ways that create alignment and resonance.
Agility in Finance can and should include an increased understanding of ‘cost cycles’. Relatively fixed BAU costs (such as rent) can be managed using agile ‘zero’ budgeting, which is similar to the idea of zero-based budgeting. This involves keeping certain ‘core’ (fixed) blocks budgeted in the traditional way, while the variable blocks are budgeted through an agile ‘zero’ methodology. The advantage of maintaining both is that, in time, the so called fixed blocks of costs may become increasingly flexible as organisations further integrate agile ways of working and change their perceptions of ‘fixed’ costs.
The combination of a shared vision and an agile organisational structure leads to more efficiently structured teams over the long term, where the use of shared responsibilities can optimise and reduce resource requirements. This increases the available options to customise team structures by making Finance a ‘present and accessible’ part of organisation-wide teams. From here, organisations could consider supplementing, or supporting this flexible team structure through additional agile methods such as Flow to Work (F2W). The Flow to Work (F2W) methodology is the concept of where pools of resources can be moved in a nimble ways to address volume challenges over peak periods. For example, moving resources to Finance Guilds where agile teams of specialists in a particular area (e.g. a ‘payment’ Guild with a deep knowledge of EFTs or cash) work across multiple business chapters or ‘tribes’.
As an example, the illustrated below uses a customised value chain, where team structures are based on tribes across functions.Despite years of championing transformation initiatives, too many sales organizations still struggle with lackluster performance. Big investments in training, sales technology, and sales and marketing support have delivered negligible returns. Sales leaders have become frustrated.
It is no surprise that change at this scale is inherently difficult. We have written before about the fact that 70 percent of all transformations fail. There are many culprits in failed sales transformations, including the size and dispersed nature of sales organizations, high attrition rates, and a culture of decision making based on “gut feelings.”
It doesn’t have to be like that. In our work with thousands of sales organizations, it has become clear that advances in the “science” of change—digital, analytics, and supporting methodologies—can make a big difference, increasing the odds of success three to four times. This scientific approach to sales transformations is made up of four elements (see exhibit):
Exhibit We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Too many sales transformations are doomed to fail long before implementation has even started. Sales leaders spend all their energy designing the perfect commercial operating model without stepping back to assess whether what looks compelling on paper is achievable and sustainable in practice, or even why they want to change in the first place.
The best companies start by using data and analytics to anchor the transformation on where they can capture growth. They identify pockets of opportunity, assess the sales function’s ability to capture that growth, and identify the necessary adjustments. The other benefit of this analytics-driven approach is that progress can be easily measured.
A European telecommunications company adopted a micromarket approach to find pockets of overlooked growth. The analysis—based on a variety of data including some provided by reps themselves—revealed exciting opportunities in some markets, while highlighting other, less promising, markets where competition was intense and there were relatively few unserved customers. The company prioritized the 500 micromarkets by growth opportunity, allocating resources accordingly throughout the transformation. Ultimately, it saw 5 to 10 percent more in-store visits by optimizing its store footprint in the best markets while shaving total store costs by 5 percent through eliminating, resizing, or refocusing less profitable locations.
With a clear view of what they want to achieve, successful sales organizations quickly pivot to how to make it happen. This is crucial in building sustainability into the transformation from the get-go. By understanding what the organization’s and individual employees’ existing capabilities are, where they need to be strengthened in order to make change stick, and ensuring that the culture and the tools change too, the organization can flourish instead of flounder.
Successful transformers take a methodical approach to testing readiness, looking, for example, at how well leadership is aligned behind the program, whether performance management for a widely distributed sales force is already in place, and whether the incentive systems match the desired change. There is only so much change that an organization can absorb, so it is critical to prioritize and sequence initiatives. This requires pressure-testing the proposed sales strategy against commercial realities, such as market headwinds, customer preferences, potential for channel conflict, and other considerations. Leadership then translates these priorities into a road map for developing the capabilities that will drive the targeted initiatives.
A global chemicals company wanted to improve its understanding of customer needs in order to target its short-term R&D pipeline. It used analytics to help identify what was hindering its ability to do so effectively and realized that organizing reps by region instead of vertical meant that they lacked the necessary deep technical insights to relay ideas back to the pipeline. It was clear an organizational structure change would be required. However, the company didn’t stop there. It also conducted a robust data-driven capability assessment to identify the full complement of skills that would result in the greatest ability to spark innovation. Finally, it determined that enabling this change would require adjustments to incentives, reporting structures, and performance-management systems.
The company then designed a go-to-market transformation that solved not just for what its future state would look like but also for how it would get there. This approach helped increase the size and quality of the pipeline by more than 30 percent in the first three months of the effort, with sustained gains well beyond that. The company also doubled the impact of innovation on revenue growth.
A scientific approach shouldn’t be mistaken for simply using analytics and data. Experimentation is the foundation of good scientific method, and that is equally true for sales transformations. In a world where change happens quickly and answers are rarely clear, a dynamic approach grounded on testing, learning, and adapting is the only one that consistently works.
For an agile approach to work, people from across functions (such as marketing, pricing, sales operations) need to work together to design the pieces of the puzzle. The most advanced organizations start by using analytics to target the highest-value transformation opportunities. Then, the change leaders must identify and build the simplest tool or process to capture that opportunity—the so-called “minimum viable product” (MVP). Once the MVP is built, small agile teams test it with real customers, using analytics and A/B testing to develop a clear perspective on what works and what doesn’t. Then they iterate the product or service accordingly. Agile principles ensure that sales teams deliver customer satisfaction early.
A B2B transportation-and-logistics company that was struggling with depressed margins noticed that rep performance varied enormously across its 6,000-strong sales force. It needed to introduce a new way of selling that used advanced analytics to target customer opportunities, improved rep capabilities to negotiate deals, and provided a new performance-management rhythm. Given the complexity of the program and uncertainty around what would work, sales leaders realized they needed to adopt a more agile approach.
The company created a prototype targeting tool, new sales scripts, and a customer-relationship-management (CRM) dashboard to help track performance against target. It began to pilot and iterate these solutions with a select group of sales managers and reps. The teams met every day to discuss customer feedback and regularly adjusted their approach accordingly. This enabled many rapid iterations, and over time, new capabilities were introduced in these daily sessions until the team had a radically improved commercial model.
While this agile approach is increasingly common, organizations often stumble because they don’t account sufficiently for how to ensure the adoption of the solutions that agile teams develop.
In the case of the logistics company above, sales managers in the pilot regions explicitly used agile experimentation and rapid feedback loops to understand where training materials should be improved, whether anything was missing—for example, if the initial training was light on handling customer objections to the new sales approach— and where reps were struggling most with the new process. They were then able to iterate and find simpler ways to introduce the new content using a series of field-and-forum workshops and digital modules. These were tested again in a few other locations to ensure they were effective before the new process, and the new way of communicating it, were introduced to the rest of the 6,000 reps.
3. Continuous capability building and performance management: Use tech to build critical skills and track change
“Great sales leaders run their operations with the precision of an engineering firm.” That quote, from the head of adviser sales at a US financial-services firm, neatly summarizes the idea that a robust performance-management system is the beating heart of a sales transformation. It helps set the direction, establishes clear metrics, tracks performance, enables recurring dialogues, incentivizes desired behaviors, and helps managers continuously act to improve outcomes. The problem with these systems, however, is that their insights are backward looking, and the time between their delivery and action taken based on them can be long.
Data and analytics can enable much quicker and more forward-looking action. The best systems deliver immediate insights into what’s working and what’s not, flag deviations from expected performance, and recommend opportunities to improve. When a tech company attempted a large transformation to capture new growth, it tried to realign coverage to match opportunities, build front-line capabilities, and redesign compensation structures, but results were slow to arrive. It turned out that it had limited data on sales, margins, and products sold at the rep level, and no performance-management systems.
The company turned to analytics and an automated report system to create dashboards personalized for each salesperson, highlighting the opportunities they needed to follow up on. Each day, reps now see their top opportunities aligned to the strategic goals of the business, which helps them prioritize their actions. The dashboard also helped managers all the way to the C-suite identify the best-performing reps, see what opportunities they had closed, and where they might need coaching. Reps could also flag where they needed help, which ensured that priority opportunities got the right level of attention.
The combination of reporting, enablement, and coaching delivered an enormous impact very quickly: a 7 percent uptick in revenues for that quarter. This didn’t require a significant investment, just making the information available at the individual level.
Based on what we see in the metrics, performance-management systems can achieve their best results even if they are automated or self-administered. For example, a company looking to improve account planning could set up its CRM tools to check that reps complete planning templates ahead of big sales meetings. The tool could then prompt reps to analyze recent order patterns, develop a clear precall plan, anticipate potential objections, and receive approval from their manager on their approach. Email reminders and other prompts could be sent to the managers and reps along the way to ensure compliance with the new way of working.
A change is transformative only if it sticks. Without support, initial enthusiasm tends to falter and progress can break down.
Leading companies combine advanced technologies and personal support to ensure that doesn’t happen. They hard-wire changes into the fabric of the organization by digitizing processes and using analytics to support new behaviors. They might, for example, price for value rather than volume, segment and prioritize customer opportunities by lifetime value, and track performance deviation and recommend interventions.
A leading manufacturing company recognized the benefits of adjusting its go-to-market approach from “one size fits all” to a model tailored to each segment. However, experience had shown that simply segmenting its customers and training the sales force on the nuanced service models for each was unlikely to work. Instead, the company used technology to embed the desired changes into every facet of its go-to-market strategy.
It began by outlining each customer segment’s unique needs across such factors as preferred method of sales interaction, supply-chain requirements, technology support, and customer service. With those preferences clear, sales executives called on tech to automate some processes and reinforce others.
For example, the CRM workflow was updated to match each segment’s preferred sales motion: customers who preferred digital interactions were switched to a more automated reordering process, while others received high-touch treatment from reps. Sellers were constantly reminded of best practice as they moved deals through the funnel, including prompts that helped hard-wire the changes the company sought, such as reminders of what services or support was available, suggestions for whom to involve from other functions, and guidelines on how much time to spend on the account. The result was significantly improved service levels and customer satisfaction, and a 4 percent improvement in return on sales.
Relying on technology to drive the change alone, however, is a mistake. For change to stick, managers need to provide sales reps with personalized coaching, often supported by analytics that highlights performance challenges, as well. The best managers focus on “microinterventions” to coach their people with feedback as needed, rather than waiting for more formal regular review sessions. The key is making sure all this coaching is done with the same level of scientific rigor as the rest of the transformation by focusing on the areas of greatest value. That includes, for example, being clear about which people to target for training (data shows that training often has the greatest impact on middle performers, who tend to have the greatest achievable upside), or tailoring feedback to a person’s performance trajectory.
As one sales executive noted, “Despite all the benefits of automation, we made sure we routinely checked in with our team to hear from them first hand whether we were sustaining our new model.”
Sales transformations aren’t new. But by understanding how to use data, analytics, and the personal touch, sales leaders can drive change that matters and sticks.The unfolding of COVID-19 has brought uncertainty to all businesses around the globe. Brands everywhere have worked to navigate the disruption, maintain or adjust their business continuity and stay afloat in these uncertain times. Many organizations have altered their operating models to fit the changing circumstances, while others have adapted their services to help the greater cause.
The quick thinking and pivoting of brands across the industry is a real-life case study in what’s known in the industry as “agile marketing.” Today’s connected consumers have more influence than ever in driving the conversation around brands. Companies sometimes only have hours to respond if they want to remain relevant. This means that, in order to maintain their edge, marketing teams should have tools to keep up with the speed of culture.
Agile marketing often thrives on quality and flexibility, and marketers who are excel at it typically depend on a few leading practices to guide them. They develop a clear point of view. They have processes in place to quickly and succinctly respond to complex reputational challenges. They also tap increasingly sophisticated predictive tools to put brands in the middle of conversations when they’re likely to peak.Disruptive business, technology, and societal forces are causing an unprecedented change in the workplace. Our human capital blog, Capital H, offers insights and learnings on the changing nature of work and humanity’s evolving role in it.
Explore the blog by browsing previous topics, subscribing to receive our newsletter, and sharing your opinions on these top-of-mind subjects. Join the conversation and tell us what you think.Your responsibilities will range from shaping strategic product designs to managing and transforming agile teams.
In this role your goal will be to disrupt the way our clients, which range from Fortune 500 companies to digital native startups, work and increase organizational agility for innovation. You will train client teams in the agile framework and a new way of working.
You will be a member of a highly collaborative team who are adept at solving complex digital problems, combining unparalleled business knowledge with a world-class agile development process. You will be a part of cross-functional unit that will design, build and deliver new and exciting capabilities for our clients.
To be successful in this role you will need to have strong communication skills to coach and mentor teams and leaders on Agile values and principles and be comfortable structuring a large-scale Agile transformation with uncertain or changing constraints.Has there even been a time when customers were more demanding of the companies serving them? Industry 4.0 technologies—many barely imaginable only a decade ago—have already enabled genuine breakthroughs in cost, convenience, and customization, creating extraordinary value for buyers while raising the performance bar for producers ever higher.
And then there’s the volatility that never entirely disappears, flaring up in crises that can upend everything from supplier relationships to entire business models—all prevalent in today’s current landscape as Covid-19 creates widespread disruption. It complicates leaders’ efforts to make lasting changes in their organizations—efforts that historically have required years of sustained effort to take root.
Institutions ranging from aerospace manufacturers to tax authorities have nevertheless persisted, focusing their efforts on lean management and agile. Both methodologies have proven their worth as integrated systems for helping improve performance.
The mistake we find many leaders and organizations making is believing they need to choose between the two. In fact, that’s not true. Not only is choosing unnecessary, but the two methodologies complement one another in ways that increase the impact they generate, often by deploying Industry 4.0 technologies to speed transformation. Under this best-of-both approach, top-performing companies combine tools, ways of working, and organizational elements from each to form a custom solution that meets the company’s unique needs more completely and quickly than has been possible.
Lean management has helped organizations create value for over 70 years. Starting in the 1940s with its roots in the Toyota Production System, lean management has spread from manufacturing to service operations and just about every other department and function at companies, governments, and non-governmental institutions around the world. Lean organizations seek to identify and eliminate activity that is not valued by the customer or end user. This systematic analysis of processes and value streams to reduce waste, variability, and inflexibility boosts performance in cost control, product quality, customer satisfaction, and employee engagement—often simultaneously. Moreover, these companies apply a mindset of continuous improvement and flexible working processes in which all employees contribute new ideas and suggestions, so that the organization becomes better over time. Freed from non-value-generating tasks, people focus more on what matters to customers.
Agile is more recent, originating in software development in the 1990s accelerating after the release of the Agile Manifesto in 2001. Over the past decade, agile has rapidly expanded into other industries, such as telecommunications and banking—and, more recently, heavy industries such as mining and oil and gas.
Rather than the traditional process of developing a new product or service—which used to be highly sequential and time-consuming—agile is much quicker and more flexible. Agile models call for iterative development that aims to get an early prototype of a new product or service out into customers’ hands as quickly as possible. Teams then capture feedback and iterate via quick cycles, refining the product or service over time. Agile approaches have since expanded beyond the realm of product development, and companies are increasingly organizing for agility across all their activities.
A common misconception is that lean management and agile are mutually exclusive, based on fundamentally different principles and approaches and applicable for very different types of activities. Lean management is for routine, repeatable operations, this thinking goes, while agile only applies to projects or creative tasks. Therefore organizations, departments or functions need to pick one and focus on it exclusively.
However, that argument reflects a fundamental misunderstanding of both lean management and agile. In reality, both systems have been successful across a range of environments, and both share a similar set of foundational objectives: to deliver value efficiently for a customer; discover better ways of working to continuously learn and improve; transparently connect strategy and goals to give teams meaningful purpose; and enable people to contribute and lead to their fullest potential (Exhibit 1).
Exhibit 1 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
These objectives apply to any team or activity across an organization. There are, however, different ways of achieving them. Both lean management and agile provide team models, ways of working, and toolkits that can be deployed in any way that makes the most sense for an organization (Exhibit 2). The fact that the two systems build on the same foundational beliefs makes their elements highly complementary. Morever, operational excellence often cannot be achieved through lean management or agile exclusively but rather through the combination of both systems, using associated toolkits.
Exhibit 2 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Team models are organizational constructs that bring together individuals in an operating model to deliver value. Lean management introduces team models such as work cells, in which teams work together to complete steps that previously happened separately and were vulnerable to delay. Meanwhile, agile relies on concepts such as cross-functional teams and flow-to-work pools, which follow the same underlying philosophy. Some ideas are similar across both systems but with different names. For example, lean management’s relationship service cells, an advanced type of work cell for longer-cycle projects, have many features in common with agile’s self-managed teams.
Ways of working are approaches or processes that teams use to get work done over time. Lean management includes integrated management practices and continuous improvement, or kaizen, with agile adding “scrum” teamwork management and extreme programming, emphasizing short development cycles and frequent releases. Not surprisingly, some ways of working, such as visual management tools, appear in both lean management and agile.
Typically, when someone says, “Lean management is for routine, repeatable operations,” they are really talking about something like a lean work cell applying a methodology for continuous improvement. Similarly, an assertion such as “Agile is for creative product development” typically conflates agile with a cross-functional squad applying scrum, which requires a high level of communication for a team to achieve a common goal. Such statements fundamentally misconstrue both systems.
The right team model, way of working, and tools to use will depend on the nature of the activity being conducted (Exhibit 3). While lean management indeed was created for highly repeatable and predictable processes, over time it branched out to expert choreography, which coordinates complex interactions so that interdependencies are resolved before they become blockages, and relationship service cells, where processes center on a single point of contact with the customer. Agile found its origin in creative, customer-facing environments, but concepts like multifunctional and self-managed agile teams are now also being used in back-offices or call centers. The best selection of team models, ways of working and tools may be a combination from both lean management and agile.
Exhibit 3 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
A growing number of companies are getting better results under a best-of-breed model than they could by applying either lean management or agile systems on their own. Consider the following two case studies.
A financial services provider was struggling with customer service. Its contact center was taking far too long to resolve inquiries—up to eight weeks in some cases—in part because the specialist teams were overwhelmed by the sheer volume of customer requests. Worse, the firm had no designated owner for the entire customer-service journey. Instead, it operated under a traditional structure in which requests were passed from one function to another. Each function operated independently, tracking performance metrics only for their own slice of the process. No one was looking at the entire experience from a customer’s perspective.
The company used a combination of lean management and agile tools to improve. From the lean management toolkit, it used value-stream mapping and design thinking to completely rethink and restructure the customer experience for a given transaction or process. It also revamped key performance indicators to better reflect specific goals—for example, how fast a customer could get his or her issue resolved. From agile, the company created self-managing, cross-functional teams to improve collaboration and foster accountability. The new self-managing team enabled employees to handle all types of customer requests from end to end. Management also established a single point of contact for each process to reduce the number of internal handoffs and improve customer engagement.
Collectively, this approach led to a 90 percent reduction in the average time required to resolve a customer issue. Not surprisingly, customer satisfaction scores increased by 30 percent, as did employee engagement. The reorganization means that teams are no longer bogged down by bureaucracy and instead can see how their individual contributions have a direct result on the customer experience—and thus on the company’s overall performance.
In the second example, a global mining company had been deploying lean management tools among frontline units for more than a decade with significant success. Frontline operations at a mining site have several attributes—physical operations, a constant workflow, predictable customer specifications and repeatable processes—that make them ideal for lean approaches like six sigma.
However, commitment and progress had stalled in recent years. To jump-start gains, the company began to apply some agile tools, ways of working and team models. Even in a process industry like mining, many activities require cross-functional collaboration and operating in variable environments, from developing new strategies and engineering process improvements to deploying innovative technologies. Agile team models such as the cross-functional squad are ideally suited to that kind of work and delivered impressive results: dedicated improvement squads increased engineering velocity by 200 percent, and a cross-functional “fuel and energy” transformation squad identified and delivered $10 million of value within months.
More broadly, the company found that the agile transformation could be the banner to improve and reinvigorate the existing lean management program among frontline units. The company selected a few specific tools from the agile toolkit and integrated these into daily, lean management-led operations.
The company established four-week sprint cycles—a time period that aligned with the rotation of workers at the front line. At the beginning of each sprint, teams gather to look over the plan for the upcoming four weeks and identify key events, such as major projects, visits by leaders, or onboarding of new employees, along with one or two themes where they want to explicitly focus their improvement activities. Similarly, at the end of each sprint, teams hold a retrospective session to analyze their performance against the objectives for that sprint and identify how they can work together more effectively in the future.
This relatively simple change—combined with a renewed focus on daily standups and visual management—led to a significant increase in engagement among the workforce with over 90 percent of frontline teams actively owning improvement initiatives and approximately 130 incremental improvements delivered within the first three months.
As these two examples show, lean management and agile are both powerful systems, and companies don’t need to choose between them as either-or options. Rather, companies can apply this all-of-the-above approach, choose the tools and applications that are most relevant for their needs, and thus generate even greater improvements across the entire organization.IT leaders who started their journey toward adopting agile will probably recognize some of the patterns described hereafter. As corporations progressively experiment with or adopt agile methodology to accelerate their speed-to-market, they can fall into a common trap if their IT department fails to fully embrace an agile mind-set and behaviors. There is a pattern among organizations that pick and choose what aspects of agile to adopt: they think they’re “being agile” when in fact they’re only “doing agile.” Because they fall short of a full commitment to agile, they fall short of agile’s full potential results.
On the surface, the process looks agile: there is a scrum master who facilitates “agile ceremonies,” the four core team meetings within each sprint (short build phase). There is also a cross-functional team mixing front-end and back-end developers, a tester, and a solution architect. There is a process to plan development and a defined cadence—say, every two weeks—to make, report on, and demonstrate progress. There are talks about a minimum viable product (MVP) when new code is pushed into production after lengthy integration tests. There are new tools, such as Jira, to log units of work and track story points to monitor team velocity (productivity).
However, scratch beneath the surface and there are reasons for concern. The scrum master is only a part-time role whose involvement stops at the end of the ceremonies. The customer-experience (CX) designer is conspicuously absent from the scrum team. Instead, CX has been outsourced. User research was performed before the program started but not since. The product owner, instead of driving the product vision, follows the developers’ lead on which features should be prioritized based on how quickly they can be developed.
The team divides user needs revealed by the early research into front-end tasks and back-end tasks assigned to a front-end developer and a back-end developer. But the tasks, once completed, aren’t reconnected to compose an end-to-end user story. Slowing things down further, the MVP release is scheduled several months down the road to allow for the inclusion of features that already exist in the legacy application.
These kinds of delays aren’t often reflected in team reports. At the end of the sprints, the team productivity report shows, for example, that it has increased regularly, although not dramatically, since the first sprint. The tester is performing tests manually and has gotten wiser at choosing what to test. But experience shows that the results of such a partial commitment to agile are, like the process itself, half-baked.
A half-hearted commitment, for example, lacks the customer-centricity mind-set and the empathy that a CX designer would bring to removing perceived inconvenience from the customer experience. A full-time scrum master would relentlessly work to remove impediments, not just facilitate the ceremonies. Priorities would be business driven, not tech driven, and would be based on maximizing user value, not minimizing time to develop.
Companies that are really being agile wouldn’t disaggregate user stories into mere programming tasks, but would use them as building blocks for a better user experience. And user validation wouldn’t be put off until after a full release. Every user story, each granular slice of the user experience, would be submitted to the test of a sprint review, ideally with feedback coming directly from end users. The sooner there’s a working prototype, the better. Efficiency tools such as Jenkins should be leveraged to automate testing as much as possible and facilitate continuous delivery.
In short, successfully adopting agile methodology requires a full commitment, a complete reboot of mindsets and behaviors. The migration to agile must be accompanied by a thorough change-management plan to first instill, then install, and finally institute agile as the new norm applying to every person, process, and tool.Although more than 70 percent of companies report that agile transformation is a top priority, we haven’t seen the extent of agile adoption among operators that this level of interest would suggest. It’s puzzling. We know companies that go agile are 50 percent likelier to outperform their competitors financially. We also know that agile directly helps operators win four of their core battles: faster time to market, higher customer satisfaction, significant productivity improvements, and a transformed employee experience that improves talent attraction and retention.
We believe part of the answer is a lack of clarity about what “agility” actually means and how it plays out in practice within a specific company. The term is often used to connote a vague notion of being flexible. One executive explained his chronic lateness by saying he was just “being agile with time.” Others associate the term with a type of software development or bean-bag chairs and flexible seating arrangements.
Think back to a crisis you were involved in or a time of urgent and decisive challenge. Maybe you were responding to an emergency in your community, serving in the military, or facing an impossible deadline at work. You assembled people from different backgrounds who were selected for their complementary skills, operated largely without hierarchy, and focused on a well-defined objective. These extraordinary achievements are often remembered as “peak experiences.”
Agile, in a nutshell, is about assembling the elements of that peak experience for every employee, every day, without the need for a crisis. Agility at scale embeds these elements in the very fabric of how things are done by providing the following:
A very clear purpose, anchored in positive meaning A sharp definition of what success looks like Teams assembled with the skills required to succeed without reliance on others A cadence that fosters short bursts of tangible output and regular celebration of outcomes
This is the core of agility—building organizations with hundreds of those great teams (Exhibit 1). However, great teams alone would result in chaos and lack of scale. The other critical piece is a strong backbone that supports these teams by providing a common purpose, cohesive culture, functional excellence, and standards, which in turn enable the processes and platforms that hold the company together.
In our work with multiple operators around the globe, we have seen two successful approaches to agile emerge: agile accelerators and enterprise-wide agile (Exhibit 2). We’ll use examples of agile in action at two different operators—Denmark’s TDC and New Zealand’s Spark—to demonstrate two emerging success patterns for how to organize teams around work. Both operators have reaped significant benefits through their transformation, including the four key benefits mentioned above, and attracted global attention in doing so. Telco executives from all over the world now visit both companies to learn how they changed long-held practices in favor of customer and operational excellence.
Exhibit 2 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
The choice between the two approaches to agile is driven by how agility can best unlock value in a particular company, the maturity of the organization, and the top management team’s convictions about starting small versus undertaking quick and comprehensive change. Common to both is the necessity for a company to be “all in” about agility—only the scope of initial change is different.
Sidebar About TDC TDC is Denmark’s incumbent telco, serving both B2B and B2C customers ~8,000 employees ~€2.8 billion annual revenue (2017) Founded in 1990 Headquartered in Copenhagen
The summer of 2016 was challenging for TDC, the leading Danish telco (see sidebar “About TDC”). The recent merger of its two main consumer brands had consolidated its B2C strategy and the newly appointed head of its B2C unit, Jaap Postma, had a long list of improvements to make in the new organization. TDC’s digital capabilities were at the top of it—market research and Postma’s own observations strongly suggested that the company was not meeting consumers’ rising expectations of online service.
Having witnessed the power of digital in his previous positions, Postma set it as a top priority and tasked Rune Keldsen, one of his trusted leaders with broad, relevant experience, to get this right. Postma and Keldsen quickly concluded that doing things the old way would not produce results fast enough. TDC had invested significant funds in digital for years, but these efforts always tended to take longer than anticipated, and by the time they were ready to hit the market, consumer needs had often shifted already.
To speed things up, TDC decided to inject agility into its digital transformation. It first launched one, then 12 cross-functional agile teams (or squads) consisting of product owners, commercial specialists, frontline experts, customer-experience designers, architects, and developers—all the competencies required to design, build, test, and improve digital customer journeys at speed. Each squad was brought under the organizational construct of a “digital tribe” led by Keldsen. The squads were given end-to-end accountability to do whatever it took to create seamless and engaging customer journeys in online sales and service, while gradually establishing a flexible IT architecture.
Postma and Keldsen knew that to succeed with the digital transformation of TDC, they needed to establish a new culture and attract top talent. A casual walk-through of their Digital Warehouse shows they achieved this. At the facility, which is a rebuilt warehouse next to TDC headquarters, there is no more talking about business and IT, no more “facilitating” middle managers, and no more long steering-committee meetings. In their place are just cross-functional squads empowered to make change.
Eighteen months later, TDC sees the benefits of the new way of working. Its customer onboarding journey, for example, had been one of the main headaches for customers and a key reason for low satisfaction ratings. Post-transformation, TDC’s onboarding experience is now endorsed with five stars by 80 percent of customers. Call volume, one of the large cost drivers for TDC, is down by more than 40 percent now that customers can easily manage their interactions and solve their problems online.
Online sales provide another striking example. Six months before the transformation began, TDC formed a traditional project team tasked with designing and implementing a new digital sales journey for the main products. But with team members located in disparate parts of the organization and working in a traditional waterfall approach, the project team hadn’t managed to release anything by the time it was rolled into the digital tribe. Once they were co-located and equipped with agile techniques like minimum-viable-product thinking, the group had not only built a new sales journey but already generated its first online sales within a few weeks. The first minimum viable product was limited in scope, yet generated momentum, secured sponsorship, and bought the team time to deal with technical complexity of an automated solution that came a few months later. Conversion rates soared. The agile approach had worked.
After the groundbreaking success of the digital tribe in B2C, TDC immediately launched a similar digital tribe in B2B. This tribe is reinventing the sales and service experience for business customers and launching solutions that have not yet been seen elsewhere in the B2B space. Over the last six months TDC has continued to scale its new agile ways of working with three new tribes around digital marketing and product development (a TV tribe and a cloud tribe), all of which kicked off with success.
Sidebar About Spark Spark is New Zealand’s incumbent telco, serving consumers, businesses, and enterprise customers ~5,500 employees ~€2 billion annual revenue (2017) Founded in 1987 Headquartered in Auckland
Spark, New Zealand’s incumbent operator, had been on a transformation journey since 2012, following the carving out of its fixed-access network to a separately listed new entity (see sidebar “About Spark”). Having completed a successful turnaround, rebranding, and IT reengineering, Spark was in good shape and shareholders enjoyed one of the sector’s best total returns.
But the executive team was setting its sights higher. In their view, the game was no longer about outperforming other operators, but being match-fit for a market increasingly made of disruptive digital-native companies such as Amazon, Netflix, and Spotify. Competing or partnering with these companies requires a step-change in mind-set, speed of execution, and time to market, which the old functional organization model struggles to provide.
Armed with renewed urgency, Spark’s top team and board of directors visited more than a dozen companies around the world to understand how agile worked for them and what it could do for Spark. They visited both born-agile companies and companies in different stages of their agile journey. These included, among others, TDC and ING in the Netherlands.
Spark leaders returned home with a simple conclusion: when it comes to agility, they needed to jump in boots and all, and trust the agile process to get them through—“be agile to go agile.” They wanted to avoid a prolonged period in which part of the company had adopted agile ways of working and the rest was still operating in a traditional hierarchy. Companies that fully embraced agility across the organization were thriving. Those that just did it half-way often faced some difficulties. Spark likened this to a person on a dock standing with one foot on the ground and one foot on a boat.
Managing Director Simon Moutter and Group HR Director Joe McCollum called for a three-day off-site in October 2017 for the leadership team to decide if Spark would be in or out. The collective team pledged to adopt agile throughout the entire business, fast and at scale.
The team laid out an ambitious timeline to keep the transition phase to a minimum. In November 2017 Spark launched a company-wide communication about the upcoming journey and appointed leads to the first three tribes it launched as frontrunners: broadband, managed data, and digital experience. Over the following months, the leads of these three tribes built their own organization of about ten cross-functional teams each. In parallel, the rest of the organization prepared the changes needed to tip the whole company into an agile setup by mid-2018.
Along the way, Spark dedicated significant effort to change management and capability building. During the first half of 2018, well before any structural change occurred, hundreds of people engaged in defining and then putting into action a new purpose for the company: “Helping all of New Zealand win big in a Digital World.” This new purpose brought about an adjustment in the company’s values, target behaviors, and capabilities. They also emphasized diversity and inclusion so employees felt comfortable bringing their whole selves to work and working together, to ensure high performance in teams.
Operating in a small, remote market where talent with agile experience was hard to find, Spark selected 40 high-performing employees and trained them as agile coaches in a newly created academy. It also had all employees go through a two-day boot camp designed to build great teams familiar with the basics of agile.
In July 2018, Spark did a “big bang” launch of 18 tribes and moved approximately 40 percent of its employees into cross-functional teams comprised of IT, networks, products, marketing, and digital people. The agile transformation for the rest of the business—channels, corporate support functions, and other units—began immediately after.
Spark’s agile model was built based on a view of where and how value is created in each part of the business. Given the nature of New Zealand’s telco sector, Spark decided to place significant focus on “product tribes.” These tribes own the customer journey, product management, and related systems for specific products like mobile or IT services, to allow full differentiation and rapid improvement. “Segment tribes” take care of attracting new customers and growing existing ones. Finally, “enabling tribes” provide services and capabilities for other tribes. Channels (such as retail, billing operations, and B2B sales and service) and support functions (such as HR and finance), use a mix of squads, self-managing teams, and other team configurations suited for the nature of the work.
Contrary to what the Spark leadership had been braced to expect from overseas companies that had made the leap to agile, Spark’s operating metrics remained rock solid during the transition. Now positive results are flowing in. The new work model with just three “layers” of hierarchy has allowed efficiency through greater focus on productive work. The new 90-day governance cycle—the quarterly business review—allows for more effective and regular steering, higher transparency, and faster decision making across the whole business. Employees are thrilled to work in a setting where they can have direct customer impact, and customers, especially in the B2B space, are starting to notice the difference. In the words of many employees, Spark would “not go back for anything in the world.”
Each of the operating-model transformations TDC and Spark undertook demonstrates a certain boldness. It’s been described as “open-heart surgery while running a marathon”—being prepared to dramatically change a company’s core operating model without missing a beat in performance.
Surgeons inform patients of the risks of an operation before performing it, and we want to conclude this article by doing something similar, so you are aware of the implications of embracing agility.
The impact on your people is profound. An agile structure is built around teams of doers with little management overhead. Spark asked about 200 of its top managers to become agile team members, openly acknowledging that agile isn’t for everyone. Some chose to leave instead. Also, you need to invest in new skills, such as agile coaching, that previously didn’t exist at scale.
You must overhaul your core finance and governance processes. Agile teams need regular direction and prioritization, for which traditional large business cases and multiyear plans that bring comfort to management won’t work. TDC leadership needed to get comfortable dealing with 90-day objectives and funding tribes instead of individual projects. This puts more responsibility on leadership to stay on top of details and to work transparently, which can require a mind-set change.
The people model and culture need to change. Valuing and paying people based on hierarchical position won’t work in a flat, high-speed organization. Extrinsic motivators like bonuses and job titles need to be reconsidered to enable intrinsic motivation in teams. Culture is so critical to success that nurturing and evolving it will likely take up most of the effort you put into your transformation.
The role of the top team is very different. Agile companies require strongly united leaders to sense the market and shape priorities, but then let the teams figure out how to meet them. At Spark, the top team led the change by becoming a leadership squad and adopting a rhythm of standups, retrospectives, and demos similar to those used by the rest of the business. They centered their deliverables around building a great organization that enables other teams to succeed.
If these realities don’t scare you, the best way to start the journey is to build strong alignment and a joint aspiration in your top team. We have found visiting agile companies an enriching and sobering way to start a journey toward agile—hearing the experiences of fellow management teams bypasses theoretical discussion to create a joint understanding of what agile can do for your company. Learn what you want and don’t want from an agile model. Then set explicit targets and design principles to keep you honest on what you are trying to achieve. Taking a decisive approach and basing it on the learnings from companies like TDC and Spark will give you the best chance at success.July 15, 2019 Most sales organizations have yet to crack the code on how to launch a successful transformation. Too many sales leaders still make quick decisions based on feelings rather than hard evidence. And high attrition rates present challenges when individuals don’t pass on their knowledge of how things should work. The good news is that there is a science-based approach that can increase the odds of a successful transformation by three to four times.
A recent McKinsey article, “Meet the missing ingredient in successful sales transformations: Science,” reveals how the science of change—digital, analytics, and supporting methodologies—can increase the odds of transformation success. To reap the benefits of scientific analysis, sales organizations should focus their efforts on four elements: comprehensive design, agile deployment, continuous capability building and performance management, and sustainability.
One European telecommunications company’s transformation illustrates just how powerful this approach can be. The telco aimed to uncover new market opportunities for growth. To begin, it conducted a micromarket analysis using internal and external data (including data provided by sales reps) to reveal a clearer picture of which markets still had a large share of unserved customers and which were saturated with competition. The findings helped the company narrow its focus and decide where to allocate its resources. As a result, the telco increased its store footprint in key markets—garnering 5 to 10 percent more in-store visits, depending on the market—and reduced total store costs through resizing less profitable locations and other tactics.
As with any good science experiment, a methodical and considered approach can help organizations achieve the desired outcome—and gather fresh insights along the way.
Create a comprehensive design. Data and analytics capabilities can give sales organizations a clear view of where to find the most promising areas of opportunity. This can be done by conducting a critical analysis of markets and specifically looking for ways to increase growth.
Thus, before jumping into a change headfirst, companies should evaluate the ability of their sales function to seize these opportunities, and then plan a path forward. In addition, leadership can help prioritize plans to prevent organizations from tackling too much at once. Organizations can perform a stress test of the proposed strategy against the realities of the market, such as changing customer preferences, and use the findings to create a road map and prioritize initiatives.
Take an agile approach to problem solving. Cross-functional collaboration from across the organization combined with the use of advanced analytics capabilities helps organizations identify change opportunities with the most potential. However, the successful launch of solutions to these areas relies on an agile approach in product testing as well as the rollout and adoption of the new process.
Leaders begin by building the minimum viable product (the tool or process) that can capture that opportunity and test it. For example, a sales organization might build a tool that helps better target customers for upselling. A/B testing and advanced analytics tools can validate whether the product is working—or if not, why. Teams should adjust their approach based on feedback and iterate rapidly to improve on the prototype. To ensure organization-wide adoption of the solution, sales leaders can test different training methods to identify the most effective way to roll out the new process.
Continuously build capabilities and manage performances. Successful sales leaders run their organization like an engineering firm. Their operations are precise and well oiled, quickly flagging deviations and making recommendations for improvement. However, most performance management systems—the heart of a sales transformation—are slow and don’t present forward-looking insights. Integrating data and analytics capabilities into the system helps organizations better track performance metrics, which facilitates a manager’s ability to make key decisions. And based on our research, these systems can produce great results even if they are automated or self-administered. The key to success is in simply making the right information available. For example, an automated system using robust data could send prompts to sales reps or managers to follow up with customers or reminders to comply with a new process.
Sustain impact. Organizations can use technology and advanced analytics tools to hardwire new procedures into organizational DNA. For example, a sales organization might want to employ a more targeted sales approach by effectively categorizing customers. An advanced analytics system could group customers based on agreed- upon parameters, making it easier for sales reps to target offers. However, technology alone cannot facilitate a sustained change; it must work in conjunction with people. Managers can offer personal coaching on new technology—and use an automated performance management system to highlight performance wins, for example—to reinforce the process.Agile, cross-functional teams and processes can help brands with more than just keeping up with the latest marketplace conversations.
Ideate, iterate, pivot, agile—once considered buzzwords heard only at the local startup incubator, these concepts are now ubiquitous across global businesses. To create and maintain an edge in today’s complex, demanding marketplace, companies often need adaptive models that can enable them to keep up with the speed of culture, conversation, and digitization. The dynamic social, economic, and cultural environment also necessitates agile decision-making—particularly in marketing, where increasingly discriminating buyers are adopting, consuming, and disposing of brands more frequently and casually.
Many leading brands are separating themselves from the pack by being more purposeful and hyper-focused than ever on the human experience, necessitating a different way of working for their marketing teams. Other brands should follow suit—moving from reactive to proactive engagement in order to address the wants and whims of customers—or potentially be left out of the race. For this, they should restructure their marketing functions, leverage the power of real-time data accessed through digital platforms, and quickly gain insights to design more personalized, human experiences in an agile manner (see sidebar, “What is agile marketing?” for more).
Agility is both a framework and a mindset. It encourages organizations to embrace immediate and novel ways of thinking while helping them restructure in a way that allows their brand to join conversations and moments organically. Here are two examples showcasing how businesses are becoming more agile:
TD Bank maximizes operational flexibility: Realizing the importance of tailoring its services for its customers, TD Bank sought new methods to tap into digital platforms to unlock a deeper understanding of the customer experience. After shifting its marketing investments online, TD Bank needed to leverage customer data more effectively to tailor products and deliver personalized messaging to customers in real time. This required the bank to examine its approach to content generation, while its operational structure required greater flexibility to respond and react to the story the data was telling. To achieve this, TD Bank redesigned its marketing function from a traditional one to one based on “marketing pods”—cross-functional teams capable of rapid prototyping and iteration in producing content. 1
Realizing the importance of tailoring its services for its customers, TD Bank sought new methods to tap into digital platforms to unlock a deeper understanding of the customer experience. After shifting its marketing investments online, TD Bank needed to leverage customer data more effectively to tailor products and deliver personalized messaging to customers in real time. This required the bank to examine its approach to content generation, while its operational structure required greater flexibility to respond and react to the story the data was telling. To achieve this, TD Bank redesigned its marketing function from a traditional one to one based on “marketing pods”—cross-functional teams capable of rapid prototyping and iteration in producing content. JetBlue improves customer service through Twitter: Traditionally considered a no-frills, low-cost airline, JetBlue recognized the opportunity to enhance its brand identity through improved customer service. The company decided to leverage Twitter to support its customers as close to real time as possible on their journeys. Under this program, JetBlue encourages customers to tweet their needs and complaints to its account and ensures they receive immediate replies, explaining what is causing flight delays or other problems. In addition, taking cues from the tweets, JetBlue deploys its airport staff to help passengers on the ground. Through these efforts, the airline repositioned itself as a “customer service company that happens to fly planes.”2 So, what made this possible? JetBlue transformed its customer service operations by removing oversight and hierarchical bottlenecks to empower employees to independently respond to issues as they arise.
What is agile marketing? Agility draws on the key principles of “agile”3 software development. It is a framework that can enable organizations to move closer to customers by helping them embrace adaptive thinking and structure cross-functional teams to increase their speed, quality, flexibility, and effectiveness in reacting to moments in the market. It also can help companies capitalize on emerging technologies such as artificial intelligence (AI) to predict and generate meaningful engagements with customers in nearly real time. Agility pushes marketing to move beyond mere content creation by offering an organizational model for businesses to quickly design, create, and launch marketing campaigns. An agile model can allow companies to validate hypotheses and pivot based on customer interactions and timely insights. Further, agility facilitates learning and assessing the impact of marketing on connections with customers to capture return on investment.
TD Bank and JetBlue are just two examples of companies realizing the need for new approaches to better engage with customers. Across the marketing landscape, our analysis illustrates how many global brands are embedding agile across their organizations in diverse ways. In the agility trend, we delve into common organizational approaches that demonstrate agility in action and discuss the transformation that may be required in marketing departments to implement these approaches.
Being agile typically requires marketers to shift from conventional approaches of generating marketing content to new, tech-enabled, moment-centric ones. Traditional marketing strategies were built around single campaigns, where static advertisements were developed in stages, turned on, and then turned off when the campaign ended. Brands latching on to agile should recognize the need to adapt both the framework and mindset across the organization. They should also build internal capabilities and cross-functional teams that speed up their reaction time to capitalize on societal moments, while leveraging predictive technologies to gain a share of culture and conversation rather than just a share of voice or brand impression. Our trends research surfaced two specific agile strategies organizations are adopting:
Building the “if/then” campaign. With agile approaches, marketers create batches of marketing content to be rolled out in a 48- to 72-hour window, if trends or live events chart a specific course in real time. For instance, printing world championship T-shirts of both competitors in the major sporting event. Sports apparel companies and franchises have scaled this “if/then” thinking to the marketing department. As sports seasons and end-of-year tourneys unfold, marketing teams prepare for possible outcomes by crafting alternate campaigns to prepare for winners in key championship games. This approach requires companies to produce batches of content in advance based on an “if/then” condition and push it out depending on the outcome of the event or trend. Acting in near real time. Brands at the forefront of real-time engagement with customers are doing more than simply increasing the speed of their reaction time. They’re fundamentally shifting their culture and organizational structure—including reconfiguring their marketing departments—to support real-time customer engagement.4 Fernando Machado, global CMO at Burger King, attributes his company’s marketing successes to their “desire to be constantly engaging with our fans and our guests. And we know that we can only accomplish that if we move fast.”5 Moving fast is essential to Burger King’s “Traffic Jam Whopper” program, which debuted in Mexico City in spring 2019. Utilizing real-time traffic data to determine when roads near a Burger King (BK) are congested, the company pushes prompts to digital billboards and displays banner ads within the Waze traffic app. Drivers can order on the BK app through voice commands to avoid texting while driving. The billboards then display updates when food is en route and orders are delivered directly to cars stuck in traffic via motorcycles using Google Maps. Burger King reported a 44 percent increase in BK app downloads and a 63 percent increase in daily delivery orders as a result of this program.6
As these examples demonstrate, the accelerating velocity of technology can create opportunities for brands to continuously evolve their messaging and human experience based on near real-time customer insights.
To put agile to work, many marketers are diffusing the time-boxed, iterative approach across their organizations in three ways. First, they’re recognizing the need to be cross-functional and embracing a newsroom approach—breaking operational barriers and silos by bringing people closer together to produce content in the moment. Second, marketing teams are delivering content in a more agile manner by embracing new ways of working. These include daily standups, scrums, and piloting and testing methods that can enable teams to work in shorter sprints and move away from annual and quarterly content calendars. Finally, new emerging technologies, led by AI and analytics, are supporting organizations in predicting culture and the direction in which the conversation is moving.
The following examples show how some marketing departments are making agile work for their brands and how you can too:
Adopt newsroom-style operations. Many companies realize that embodying agile means improving the cross-functionality and proximity of their teams and, often, restructuring of their marketing function to build newsroom-like operations. Take the example of Taco Bell, which instituted a newsroom model to capitalize on the moment after it realized customers were accessing the brand and were most active on its social media channels between 9 p.m. and 2 a.m. From copywriting and legal to public relations and content designers, Taco Bell brought traditionally siloed groups together, enabling shorter lead times, instantaneous legal approvals, and quicker decision-making. This restructuring helped it gain a share of the conversation with customers in the moment, based on what its sensing and data capabilities were saying. 7
Bosch, a German engineering and technology company, similarly recognized the value of proximity among teams in an agile approach. It abolished its traditional structural hierarchy and created small, matrixed business teams, all reporting to a management board. Each “purpose team,” as they were called, was built around specific product and design goals.8 The restructuring required teams to interact more frequently. Daily standups were instituted to produce content in batches, while the marketing team developed the ability to quickly test and incorporate data to see what was working and what was not. Pilot then scale. Many marketers are piloting agile within a single business unit to test, learn, and iterate how they can make it work for their organizations. For instance, TD Bank in Canada wanted to embrace agile in its digital marketing function.9 The marketing team started with an assessment of the company’s digital maturity across business units to understand where they fell on the digital adoption curve, before piloting agile within a single business unit to gain insights on how to diffuse it across the company. Pulling together six cross-functional workers—from content, analytics, strategy, planning, and leadership—the team developed a “north star” to guide its agile approach with the goal of increasing the number of insurance quotes. Utilizing daily standups and a scrum model, the team ran two-week design sprints over three months, documenting experiences to present lessons learned to the business leadership; the aim was to understand the secret sauce for scaling agile across the company. Lowering barriers to entry by deploying agile in one unit enabled TD Bank to create a scaling plan and adopt it over time. Through the agile pilot, the bank cut costs by 30 percent in the first month and campaign turnaround time within digital marketing moved from four-month timeframes to two weeks. TD Bank also learned that demonstrating the ROI to leaders and achieving quick wins would help other units adopt agile as the company scaled the approach. 10 Deploy predictive sensing. Agile marketing typically requires internal teams to listen to the conversation and produce content in short windows by testing, measuring, and predicting consumers’ purchases, discussions, and reactions. Marketers have predictive technologies and AI tools such as Heat AI11 to aid them in this “predictive sensing” process. Analytics and AI tools can provide marketers with “social intelligence,” enabling them to predict and sense where conversations are heading. Content and conversations recycle every six hours on average; thus, speed in sensing is key to staying relevant. These tools also help marketing teams quickly identify whether their content is meeting its desired results in the moment. Conversations can be forecast 72 hours in advance, allowing a brand roughly three days to anticipate, create, and launch content.12
For example, in 2018, Facebook and National Geographic teamed up to grow a new community focused on “Women of Impact.” Leveraging sensing technology and AI to crowdsource and predict trending keywords and topics, the team created content using agile and expanded the community to four times its original size in just two weeks.13 Armed with such insights, flexible teams can abandon an underperforming idea, pivot, and update their creative approach to capitalize on what is being learned. On the back end, insights and patterns in the data also reveal the impact of the investment, offering learnings for the organization on where to go next.
Marketing leaders and departments can lead the agile charge for the entire organization, and in the process, transform their companies into customer-centric operations. By embracing agile across structures, teams and processes, and mindsets, brands are better suited to act and capitalize on moments to create deeper engagement with customers.Combines knowledge of digital with extensive experience in IT strategy and transformation to advise clients on all dimensions of digital, agile, and advanced analytics
Sid is an expert in the Ops practice with extensive experience in helping clients solve problems using digital, analytics, and lean Six Sigma tools.
October 18, 2019 Imagine a future where smart robots assemble products from multiple manufacturing lines by physically reconfiguring themselves on the factory floor. Security drones handle tedious tasks ranging from monitoring for intruders to validating employee parking. Autonomous vehicles transport parts not only between buildings, but also across the country. And factory inspections are performed remotely from a thousand miles away.
Just a few years ago, these were impossible dreams reserved for the realms of science fiction. But with the arrival of 5G connectivity, combined with advances in artificial intelligence (AI) and cloud computing, these dreams are becoming increasingly attainable for today’s manufacturing organizations.
The hype is intense. With data speeds slated to be 25 times faster than today’s 4G networks and lag reduced to virtually zero, 5G appears to promise unending opportunities to strengthen connectivity and digitization—both within factories’ four walls, and beyond them at every step along the entire value chain.
But which potential applications deserve manufacturers’ attention? Five show particularly strong potential for boosting factory productivity:
Cloud control of machines —For decades, factory automation has relied on programmable logic controllers (PLCs) that were physically installed on (or very near) the machines they controlled, and then hard-wired into computer networks to ensure precise, reliable control under extreme conditions. If 5G consistently meets its performance promises, the PLC could be virtualized in the cloud, enabling machines to be controlled wirelessly in real time at a fraction of the current cost.
—For decades, factory automation has relied on programmable logic controllers (PLCs) that were physically installed on (or very near) the machines they controlled, and then hard-wired into computer networks to ensure precise, reliable control under extreme conditions. If 5G consistently meets its performance promises, the PLC could be virtualized in the cloud, enabling machines to be controlled wirelessly in real time at a fraction of the current cost. Augmented reality —Factory workers are no strangers to performing complex maintenance and control tasks, often guided by standard operating procedures (SOPs) in paper manuals, videos, or—in some cases—even augmented reality. But instructions streamed over 4G networks can be unreliable due to bandwidth constraints, and fail to deliver the required levels of quality without stuttering. 5G promises not only the streaming of high-quality instructions on the shop floor, but also stutter-free augmented reality that can guide people, step by step, through each individual motion they need to make. This will allow shop-floor workers to undertake advanced tasks without waiting for specialist engineers or incurring costly machine downtime. The best knowledge and work instructions can therefore be shared with all workers exactly when they need it, building worker skills more quickly, safely, and effectively than ever before.
—Factory workers are no strangers to performing complex maintenance and control tasks, often guided by standard operating procedures (SOPs) in paper manuals, videos, or—in some cases—even augmented reality. But instructions streamed over 4G networks can be unreliable due to bandwidth constraints, and fail to deliver the required levels of quality without stuttering. 5G promises not only the streaming of high-quality instructions on the shop floor, but also stutter-free augmented reality that can guide people, step by step, through each individual motion they need to make. This will allow shop-floor workers to undertake advanced tasks without waiting for specialist engineers or incurring costly machine downtime. The best knowledge and work instructions can therefore be shared with all workers exactly when they need it, building worker skills more quickly, safely, and effectively than ever before. Perceptive AI eyes on the factory floor —Cameras are already common in modern factories to monitor processes and security. However, their use is limited to focused applications and often requires workers to monitor video feeds. 5G will allow the streaming of data in real time to the cloud, and the use of live video analytics. For example, a security camera could see a disturbance, identify if there is an imminent threat or danger, and dispatch a drone or alert a worker to investigate. Alternatively, the same security camera could provide a more efficient mechanism to measure cycle times and monitor process deviations.
—Cameras are already common in modern factories to monitor processes and security. However, their use is limited to focused applications and often requires workers to monitor video feeds. 5G will allow the streaming of data in real time to the cloud, and the use of live video analytics. For example, a security camera could see a disturbance, identify if there is an imminent threat or danger, and dispatch a drone or alert a worker to investigate. Alternatively, the same security camera could provide a more efficient mechanism to measure cycle times and monitor process deviations. High-speed decisioning —The best-run factories rely on vast data pools to make decisions—with inevitable delays as data is collected, cleaned, and analyzed. 5G speeds up the decision-cycle time, allowing massive amounts of data to be ingested, processed, and actioned in near real time. In several heavy industries, for example, manufacturers have been able to sell excess energy back to the grid when machines aren’t running and prices are favorable.
—The best-run factories rely on vast data pools to make decisions—with inevitable delays as data is collected, cleaned, and analyzed. 5G speeds up the decision-cycle time, allowing massive amounts of data to be ingested, processed, and actioned in near real time. In several heavy industries, for example, manufacturers have been able to sell excess energy back to the grid when machines aren’t running and prices are favorable. Shop floor Internet of Things—The addition of sensors to multiple machines means factories are creating more data than ever before. Transmission through wired networks is expensive to scale, and Wi-Fi networks can quickly get congested—as anyone who has tried to connect to public Wi-Fi networks can attest to. 5G has the ability to support high connection density with tens of thousands of endpoints, thereby truly enabling the use of industrial data at scale.
These technologies are all still at an early stage of testing, but the pilots undertaken to date are encouraging. Long-term, one of the most intriguing effects may be on the humans who work alongside 5G. Far from creating a world of lights-out, human-free factories, industrial 5G appears more likely to allow people to move away from tasks that have previously been considered dirty, dull, and dangerous. Instead, people’s focus will shift to capturing the value made possible by the vast data harvests that 5G will enable—and that 4G could not reliably and seamlessly support at scale.Wave 1: First, teams – across or within IT departments – start experimenting as agile, cross-functional teams. Daily business supporting those teams continues as usual, and overall decision-making power and responsibility remain with the line organization.
Wave 2: Once some cross-functional experiments have proven successful, the number of teams grows. Senior IT management starts to notice the advantage of faster time to market and cross-functional teams are scaled across the previously functionally oriented IT area. Project-based work starts to shift towards a continuous, product-centric flow with incremental delivery. Team autonomy increases as core value delivery to the business begins to come from cross-functional, agile teams.
Wave 3: As the teams mature, their prime focus becomes the delivery of end-to-end customer value. This requires experts across departments to work together, driving expansion of the model outside IT. When project scope and responsibilities cross departments, it quickly becomes clear that existing organizational structures and processes inhibit progress and that value-centric teams drive decisions and deliver value more autonomously across department boundaries. Business and IT grow more intertwined as complementary skill sets are needed in teams, depending on the technical depth of the product.
Wave 4: Once executive management has fully understood the value of cross-functionality at scale, these principles are reinforced on strategic levels. New organizational structures emerge; teams form around products based on the required skills. The organization’s middle management disappears as line managers become redundant to entirely decentralized, collective decision mechanisms. Interdisciplinary teams change their configurations when needed to respond to changing customer or market demands.
Even though the core of organizational delivery will change fundamentally, not all decisions can be made by these cross-functional teams. Like agile ways of working, cross-functionality is not the “silver bullet” that solves all future organizational challenges. Firms need to carefully consider the fit of a cross-functional team for each product and implement this transformation case by case. Cross-functional teams may perform better in highly dynamic, technology-driven environments. In line with the well-known Stacey matrix, cross-functional teams reach their fullest potential in complex environments where future requirements, methods and technologies are far from certain. In other situations, however, the conventional structure of teams as specialized functional units may prove more effective. Companies will have to experiment with different models to find the best structure. Central corporate strategy, governance and overall orchestration among teams will still be required. Furthermore, units that are highly driven by regulatory requirements and legal policies will be difficult to transform and will likely remain as they are today. Finally, depending on the maturity of the cross-functional teams, dedicated specialist services and (central) support functions may still be required; these can be pooled, deployed or integrated into existing cross-functional teams as needed.For many organizations, surviving and thriving in today’s environment depends on making a fundamental transformation to become more agile. Those making the transition successfully are achieving substantive performance and health improvements: enhanced growth, profitability, customer satisfaction, and employee engagement.
More than any other factor, the key to a successful agile transformation is for leaders, particularly senior leaders, to develop substantially new mind-sets and capabilities. This article summarizes our guide, Leading agile transformation: The new capabilities leaders need to build 21st-century organizations (PDF–765KB), to readying leaders for agile transformations.
Before we dive deep, it’s useful to take a broader view of agile, and particularly what sets agile organizations apart from traditional ones.
Simply put, the dominant traditional organization model evolved primarily for stability in a well-known environment. It is based on the idea of an organization as a machine, with a static, siloed, structural hierarchy that operates through linear planning and control to execute one or very few business models.
Agile organizations, viewed as living systems, have evolved to thrive in an unpredictable, rapidly changing environment. These organizations are both stable and dynamic. They focus on customers, fluidly adapt to environmental changes, and are open, inclusive, and nonhierarchical; they evolve continually and embrace uncertainty and ambiguity. Such organizations, we believe, are far better equipped than traditional ones for the future.
While there are many different forms of enterprise agility, they share some common trademarks. We have identified and enumerated these in a related article, “The five trademarks of agile organizations.”
This new kind of agile organization requires a fundamentally different kind of leadership. Recent research confirms that leadership and how leadership shapes culture are the biggest barriers to—and the biggest enablers of—successful agile transformations.
Organizations must therefore begin by both extending and transcending the competencies that made their leaders successful in the past. Leaders need three new sets of capabilities for agile transformations. First, they must transform themselves to evolve new personal mind-sets and behaviors. Second, they need to transform their teams to work in new ways. Third, it’s essential to build the capabilities to transform the organization by building agility into the design and culture of the whole enterprise.
To fully transform yourself, several shifts will be necessary—and leaders will need to make these changes in a disciplined way.
Changing our mind-set—or adjusting it to the new context—is no easy task, but developing this “inner agility” is essential in releasing our potential to lead an agile transformation.
Reactive, or socialized, mind-sets are an outside-in way of experiencing the world based on reacting to circumstances and other people. Creative, or self-authoring, mind-sets are an inside-out way of experiencing the world based on creating our reality through tapping into our authentic selves, our core passion and purpose.
Research shows that most adults spend most time “in the reactive,” particularly when challenged, and as a result, traditional organizations are designed to run on the reactive. To build and lead agile organizations, however, leaders must make a personal shift to run primarily “in the creative.”
There are three fundamental reactive-to-creative mind-set shifts we have found critical to foster the culture of innovation, collaboration, and value creation at the heart of agile organizations:
From certainty to discovery: fostering innovation. A reactive mind-set of certainty is about playing not to lose, being in control, and replicating the past. Today, leaders need to shift to a creative mind-set of discovery, which is about playing to win, seeking diversity of thought, fostering creative collision, embracing risk, and experimenting.
From authority to partnership: fostering collaboration. Traditional organization design tends towards siloed hierarchies based on a reactive mind-set of authority. The relationship between leaders and teams is one of superior to subordinate. Designed for collaboration, agile organizations employ networks of autonomous teams. This requires an underlying creative mind-set of partnership, of managing by agreement based on freedom, trust, and accountability.
From scarcity to abundance: fostering value creation. In stable markets, companies maximize their shares at the expense of others. This win–lose approach reflects a reactive mind-set of scarcity, based on an assumption of limited opportunities and resources. Today’s markets, however, evolve continually and rapidly. To deliver results, leaders must view markets with a creative mind-set of abundance, which recognizes the unlimited resources and potential available to their organizations and enables customer-centricity, entrepreneurship, inclusion, and cocreation.
While these mind-set shifts might be new and require a significant “letting go” of old beliefs and paradigms, collectively, they form a very disciplined approach to leadership. And because of inherent autonomy and freedom, leadership in agile organizations comes from a self-disciplined approach—leading not in fear of punishment or sanction but in service of purpose and passion.
How might leaders help teams work in new and more agile ways? And what does this new way of working require of leaders? There are three essential leadership requirements that follow from all agile ways of working.
First, leaders must learn to build teams that are small, diverse, empowered, and connected. Second, leaders must allow and encourage agile teams to work in rapid cycles to enable them to deliver greater value more efficiently and more quickly. Third, leaders must keep agile teams focused on the external or internal customer and on creating value for customers, by understanding and addressing their unmet, and potentially even unrecognized, needs.
We have found that in addition to being able to lead in this new agile way of working, it is important for leaders to understand the key elements of two other relatively new disciplines: design thinking and business-model innovation.
Originating in industrial and other forms of design, design thinking is a powerful approach to developing innovative customer solutions, business models, and other types of systems. This begins with understanding the entire customer experience at each stage of the customer journey.
In organizations that are agile, each team is viewed as a value-creating unit, or as a “business.” These teams pursue business-model innovation at every opportunity, seeking new ways to meet the needs of their internal or external customers and deliver more value to employees, investors, partners, and other stakeholders.
The first distinctive organization-level skill leaders need to develop is the ability to distill a clear, shared, and compelling purpose—a north star—for their organization. Rather than the traditional executive-team exercise, in agile organizations, leaders must learn to sense and draw out the organization’s purpose in conversation with people across the enterprise.
The second organization-level skill leaders need to develop is the ability to design the strategy and operating model of the organization based on agile-organization principles and practices. Most senior leaders of traditional companies have a well-honed skill set in this area that reflects traditional organization design as a relatively concentrated, static system: one or a very limited number of major businesses, each with a long-established business model, typically coexisting somewhat uneasily with a set of corporate functions.
To design and build an agile organization, leaders need a different set of skills based on a different understanding of organizations. They must learn to design their organization as a distributed, continually evolving system. Such an organization comprises a network of smaller empowered units, with fewer layers, greater transparency, and leaner governance than a traditional model. More specifically, leaders must learn how to disaggregate existing large businesses into a more granular portfolio; transform corporate functions into a lean, enabling backbone; and attract a wide range of partners into a powerful ecosystem.
The third organization-level skill leaders need to develop is the ability to shape a new culture across the organization, based on the creative mind-sets of discovery, partnership, and abundance and their associated behaviors.
Given the openness and freedom people experience in an agile organization, culture arguably plays an even more important role here than in traditional organizations. To shape this culture, leaders must learn how to undertake a multifaceted culture-transformation effort that centers on their own capabilities and behaviors. This includes the following steps:
fostering understanding and conviction in a highly interactive way, through sharing stories and being inspired by the energy and ideas of frontline teams
building new mind-sets and capabilities across the organization, including among those who do not formally manage people, and weaving learning into the fabric of daily activity to become true learning organizations
Many organizations start their agile pilots in discrete pockets. Initially, at least, they can build agile-leadership capabilities there. But to scale agility through an organization successfully, top leaders must embrace its precepts and be willing to enhance their own capabilities significantly. Eventually, a full agile transformation will need to encompass building the mind-sets and capabilities of the entire senior leadership across the enterprise. To do this in an agile way, five elements are essential:
Build a cadre of enterprise agility coaches, a new kind of deeply experienced expert able to help leaders navigate the journey, supported by a leadership-transformation team. Get the top team engaged in developing its own capabilities early on, as all senior leaders will take their cue from the executive team. Create an immersive leadership experience (anything from a concentrated effort over three or four days to a learning journey over several months) to introduce the new mind-sets and capabilities, and roll it out to all senior leaders. Invite leaders to apply their learning in practice, both in agile-transformation initiatives already under way and through launching new organizational experiments. Roll out the leadership capability building at an agile tempo, with quarterly pauses to review the leadership experiences, experiments, and culture shifts over the past 90 days, and then finalize plans and priorities for the next 90 days.
Agile transformation is a high priority for an increasing number of organizations. More than any other factor, the key enabler to a successful agile transformation is to help leaders, particularly senior leaders, develop new mind-sets and capabilities. Doing so in an agile way will enable the organization to move faster, drive innovation, and both adapt to and shape its changing environment.
Download Leading agile transformation: The new capabilities leaders need to build 21st-century organizations, the full report on which this article is based (PDF–765KB).Many companies have accelerated application development by adopting agile principles and modern software-engineering best practices, such as automated testing. Yet it remains uncommon to apply these methods and tools to IT infrastructure and operations, even though doing so presents opportunities to increase productivity and the pace at which digital products and services are brought to market. The typical IT infrastructure organization continues to emphasize stability over speed. Requests for infrastructure services still often go through an assembly line-style process involving many handoffs, long delays, and frequent misunderstandings.
Traditional IT infrastructure processes made sense in the past. But now that the latest technology advances have eliminated the need for manual configuration work and consumers expect to interact with companies digitally, it has become essential for companies to modernize their IT infrastructure organizations, thereby accelerating IT deployments and shortening time to market for technology projects. Four shifts can enable IT infrastructure organizations to operate in a more agile and efficient manner. The first of these shifts involves managing infrastructure much as application developers manage code, by using software to configure environments in a swift, reliable way. The other three are organizational: forming cross-functional teams (or “squads”) of well-rounded infrastructure engineers that work using agile methods, simplifying processes for delivering infrastructure service offerings, and improving how infrastructure teams and development teams work together.
Using an agile transformation to modernize an IT infrastructure organization isn’t easy, but it is worthwhile. In our experience, agile approaches can enable IT infrastructure groups to boost their productivity by 25 to 30 percent in six to 18 months, depending on the size of the organization. The gains can increase further as automated solutions are built and fully adopted. Additional benefits often include improved infrastructure service delivery and shortened time to market for digital products and features. In this article, we explore how infrastructure organizations can modernize themselves using agile methods, starting with a glimpse of what the shift looked like at three companies. We also provide a look at the four shifts described above, along with practical recommendations for how to get the transition under way.
Three companies demonstrate how unique approaches to agile transformation, based on similar principles and tailored to their needs, can help modernize their IT infrastructure organizations while improving performance significantly. At a large provider of software and services, the infrastructure staff of several thousand people managed a global footprint capable of handling millions of active users and thousands of log-ins a second. The processes that the company had used to provide infrastructure services had grown more complex and labor intensive as the company grew, so it could take months to bring new products and features to market.
When the company’s IT infrastructure leaders modeled the effects of applying agile methods to their organization, they saw an opportunity to improve productivity by 20 to 25 percent in 12 to 18 months. Given the scale of the infrastructure group, the leadership team chose to roll out agile ways of working over that span of time iteratively, launching about 150 agile teams to bring new methods and technologies to the entire company. The leadership had teams focus first on improving the infrastructure department’s internal operations by simplifying and automating processes and then on developing self-service tools and application programming interfaces (APIs) that could be used more broadly.
A European financial-services company with a far smaller IT infrastructure organization also recognized that traditional processes for building and managing infrastructure were slowing the release of digital products and services, as well as the adoption of more efficient, sophisticated application-development practices and tools. This company too set out to introduce agile methods and to implement highly automated infrastructure service offerings within its organization. However, its approach was to roll out a new agile operating model to its entire infrastructure organization at once instead of iteratively, as the software-and-services company did. The company also chose to focus from the start on building an operating model and tools that would empower developers to manage the operations of their applications directly.
Another business—a large US-based financial-services company—also adopted an agile approach in its 250-person IT infrastructure & operations group. Like the European financial-services company, it rolled out a new agile operating model to its entire infrastructure organization at once. However, the company chose to focus initially on improving its processes. In six months, it completed a transformation that cut IT costs by more than 35 percent and doubled overall productivity. With the new operating model in place, the company now plans to focus on automating up to 80 percent of its operations work.
Despite the differences between their transformation approaches, these companies followed many of the same principles. In the sections below, we’ll explore those principles in four areas: technology, organization and talent, processes, and collaboration with developers (exhibit).
Exhibit We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
One reason traditional infrastructure organizations operate slowly is that their technology systems require teams to configure infrastructure manually for each new application. To bring agility to the infrastructure function, companies can not only eliminate manual work by building automated systems that allow infrastructure to be defined by software but also provide “guardrails” that enable application-development teams to manage more of their own operations safely. And while it’s possible to build such systems with existing infrastructure, automation becomes easier as a company moves more of its infrastructure onto modern platforms, especially cloud platforms offering a wide array of enabling tools and technologies.
At the software-and-services company, even though the infrastructure team had standardized much of the hardware and virtualization architecture, it still spent a lot of time creating custom virtual-machine and operating-system configurations for product-development teams. Solution engineers reviewed the needs of each application with its developers and then set up the necessary environments, which often involved performing many steps manually.
As part of the company’s agile transformation, agile infrastructure teams implemented automated solutions to streamline the provisioning and configuration of servers. One agile team built and maintained a centralized platform that automated the provisioning of servers and could be accessed through self-service tools. Other agile infrastructure teams, each aligned with specific software-as-a-service (SaaS) products, automated the configuration of those servers for the products they supported, using a configuration-management tool to define the servers’ configurations entirely in code. This change reduced build times for environments from several months to about ten minutes. After these solutions were implemented, whenever a cluster of servers had to be updated or expanded, teams could make the necessary changes rapidly, with minimal manual effort and risk of error.
The European financial-services company chose to automate its IT infrastructure offerings using similar technologies. As part of a broad push to adopt DevOps principles, it also sought to empower application developers to manage their own operations as much as possible. IT infrastructure squads built automated, self-service infrastructure solutions for application developers and taught them how to use those solutions. Developers could then, for instance, produce code to tell the system how to configure or update servers given the unique requirements of their applications.
At traditional companies, infrastructure organizations have long been structured around teams with narrowly defined responsibilities for specific technical functions (for example, managing relational databases or operating systems) or stages of the plan-build-run IT service life cycle. Neither this structure nor the specialization it promotes is conducive to efficiency or agility, because multiple teams must typically work on each service request. To become more agile, infrastructure organizations can organize their staffs into small cross-functional teams focused on providing well-defined services. They can also develop modern workforces of well-rounded engineers who can learn new skills rapidly and work across multiple functional domains to carry out the end-to-end delivery of infrastructure services, as we describe below.
CIOs and technology leaders should bear in mind that engineers in agile infrastructure organizations typically need more diverse skill sets than application developers do. For infrastructure, that makes agile transformations more challenging. The infrastructure organization at the European financial-services company found some of the well-rounded infrastructure engineers it needed by carefully screening existing employees. The most capable ones were offered roles on infrastructure squads charged with building the highly automated self-service solutions described above.
At the software-and-services company, the leaders of the infrastructure group chose to organize their staff into skill-focused “chapters” to help with capability building, professional development, and standard setting. Chapter leaders determined which new skill sets their areas needed and were asked to develop training or hiring plans to meet those needs. For working purposes, the company organized everyone from those chapters into two types of cross-functional agile squads led by product owners who defined and prioritized the backlog of activities that their squads would work on. Infrastructure squads focused on developing highly automated foundational infrastructure solutions (such as server provisioning) that other teams could use to set up, manage, and decommission infrastructure. Product squads were aligned closely with specific SaaS product-development teams and worked to engineer and automate hosting and operations for their applications, leveraging services from infrastructure squads when available.
The traditional IT infrastructure organization’s functionally oriented structure imposes a particular working style—specialized resources complete tasks in a prescribed order, with many handoffs between groups. This working style causes innumerable delays: every time a request is passed to a new group, it goes to the bottom of that group’s task list, where it might languish for days. Frequently, tasks are sent back to previous groups for clarification, increasing wait times even further.
Companies can eliminate many of these delays by creating small cross-functional teams as described in the previous section. Such teams can minimize or even eliminate process handoffs by managing the end-to-end delivery of specific service offerings. They should be empowered not only to deliver service offerings but also to improve their delivery by streamlining processes and engineering fully automated solutions.
The processes of the software-and-services company’s infrastructure group had become increasingly complex as the company grew and added new customer-facing products. That led to the use of project coordinators to help push service requests through the organization. After the company grouped its infrastructure engineers into agile squads, however, the waiting periods that had previously followed handoffs among functional groups vanished. That change alone halved the amount of time required to provide many core service offerings. The company’s squads also redesigned common processes to simplify workflows or eliminate unnecessary steps, such as certain approvals. The number of steps in virtual-server provisioning, for example, was cut by more than two-thirds, and the remaining steps were then largely automated through better engineering.
By contrast, the US-based financial services company mentioned earlier took a different approach to compensate for the limited development skills of its infrastructure organization. First, it set up cross-functional squads to simplify processes without automation. The resulting productivity gains bought employees enough time to learn more advanced engineering skills. Then they began planning the development of automated capabilities to address common requests.
Traditional infrastructure organizations have minimal interaction with application-development teams. Collaboration between the two camps is normally limited to the initial setting up of systems for new applications and the resolution of critical incidents. As a result, typical infrastructure engineers know too little about each of the applications they support to help improve the stability of those applications. Moreover, developers lack the awareness of operational issues they would need to engineer robust, easy-to-support applications. Modern agile organizations, by contrast, make a point of increasing the level of collaboration between their application-development and infrastructure functions.
The European financial-service company described earlier exemplifies one collaboration style: making developers accountable for operating their applications. Involving developers in the incident-response and postoutage follow-up processes for their applications makes them more aware of issues in their application code. Involving developers in operations also encourages them to write code easy to manage and support—they can be awakened in the middle of the night if incidents occur.
The large software-and-services company demonstrates a contrasting approach. Its infrastructure organization continued to support operations for application-development teams but found a new way of doing so: closely aligning agile product squads and application-development teams. The alignment greatly increased coordination and collaboration. Many of the product squads were co-located, at least in part, with the application-development teams they partnered with. Core members of each product squad would attend some of the agile ceremonies of the application-development teams. In addition, the close alignment helped infrastructure engineers to gain familiarity with the applications they managed, so they had a stronger attachment to the success of those applications, which could now be better monitored and supported.
In our experience, the challenges of modernizing IT infrastructure using agile can be overcome using a structured approach to designing, launching, monitoring, and enabling agile teams. (At larger organizations, applying that kind of approach in waves can help the transformation get under way quickly.) This can be effective as part of a broader effort to transform a company with agile methods, or as an effort that is solely focused on the IT infrastructure group. Either way, the key steps in structuring an agile transformation of an IT infrastructure function are as follows.
1. Create a vision for the new infrastructure organization, particularly how the organization should operate and how quickly it should evolve. Several key questions will help IT and business leaders to define their vision for the organization.
What infrastructure service offerings should the organization provide to application developers and business users? Establishing a catalog of infrastructure service offerings helps companies to design and define the scope of agile teams and to decide which of them should own the tasks of delivering and improving those services.
How should the infrastructure organization collaborate with application developers and how should the interaction model evolve over time? Teams that are closely aligned with application-development teams can be beneficial if the infrastructure organization has responsibilities related to operating applications (for example, deploying code).
How quickly should the organization push to engineer automated solutions and adopt cloud technologies? The structures, processes, and skills of agile teams that focus on operations can be very different from those that focus on engineering infrastructure offerings.
How will infrastructure leaders and business executives gauge the efficacy of the transformation? Going into an agile transformation of the infrastructure organization, business and IT leaders should set clear objectives for improving performance and value creation, so that they can track progress and results with well-defined measurements.
2. Segment and prioritize opportunities with respect to the potential to create value for the organization. It is important to assess demand for infrastructure by developing a data-driven understanding of past consumption patterns and projected future needs. Knowing how much work is involved in delivering specific infrastructure offerings helps with organizing the work into scopes appropriate for an agile team. If, for instance, demand for storage-related work calls for a workforce of 24 people—too many for a single team—the effort might be divided among two teams: one focused on block storage and another on file storage services.
Analyzing demand can also help with identifying the greatest opportunities for improving efficiency and with prioritizing the rollout of teams accordingly. For example, a company can realize a great deal of value in a transformation by assigning the first agile infrastructure teams to handle and improve frequently performed labor-intensive services.
3. Design each agile infrastructure team to match the focus of each team with the working methods it will use. Teams focused on developing automated infrastructure service offerings tend to be relatively small—typically with eight to 12 people. They usually find that they work best using the scrum methodology, developing solutions in two- to three-week development sprints. Teams focused mainly on operations (such as level-one support teams) might benefit from longer rosters of up to a couple of dozen people. These teams often use the kanban or scrumban methodologies, which are more appropriate for managing a continuous flow of unplanned or event-driven work.
Over the long term, it is often preferable to have the same infrastructure team own both the planned development work and the unplanned operational work for a specific offering. This approach encourages teams to identify operational issues and fix them. However, at the beginning of an agile transformation, separating out unplanned operational work can help newly established infrastructure teams to focus on engineering highly automated solutions.
4. Create a structured process for rolling out agile infrastructure teams. The process should give all the people involved enough time to prepare for the launch of their teams. Our experience shows that it is critical to provide time and guidance to train team members, develop a strong team charter, align key stakeholders, and build out an initial backlog.
At the software-and-services company, for example, before each agile squad launched, its product owner and scrum master received two days of role training on how to perform their new roles. They then completed a six-week self-organized program, facilitated by agile coaches, in which they designed their teams’ vision, scope, objectives, performance metrics, minimum viable product for improving delivery, and composition. Product owners also had to identify their key stakeholders up front and to review their plans with them and with the sponsors of the transformation so that everyone was aligned. Once the product owner and scrum master had finished these steps, the agile coach would lead the full team through a one-week “sprint zero,” when it received training on agile and built out an initial backlog of work. After the sprint zero, the agile coach attended key ceremonies during the first several sprints of the team to make sure it was stable.
5. Focus on the sustainability of the transformation. Soon after agile infrastructure teams have been launched, governance bodies (such as a committee composed of senior IT leaders) will probably be needed to ensure that the teams are advancing toward their goals, refreshing their objectives as the organization’s priorities change, and improving their use of agile practices. In addition, many infrastructure organizations quickly discover a range of opportunities to build on the agile transformation’s initial improvements. These include revising career models to support new agile roles, adopting more flexible budgeting processes, and making strategic planning more agile.
Addressing these improvement opportunities will take time, but senior IT infrastructure leaders can handle the work by using the same methods their newly launched teams do. They can organize themselves as a team, create a backlog of opportunities, determine priorities, assign owners, and carry out the work in sprints.
Legacy IT infrastructure processes common at companies that weren’t “born digital” can impede the rapid delivery of new digital products and features. Agile methods can speed up the process significantly, and the benefits often start to materialize within the first six months of an agile transformation. A modern IT infrastructure organization that collaborates closely with developers and uses automation to accelerate configuration and maintenance can greatly boost its own performance, along with that of the wider company. For incumbents facing the threat of disruption from digital challengers, this can help make the difference between success and obsolescence.January 3, 2020 The ten most popular McKinsey.com pieces of the last year, taken from the hundreds of articles, reports, blog posts, and podcasts that we published in 2019, reflect the hopes and anxieties of business leaders in every sector: hope for a better meeting, a better mindset, a more agile organization; anxiety over the future of work in America, globalization, the energy transition, blockchain, and more.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
How can senior managers get better, faster business decisions from meetings? Here are the three questions they should ask with every calendar invitation.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Where is blockchain headed? This piece offers a hard-nosed look at the blockchain ecosystem as doubts have emerged about the technology’s true potential.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Debates about tariffs have obscured how globalization has changed. Trade intensity is down, and the flow of services and data play a more important role that isn’t fully captured by how we measure economic growth.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
McKinsey Global Institute’s blockbuster report looks at who will be most affected by emerging workforce shifts and how policymakers can choose to create more inclusive growth.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
A guide to how the best CEOs think and act, based on our proprietary performance database and decades of firsthand experience counseling thousands of CEOs.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Navigating an organization to an agile operating model isn’t easy. This guide describes every element of the transformation that needs to occur.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
This podcast interview explores how leaders can apply structured problem solving to work through the most complex questions we face in any sector.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
What exactly is the energy transition, and what will it look like in the coming decades? This is an essential piece about a sector that’s changing rapidly and how those changes will transform many aspects of our lives.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
On top of everything else they do, Meg Whitman, Doug McMillon, Salman Khan, and other CEOs share what they’re reading for pleasure and self-improvement.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Any company can operate like a tech company – if its IT department can become an enabler and driver of continuous innovation and adaptation.Enterprise resource planning (ERP) solutions are a fundamental asset for most large companies, yet ERP transformations remain time-consuming and complex. An agile approach has the potential to dramatically streamline ERP projects, but IT professionals have long believed agile to be incompatible with ERP. Our experience in helping many organizations adopt agile practices in a wide variety of situations, however, has proved the opposite: that agile can successfully be applied to ERP programs, with quantifiably better results. The methodology simply has to be adapted to the unique requirements of these complex solutions.
Large ERP solutions have slipped to the bottom of IT management’s agenda to make room for trendier topics, such as digital, big data, machine learning, and cloud. But the business benefits of ERP solutions—namely, the enablement of seamless, end-to-end integration across functions and the process standardization across geographies and business units—make them a fundamental asset for most large companies. Moreover, the next generation of ERP solutions, such as Oracle Cloud and SAP S/4HANA, offer even more promising capabilities, both functionally and technologically. Companies focusing on digital transformation or advanced-analytics programs are beginning to realize that, to unlock the full potential of their investments, linking the new technologies to their ERP base is essential.
As fundamental as they are, three-fourths of ERP transformation projects fail to stay on schedule or within budget, and two-thirds have a negative return on investment. There are five main reasons (Exhibit 1).
Exhibit 1 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
First, all parties may not share the same objectives. For example, a system integrator may have the incentive to increase the program’s scope and duration if it makes more revenue from a complex integration. The company, meanwhile, wants to deliver the project and capture its value as soon as possible.
Second, most organizations lack experience in managing major IT projects and multivendor programs. They do not have enough skilled managers, have never set up rigorous governance for such programs, and fail to understand the level of input needed from business sponsors.
Next, ERP systems cover a vast, integrated, functional scope and thus require complex discussions with the business on operating models, data management, and validation rights. These decisions tend to come up mid-program and require executive-committee-level input based on information that is not yet available. The project must often pause for these decisions to be made, slowing progress and even undermining the initiative’s value.
Fourth, activities and deliverables tend to drive ERP transformations; instead, the transformation should be based on business value, which must be quantified, documented, and monitored to drive the program.
Last, most ERP projects are undertaken using a linear, sequential waterfall approach, which delays the project’s realization of value.
These challenges often cause ERP implementations to drag on for five or even ten years. The typical implementation involves long phases of design, specifications, and blueprinting but yields no measurable impact—while shareholder value diminishes, day after day.
The myth that agile methodology cannot be applied to ERP implementations is based on several misconceptions: that an ERP implementation is too big and complex to be managed and delivered by small agile teams, meaning that highly integrated, intricate ERP requirements cannot be broken down into vertical user stories that can be developed and tested in the short sprints that define agile delivery; that ERP is a standardized software, and that hence an agile approach—which is designed for constantly changing or unknown requirements—is not needed or applicable; and that an ERP solution cannot be shown incrementally to end users, as they will not be able to perceive any value before it is fully built and integrated.
In truth, agile practices can greatly mitigate the risks and challenges that plague typical ERP implementations in a number of ways. Agile has, for example, vendors and system integrators work together as one end-to-end team focused on the same set of key performance indicators (KPIs) and outcomes.
It involves a faster pace and greater transparency, making it easier for managers to make timely, critical decisions. Contrary to popular belief, agile does not mean “no planning”—rather, agile replaces long, opaque project phases with two- to three-week sprints so that managers can track outcomes, progress, and challenges.
Agile calls for the business and IT groups to be integrated into the project team, which is structurally geared toward value creation. These two groups collaborate from the project’s beginning, fostering agility for both.
And agile helps to break down the functional scope of ERP into a smaller set of features that small teams can deliver in sprints. This iterative approach helps projects to realize business value quickly.
In short, agile practices are exactly what is needed to manage ERP implementations. It should be no surprise that leading ERP vendors, such as SAP, are now promoting a more agile approach.
Some agile practices can be directly applied to ERP implementations without adaptation: forming small, end-to-end, cross-functional agile teams, with dedicated product owners from the business and end users; working in short cycles of two to three weeks to produce working software (or configurations, interfaces, et cetera) incrementally; adopting scrum-based ceremonies focusing on continuous improvement, with transparency facilitated by the ceremonies and KPIs; and using tools and technologies—such as test automation and continuous integration—that optimize and accelerate the delivery process.
Other agile practices, however, need to be adapted further. For instance, the project’s entire scope must be defined up front at a high level to include clear success criteria, as opposed to agile’s more common approach toward a minimum viable product. Teams should be allowed, however, to refine the detailed scope and to set priorities as they go along.
In addition, to ensure consistent development, more work must be done on the business process and architecture than in the typical agile implementation, so that the work can be split among small teams.
Strong linkages are needed between the agile teams delivering functionalities and the “transversal” teams, which are nonfunctional teams—for example, the data-migration team, the integration team, or the change team that support the functional or feature teams. All teams should be synchronized so that they work in the same rhythm and meet the finish line together.
“Production ready” software cannot be delivered as frequently as in typical agile software development. A phase of end-to-end (E2E) testing and cut-over is needed to consolidate the increments delivered by individual teams and to test complex interfaces with legacy systems; this often takes longer than one sprint to complete.
Finally, a strong agile program management office (PMO) should be added for faster resolution of issues and cross-team decision making.
A classical ERP implementation has four stages: developing an ERP strategy and road map, setting up the program, implementation, and deployment. Each stage can be adapted for agile delivery.
Developing an ERP strategy and road map results in a target architecture with high-level principles and a business case to implement the new solution. This stage remains largely unchanged, but it can be accelerated by doing a rapid fit-gap analysis at a high level, rather than endless blueprinting, and by working iteratively in sprints—to avoid an overly detailed business case. Product owners should be brought on board and empowered to make key decisions from the beginning, and smaller, cross-functional teams should be set up to achieve program goals.
Setting up the program changes substantially in an agile approach; it is much faster, primarily because the teams are empowered to quickly tackle real-life difficulties instead of engaging in theoretical design. This stage includes rapidly selecting a partner that has experience with the solution and agile—as opposed to engaging in a lengthy request-for-proposal process to try to find a supplier and negotiate a fixed-priced contract; building a high-level, macro-feature road map, based on a list of identified improvements, that is detailed enough to determine the size and form of the agile organization needed to deliver the program; staffing and training the organization in agile ways of working; and establishing a strong PMO that will coordinate the functional and nonfunctional workstreams.
Implementing the solution is dramatically different in an agile approach. Implementation happens in several waves to quickly capture value. Functional delivery teams adopt most of the typical scrum practices. End-to-end teams of eight to ten people, from both a company’s business and IT and from the system integrator, complete design, development, and system testing in two- to three-week sprints. E2E testing and user-acceptance testing (UAT) are conducted at regular intervals—as opposed to only once at the end of the development—resulting in better code quality and ongoing test automation. Nonfunctional work (for instance, data migration, training, and deployment) is less affected by the agile approach, although close coordination is needed between functional and nonfunctional teams; for example, because data are required early for frequent functional testing, the data migration team must gather the data to populate the testing environment. Nonfunctional testing and the cut-over phase remain the same as in a classical implementation.
Sidebar How a logistics company used agile for its ERP transformation One of the largest shipping and logistics providers in Europe embarked on a multiyear core-technology transformation. The program’s goal was to replace the old enterprise resource planning (ERP) system with up-to-date technologies and to provide new functionalities. A few years in, the program was fraught with multiple challenges and lacked a business case, business ownership, and robust vendor and program management. Also, the scope was too large and complex to be delivered in an effective and sequential waterfall manner. To get the program back on track, the company focused on three steps: (1) rescoping the program around the most valuable elements, (2) designing and implementing an agile ERP delivery methodology, and (3) establishing a rigorous PMO. To enable agile delivery, a new agile operating model was designed for 300-plus full-time-equivalent (FTE) employees by aligning numerous stakeholders—including business and IT internal clients, the ERP vendor, the company’s system-integration partner, the onshore- and offshore-development partner, and the infrastructure partner. The FTEs and the program were then transitioned to agile delivery at an accelerated pace. To do so, the FTEs were first reorganized into six functional domains, that consisted of 11 cross-functional agile teams, focusing on such tasks as developing and integrating the product catalog. There were six transversal domains with about 15 teams focusing on areas such as data migration and electronic data interchange (EDI). Next, a detailed agile approach was designed to consider ERP specificities, and the new organization was trained and coached in this new approach. The agile PMO steered the program, supported agile ceremonies for the overall project, solved complex issues, facilitated the swift removal of any impediments, and implemented a new backlog management and tracking tool. The application of agile to this ERP implementation resulted in several significant benefits: Enhanced transparency. The project teams put their macrofeatures (“epics”) into a work-flow-management tool that attached each to the increment or sprint in which it was to be delivered. At the end of every sprint, progress was measured, in the number of user stories and story points delivered, and of the entire project, in the number of epics delivered and analyzed. Because of this transparency, the teams could measure and take ownership of their progress, which enabled them to rapidly correct their course using agile retrospectives as a tool. The teams were also able to promptly escalate any impediments to their managers. The managers enjoyed an unprecedented level of transparency; they could now see the duration, cost, and causes of delays each week and take swift action. Moreover, knowing the project’s precise status on an ongoing basis allowed the product owners and leadership to make informed decisions about what to prioritize based on value.
Strong coordination among teams. To foster coordination and communication among teams, the process began with increment planning with all teams—both functional and transversal—together in one room. Then, at the start of every sprint, each team gave its input to the other teams on dependencies. Functional and transversal teams had biweekly huddles. From there, issues were escalated to the weekly “war room,” where all teams met to discuss dependencies and performance.
Rapid, targeted troubleshooting. The PMO, comprising roughly 12 to 15 people, in addition to performing classical activities, served as a SWAT team that could address complex issues on an ad hoc basis. Almost half of the PMO’s work focused on troubleshooting, such as scenario building to assess the impact of a delay in delivering a large interface; building a complex, CEO-ready document about rescoping; providing extra analytical capacity to plan 3,000 test cases; and reorganizing the full operating model as needs evolved—for example, merging functional teams after rescoping and building an efficient test factory based on lean principles.
Agile organization. The 11 agile teams had the capabilities to deliver an end-to-end solution, including business representation. Their three-week sprints included development, solution testing, and a demonstration to end users at the end of each sprint. In addition, at the end of each increment (or three-sprint period), comprehensive, end-to-end solution- and user-acceptance testing was performed to ensure the quality and integrity of the functionality delivered. The teams followed all scrum-based ceremonies and began to realize benefits after only a few weeks.
A detailed agile playbook. The agile approach—which was tailored to the company and ERP—was documented in detail in a playbook that remained a living document throughout the program. The playbook included elements such as how to translate traditional ERP requirements into epics and user stories to create a product backlog, as well as project documentation that was adapted to agile—for instance, simplified technical specifications, since developers were working directly with product owners and analysts, and new terminology, such as the definition of “ready and done.” As a result, the program was able to meet and even exceed its performance targets. Delivery was 20 percent faster than the previous estimate. This was a result of far less rework due to iterative improvements made by working with end users to inspect and adapt each iteration. It was also a result of the ability to better manage project delays, which made them less likely to affect the overall timeline because of the use of intermediary deadlines and having an incremental scope. Additionally, fewer bugs were found by using integrated, end-to-end, and user-acceptance testing for the agile release—as opposed to the two previous waterfall releases—and by conducting more-frequent testing. The scope delivered was three to ten times greater than in previous releases of similar durations, due to better alignment among functional teams. User acceptance of the new solution was much higher, as users were involved throughout the implementation. Finally, the agile team’s morale improved significantly, as measured during agile retrospectives, which contributed to the delivery’s success. Since the project began, more than 100 people have now been trained in the agile mind-set and ways of working, resulting in a new operating model for the company, which reflects the realized benefits of the agile approach—and ultimately disproving the myth that agile does not apply to ERP.
To illustrate, one company undertaking a transformation reorganized people into 26 teams. Of these, 11 were end-to-end, cross-functional agile teams delivering features, while 15 others were transversal teams that supported the agile teams. All agile teams included the capabilities required to deliver an end-to-end solution, including business representation (see sidebar, “How a logistics company used agile for its ERP transformation”).
Deploying the solution largely follows the classical approach, but deployments occur more frequently, and agile practices can help to remove bottlenecks. A “deploy all development rapidly” mind-set can mitigate early deployment risk, analytics can help to optimize the process (for example, the number of “key users” to be trained), and local templates can be designed early by onboarding local users. A shorter hypercare phase can be planned because of the continuous focus on quality. Since releases are more frequent in an agile approach, there is more opportunity to industrialize all steps in the deployment.
It is important to note that, in an agile-adapted implementation, the initial stages are accelerated when compared with the traditional waterfall approach. Most time is spent on later stages, focusing on delivering functionalities.
Much of agile’s popularity is based on its results. Research shows that agile organizations have a 70 percent chance of being in the top quartile of organizational health, the best indicator of long-term performance. Moreover, such companies simultaneously achieve greater customer centricity, faster time to market, higher revenue growth, lower costs, and a more engaged workforce.
Specific to ERP implementation, deploying ERP in an agile way—irrespective of the underlying technology—translates into a range of tangible and intangible benefits (Exhibit 2):
reduction of program cost by 10 percent, driven primarily by having to do less rework in the E2E testing and UAT phases
increase in the program’s value by 20 percent by giving the product owner enough visibility into the project’s progress to focus on high-value items
ability to compress three times more workload into a given period through greater parallelization of functional teams
Exhibit 2 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Although ERP systems are often considered a “necessary evil,” they are here to stay and cannot be ignored as companies go digital. The traditional, often complicated approach to ERP transformation should be drastically revised and, whenever possible, adapted to include agile ways of working.
Companies and system integrators should dispense with the myth that agile cannot be applied to ERP and instead industrialize the agile approach for ERP transformation. Further, ERP solutions should become more modular so that deployment can be phased—resulting in lower costs and faster realization of value.
ERP transformations are always challenging, but these challenges can be far less daunting with an agile approach.With the rise of these frameworks, a debate has also started on whether frameworks have a place in Agile. The debate was that frameworks were moving back to a traditional way of working and the intent of Agile was to focus on the mindset and principles. At Deloitte, we have seen that a balance between mindset and practices/frameworks needs to be taken to effectively enable the change in large scale enterprise when adopting Agile ways of working.
As more and more of the business has been exposed to agile ways of working, there has been a realisation that agile isn’t just for technology. This has led to Agile being extended to core business functions such as Marketing, Legal, Sales, Operations, etc. to move towards phase (3).
A local example of this is the Australian Real estate giant REA group, where every core business function in the organisation functions in an Agile way. REA started to adopt Agile practices in late 2010 within the Technology services / Software Development group. Shortly after, the success of the technology teams led the then CIO to embed Agile practices to the whole organisation. By scaling Agile into business, organisations have realised benefits such as accelerated product delivery, ability to adapt priorities based on changing market, and productivity improvements.
(We have also seen instances where phase 2 and 3 occurred before phase 1. While this was less frequent, in some organisations Agile adoption was driven more by business functions, such as products and marketing before their IT teams were on the journey.)
As organisations have realised benefits from agile at scale, they are looking to scale these benefits now across the organisation.
Seventeen years since signing the agile manifesto, agile has moved far beyond something that is only for development teams within the technology practice and for complex program delivery. Now, in today’s quickly changing market, organisations are seeing the need to use agile ways-of-working to enable their organisation more broadly, which leads us to Enterprise Agility.
Enterprise Agility in our definition is using new ways-of-working across all elements of an organisation to enable how a business creates ideas, plans, executes, makes decisions, learns, manages risk, and empowers teams.[5]As the business impact of the COVID-19 crisis mounts, leaders in every industry are moving urgently to protect employees and build resilience. Governments are mobilizing to safeguard citizens and manage the economic fallout. Immediate action is critical, but leaders must also embrace a new agenda—one aimed squarely at what comes next.Insert Custom CSS fragment. Do not delete! This box/component contains code needed on this page. This message will not be visible when page is activated.The Life Science and Health Care Industry (LSHC) has always been in the lime light for its strict regulations. Though these regulations are cumbersome, they are deemed necessary in order to comply with patient safety and product quality. In line with the strict regulations, the traditional Waterfall Method was always used in Software Development in LSHC industry.
In recent years, the aspect of being cost –effective whilst not deviating from the regulatory framework has been repeatedly discussed.
The advent of Agile Methodology has disrupted the traditional development methods with its clear focus on continuous development, agility and over all “lean” concept.
“Agile” was introduced as a means to tackle the limitations in Waterfall and other traditional development methodologies by concentrating on continuous improvement and conducting tests in smaller iterations, all the while not compromising on the development quality of a product.Works with clients to define, develop, and implement digital solutions to succeed in an ever-accelerating world. Helps large organizations to become more agile, empower teams, create nimble structures and accelerate innovation.
September 6, 2018 As more companies go fully digital and agile, they start to look more like technology companies. No matter the product or service they offer, companies must embrace that technology is shaping our world and today’s business cannot run without IT.
CIOs can serve as catalysts by setting direction and establishing the system and infrastructure for people to do their jobs effectively in an agile organization. Their opportunity lies in becoming a product visionary, being much less of an IT manager and, instead, defining and driving strategic technology initiatives. The agile CIO is thinking constantly of creative ideas to grow and nurture talent in the organization, encouraging expertise development and further learning. And they love IT for IT’s sake.
Take one CIO, who on his time off learned new programming languages to educate the team. Another CIO organized a hackathon with programmers to recruit fresh talent. Yet another insisted all the members of the team read the classic IT book “Continuous Delivery” by Jez Humble as part of a team-building exercise.
Traditionally, CIOs manage practically everything related to information and communication technology, including policy and practice development, planning, budgeting, resourcing, and training. But in an agile organization, given the pressure to speed up innovation and land superior talent, the CIO position is redefined— a successful CIO fills three key roles:
Architect/technology visionary The CIO is in charge of IT strategy and the IT systems required to support the organization's unique objectives and goals. Analyzing how these technologies benefit the company or improve an existing business process, and then integrating a system to realize that benefit or improvement is key to this role. Responsibilities include: Building the overall IT strategy. Delivering a strong technology/product vision and influencing the direction in meaningful ways. Embracing enterprise-wide IT decisions about systems and technology. Driving strategic partnerships with business ecosystem partners, technology partners and vendors.
Driver of knowledge and talent The CIO is not only an expert in their own right, but also serves as a visionary and leader building and inspiring their team while offering opportunities to grow. Responsibilities include: Managing the workforce (hiring, firing, capability building, evaluations). Setting IT talent performance standards. Ensuring consistency of practices (including architecture, technology choices, DevOps practices, etc.).
Problem solver The agile CIO aligns the team around a vision and creates an environment that empowers colleagues to make decisions and move quickly on delivering results. Responsibilities include: Removing impediments to reach goals and leading key strategic initiatives. Working to guide, direct and give feedback to the team in real time. Ensuring the collection of squads (teams with representatives from different functions working at a single location, with interconnected missions) are working cohesively together; playing the “tribe-lead” role for some IT-enabling squads (core platforms, shared services, etc.).
In their redefined position, agile CIOs actively offer perspectives and skills beyond just technology. They grasp how to be collaborative with immediate team members, the broader organization and customers. They don’t forego their traditional role; if a critical piece of enterprise technology crashes, they must handle it. But, above all, they must possess a nimble mindset. For, in this new organizational world, the CIO could be next in line to become the CEO.​Contracting for Agile software development should focus on enabling a smooth vendor-client relationship rather than on specifying terms and conditions in exhaustive detail.
Government organizations are increasingly looking to partner with vendors who use Agile to deliver software systems. But for government to successfully take advantage of what Agile has to offer requires a change in mind-set for procurement officials.
For most things that government buys, most people aren’t overly concerned with the process of how it is made. From office furniture to computers, how the item being purchased was built doesn’t really matter.
But if you want to buy software that is developed through an Agile process, you need to alter your procurement process. The procurement officials, the lawyers, and the purchasing agency’s business leaders need to embrace a new way of thinking about their role.
Why? Because the Agile process combines design with development and user acceptance. In other words, the software’s final design emerges through a collaborative effort between developers and business users. So the traditional procurement approach, heavy on functional specifications written up front, isn’t consistent with the Agile approach.
The new mind-set of procuring for Agile involves many major shifts in thinking. Five of the most important shifts include:
The Agile Manifesto, which kick-started the Agile movement in 2001, explicitly talks about the relative value of various aspects of software development. The manifesto’s signers declared that they had come to value:
The signers of the manifesto acknowledge: “While there is value in the items on the right, we value the items on the left more.”1 Those familiar with government will quickly recognize that public procurement is strongly weighted to the items on the right.
For procurement officials looking to use Agile, this has clear and obvious implications. The contract has always been a cornerstone of public software procurement, the document that defines the relationship between a government agency and a vendor. Traditionally, a well-written contract, including detailed specifications, was seen as critical to a successful engagement.
This makes intuitive sense, and a linear, rules-based approach certainly feels safe. But experience teaches us that that feeling is often an illusion. The Standish Group’s CHAOS Report routinely shows that Agile projects have a higher success rate than linear waterfall projects, and waterfall is more likely not just to go over budget, but to fail in delivering software that works for users.2 Paper safeguards are of little use if they don’t result in successful projects. Good stewards of government focus on ensuring value from an investment. That may mean rethinking the massive requirement-laden contracts of yesteryear.
In the old contract-centric world, the contracting agency spends months, maybe years, soliciting and documenting user requirements, then “tosses” this blueprint over the wall. The vendor collects it, and many months, or years, later, delivers a final product—sometimes deeply flawed. While any number of sanctions in the contract make it appear “tough-nosed,” these sanctions may prove difficult to enforce as agencies find that the software “is what they asked for just not what they really needed.” This contract-centric approach too often leads to disappointment and disagreement.
In Agile, there is no blueprint and there is no wall. The agency and the vendor partner to build a system. The vendor’s assistance may include project management as well as the heavy lifting of development—but throughout the process the government agency actively participates, helping to ensure that the final result will meet its needs.
More than a well-written contract or massive spec document, for Agile to succeed there must be a leader at the agency with a vision for what the application is going to do: Whom does the software support? What is the business challenge being addressed? How will data enter and leave the system? The Agile process turns this vision into working software.
Agile software development requires software buyers to rethink the role of the contract. Instead of serving as the ultimate blueprint for the projects—detailed specs, precise price, firm deadlines—the contract becomes a guide for structuring the relationship between the government agency and the vendor. The shift in mind-set is profound. The agency is no longer looking to buy a “thing”—in this case a new software system. Instead, the agency is entering a relationship to jointly design and build a new software system.
Hence, the contract doesn’t primarily define the software. The contract’s main purpose is to define the expectations of the relationship. This can include pricing associated with a series of performance reviews, defining “done,” and clarifying the role of agency representatives and the vendor. One of the biggest challenges for IT vendors can be insufficient access to subject matter experts and managers empowered to make quick decisions—these should be spelled out in advance.
No builder can provide a precise fixed cost bid on a house without a highly detailed set of blueprints. The same is true when building software. Because Agile doesn’t provide precise specifications up front, it’s somewhere between difficult and impossible to calculate an accurate fixed price in advance. This means there will likely need to be some form of incremental pricing, which could entail a time and materials approach, or breaking the project into smaller chunks, or paying for “development points.”
Traditional contract management focused on the terms of the contract: Are the correct number of people on the task and are their hours properly documented? Agile leaders can still track that sort of compliance if they’d like, but more important is performance monitoring. One Agile principle states: “Working software is the primary measure of progress.”3 After every Agile “sprint,” hands-on review of the software is critical. One project manager told us, “Paper reviews are mostly worthless. You’ve got to regularly see demos of the software as it is being developed.”4 Bye-bye, Gantt charts. Hello, demos.
Agile isn’t the right approach for every project, and there is considerable variation within the various “flavors” of Agile. But for those procurement officials looking to buy software developed through Agile, a significant shift in mind-set is in order.Financial services need to shift from product to customer focus, embrace fintech and prioritize technology investments to remain competitive. To increase time to market and remove bureaucracy banks are making the radical shift to implement cross functional, customer obsessed teams and agile ways of working and focused on serving customers through life stages (e.g, help me save for my future, help me manage my lending accounts) instead of through their own products and channel structures. Early, and well publicized, experimentation within the banks in this space became a model for other industries to pursue networks of teams, new structures and ways of work. With the maturity and strength of agile capabilities within banking and insurance, financial services will continue to be a hotbed of experimentation around AO as technology, product and business teams continue to merge.April 27, 2020 Over the past several weeks, we’ve been helping leaders of all kinds get the facts on COVID-19 through more than 100 new articles that offer historical points of view, outlooks for the future, and deep dives into the economic and business implications of the pandemic.
In this post, we highlight four articles that focus on the societal side of the coronavirus equation—and offer ways forward on each issue.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Black Americans will suffer more from COVID-19 than any other demographic group when it comes to health outcomes, job losses, and economic suffering. This is due to long-established disparities—in education, in job opportunities—embedded in the communities where they live. While this article outlines the health risks for black people in America in stark tones, it also issues a call to use this crisis as an opportunity to increase the resilience of black communities and institutions, by a variety of both tried-and-true and innovative approaches. These include using analytics to help erase racial bias in testing and treatment, making an investment in telehealth solutions, and expanding broadband communications in black communities to increase access to education.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
While much of COVID-19 coverage reports on hard metrics—daily death rates, number of hospital beds, rate of unemployment—it’s critical that we also focus on our collective resilience. Almost half of Americans—45 percent—say that the coronavirus has negatively affected their mental health. This article outlines the behavioral-health crises sparked by COVID-19, including addiction, depression, and substance-use disorders, and the staggering economic and social costs associated with them. It then offers pragmatic ways to heal our spiritual psyche, such as community outreach; programs to support basic food, housing, and healthcare needs during a crisis; and innovations such as telemedicine and analytics to reach more at-risk citizens.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
COVID-19 is defining an entire generation of young adults. Waves of college students were sent home from all corners of the world in a matter of days. Many will miss out on a life milestone: graduation. Others are putting academic careers that require hands-on training, such as medicine and performance arts, on indefinite hold. All are facing what can only be described as a dismal employment outlook. This report outlines three scenarios higher-education institutions may be facing as the pandemic unfolds, and presents concrete steps they can take now to keep students and faculty safe—and keep learning alive.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
In a world fighting pandemic, is climate change still something we should pay attention to? This article argues that we simply cannot afford to do otherwise. What may help the cause going forward, the authors write, is that behavioral changes ushered in by this moment, like the rise of teleworking and virtual events, may stick in ways that mitigate the effects of climate change. Elsewhere, supply chains could be repatriated, reducing certain types of emissions that reside across businesses entire value chains. And finally, public appreciation for scientific expertise could rise, along with a greater appetite for the role of governments in tackling systemic risks.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.Corporate and business strategy have greatly evolved since BCG pioneered the fields in the 1960s and 1970s with the growth share matrix and experience curve. Today’s business leaders must match their strategies—and their strategy development approaches—to a broader range of environments. They must embrace the opportunities and disruptive potential of digital while maintaining the agility to adapt to changing conditions. Explore BCG’s latest strategy thought leadership to learn more.Topic List. Do not delete! This box/component contains JavaScript that is needed on this page. This message will not be visible when page is activated.Karel co-leads the Firm’s Operations practice and Internet of Things (IoT) group in Asia. Since joining the Firm in 1997, Karel has worked across multiple industries including advanced industries, automotive, electronics, energy and materials, technology, as well as private equity.
October 16, 2018 Nearly every global manufacturer seems to be testing Industrial Internet of Things (IIoT) technology, but in a recent McKinsey survey, nearly 70 percent of business executives said that their IoT initiatives are stuck in pilot purgatory, unable to reach company-wide scale. Furthermore, respondents said that only 15 percent of IIoT initiatives move to scale within one year, and a quarter of these initiatives extend longer than two years in pilot mode.
Clearly, this is not ideal, as pilots alone do not deliver the bottom-line impact companies need to remain competitive in the Industry 4.0 era. Even worse, because pilots do not encompass the full spectrum of what is possible with IoT-led technology transformation, these initiatives too often get cancelled because of the lack of a long-term vision and roadmap. But there is good news: designing the information technology/operational technology (IT/OT) architecture properly will enable companies to architect robust IIoT pilots that can rapidly scale.
Given that pilots often get bogged down because they’re too narrow to scale well, it’s imperative to design use cases so that they deliver end-to-end value for company-wide benefits. That also means addressing the overall IT/OT architecture design from the get-go to encompass the breadth of use cases. And with the IT/OT environment becoming more complex every day, the goal must be to sequence use cases based on two considerations:
The priority of the use cases to the enterprise, based on predetermined KPIs that are linked to business value creation, and The ability of technology to support these use cases, while in parallel building both the technology stack (also known as the “platform”) and the applications specific to those use cases.
In our previous post, we described the factors that make constructing a scalable technology stack especially challenging in an industrial setting, such as the complexity of the industrial-automation ecosystem, the alphabet soup of sensor subsystems, legacy machines that are still unconnected, and poor collaboration between IT and OT departments.
Consequently, industrial companies often struggle to determine how best to source a solution that truly unlocks value from data and analytics. Vendors of all types are introducing new technology to capitalize on this trend, as they seek to secure a portion of the multi-billion-dollar market (exhibit).
Exhibit We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
At one end, traditional industry-automation vendors that are established incumbents, with strong positions in control points, are introducing complementary IoT solutions to help manufacturers deploy an end-to-end IIoT platform. The playing field also comprises established vendors from both the OT and IT stack, each with strengths in different technologies. Some vendors are attempting to create portfolios that span most of the IT/OT automation stack, while others are steadfast in their commitment to a focused area of expertise.
We looked at five of the top automation vendors and found that most are expanding their IIoT portfolio and capabilities. The overall landscape thus remains unsettled. For example, just among this vendor subset, there are almost 50 proprietary offerings in more mature areas of the stack, such as manufacturing execution systems and similar technologies—and standardization across industry use cases has yet to take off. We also found that several major vendors lack offerings in areas such as building automation, human-machine interfaces, and sensors and RFID.
To add another layer of complexity, traditional software vendors are competing for their share of the industrial-cloud ecosystem. Most approach the ecosystem from bottom up, with initial success as an infrastructure-as-a-service (IaaS) provider, leading to vertical integration in platform-as-a-service (PaaS), and finally leading to non-industrial software-as-a-service (SaaS). The natural extension is then to enable industrial SaaS.
As with the automation stack, there are several major players competing but there is no clear leader. For plant operators, it’s therefore nearly impossible to predict who will come out on top, leaving internal teams to navigate a complex landscape of evolving technology offerings from vendors with whom they have an established and amicable relationship—both on the IT and OT side. The only clear message right now is that no single vendor will likely be able to solve all of a company’s requirements.
Knowing your starting point and destination can help make even the most complex journey navigable. This is true of developing an IIoT stack capable of scaling. We recommend our clients take the following steps when initiating an IIoT pilot. Over the next few blog posts, we will deep-dive on each of the following steps with examples where applicable.
Start by generating a solid list of use cases. Focus not only within the four walls of a given plant, but also extend into supply chain and design, with a view to enabling digitization of complete value chains. This exercise doesn’t have to be exhaustive, but it should be representative of the things the stack needs to be able to do for you. For each use case, you can then determine the tech-stack requirements, which collectively will show what the tech stack will have to deliver to achieve scale at the right speed and cost.
Focus not only within the four walls of a given plant, but also extend into supply chain and design, with a view to enabling digitization of complete value chains. This exercise doesn’t have to be exhaustive, but it should be representative of the things the stack needs to be able to do for you. For each use case, you can then determine the tech-stack requirements, which collectively will show what the tech stack will have to deliver to achieve scale at the right speed and cost. Develop a future-state reference architecture based on business need. Begin with an assessment of your current IT/OT stack, from plant level to the whole enterprise, looking at everything from technology architecture to manufacturing applications and tools. Also review previous IIoT pilots, identifying pain points that prevented projects from moving forward.
Begin with an assessment of your current IT/OT stack, from plant level to the whole enterprise, looking at everything from technology architecture to manufacturing applications and tools. Also review previous IIoT pilots, identifying pain points that prevented projects from moving forward. Incorporate data expertise up front. Avoid delays and needless iteration during implementation by having data scientists, who know the data they will need to have when building their analytics models, participate in the design of the reference architecture. The data scientists will also need to work with the process engineers to ensure that the data can be both collected accurately at source and aggregated into the right location at the right time.
Avoid delays and needless iteration during implementation by having data scientists, who know the data they will need to have when building their analytics models, participate in the design of the reference architecture. The data scientists will also need to work with the process engineers to ensure that the data can be both collected accurately at source and aggregated into the right location at the right time. Define a core architecture choice. Assess the pros and cons of selecting a single platform, an ecosystem of vendors, or a hybrid approach, before aligning on an overall direction.
Assess the pros and cons of selecting a single platform, an ecosystem of vendors, or a hybrid approach, before aligning on an overall direction. Recommend tech choices specific to use cases. Agree on tech-stack requirements for prioritized use cases and compile decision criteria. Tailor existing evaluations of IIoT platform providers against the decision criteria to identify top choices.
Agree on tech-stack requirements for prioritized use cases and compile decision criteria. Tailor existing evaluations of IIoT platform providers against the decision criteria to identify top choices. Chose vendors based on both tech capacity and human capability. While getting the right tech is essential, getting it to work depends on system-integration capabilities as well.
Deploy technology for prioritized use cases in the short term. For the prioritized use cases, invite a curated list of vendors into your organization’s ecosystem.
For the prioritized use cases, invite a curated list of vendors into your organization’s ecosystem. For the long term, create and align IT/OT roadmaps. Draft consistent IT and OT roadmaps that align with your organization’s broader business goals and underlying tech, then syndicate and refine them—noting that the time scale will be very different from a multi-year ERP implementation.
Following this approach will help your company navigate the complexities of the IIoT landscape to capture value quickly. Watch this space for more on each of the steps listed above.
The authors would like to thank Mike Coxon, Subu Naranayan and Bodo Koerber for their contributions to this post.We as the IoT practice of Deloitte Germany are delighted to introduce our new blog today.As part of the global IoT initiative at Deloitte, the German practice drives business-value focused IoT solutions from the very first idea to the global operation. We offer detailed insights into the possibilities and sustainable value of IoT solutions and develop custom strategies across industries.
On this blog, we share learnings from our IoT projects and introduce best practices as well as our Point of Views. We offer additional findings, statistics and analyses, publish interviews with IoT experts and keep you up to date about major IoT developments.
Initially established in summer 2016, we have since grown into a team of 40+ practitioners led by Dr. Gunther Wagner and Andreas Staffen. To name just a few, let us introduce ourselves as some of the contributors to this blog.
Nowadays, billions of interconnected sensors and devices are enabled and qualified to exchange data in real-time. Together, they form the Internet of Things, enabling critical insights, greater efficiency, and new business models in dozens of industries, creating trillions of dollars of value globally.
We focus on the corporate application of IoT solutions in specific organizations rather than single end-user devices, which is reflected in how we approach IoT. Our work spans from the identification of suitable strategic courses of action, over respective technology and organizational transformation to a steady optimization of operation and delivery principles. More details regarding our IoT service offerings are following in a separate blog post.
Get in touch with our team to start a conversation about how your organization can leverage the full potential of the Internet of Things.The role of IoT in the manufacturing industry is increasing. Gartner forecasts 20 billion internet-connected things by 2020. Although it is not about general-purpose devices, but about dedicated-function objects, such as jet engines, connected cars or even coffee machines. Besides new business applications, IoT solutions enable businesses to analyze data generated by IoT edge devices and use these insights as a basis to improve business decisions. This article focuses on the IoT platform as one essential component of this development as well as introduces the Deloitte Digital Platform (D²P), which allows you to integrate and collaborate with data coming from various systems, devices, applications and human interaction.
A lack of interface and communication standards lead to a gap between IoT edge devices and business applications. An IoT platform closes this gap by acting as a middleware, which mediates between the two ends. However, modern IoT platforms go one-step further by adding functionality to the hardware and application layer. For this reason, capabilities for edge data processing or complex data analytic algorithms can also belong to the functionality set of an IoT platform. In general, IoT platforms are all about enabling businesses to build IoT solutions faster, cheaper and better, by solving problems and complexities related to the interoperability between infrastructure and business applications.The Internet of Things (IoT) is playing an increasingly important role not only in industry, but also in our daily life. A basic understanding of the relevant technologies, procedures and tools is very helpful in order to benefit from the tremendous opportunities of the IoT as an IT professional, manager and entrepreneur. Therefore, Deloitte’s IoT Community hosted the IoT Bootcamp for industry partners at the Deloitte Digital Factory in Dusseldorf on December 5th and 6th 2019.Niccolò Machiavelli, one of history’s great futurists, might have predicted the Internet of Things (IoT) when he wrote, “There is nothing more difficult to take in hand, more perilous to conduct, or more uncertain in its success, than to take the lead in the introduction of a new order of things.” The IoT’s early innovators, who have grappled with mixed overall demand, a lack of consistent standards, and other challenges, would agree that their road has been difficult. But, like other visionaries before them, they have persisted in establishing a new order because they see the promise ahead.
Both consumers and the media are fascinated by IoT innovations that have already hit the market. These “smart” devices have sensors that communicate seamlessly over the Internet with other devices or the cloud, generating data that make the world safer, more productive, and healthier. In just a few years, some IoT devices have become standard, including thermostats that automatically adjust the temperature and production-line sensors that inform workshop supervisors of machine condition. Now innovators want to enable more sophisticated IoT technologies for self-driving cars, drone-delivery services, and other advanced applications.
Although some analysts are excited about the IoT’s potential, others have argued that it is overhyped. We take a more balanced view, based on our extensive research as well as our direct work with IoT application developers and their customers. Like the optimists, we believe that the IoT could have a significant, and possibly revolutionary, impact across society. But we also think that the lead time to achieve these benefits, as well as the widespread adoption of IoT applications, may take longer than anticipated. The uptake of IoT applications could be particularly slow in the industrial sector, since companies are often constrained by long capital cycles, organizational inertia, and a shortage of talented staff that can develop and deploy IoT solutions.
For semiconductor companies, which are looking for new sources of revenue, the rate of IoT adoption is an important concern. In this article, we will look at the case for optimism, as well as the reasons for more modest expectations. We will also examine new technologies that could accelerate the IoT’s growth and product-development strategies that semiconductor companies could implement to increase the appeal of IoT offerings.
If we look at the IoT’s recent growth, the optimists have reason to be encouraged. Consumers are more connected than ever, owning an average of four IoT devices that communicate with the cloud. Globally, an estimated 127 new devices connect to the Internet every second. A report from the McKinsey Global Institute estimates that the IoT could have an annual economic impact of $3.9 trillion to $11.1 trillion by 2025 across many different settings, including factories, cities, retail environments, and the human body (Exhibit 1).
Exhibit 1 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
The IoT is also benefiting from infrastructure improvements that have enhanced connectivity. For example, only 20 percent of the global population is now covered by low-power, wide-area networks (LPWANs) that allow long-range communications among connected devices while optimizing both costs and power-consumption requirements. By 2022, however, we expect that 100 percent of the population will have LPWAN coverage. Similarly, technological advances are reducing power requirements, decreasing costs, and promoting the development of more integrated IoT solutions. Consider lidar sensors, the laser-based sensor packages that scan and detect surroundings, which are essential for autonomous driving. Their price has declined more than 10-fold over the past eight years and is expected to drop more than 65-fold over the next two. This decrease, combined with the increased technological sophistication of lidar, is contributing to the development of fully autonomous cars, which could constitute 25 percent of all vehicle purchases by 2035.
Many experts view the IoT’s slower-than-expected growth within the industrial sector with particular concern. To gain more perspective, we investigated how industrial companies are using IoT applications and tried to estimate whether business-to-business (B2B) growth might accelerate. In addition to basic research, we interviewed and surveyed over 100 leaders from various industries, including public sector and utilities, discrete manufacturing, oil and gas, mining, telecommunications, technology, media, healthcare, and pharmaceuticals.
Our interviews revealed that most businesses are adopting the IoT only to a limited extent. With the exception of oil and gas and mining, leaders from all industries reported that their companies often received real-time data from IoT sensors. However, most leaders reported that their enterprise deployments were still at proof-of-concept stage, and none have yet embarked on large-scale programs (Exhibit 2).
Exhibit 2 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Although IoT sensors collect vast stores of data, a recent report from MGI showed that companies do not analyze most of them. For example, on an oil rig that had 30,000 sensors, managers examined only 1 percent of data. What’s more, business leaders seldom consider information from IoT sensors when making important decisions, including those related to maintenance planning or automation procedures. Their reluctance to examine IoT data stems from several factors, including a lack of data-analytics staff, but the most important reason is simple: as humans, we prefer to consult other people for advice or to look back on our own experience, when making decisions. Although hard data from IoT devices are more complete and objective, we tend to assign them less value. Before IoT data gain a more prominent role in corporate decision making, business leaders and other important managers—maintenance supervisors, field service technicians, and retail merchandisers, to name just a few—will have to appreciate their value.
In our survey, respondents favored simple use cases that enable tracking data and sending status alerts related to changes in the physical world (Exhibit 3). Some companies, for instance, have placed sensors in food packaging that track a product’s location throughout the distribution supply chain. Simple tracking and alert functions are relatively easy to deploy because they do not require advanced analytics, complex algorithms, or data-science capabilities, allowing them to generate value quickly. Although some innovators are enthusiastic about IoT applications for optimization and prediction, we expect that most customers will remain focused on simple use cases, at least for the immediate future. And that means they will not obtain full value from the IoT.
Exhibit 3 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
IoT devices, connected cars, and edge gateways are all potential entry points for a cyberattack—and we recently saw the full extent of this vulnerability. In the 2016 Mirai botnet attack, hackers specifically targeted IoT devices, including appliances and routers, and disrupted many major Internet service providers. The attack, the most significant of its kind, was possible only because of human weakness—a failure to reset generic or default password and username combinations. This attack, and others like it, demonstrate that IoT vulnerabilities often result from a lack of basic care in managing and maintaining devices. Such weaknesses cannot be eliminated through encryption, attack-detection programs, biometric-access control, or other sophisticated technologies. That means companies that want to expand their IoT efforts will need to launch comprehensive security initiatives that address weaknesses resulting from both technological vulnerabilities and a lack of caution among those who use IoT devices.
A few important, and potentially disruptive, developments could accelerate IoT uptake and create opportunities for semiconductor players.
Video analytics—the application of sophisticated algorithms to video feeds—is spurring the creation of new IoT applications and use cases. For instance, data analysts can now examine customer demographics by applying sophisticated algorithms to videos taken as shoppers browse through merchandise. Recent evidence also suggests that the IoT will benefit from audio captured on microphones.
The costs associated with video and audio feeds are falling, with sensors now embedded in devices at low cost—under $2 each. The data gathered from these feeds are extremely rich, diverse, and relevant to many widely used IoT applications. Lower data-communication rates, the growth of 5G data networks, and ongoing decreases in cloud-storage costs will continue to encourage developers to find new uses for video and audio.
For semiconductor companies, the increased importance of IoT video and audio feeds may create an opportunity to combine hardware with end-to-end approaches for analytics and control. They will have to move quickly to meet customer needs, however, since the technology related to advanced applications, such as those that use analytics to recognize faces, is evolving rapidly. Semiconductor customers may be particularly interested in products that integrate hardware and software more closely, as well as new architectures that optimize transmission, processing, and analytics on devices, in the network, and in the cloud.
The advent of standards that support truly LPWANs, including LoRa, NarrowBand IOT, and Sigfox, will enable large-scale sensor deployment of IoT applications in many areas, including agriculture (analysis of soil conditions), safety (citywide monitoring of air quality), and productivity (real-time logistical tracking along the supply chain). But the growth of the IoT, combined with the increase in sensors and connectivity, will also make it more challenging to provide power to untethered devices and sending nodes. Even with long-life battery technology, many of these devices can only function for a few months without a recharge.
Energy harvesting, a process in which energy derived from external sources is captured and stored for use in wireless devices, might resolve power-related issues. Although solar energy could provide an answer for many IoT applications, semiconductor companies should also investigate other sources, such as wind, thermal energy (derived from heat), and kinetic energy (derived from an object’s motion). Optimizing energy harvesting, management, and storage will require companies to create innovative designs, at both the silicon and system level.
As the IoT expands, innovators are rapidly developing complementary architectures that combine the following two important features:
the power of the cloud, which offers robust storage and greatly extensible computing power at low cost
the ability to process and store data on a device (or edge), or within a network at gateways that connect multiple end-devices to the cloud
Multiple IT architectures with these properties have already reached the market, each offering a compelling approach. But semiconductor companies have an opportunity to go further—and to make more rapid progress—in defining the future architecture of the IoT. In particular, they should focus on products related to video and audio sensors, since these devices are proliferating and generating significant amounts of data.
Many IoT applications require data to be processed on the devices themselves. For instance, applications for autonomous driving, surveillance, and security all have strict latency specifications that require systems to respond immediately after data input. To meet these requirements, the IoT devices that collect the data must process them and use the output to make decisions. Applications that require on-device processing are power hungry and include relatively expensive components, such as multiple application processors. Semiconductor companies could take the lead in optimizing on-device solutions for these applications. For instance, they could create edge-device solutions for autonomous control, facial recognition, and audio analytics, all of which have different hardware and software requirements with respect to computing performance, signal processing, and storage.
Before any company explores IoT opportunities, it should take a new look at strategy, including the factors that it considers when developing solutions.
Both developers and business leaders often focus on the technological potential of the IoT, including its ability to collect and analyze vast stores of data. But technological advances alone will not make an IoT application more valuable or desirable to customers. Instead, developers should focus on outcomes—how a new application will improve safety, financial returns (for businesses), and convenience.
Consider, for example, the outcomes that one airplane manufacturer achieved by using IoT sensors to monitor jet-engine performance. By providing real-time data, the sensors immediately alert the manufacturer about potential problems, which makes it easy to conduct preventive maintenance and maximize uptime. Other sensors help with parts-inventory management. Together, these IoT enhancements have contributed to 9 percent revenue growth and a 30 percent increase in engine availability. That means airplanes spend more miles in the air and less time on the ground, consistently reducing overall operating costs.
To focus on outcomes, companies will have to coordinate activities across the value chain. In addition to providing the technology and data that enable the IoT, they will need to adapt their business models—a difficult process, in our experience, since incumbents often resist change. If they fail to evolve, a start-up or another disruptive player may take the lead in establishing a new approach to IoT application development, especially if new investors emerge to finance innovative ventures.
As companies shift their focus from technology to outcomes, they will need to provide incentives that encourage upstream vendors and customers to support the use of their applications.
Just as IoT innovators tend to focus on technology, many IoT marketing materials try to appeal to customers by discussing the latest product upgrade, including better sensors, connectivity, computing power, and analytics. But our experience has consistently offered one clear insight: users, both personal and industrial, are more likely to adopt IoT technologies that generate a positive emotional reaction. Consider smart homes, where technology companies have recently won many customers by offering voice-based products—devices with basic conversational abilities that often respond to a name, just like a person. For instance, Amazon’s Echo, a smart-home speaker, answers to the name Alexa and can respond to basic commands and questions. Such qualities may create an emotional connection between users and devices, and they could be partly responsible for the strong sales of voice-based products.
As technology companies develop new IoT offerings, they should ask digital designers to provide insights about customer behavior, since this information might help them create products that prompt strong positive feelings and accelerate adoption rates. As always, products will also need strong technical and analytical capabilities, but companies are more accustomed to delivering such features.
Current IoT trends create an uncertain and sometimes confusing picture of the sector’s future prospects. When we look at the evidence in total, however, we believe that the IoT is poised to serve as a major growth driver for semiconductor companies. Adoption rates have risen more slowly than expected, but that should not be a reason for pessimism, since many IoT technologies are immature or undergoing development. Semiconductor companies and other players can still undertake new strategies to accelerate IoT growth. Rather than focusing on technology upgrades, they could develop IoT products that truly improve customer outcomes for cost, performance, and other important metrics. They could also emphasize design-driven insights about customer needs, including the product features that generate a positive emotional response. This new approach to development will be challenging, but it will accelerate IoT adoption and help more customers, both personal and industrial, achieve benefits from this exciting new technology.Digitization in companies is advancing more and more. Even though processes are increasingly being carried out electronically, logistics service providers often receive their orders outside the transport systems - often still via analog channels. This increases the effort required on the part of logistics service providers to record shipment data.
In order to optimize the yard planning, staff utilization and operational processes, an increasing number of clients is asking their logistics providers to book dedicated time windows to pick-up and deliver goods. The booking of the time windows usually needs to take place 24h before pick-up/delivery. The booking itself causes additional effort for the logistics providers and reduces efficiency. In addition to that, the flexibility to plan the pick-up/delivery tour is reduced which can negatively affect the utilization of the available loading capacity.
Customers are increasingly demanding reliable transparency on the status of shipments from their service providers. This requirement presents logistics companies with an enormous challenge. On the one hand, the recording of the conventional barcode by warehouse personnel is time-consuming and therefore inefficient. On the other hand, additional information, such as temperature or vibrations, must be transmitted to the customer more frequently. Current transport systems are often not suited to provide this type of information.
In the event that companies do not transmit their shipment data electronically, the data must be recorded by the service provider. This entails the risk of incorrect information being recorded, which is even increased by the existing shortage of skilled workers and outsourcing. In addition, shipments cannot be reloaded as long as the shipment data has not been recorded. In reality, this repeatedly leads to delays in operational processes.The Internet of Things (IoT) can not only help you get ahead today, its powerful outcomes and analytics can propel your business far into the future. Deloitte can help companies harness the power of IoT to deliver transformative outcomes and tangible business value.Maria is the Lead Enterprise Agility Partner in Deloitte’s Consulting Practice in Asia-Pacific. Maria has worked with a wide variety of teams, leaders, and organisations to re-wire their management philosophy and enable the shift in thinking required for her clients across Asia-Pacific to deliver projects better, with more value, sooner, safer and happier. She has been working with her clients to create customer-centric, high performance delivery, and learning ecosystems across industries, particularly with extensive experience in financial services, telecommunications, and energy & resources. Based on her technology delivery background, Maria’s approach to change and leveraging new ways of working is pragmatic and has an effective balance between delivery and an outcome focussed mindset and culture.Nowadays, Agile methodologies have well and truly arrived in most organizations. The complexity of digital opportunities and the unpredictability of customers and competitors are both on the rise, making it impossible to predict what businesses will need in the future. That is why Agile is such a decisive factor to enhance organization’s responsiveness towards volatility. Strategy management has to evolve as well, which is where Agile concepts come into play. More...A blog delivering insights into the latest discussions, trends and lessons from the front line on Agile. Deloitte is a pre-eminent Agile advisor and a leading expert on Agile, providing tailored solutions across various organisations, industries, and projects, at any scale.
Agile is a set of principles and practices based around the concept of iterative and incremental development, with collaboration between teams at its cornerstone. Agile approaches to delivery can increase quality, reduce waste, improve predictability and boost morale in organisations.
Our experts in Agile will provide their views on the latest developments within the Agile community, developed through first-hand experience across a range of industries and services, and will help keep you up to date with the tools and considerations needed for successful Agile development.Searching “what is agile?” we find words like “iterative development, software delivery, self-organising teams, scrum, and sprint”. If you’re reading this blog, you’re probably familiar with most of these terms, and you may even be thinking about Agile at scale, or “Enterprise Agility”. As we start to scale agile, the human aspects tend to be outweighed by a focus on execution. However in our experience, there are a small number of factors that become critical to truly realising benefits as organisations begin to scale Continuous Delivery, DevOps or Agile principles beyond 1-2 teams, and start looking at a whole function or even an entire organisation….
So what do we mean by human aspects? … It’s anything and everything to do with an organisation and its people, how they work together, and its workforce.
In a series of blog posts, we will explore these critical human aspects by asking the question: “What practical steps can we take to start making a difference?” With the first of the series focusing on Leadership.
We are quite excited to see some really informative research around Agile Leadership emerging. The Puppet + DORA State of DevOps Report examines the idea of transformational leadership, and Deloitte’s 2017 Human Capital Trends which explores the idea of “hero leader”, and how it can no longer scale, detailing how the US Military has reinvented itself as a network of teams.
As we begin to explore the idea of Leadership in an Agile environment, we are immediately compelled to examine what leadership means alongside (increasingly) autonomous / self-managed teams. What is the role of leadership in these new ways of working? Is a different type of leadership needed? Are leadership roles needed at all?
Our view is that leadership is becoming more diffused across the organisation rather than the traditional approach where it is distilled in discrete roles at the top of an organisation. More and more, leadership is a capability that is integral to all roles, at all levels of the organisation, irrespective of whether a role has direct reports or not. This means there will be far fewer roles that are considered “only leadership”, and even when these discrete leadership roles exist, what they do is changing significantly.
There are some well documented examples of this in practice; LeLoux explores a number of these in his seminal book: Reinventing Organizations. Atlassian’s (the now famous Australian start-up that even AFR now considers the “coolest company in Australia”) focuses their leadership teams almost exclusively on the “sustainability of the eco-system”. Leaders amplify the company’s vision and purpose, develop “the guard-rails” that enable everyone to deliver great customer outcomes, and identifying potential threats by assessing their ongoing competitive position.
And Microsoft who’s transformation from “a battleship to 3000 canoes”, has been underpinned by leaders who focus on translating customer value into outcomes, challenging the norm, and inspiring people.
One of the key characteristics is authenticity. Authentic leaders communicate their team / organisation’s purpose in a practical way. Their passion for the customer is infectious and creates the oxygen for teams to take meaningful action rather than waiting to be “told what to do”.
This is tightly coupled with coaching. Coaching has become a core tenant of leadership, incorporating both personal recognition of great work, as well as creating an environment of- and space for- continuous development and collective accountability that encourages personal and collaborative reflection in the absence of blame.
Demonstrate empathy, care and inclusion – taking the time to seek out people’s stories and experiences, encouraging them to be themselves at work, and connecting personal interests to organisational purpose and customer outcomes. These leadership behaviours encouraging engagement and wellness that research is showing drives improved performance.
Research from Bersin by Deloitte found that inclusive leadership is one of the most significant driver of employee engagement. This is because when people feel included they feel safe; safety enables people to suspend self-interest, and it’s only when we can suspend self-interest that it possible for effective teams that are focused on delivering customer outcomes.
So on reflection… authenticity, coaching, empathy, care and inclusion; these are not aspects of leadership that most people would disagree with, but neither are the first words that would come to mind if you asked 100 people from a corporate Family Feud audience.
Start with purpose and customer ; have your team members spend (more) time with customers, sharing their stories, and demonstrate your personal connection to customer outcomes.
and ; have your team members spend (more) time with customers, sharing their stories, and demonstrate your personal connection to customer outcomes. Think differently by spending more time conceptualising possibilities, seeking out divergent views, and embracing complexity, and less time formulating specific strategies and plans.
by spending more time conceptualising possibilities, seeking out divergent views, and embracing complexity, and less time formulating specific strategies and plans. Act differently by playing an active role in multiple teams, embracing the Agile tools and ceremonies that your teams are using, and spend more time coaching and less directing.
by playing an active role in multiple teams, embracing the Agile tools and ceremonies that your teams are using, and spend more time coaching and less directing. React differently by explicitly tolerating risk and celebrating experimentation, demonstrating resilience when things don’t work perfectly the first time and consciously not laying blame.
So in summary, as a leader and influencer in your organisation the first port of call to scaling Agile is to take conscious control of your own “leadership style”, start thinking, acting and reacting differently, and you’ll begin to see the benefits we’ve discussed above. This can be the case, even when the rest of the organisation around you hasn’t changed. However to take those benefits to the next level and successfully scale even further, the next factor you would likely consider will be organisational structure. We’ll cover this in our next blog in this series.
You can find further Deloitte thinking and resources here. We would recommend the following further reading:It’s no secret that the success of any program hinges on senior executive ownership, support and their ability to cascade messaging down to all layers of an organisation. What’s also trending in Agile is the movement from leader-led change to intent-based leadership. Leadership should be viewed as a set of behaviours, not only a role. As such, leaders should empower passionate individuals to lead from all levels within the organisation.
Agile requires cultural change, not just technology. Every person up and down the chain should be versed in the language of agile, and be guided by a single framework and approach for doing so. Pilots enable you to slice off a sliver of the business, fundamentally transform this small group’s way of working, demonstrate benefits and then scale. Starting lots of little ‘spot fires’ such as this around the organisation will attract others, and draw them in to the movement.
Wise companies will proactively consider what they can learn from organisation models being created within digital-native companies. Removal of silos and hierarchy, with the blending of roles can help to create autonomous teams. When structures cannot be changed, alternatives such as creating ‘guilds’ – voluntary communities of like-minded people that come together to discuss topics of interest – can help create pockets of agile evangelists.
The ‘spot fires’ mentioned in the point on culture, are also a way of winning hearts when it comes to targets and incentives. Leaders should strive for voluntary participation over mandated participation, so that it becomes every individual’s idea and prerogative to operate in this new way. Key to this is addressing the genuine needs of people – get to the heart of the noble purpose so people are motivated intrinsically.
Only in an environment where people feel safe to play with ideas, and where they are recognised and rewarded for being agile will it occur. Something as simple as buying ‘failure cupcakes’ at the end of a sprint can help set in motion this new paradigm. Building elements of gamification, playfulness and fun into team challenges and goals can also help drive creativity, innovation and agility.
In summary, to make an organisation truly agile, companies need to focus on the five building blocks of an effective environment: leadership, culture, organisation design, targets and incentives, and celebrating outcomes. Get these right, and the rest will follow.Someone posted an article on LinkedIn the other day claiming “Agile is Dead”. The comments that followed were more interesting than the actual article. Many people were bashing agile frameworks. It is no secret that organizations have spend a lot of money on doing agile and many times never really achieved being agile. Right now, SAFe (Scaled Agile Framework) is trending and many of my clients are implementing it. But methodologies and frameworks are nothing more than a set of guiding principles for delivering software. At the end of the day, doing agile comes down to the three things:
A framework is only as good as the people, processes, and organizational structures that use it. Silos with competing goals always trump frameworks. Each silo creates an unnecessary handoff and increases wait time. Too often, additional processes get added to deal with the interaction between silos.
Then there is the people part. I am old enough to remember when all projects managers had to be PMBOK certified which trained project managers how to follow a set of processes and procedures (framework) to navigate the waterfall methodology. When we moved to agile, all these people were retrained and became certified scrum masters. Unfortunately, they still had the old command and control, sequential mindset and most agile efforts became “Wagile” — waterfall with daily standups.
The point here is it takes much more than a few training classes or certifications to change the mindset. This is a transformation and requires an investment in organizational change management to get the value out of the new frameworks.
All the process in the world can’t fix a bad architecture. To do agile, one must have an architecture that supports being agile. Characteristics of an agile architecture include:
Service-oriented — opposite of Monoliths, the system is made up of small parts that can be deployed separately
Testable — system supports testing hypothesis with methods such as A/B testing, feature flags, chaos engineering, etc.
The more a system supports the characteristics above, the more agility can be achieved. Not all systems need to implement all of those characteristics, but each characteristic can reduce manual intervention, allow for more frequent deployments and quicker MTTR, reduce widespread system outages, and provide for better availability. It can also reduce the amount of unexpected work which is probably the biggest single issue all agile frameworks struggle to deal with.
Even if you have an agile architecture and your agile framework is being executed flawlessly, if your operations people and processes are not in alignment, the whole house of cards will come tumbling down.
There is a lot disruption in operations these days. DevOps has played a huge roll in getting developers and operators collaborating better. Operations is now being thought of earlier in the lifecycle and teams are designing for ops. Companies are reevaluating their operating models and investigating newer practices such as Site Reliability Engineering (SRE), accepting that testing in production is a good thing (if done right), moving from reactive to proactive operations, embracing observability, and much more. As we move to more agile architectures, it’s common sense that we need to embrace more agile methods of operations.
The list goes on and on. I have yet to see a framework that even mentions most of these characteristics. The frameworks focus mostly on how to manage backlogs which is important, but if the software and the operations of that software does not promote agility, the framework is not going save you.
Organizations should focus more on being agile rather than doing agile. Being agile requires more than a framework. It is a mindset and it should be applied everywhere, not just in Dev and Ops. The Security and Governance teams need to be agile. Procurement can’t take six months to procure a software product. Decisionmakers need to come to conclusions in a timely manner. Processes that take forever should be redesigned. Approvals should not take forever. You get the point.
Being agile is a cultural issue and should be treated as one. If you want to make your organization agile, adopting a framework is only one piece of the puzzle. In fact, many teams that I have seen that are truly agile use no framework at all. They do a good job of managing a backlog and they do a great job of collaborating, writing good software, automating everything they can, and recovering from issues quickly. At the end of the day, agility can be measured by customer satisfaction. If the customer is getting their demands met, the system is reliable, and issues are resolved quickly, it really doesn’t matter what framework you use.Despite the apparent threat, Enterprise Agility does not spell the end of Architecture but in fact can be a catalyst for change and disruption. Whether a company is Waterfall, Agile or Hybrid, architects will always be required to support technology decisions and align IT to business strategy[2][5]. These outcomes remain as critical as ever, but how they are reached will be vastly different. In this blog we will discuss four ways Enterprise Agility will redefine Architecture. Get ready.
1. Architects will be less involved with delivering things but more involved with ensuring the right things are delivered
There is a misconception that architects spend all of their time ‘doing’ architecture and producing complex diagrams[4]. It’s the organisational decision-making process that the architect must drive before an artefact is delivered, however, that really matters. Reaching consensus on complex decisions involving diverse stakeholders with competing views is where the architect is irreplaceable[12]. Be it navigating emerging technologies, legacy system replacement, or completing post M&A consolidation roadmaps; as Agility scales, the need to make these architectural decisions in a timely manner goes up. The need for Architects to support this goes up.
This doesn’t mean architects won’t produce any diagrams, but enabling the best technology decisions to be made is where the value of architecture will be realised in an Agile Enterprise[3][4]
Intentional architecture is the traditional up-front, plan based architecture that most of us are familiar with. The Architecture is designed and handed over to development teams to build. The more detailed the architecture the more ‘intentional’ it becomes.
There is little doubt that in a fixed-price contract world, having as much detail as possible up front is a necessity. And in general, updates are avoided at all cost for fear of the change request. But in an Agile Enterprise, procurement functions will evolve along with the Architecture function. And through a combination of incentive-based or time and materials contracting[21][22][23], this evolution will permit Product Owners to inspect and adapt.
So for the architect, as agility scales, a degree of up front planning remains essential. But defining detailed architectures across large time horizons is no longer required. Architectural work will be decomposed into smaller packages and managed in a ‘just in time’ fashion[11][12][13]. The Scaled Agile Framework (SAFe) provides an example of this with its Architectural Runway that is used to ensure technical dependencies are always delivered at least one sprint before the application functionality that needs it[10][11][17]Finally, at the core of transforming recruitment, should be the Agile principles. By changing the decision criteria for how you select a new hire, you can prioritise the talent you want most in the organisation. This gives you a workforce of individuals culturally aligned to your strategy and ways of working.
Changing the decision criteria to be Agile involves re-writing position descriptions to be light and flexible. This ensures that you don’t become locked into hiring for a position that, by the time you fill the role, is no longer relevant. Bersin by Deloitte wrote, in a piece titled ‘The end of the job as we know it’, that companies should be hiring “for values, innate skills, and fit, not for experience.” This means replacing your traditional job description with value descriptions instead, speaking to the inherent Agile cultural attitudes required in the position, like agility and comfort with ambiguity. In the Agile Manifesto, this is best denoted by the value of “Responding to change over following a plan”. The focus of good Agile job descriptions, should be on flexing positions, so that HR is building complete teams, rather than attempting to hire the ‘every man’ candidate.
The best example of this is the technology giant Google, who openly targets individuals for a quality called ‘Googleyness’. Head of People Operations, Lazlo Bock , defines this as:
A certain dose of intellectual humility (it’s hard to learn if you can’t admit that you might be wrong),
Comfort with ambiguity (we don’t know how our business will evolve, and navigating Google internally requires dealing with a lot of ambiguity), and
None of those elements would make a classic job description, but they do focus on what Google treasures most, a person’s values. They search for the right fit, not the right set of functional skills.
Applying an Agile mindset to recruitment is not simple. It spans a range of elements from redefining selection criteria, to re-inventing the hiring process. However embedding Agile within your recruitment practices is crucial in supporting an Agile organisation.
Our challenge to you is to look at how your recruiting currently operates, and determine where you can leverage Agile principles to improve the process. Even if it is as simple as giving new hires feedback forms so they can reflect on their experience of the hiring process, you’ll see the benefits that greater transparency and Agile provides.Both agile and mindfulness practitioners place importance on the ability to understand and respond to the needs of others. In an agile context, customers are critical stakeholders requiring compassion, empathy and deep understanding. Mindfulness emphasises the importance of regulation and control of self-emotion in order to better understand and respond to the emotional needs of others, which are relevant skills for an agile team.
Self-organising teams advocate the importance of positive team dynamics as well as the unique contribution of each team member, encouraging collaboration, and face to face communication. Mindfulness can help cultivate team wellness and empathy by encouraging practitioners to control and focus their emotions. This promotes a purposeful, flexible, and open state of attention that ultimately drives intention. By embracing this open attentiveness, mindfulness practitioners increase the likelihood of developing and sustaining positive, respectful, and resilient relationships within their team. This is critical to an effective agile practice, as collaboration, good communication and positive teaming are at agile’s core. Consequently, team productivity can be enhanced by promoting stronger, more engaged, and collaborative teams.
By developing, strengthening and leveraging emotional intelligence through mindfulness techniques, such as focussed attention, agile teams can increase team performance and foster customer empathy through a more in-depth understanding of team dynamics and individual needs.
Simplicity is a fundamental principle of both agile and mindfulness which follows the basic premise: a focus on high value yet simple processes and solutions will reduce waste (e.g. of time, energy, or cost) and increase quality (e.g. of software, communication, or life).
Mindfulness practitioners advocate the importance of de-cluttering to create the emotional and physical space necessary to develop awareness, focused attention, and sustainable living. De-cluttering practices, which can be either physical (such as voluntary simplicity which means to reduce materialism and consumerism, a re-assessment or minimalist re-design of your surroundings, or literally de-cluttering surfaces and spaces in your physical environment), or spiritual (such as letting go of negativity, uncertainty and mental “noise”) ultimately increases quality of life through a focus on value rather than abundance.
In an agile context the focus on simplicity manifests itself in simple design, succinct meetings and communication, continuous integration, story cards, minimal but clear roles, and sprint boards (to name a few). As an example, the physical sprint board puts the agile simplicity principle (“Simplicity – the art of maximising the amount of work not done – is essential”) to practice and facilitates visibility of work not done. The sprint board enables the agile team to organise activities so that those of the highest value are prioritised, reducing waste and maximising efficiency.
Simplicity is a key component in both agile and mindfulness, with focus placed on value and a deliberate effort to remove redundancy. Agile teams can further develop day-to-day simplicity through mindful practices, such as intentional physical and emotional de-cluttering.
Agile enthusiasts embrace changing requirements and environments, those practicing mindfulness also develop the flexibility to accept and respond, rather than react to change.
Mindfulness practitioners advocate that adaptability stems directly from acceptance of the transient and fluid nature of life. The ability to maintain a purposeful, flexible, and open state of attention increases quality of life and sustainability.
Likewise, agile teams maintain the mindset that change is expected and welcome, identifying flexible boundaries, and designing processes and expected outcomes which enable adaptability. Cross-functional, self-organising agile teams that value constant communication, continuous validation, and incremental product evolution are well placed to respond to changing requirements and shifting landscapes.
For both mindfulness and agile, it is communication and contact with the present moment that establishes the foundation for adaptability and increases the likelihood of resilience and stability.
Agile teams can apply their practiced adaptive mindset to leverage mindful techniques, such as acknowledgement and acceptance of change, which can help to remove human emotion (reactive behaviour) from decision making during periods of change.
Another fundamental principle of both agile and mindfulness is controlled and targeted focus on one task at a time. The value and objectives of the focus principle are similar to those of the Simplicity principle – high value yet simple processes and solutions will reduce waste and increase quality.
Mindfulness practitioners advocate the importance of awareness and control in order to focus completely on a single task. Similarly, agile practitioners advocate that productivity is increased through focus on one task at a time, enabled by small engaged teams, short targeted sprints, visibility of activity and direction (agile boards), and regular communication to maintain awareness of blockers and impediments to progress.
Both approaches support the view that the cost of context switching (reduced focus and concentration and ultimately decreased productivity) greatly outweighs any perceived benefit to efficiency or progress.
Agile teams advocate singular focus, however this is not to say that there is no challenge in doing so at an individual level. By using mindfulness practices, such as control of attention, agile teams can turbocharge their ability to filter out distraction, and focus only on the task with the greatest business value.
The core areas of commonality between agile and mindfulness are also some of the defining characteristics of each approach: People, Simplicity, Adaptability, and Focus. Agile teams can leverage the touchpoints with mindfulness to maximise their existing skillsets and ultimately achieve their goals. As an example, mindfulness promises to enhance and enrich interpersonal communication, while agile projects sink or swim on the quality and timeliness of the interactions between all of the project’s stakeholders (including the agile team itself). The two approaches are complementary.
While both agile and mindfulness have been described as “buzzwords” and are being referenced and discussed across multiple forums and platforms, neither introduce any complex or ground-breaking new concepts. In fact, the four principles discussed in this article, which sound very much like common sense, are a reminder that in the 21st century – an era dominated by disruption, technology and immediacy, there is great value to be gained in getting back to basics.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.Traditionally, leaders have been encouraged to dynamically reallocate capital to the most pressing and attractive opportunities. This focus remains today, but many companies face a challenge: human capital is now the scarcer of the two main capitals. Companies that manage talent with the same rigor they do financial capital, treating it like the precious resource it is, typically see better results. They reallocate talent to high-value areas and push talent management to the top of their growth ...Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.Developing a successful strategy is essential to simplifying the complexities of transformation. These key areas to consider can empower your transformation strategy and clarify the road ahead for digital controllership.Imagine you work for a company that has a busy season—the annual crunch time for achieving results. Everyone works at full stretch for six weeks, and then there’s a lull before the next cycle gets under way. If you’re designing a learning program, when should you schedule it? Most designers would probably say after the rush, when people can spare time out of their everyday routine. But is that the right answer? We don’t think so. With this timing, the next busy season could be eight or nine ...Coleads the Organization Practice globally and is one of the leading experts in transformational change
Coleads the Organization Practice globally and is head of McKinsey’s OrgSolutions group, helping clients organize in an integrated way by applying analytics methodologies and tools to improve culture, talent, change management, agility, and leadership
November 27, 2017 Let’s face it. Our hyper-dynamic, hyper-competitive and hyper-connected world has become a breeding ground for hyper-advice. Over 10,000 business books appear annually (and that doesn’t count the thousands of articles, blog posts, podcasts and video lectures produced). Search the internet for how to motivate employees and hundreds of thousands of results emerge in roughly half a second!
So, why are we at McKinsey & Company launching a weekly blog that risks simply adding to the clutter? We are hopeful that our weekly Insights on Leadership & Organization will be a one-stop shop where leaders can find impactful, fact-based and pragmatic advice – in 600 words or less.
We don’t want this to be run-of-the-mill head-nodding material. All up, as a firm we invest over $400 million annually in knowledge development, and we want you to benefit from that investment by providing genuinely provocative ideas that recalibrate and expand your thinking. Then we want to do that again. And again.
For this blog, we will address a range of both timely and timeless topics related to leading organizations and that apply to every leader, whether you’re a leader in an investment bank or a not-for-profit. Or whether you’re in India or Indiana. Over time, we will explore four principal areas:
Increasing organizational agility to effectively adapt to and shape market changes with speed. This requires organizations to master the paradox of being nimble in innovating and executing rapidly, while at the same time capturing the benefits of stability and harnessing the virtues of size and consistency.
to effectively adapt to and shape market changes with speed. This requires organizations to master the paradox of being nimble in innovating and executing rapidly, while at the same time capturing the benefits of stability and harnessing the virtues of size and consistency. Converting talent to value by combining traditional methods with advanced analytics-based methods to forecast talent supply and demand based on the business strategy; and improving how needed talent is identified, attracted, placed, developed, evaluated and retained—all the way from the front line to the C-suite.
by combining traditional methods with advanced analytics-based methods to forecast talent supply and demand based on the business strategy; and improving how needed talent is identified, attracted, placed, developed, evaluated and retained—all the way from the front line to the C-suite. Managing culture and change to deliver sustainable results and create lasting competitive advantage. This includes the tools and methods to overcome the digital, customer-centric, simplification, risk management, and numerous other large-scale transformation challenges that today’s global enterprises face.
to deliver sustainable results and create lasting competitive advantage. This includes the tools and methods to overcome the digital, customer-centric, simplification, risk management, and numerous other large-scale transformation challenges that today’s global enterprises face. Maximizing merger impact by building M&A capability to be ready to make the right deals happen—and then, once one does, developing and executing the right master plan related to governance, sources of value, organization, talent, capability building, and cultural and technology alignment.
Put simply, our goal is to help leaders lead better so, in turn, their organizations will be more successful and their employees’ experiences more meaningful and fulfilling.The IMA® (Institute of Management Accountants), the association of accountants and financial professionals in business, held its 2019 Annual Conference and Expo (ACE2019) this past June in San Diego, California. The event officially celebrated the Institute of Management Accountant’s 100-year anniversary with a special Centennial Celebration honoring IMA’s thriving global community of accounting and finance professionals. Attendees had the opportunity to network with other industry professionals, hear presentations from leaders, and choose from more than 75 job-relevant sessions tracks designed for management accountants to customize their learning experience on topics ranging from corporate governance to technology and finance trends for the future.
As a diamond level sponsor, Deloitte had the opportunity to attend the action-packed conference and deliver presentations on specialty topics. Deloitte delivered a specialty breakout session on touchless close as well as a general presentation on the Center for Controllership™ during the IMA annual conference dinner.
To gather some insights and perspectives that may help us with future conferences and projects with IMA, we caught up with our presenters and some of the attendees to hear about some of their highlights from the experience and insights they were able to take away from the conference.Though major crises may inflict significant economic damage, they can also inspire innovation. From digital connectivity to diversity, this issue of Deloitte Review explores innovations that organizations can put to use both now and in the future.JH, a partner at Deloitte Risk & Financial Advisory, Deloitte & Touche LLP, as well as Global Risk Advisory leader for the Financial Services Industry, has more than 25 years of risk management experience within the sector. He has deep experience with the complete credit lifecycle, enterprise risk management, operational risk, and integrated compliance risk management. His extensive experience in the area of credit includes quantitative methodology, portfolio analytics, process, and controls, integrating risk management practices, and addressing and resolving the Options Clearing Corporation (OCC) and other regulatory issues. JH has worked with seven of the top 10 credit card providers, four of the top five mortgage originators and servicers, two of the top three student lending organizations, and three of the top five auto loan financing companies. In addition, he has performed training sessions for the American Institute of Certified Public Accountants (AICPA) and the Federal Financial Institutions Examination Council (FFIEC) regulatory round table on accounting issues and pronouncements facing retail credit organizations.You previously joined My Deloitte using the same email. Log in here with your My Deloitte password to link accounts. | | Deloitte users: Log in here one time only with the password you have been using for Dbriefs/My Deloitte.
You've previously logged into My Deloitte with a different account. Link your accounts by re-verifying below, or by logging in with a social media account.After centuries of near uni-directional innovation—from the West to the rest—we are in the early days of a massive rebalancing, aided by connective technologies. Innovation now happens everywhere.
Innovation has always been important to humanity—it’s the driver of increased prosperity and well-being. It has also been steadily increasing in importance to business in a fast-changing, opportunity-rich, and highly competitive world. The evidence is plain, for example, in MBA programs, where innovation courses for the next generation of managers are rapidly proliferating. Bill Gates expressed the point in stark terms: Companies must “innovate or die.”1 So where does innovation come from?
For the last few centuries it came mainly from the West. Certain key ingredients necessary for innovation to flourish were in place in the societies and economies of the Western hemisphere far earlier than elsewhere. This advantage became such a powerful, self-reinforcing phenomenon that many in the West came to view their innovation advantage as something like a birthright, an intrinsic relative strength that could never be taken from them.
But in an enormously important trend for business, that is changing. Now, thanks to spreading economic growth, shifting national priorities and new “open” technologies, innovation comes from everywhere. Players based in emerging economies—and, in the West, many other players who lack the assets of large-scale firms—are becoming forces to reckon with in global innovation systems.
For those responsible for corporate innovation, this shift is challenging much of how they do their work. To keep evolving their offerings and ways of operating, companies are looking beyond their internal research and development functions and connecting with innovators at the fringes of their businesses. This will require different aptitudes and, perhaps harder to put in place, different attitudes. But if they can learn to embrace what is “not invented here,” organizations of all kinds can participate in an exciting new world of innovation possibilities.
If you think about what is required for innovation, it comes down to a few basic elements and conditions. Raw intellect is required to produce novel ideas. But ideas are only a small first step in the innovation process; there must also be incentives for inventors to turn those ideas into reality. Putting them into production and bringing them to market at scale requires substantial infrastructure. And since that requires investment far in advance of the hoped-for returns, there also need to be infusions of capital.
These came together in the West, both at the level of the economy and within the closed systems of firms. Corporations like Xerox and General Motors pulled together high-intellect groups in lab settings to cook up inventions, all kept tightly under wraps.2 Governments put a priority on fundamental scientific research, and made it easy for commercial entities to capitalize on the publicly funded and “best-in-class” work of universities. Managers devised standard processes by which the most promising possibilities were selected and funded, and leveraged their infrastructure to get them engineered, manufactured, and marketed in a consistent, high-quality fashion. Firms were able to profit handsomely from the bets that paid off. With every subsequent successful innovation, a company’s infrastructure gained scale, improving the chances that the next one would be a success. With such self-reinforcing systems in place, some nations’ economies matured at faster rates than others’. It was hard to see how to break the lock that Western corporations had on innovation.
A key change is in the infrastructure now required—or rather, not required—to bring a good idea to fruition. We are now decades into the revolution unleashed by information and communications technology, and the effect on industries has been a radical “de-verticalization” of the elements required to launch new offerings. Capabilities that were once exclusive to large businesses are now available on efficient open markets. Innovators no longer need to assemble large organizations, let alone make enormous capital outlays for plant and equipment, because infrastructure is available to them on an as-needed basis. Open platforms that enable collaboration are the new infrastructure of innovation.
Indeed, infrastructure these days could even be a liability—the millstone that limits agility. Players with the largest infrastructure in place could find themselves at an innovation disadvantage. We have already witnessed the phenomenon of “leapfrogging”—the upside of having essentially sat out an era of infrastructural investment and, unencumbered by legacy systems, being able to jump more quickly into the next era. This happened 20 years ago in emerging economies with respect to telephony, as their adoption of mobile phones far outpaced mature economies’, thanks to their lack of land lines.3 With new, potentially transformative technologies coming online every few years, from DNA sequencing to 3D manufacturing, there will surely be many other opportunities for seeming laggards to leapfrog leaders.
But infrastructure is not the whole story behind today’s more accessible and democratic innovation. Managers are now more generally knowledgeable about the processes by which ideas are transformed into profitable offerings. “Innovation is revealing its secrets,” as our colleague Larry Keeley, Deloitte Consulting LLP, puts it—among them, that the word innovation has been applied to what are actually multiple different ways and realms in which companies create new value.4 It is not simply about creating new products and services, but also involves systemic changes elsewhere—including financing and business models, new processes, and enhancement to delivery systems and client experience. And scores of tried and tested tactics to drive these changes have been identified and are now available to all.
Would-be innovators are also being fueled by new incentives as governments put new emphasis on innovation. The encouragement goes far beyond specific market interventions such as tax subsidies for pioneers in next-generation technologies like solar power. Particularly in emerging economies, where businesses have prospered by being “fast followers” or suppliers to Western firms, policymakers are encouraging homegrown innovation in numerous ways. See for example figure 1, showing how various countries’ investments in biomedical R&D have grown over time.
Companies are sending the same signals to their employees. When Deloitte surveyed senior executives of global firms in 2013, roughly 60 percent or more of developed-market executives and emerging-market executives reported that company employees, external partners, and company R&D centers are extremely or very important sources of innovation and new ideas for their organizations.5
As for the infusion of capital into new ventures, the importance of that hasn’t gone away—even in an era of what Keeley calls “lightweight innovation.”6 New developments in this area also contribute to the shift we’re describing. Microfinance was a huge early development; it turned people in villages across the developing world into entrepreneurs. More recently, consider the advent of crowd-funding. Using a tool like Kickstarter, which essentially asks customers (or stakeholders) to pitch in small amounts that collectively enable the development of an idea, an innovator can get a project off the ground that, for whatever reason, isn’t a fit for conventional forms of funding such as venture capital. In 2012, the total raised across 308 global crowd-funding platforms was $2.7 billion, an 81 percent increase over 2011, suggesting that this model is still in the earliest stages of explosive growth. When the numbers come in on 2013, the crowdsourcing research firm Massolution expects them to show that some 600 global crowd-funding platforms raised over $5 billion.7
Of course, all the infrastructure, incentives, and infusions of capital in the world can’t achieve innovation if there aren’t good ideas to begin with. When it comes to intellect, no one would claim that the West ever had a monopoly; raw brainpower is evenly distributed in the world. Much of the trend we’re describing is about tapping historically underutilized pools of it. There are also new developments making these pools larger.
The developed world may not have had bigger brains, but it did have huge advantages in education. Note, however, that by 2030, China will have 200 million college graduates, a number that exceeds the entire US workforce. By 2020, India will be producing four times as many college graduates as the United States.8 This dynamic is also reflected in fundamental science: In the 1980s, Asia Pacific accounted for 14 percent of total world science publications; by 2011, the proportion had doubled to 28 percent.9 The most recent rankings from the OECD’s Programme for International Student Assessment (PISA) put Asian education systems on top, especially with regard to math and science. According to these rankings, the top seven regions of the world in math performance are all in Asia (with Shanghai taking first place.)10Moreover, as economic opportunities grow in emerging economies, talent is more likely to stay there, or return after periods of work or education overseas. The Chinese Ministry of Education tracks the numbers of these returning “sea turtles” and reports ever-rising figures.11
Also propelling the talent shift is the rise of digital natives—a global cohort that, thanks to fundamental demographics, is increasingly dominant in the developing world.12 This youthful source of strength will grow along with expanding Internet penetration. (Today, more than 60 percent of the world’s population still lacks reliable Internet access—but that is changing fast.)13 It is clear that emerging-market Millennials are attracted to innovative businesses: In a recent Deloitte survey, more than 86 percent of respondents from this cohort claimed that their employment choices were strongly influenced by a company’s reputation for innovation—a higher proportion than that reported by developed-economy Millennials.14As they attain positions of leadership, expect to see more creative exploitation of the opportunities inherent in 21st-century technology.
Together, these developments are likely to reshape the global business landscape, steadily undermining the historic advantages of incumbents while empowering new actors. As innovation thrives outside large firms, it will also escape its long-time association with the institution-rich economies of the West (figure 2). It will become ever more accessible and open as organizations around the world gain greater (and lower-cost) access to the elements that drive it. Larry Keeley calls it “the biggest revolution in innovation that I have seen in 30 years.”15 Innovation will now come from anywhere—and everywhere.
Managers will need to respond thoughtfully and strategically to this transformation of the innovation ecosystem. First, from a defensive standpoint, they should acknowledge that the threat of disruption—of their products, processes, and business models—is very real, and likely to come from an unexpected direction. More positively and proactively, they should find ways to make the unfolding developments work in their favor.
Business leaders today realize that the smartest people in the world don’t all work within their organizations. How are for-profit companies tapping into the ideas of broader swathes of consumers and idea-generators? Through a growing range of methods. For example, Innocentive, Kaggle, TopCoder, and Gigwalk all allow them to engage external talent to help research and solve problems at a fraction of what it would cost to employ full-time resources, and with many more options than would typically be suggested by expert advisors.16
[The] biggest obstacle to innovation is not the scarcity of ideas—rather, it is the lack of capabilities to engage far-flung and unusual sources of perspective on a regular and ongoing basis.
XPRIZE is in the business of innovation, and it aims big. Its mission: “To bring about radical breakthroughs for the benefits of humanity, thereby inspiring the formation of new industries and the revitalization of markets.”17 How does it do it? By announcing grand challenges with handsome prizes (funded through donations to its nonprofit organization), it has elicited thousands of entries globally to solve complex technological challenges from private space flight to environmental cleanup. These entries have come from major research and traditional innovation hubs, but also from rank amateurs and dilettantes.18
But being “open” is more than issuing challenges to all comers. It calls for a broader intellectual curiosity that involves listening in and observing as creative people address the problems they consider important and interesting. Companies should consider, for example, connecting with the “hackers” in its space. The “maker movement” around the world consists of a vibrant community pushing each other’s skills and ambitions in small-scale fabrication, and some claim that it could form the basis for the next industrial revolution. We know of Western entrepreneurs who have spent months in Shenzhen, the capital of the hacker culture, immersing themselves in the flow of all the component parts of manufactured goods and the know-how of masters in manipulating them.19
Apple’s and Android’s success in pursuing “platform” strategies has been widely observed.20 They provide a foundation on which many external parties can build by designing applications that will run on it. This makes it easy for these parties to create and capture value, and as they do so, the platform itself will become more valuable and its creator more profitable. But to date, relatively few leaders have seriously explored how their own companies could potentially emulate this model.
Platforms, after all, can come in many forms. Take Quirky, a company that was envisioned from its inception to be a platform for independent inventors. Would-be entrepreneurs submit ideas for useful new consumer products, which Quirky engages a crowd to evaluate. For the three product innovations it launches per week, it provides full support from engineering to marketing, and splits any profits between itself, the inventor, and the voting crowd. At the time of writing this article, Quirky has developed over 420 products in this fashion.21
A valuable platform in a more familiar industry context can be found in Chongqing, China, the epicenter of the world’s biggest and most dynamic region engaged in the production of motorcycles.22 One of the largest manufacturers there, Dachangjiang, found itself short of high-quality local suppliers. Rather than try to build a single, verticalized channel of suppliers, however, it broke its design into several modules and, for each, awarded two to three suppliers the responsibility for developing parts.23 The suppliers worked under common, tight timeframes, but were given great latitude to fashion the different modules, and assurance that Dachangjiang would support innovative designs with investments in the appropriate equipment and processes to build them. The suppliers responsible for each module found modes of collaboration that worked for them, and they varied; there were vertically integrated state-owned enterprises, traditional joint ventures, and more loosely coupled arrangements.24 Interestingly, these collaborations didn’t end with participation on Dachangjiang’s platform. Some of them parlayed their new expertise into growth in adjacent markets, such as automotive.25 Thus, not only was Dachangjiang’s need for a vibrant supplier network met, but the network proved capable of far more innovation than would have occurred had it been directed and controlled by a single entity.
In each of these cases, the platform offers standardized interfaces and a plug-in architecture that can be leveraged by third-party innovators. Most of the costs of doing business are already embedded in that infrastructure, making it easier for smaller entrants to participate, either by targeting niche or emerging opportunities, or by offering something better to the platform’s core market. And in each case, the platform thrives because everyone participating in it has a stake in its success. It’s an arrangement that looks increasingly sensible as it becomes harder for individual firms to assemble and own the complete set of capabilities and knowledge required to sense and respond to market opportunities. Platforms are the bases of “business ecosystems,” and a key dimension of future approaches to innovation.
These dynamics point toward a similar conclusion: Leaders today might do well to reprioritize mastering “flows” of innovation over owning “stocks” of intellectual property. Economists have long recognized the important distinction between stocks and flows in terms of capital. But intellectual capital features both, as well. Traditionally, most businesses have focused on the stock—the patents a company owns, for example, and how to protect them. As John Hagel has observed, however, the dynamics of today’s innovation advantages suggest greater focus on the flows—figuring out how to ensure a steady influx of new ideas and a process by which they will rapidly yield value.26 Recall the motorcycle industry example cited above. Dachangjiang prospered more by facilitating flows than it would have by protecting and exploiting existing stocks of industry-relevant knowledge.27
Various technology executives claim that by the end of this decade, everyone on earth will be connected.28 We can therefore expect further acceleration of the tremendous changes already underway, with a continued rebalancing of the contributions to global innovation from emerging economies. The vectors, velocity, and variety of innovation can be altered fundamentally and permanently.
Today, awareness of the power and potential of this shift is limited. After all, it challenges more than a hundred years of history, and undermines deeply embedded assumptions. But the business world is adapting, and can, in the years ahead, rapidly adjust to the new reality. It will become an increasingly important agenda item for organizations to track, sense, and act upon. Businesses will likely work to develop more accurate sensing mechanisms in order to discover the innovations brewing around the world, and will embrace new models and innovation systems themselves.
The conventional wisdom around keeping a tight hold of ideas could become a drag on organizations that are too slow to let go of it. But as they necessarily engage in new forms of collaboration, many more will discover greater returns from facilitating flows of innovation through open networks. And they will come to recognize that their biggest obstacle to innovation is not the scarcity of ideas—rather it is the lack of capabilities to engage far-flung and unusual sources of perspective on a regular and ongoing basis. And successful innovation will continue to become far less mysterious, as what was once seen as “lightning in a bottle” is increasingly parsed, researched, codified, and turned into reliable (if never foolproof) methods.
Innovation is being democratized away from the insulated confines of the corporate lab and outwards toward the edges of social and market value webs. This transformation is being driven by three factors: the golden age of the platform, rivers of data being shared between connected consumers, and a growing awareness that the final value of things often expands tremendously when users are free to customize, collaborate, and recreate.
The golden age of the platform can be thought of as one of many small operating systems loosely connected. These coupled ecosystems are being developed in ways that allow for individual components to be constantly monitored, tested, altered, swapped out, or shut down. The resulting architectures are cohesive without being deterministic, allowing for rapid innovation at lower cost and without interruption. Success over these platforms is not dependent on accumulated knowledge or embedded infrastructure, so much as on the ability to swarm emerging problems and solutions quickly. Distributed networks of innovators are enabled by the very platforms that they now have the ability to change and improve. And those self-forming bands of problem solvers are essentially location-free.
Increasingly, we live within the so-called Internet of Things, a world in which everyone and everything is connected, with data being the essential lubricant. “Big data” and “analytics” have been buzzwords in the technology and corporate worlds for some time now, but the measurable impact and potential of this data is now starting to become clear. The truly stunning thing about big data is not how much of it there is, but its breadth of distribution. Current sensing, pulsing, and polling devices built into our digital worlds allow us to see one another, both as individuals and collectively, with the clarity that makes smart, data-driven, innovation possible practically everywhere.
As these ecosystems have developed, and as the amount and quality of data has improved, an enormous opportunity zone has opened. Salesforce has over 1 million developers, most of whom are not on our payroll, who customize the Salesforce platform at the point of usage to unlock value which often remains hidden to us at the hub. Rather than fight that, we run the company to magnify the innovation quotient at those distant transactional edges. End users might now find themselves delighted by the contributions of the whole ecosystem—customers, partners, and ISVs—augmenting the innovation they’re used to, delivered by the folks at Salesforce.com.We as the IoT practice of Deloitte Germany are delighted to introduce our new blog today.As part of the global IoT initiative at Deloitte, the German practice drives business-value focused IoT solutions from the very first idea to the global operation. We offer detailed insights into the possibilities and sustainable value of IoT solutions and develop custom strategies across industries.
On this blog, we share learnings from our IoT projects and introduce best practices as well as our Point of Views. We offer additional findings, statistics and analyses, publish interviews with IoT experts and keep you up to date about major IoT developments.
Initially established in summer 2016, we have since grown into a team of 40+ practitioners led by Dr. Gunther Wagner and Andreas Staffen. To name just a few, let us introduce ourselves as some of the contributors to this blog.
Nowadays, billions of interconnected sensors and devices are enabled and qualified to exchange data in real-time. Together, they form the Internet of Things, enabling critical insights, greater efficiency, and new business models in dozens of industries, creating trillions of dollars of value globally.
We focus on the corporate application of IoT solutions in specific organizations rather than single end-user devices, which is reflected in how we approach IoT. Our work spans from the identification of suitable strategic courses of action, over respective technology and organizational transformation to a steady optimization of operation and delivery principles. More details regarding our IoT service offerings are following in a separate blog post.
Get in touch with our team to start a conversation about how your organization can leverage the full potential of the Internet of Things.The Internet of Things (IoT) is playing an increasingly important role not only in industry, but also in our daily life. A basic understanding of the relevant technologies, procedures and tools is very helpful in order to benefit from the tremendous opportunities of the IoT as an IT professional, manager and entrepreneur. Therefore, Deloitte’s IoT Community hosted the IoT Bootcamp for industry partners at the Deloitte Digital Factory in Dusseldorf on December 5th and 6th 2019.Karel co-leads the Firm’s Operations practice and Internet of Things (IoT) group in Asia. Since joining the Firm in 1997, Karel has worked across multiple industries including advanced industries, automotive, electronics, energy and materials, technology, as well as private equity.
October 16, 2018 Nearly every global manufacturer seems to be testing Industrial Internet of Things (IIoT) technology, but in a recent McKinsey survey, nearly 70 percent of business executives said that their IoT initiatives are stuck in pilot purgatory, unable to reach company-wide scale. Furthermore, respondents said that only 15 percent of IIoT initiatives move to scale within one year, and a quarter of these initiatives extend longer than two years in pilot mode.
Clearly, this is not ideal, as pilots alone do not deliver the bottom-line impact companies need to remain competitive in the Industry 4.0 era. Even worse, because pilots do not encompass the full spectrum of what is possible with IoT-led technology transformation, these initiatives too often get cancelled because of the lack of a long-term vision and roadmap. But there is good news: designing the information technology/operational technology (IT/OT) architecture properly will enable companies to architect robust IIoT pilots that can rapidly scale.
Given that pilots often get bogged down because they’re too narrow to scale well, it’s imperative to design use cases so that they deliver end-to-end value for company-wide benefits. That also means addressing the overall IT/OT architecture design from the get-go to encompass the breadth of use cases. And with the IT/OT environment becoming more complex every day, the goal must be to sequence use cases based on two considerations:
The priority of the use cases to the enterprise, based on predetermined KPIs that are linked to business value creation, and The ability of technology to support these use cases, while in parallel building both the technology stack (also known as the “platform”) and the applications specific to those use cases.
In our previous post, we described the factors that make constructing a scalable technology stack especially challenging in an industrial setting, such as the complexity of the industrial-automation ecosystem, the alphabet soup of sensor subsystems, legacy machines that are still unconnected, and poor collaboration between IT and OT departments.
Consequently, industrial companies often struggle to determine how best to source a solution that truly unlocks value from data and analytics. Vendors of all types are introducing new technology to capitalize on this trend, as they seek to secure a portion of the multi-billion-dollar market (exhibit).
Exhibit We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
At one end, traditional industry-automation vendors that are established incumbents, with strong positions in control points, are introducing complementary IoT solutions to help manufacturers deploy an end-to-end IIoT platform. The playing field also comprises established vendors from both the OT and IT stack, each with strengths in different technologies. Some vendors are attempting to create portfolios that span most of the IT/OT automation stack, while others are steadfast in their commitment to a focused area of expertise.
We looked at five of the top automation vendors and found that most are expanding their IIoT portfolio and capabilities. The overall landscape thus remains unsettled. For example, just among this vendor subset, there are almost 50 proprietary offerings in more mature areas of the stack, such as manufacturing execution systems and similar technologies—and standardization across industry use cases has yet to take off. We also found that several major vendors lack offerings in areas such as building automation, human-machine interfaces, and sensors and RFID.
To add another layer of complexity, traditional software vendors are competing for their share of the industrial-cloud ecosystem. Most approach the ecosystem from bottom up, with initial success as an infrastructure-as-a-service (IaaS) provider, leading to vertical integration in platform-as-a-service (PaaS), and finally leading to non-industrial software-as-a-service (SaaS). The natural extension is then to enable industrial SaaS.
As with the automation stack, there are several major players competing but there is no clear leader. For plant operators, it’s therefore nearly impossible to predict who will come out on top, leaving internal teams to navigate a complex landscape of evolving technology offerings from vendors with whom they have an established and amicable relationship—both on the IT and OT side. The only clear message right now is that no single vendor will likely be able to solve all of a company’s requirements.
Knowing your starting point and destination can help make even the most complex journey navigable. This is true of developing an IIoT stack capable of scaling. We recommend our clients take the following steps when initiating an IIoT pilot. Over the next few blog posts, we will deep-dive on each of the following steps with examples where applicable.
Start by generating a solid list of use cases. Focus not only within the four walls of a given plant, but also extend into supply chain and design, with a view to enabling digitization of complete value chains. This exercise doesn’t have to be exhaustive, but it should be representative of the things the stack needs to be able to do for you. For each use case, you can then determine the tech-stack requirements, which collectively will show what the tech stack will have to deliver to achieve scale at the right speed and cost.
Focus not only within the four walls of a given plant, but also extend into supply chain and design, with a view to enabling digitization of complete value chains. This exercise doesn’t have to be exhaustive, but it should be representative of the things the stack needs to be able to do for you. For each use case, you can then determine the tech-stack requirements, which collectively will show what the tech stack will have to deliver to achieve scale at the right speed and cost. Develop a future-state reference architecture based on business need. Begin with an assessment of your current IT/OT stack, from plant level to the whole enterprise, looking at everything from technology architecture to manufacturing applications and tools. Also review previous IIoT pilots, identifying pain points that prevented projects from moving forward.
Begin with an assessment of your current IT/OT stack, from plant level to the whole enterprise, looking at everything from technology architecture to manufacturing applications and tools. Also review previous IIoT pilots, identifying pain points that prevented projects from moving forward. Incorporate data expertise up front. Avoid delays and needless iteration during implementation by having data scientists, who know the data they will need to have when building their analytics models, participate in the design of the reference architecture. The data scientists will also need to work with the process engineers to ensure that the data can be both collected accurately at source and aggregated into the right location at the right time.
Avoid delays and needless iteration during implementation by having data scientists, who know the data they will need to have when building their analytics models, participate in the design of the reference architecture. The data scientists will also need to work with the process engineers to ensure that the data can be both collected accurately at source and aggregated into the right location at the right time. Define a core architecture choice. Assess the pros and cons of selecting a single platform, an ecosystem of vendors, or a hybrid approach, before aligning on an overall direction.
Assess the pros and cons of selecting a single platform, an ecosystem of vendors, or a hybrid approach, before aligning on an overall direction. Recommend tech choices specific to use cases. Agree on tech-stack requirements for prioritized use cases and compile decision criteria. Tailor existing evaluations of IIoT platform providers against the decision criteria to identify top choices.
Agree on tech-stack requirements for prioritized use cases and compile decision criteria. Tailor existing evaluations of IIoT platform providers against the decision criteria to identify top choices. Chose vendors based on both tech capacity and human capability. While getting the right tech is essential, getting it to work depends on system-integration capabilities as well.
Deploy technology for prioritized use cases in the short term. For the prioritized use cases, invite a curated list of vendors into your organization’s ecosystem.
For the prioritized use cases, invite a curated list of vendors into your organization’s ecosystem. For the long term, create and align IT/OT roadmaps. Draft consistent IT and OT roadmaps that align with your organization’s broader business goals and underlying tech, then syndicate and refine them—noting that the time scale will be very different from a multi-year ERP implementation.
Following this approach will help your company navigate the complexities of the IIoT landscape to capture value quickly. Watch this space for more on each of the steps listed above.
The authors would like to thank Mike Coxon, Subu Naranayan and Bodo Koerber for their contributions to this post.Digitization in companies is advancing more and more. Even though processes are increasingly being carried out electronically, logistics service providers often receive their orders outside the transport systems - often still via analog channels. This increases the effort required on the part of logistics service providers to record shipment data.
In order to optimize the yard planning, staff utilization and operational processes, an increasing number of clients is asking their logistics providers to book dedicated time windows to pick-up and deliver goods. The booking of the time windows usually needs to take place 24h before pick-up/delivery. The booking itself causes additional effort for the logistics providers and reduces efficiency. In addition to that, the flexibility to plan the pick-up/delivery tour is reduced which can negatively affect the utilization of the available loading capacity.
Customers are increasingly demanding reliable transparency on the status of shipments from their service providers. This requirement presents logistics companies with an enormous challenge. On the one hand, the recording of the conventional barcode by warehouse personnel is time-consuming and therefore inefficient. On the other hand, additional information, such as temperature or vibrations, must be transmitted to the customer more frequently. Current transport systems are often not suited to provide this type of information.
In the event that companies do not transmit their shipment data electronically, the data must be recorded by the service provider. This entails the risk of incorrect information being recorded, which is even increased by the existing shortage of skilled workers and outsourcing. In addition, shipments cannot be reloaded as long as the shipment data has not been recorded. In reality, this repeatedly leads to delays in operational processes.The role of IoT in the manufacturing industry is increasing. Gartner forecasts 20 billion internet-connected things by 2020. Although it is not about general-purpose devices, but about dedicated-function objects, such as jet engines, connected cars or even coffee machines. Besides new business applications, IoT solutions enable businesses to analyze data generated by IoT edge devices and use these insights as a basis to improve business decisions. This article focuses on the IoT platform as one essential component of this development as well as introduces the Deloitte Digital Platform (D²P), which allows you to integrate and collaborate with data coming from various systems, devices, applications and human interaction.
A lack of interface and communication standards lead to a gap between IoT edge devices and business applications. An IoT platform closes this gap by acting as a middleware, which mediates between the two ends. However, modern IoT platforms go one-step further by adding functionality to the hardware and application layer. For this reason, capabilities for edge data processing or complex data analytic algorithms can also belong to the functionality set of an IoT platform. In general, IoT platforms are all about enabling businesses to build IoT solutions faster, cheaper and better, by solving problems and complexities related to the interoperability between infrastructure and business applications.Niccolò Machiavelli, one of history’s great futurists, might have predicted the Internet of Things (IoT) when he wrote, “There is nothing more difficult to take in hand, more perilous to conduct, or more uncertain in its success, than to take the lead in the introduction of a new order of things.” The IoT’s early innovators, who have grappled with mixed overall demand, a lack of consistent standards, and other challenges, would agree that their road has been difficult. But, like other visionaries before them, they have persisted in establishing a new order because they see the promise ahead.
Both consumers and the media are fascinated by IoT innovations that have already hit the market. These “smart” devices have sensors that communicate seamlessly over the Internet with other devices or the cloud, generating data that make the world safer, more productive, and healthier. In just a few years, some IoT devices have become standard, including thermostats that automatically adjust the temperature and production-line sensors that inform workshop supervisors of machine condition. Now innovators want to enable more sophisticated IoT technologies for self-driving cars, drone-delivery services, and other advanced applications.
Although some analysts are excited about the IoT’s potential, others have argued that it is overhyped. We take a more balanced view, based on our extensive research as well as our direct work with IoT application developers and their customers. Like the optimists, we believe that the IoT could have a significant, and possibly revolutionary, impact across society. But we also think that the lead time to achieve these benefits, as well as the widespread adoption of IoT applications, may take longer than anticipated. The uptake of IoT applications could be particularly slow in the industrial sector, since companies are often constrained by long capital cycles, organizational inertia, and a shortage of talented staff that can develop and deploy IoT solutions.
For semiconductor companies, which are looking for new sources of revenue, the rate of IoT adoption is an important concern. In this article, we will look at the case for optimism, as well as the reasons for more modest expectations. We will also examine new technologies that could accelerate the IoT’s growth and product-development strategies that semiconductor companies could implement to increase the appeal of IoT offerings.
If we look at the IoT’s recent growth, the optimists have reason to be encouraged. Consumers are more connected than ever, owning an average of four IoT devices that communicate with the cloud. Globally, an estimated 127 new devices connect to the Internet every second. A report from the McKinsey Global Institute estimates that the IoT could have an annual economic impact of $3.9 trillion to $11.1 trillion by 2025 across many different settings, including factories, cities, retail environments, and the human body (Exhibit 1).
Exhibit 1 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
The IoT is also benefiting from infrastructure improvements that have enhanced connectivity. For example, only 20 percent of the global population is now covered by low-power, wide-area networks (LPWANs) that allow long-range communications among connected devices while optimizing both costs and power-consumption requirements. By 2022, however, we expect that 100 percent of the population will have LPWAN coverage. Similarly, technological advances are reducing power requirements, decreasing costs, and promoting the development of more integrated IoT solutions. Consider lidar sensors, the laser-based sensor packages that scan and detect surroundings, which are essential for autonomous driving. Their price has declined more than 10-fold over the past eight years and is expected to drop more than 65-fold over the next two. This decrease, combined with the increased technological sophistication of lidar, is contributing to the development of fully autonomous cars, which could constitute 25 percent of all vehicle purchases by 2035.
Many experts view the IoT’s slower-than-expected growth within the industrial sector with particular concern. To gain more perspective, we investigated how industrial companies are using IoT applications and tried to estimate whether business-to-business (B2B) growth might accelerate. In addition to basic research, we interviewed and surveyed over 100 leaders from various industries, including public sector and utilities, discrete manufacturing, oil and gas, mining, telecommunications, technology, media, healthcare, and pharmaceuticals.
Our interviews revealed that most businesses are adopting the IoT only to a limited extent. With the exception of oil and gas and mining, leaders from all industries reported that their companies often received real-time data from IoT sensors. However, most leaders reported that their enterprise deployments were still at proof-of-concept stage, and none have yet embarked on large-scale programs (Exhibit 2).
Exhibit 2 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Although IoT sensors collect vast stores of data, a recent report from MGI showed that companies do not analyze most of them. For example, on an oil rig that had 30,000 sensors, managers examined only 1 percent of data. What’s more, business leaders seldom consider information from IoT sensors when making important decisions, including those related to maintenance planning or automation procedures. Their reluctance to examine IoT data stems from several factors, including a lack of data-analytics staff, but the most important reason is simple: as humans, we prefer to consult other people for advice or to look back on our own experience, when making decisions. Although hard data from IoT devices are more complete and objective, we tend to assign them less value. Before IoT data gain a more prominent role in corporate decision making, business leaders and other important managers—maintenance supervisors, field service technicians, and retail merchandisers, to name just a few—will have to appreciate their value.
In our survey, respondents favored simple use cases that enable tracking data and sending status alerts related to changes in the physical world (Exhibit 3). Some companies, for instance, have placed sensors in food packaging that track a product’s location throughout the distribution supply chain. Simple tracking and alert functions are relatively easy to deploy because they do not require advanced analytics, complex algorithms, or data-science capabilities, allowing them to generate value quickly. Although some innovators are enthusiastic about IoT applications for optimization and prediction, we expect that most customers will remain focused on simple use cases, at least for the immediate future. And that means they will not obtain full value from the IoT.
Exhibit 3 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
IoT devices, connected cars, and edge gateways are all potential entry points for a cyberattack—and we recently saw the full extent of this vulnerability. In the 2016 Mirai botnet attack, hackers specifically targeted IoT devices, including appliances and routers, and disrupted many major Internet service providers. The attack, the most significant of its kind, was possible only because of human weakness—a failure to reset generic or default password and username combinations. This attack, and others like it, demonstrate that IoT vulnerabilities often result from a lack of basic care in managing and maintaining devices. Such weaknesses cannot be eliminated through encryption, attack-detection programs, biometric-access control, or other sophisticated technologies. That means companies that want to expand their IoT efforts will need to launch comprehensive security initiatives that address weaknesses resulting from both technological vulnerabilities and a lack of caution among those who use IoT devices.
A few important, and potentially disruptive, developments could accelerate IoT uptake and create opportunities for semiconductor players.
Video analytics—the application of sophisticated algorithms to video feeds—is spurring the creation of new IoT applications and use cases. For instance, data analysts can now examine customer demographics by applying sophisticated algorithms to videos taken as shoppers browse through merchandise. Recent evidence also suggests that the IoT will benefit from audio captured on microphones.
The costs associated with video and audio feeds are falling, with sensors now embedded in devices at low cost—under $2 each. The data gathered from these feeds are extremely rich, diverse, and relevant to many widely used IoT applications. Lower data-communication rates, the growth of 5G data networks, and ongoing decreases in cloud-storage costs will continue to encourage developers to find new uses for video and audio.
For semiconductor companies, the increased importance of IoT video and audio feeds may create an opportunity to combine hardware with end-to-end approaches for analytics and control. They will have to move quickly to meet customer needs, however, since the technology related to advanced applications, such as those that use analytics to recognize faces, is evolving rapidly. Semiconductor customers may be particularly interested in products that integrate hardware and software more closely, as well as new architectures that optimize transmission, processing, and analytics on devices, in the network, and in the cloud.
The advent of standards that support truly LPWANs, including LoRa, NarrowBand IOT, and Sigfox, will enable large-scale sensor deployment of IoT applications in many areas, including agriculture (analysis of soil conditions), safety (citywide monitoring of air quality), and productivity (real-time logistical tracking along the supply chain). But the growth of the IoT, combined with the increase in sensors and connectivity, will also make it more challenging to provide power to untethered devices and sending nodes. Even with long-life battery technology, many of these devices can only function for a few months without a recharge.
Energy harvesting, a process in which energy derived from external sources is captured and stored for use in wireless devices, might resolve power-related issues. Although solar energy could provide an answer for many IoT applications, semiconductor companies should also investigate other sources, such as wind, thermal energy (derived from heat), and kinetic energy (derived from an object’s motion). Optimizing energy harvesting, management, and storage will require companies to create innovative designs, at both the silicon and system level.
As the IoT expands, innovators are rapidly developing complementary architectures that combine the following two important features:
the power of the cloud, which offers robust storage and greatly extensible computing power at low cost
the ability to process and store data on a device (or edge), or within a network at gateways that connect multiple end-devices to the cloud
Multiple IT architectures with these properties have already reached the market, each offering a compelling approach. But semiconductor companies have an opportunity to go further—and to make more rapid progress—in defining the future architecture of the IoT. In particular, they should focus on products related to video and audio sensors, since these devices are proliferating and generating significant amounts of data.
Many IoT applications require data to be processed on the devices themselves. For instance, applications for autonomous driving, surveillance, and security all have strict latency specifications that require systems to respond immediately after data input. To meet these requirements, the IoT devices that collect the data must process them and use the output to make decisions. Applications that require on-device processing are power hungry and include relatively expensive components, such as multiple application processors. Semiconductor companies could take the lead in optimizing on-device solutions for these applications. For instance, they could create edge-device solutions for autonomous control, facial recognition, and audio analytics, all of which have different hardware and software requirements with respect to computing performance, signal processing, and storage.
Before any company explores IoT opportunities, it should take a new look at strategy, including the factors that it considers when developing solutions.
Both developers and business leaders often focus on the technological potential of the IoT, including its ability to collect and analyze vast stores of data. But technological advances alone will not make an IoT application more valuable or desirable to customers. Instead, developers should focus on outcomes—how a new application will improve safety, financial returns (for businesses), and convenience.
Consider, for example, the outcomes that one airplane manufacturer achieved by using IoT sensors to monitor jet-engine performance. By providing real-time data, the sensors immediately alert the manufacturer about potential problems, which makes it easy to conduct preventive maintenance and maximize uptime. Other sensors help with parts-inventory management. Together, these IoT enhancements have contributed to 9 percent revenue growth and a 30 percent increase in engine availability. That means airplanes spend more miles in the air and less time on the ground, consistently reducing overall operating costs.
To focus on outcomes, companies will have to coordinate activities across the value chain. In addition to providing the technology and data that enable the IoT, they will need to adapt their business models—a difficult process, in our experience, since incumbents often resist change. If they fail to evolve, a start-up or another disruptive player may take the lead in establishing a new approach to IoT application development, especially if new investors emerge to finance innovative ventures.
As companies shift their focus from technology to outcomes, they will need to provide incentives that encourage upstream vendors and customers to support the use of their applications.
Just as IoT innovators tend to focus on technology, many IoT marketing materials try to appeal to customers by discussing the latest product upgrade, including better sensors, connectivity, computing power, and analytics. But our experience has consistently offered one clear insight: users, both personal and industrial, are more likely to adopt IoT technologies that generate a positive emotional reaction. Consider smart homes, where technology companies have recently won many customers by offering voice-based products—devices with basic conversational abilities that often respond to a name, just like a person. For instance, Amazon’s Echo, a smart-home speaker, answers to the name Alexa and can respond to basic commands and questions. Such qualities may create an emotional connection between users and devices, and they could be partly responsible for the strong sales of voice-based products.
As technology companies develop new IoT offerings, they should ask digital designers to provide insights about customer behavior, since this information might help them create products that prompt strong positive feelings and accelerate adoption rates. As always, products will also need strong technical and analytical capabilities, but companies are more accustomed to delivering such features.
Current IoT trends create an uncertain and sometimes confusing picture of the sector’s future prospects. When we look at the evidence in total, however, we believe that the IoT is poised to serve as a major growth driver for semiconductor companies. Adoption rates have risen more slowly than expected, but that should not be a reason for pessimism, since many IoT technologies are immature or undergoing development. Semiconductor companies and other players can still undertake new strategies to accelerate IoT growth. Rather than focusing on technology upgrades, they could develop IoT products that truly improve customer outcomes for cost, performance, and other important metrics. They could also emphasize design-driven insights about customer needs, including the product features that generate a positive emotional response. This new approach to development will be challenging, but it will accelerate IoT adoption and help more customers, both personal and industrial, achieve benefits from this exciting new technology.Internet of Things (IoT) technologies have evolved rapidly in recent years and continue to change how we interact with our surroundings. For companies, IoT brings new ways to monitor and manage objects in the physical world, while massive new streams of data offer better avenues for decision making (often mediated by machines). The steady fall in prices of sensors and communications technologies, combined with a parallel rise in understanding of how they can be applied, have raised the strategic importance of IoT. As we have shown elsewhere, this can produce immense value in settings ranging from retail and healthcare to manufacturing and technology.
Despite the promise, we continue to see substantial differences in how well companies apply IoT in their businesses. Targeting IoT applications correctly and managing them effectively is far from easy, leaving many companies stuck and unable to move beyond pilots. To better understand what differentiates successful initiatives from struggling ones, we surveyed IoT executives at 300 companies—those that have moved beyond experiments and have scaled up IoT use in their businesses. We asked them about the practices that directly support their IoT strategy, as well as other factors that may influence it, and sorted leaders from laggards based on their self-reported economic impact from IoT. We found that while a number of IoT “habits” play a role in successes, three are particularly relevant for C-level executives who may be considering heavier investment in IoT or searching for reasons their programs have failed to gain traction.
There’s no single path to IoT success. Some companies focus on connecting existing products to make them more attractive and useful to customers. Others exploit opportunities to achieve operational improvements that increase efficiency and lower costs. Still others push more boldly, using connectivity to create entirely new products or remake business models (even moving into separate IoT businesses). Our survey found that companies that achieved scale in IoT did so by pursuing a variety of strategies—and all with at least some degree of success. However, when we looked more closely at the gains, we found that the most successful companies often played to their strengths—rather than betting on unfamiliar markets or new products (Exhibit 1). These IoT leaders, the group getting the most economic benefit from IoT, were nearly three times more likely to add IoT connectivity to existing products they sell than the laggards were. Conversely, laggards—those in the bottom quintile of economic returns—were significantly more likely to focus on developing new IoT products or services.
Exhibit 1 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Playing to market strengths was the course chosen by strategists at an agricultural-equipment manufacturer, after they observed digital players from outside the industry sizing up opportunities to offer sophisticated analytics services to farmers. In response, the company shifted R&D investments to “IoT-enabled” products and services in existing lines of business. Their new system used farm-based sensors to read soil conditions continuously, relaying the information to a cloud-based analytics platform that farmers could use to monitor variations on their mobile devices. Other sensors tracked irrigation levels and sent alerts whenever moisture readings hit predefined levels demanding attention. With these real-time insights, farmers were able to optimize their water and fertilizer use. That, in turn, increased yields over the growing season while substantially reducing water, fertilizer, and fuel costs for equipment. As the manufacturer added users, the growing quality and breadth of data improved the predictive capabilities of the system, further increasing value to farmers who joined the ecosystem.
The success of the agriculture manufacturer underscores the advantages incumbents often have in their ability to define use cases for IoT that build upon existing product lines, as well as their better line of sight on how improvements can create value for customers.
Many companies become frustrated when they don’t see early signs of transformative impact from an IoT pilot. Our research points to one key reason: a single use case just won’t get you there. Scale, both in terms of number of use cases as well as the breadth of application, helps maximize impact. Leading companies in our survey implemented on average 80 percent more IoT applications than laggards. More widespread usage, it seems, forces a cultural shift. It stokes organizational energy behind changes and creates new mindfulness about the benefits of IoT. In a ripple effect, this momentum often exposes weakness in technology along with gaps in talent—both in terms of in-house IoT skill levels and the numbers of experts needed to implement IoT at scale. This “go big” approach may seem counterintuitive, particularly among executives who have fewer resources to deploy and feel more comfortable focusing on a small number of applications. While a smaller scale may be good for very early days, there is a clear learning curve that companies climb as they add use cases—and one that has a powerful impact. Our research shows that a greater number of use cases correlates with economic success (Exhibit 2), regardless of the use case or type of company.
Exhibit 2 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Take the experience of one major transportation-equipment manufacturer whose initial IoT deployment, executives soon realized, just wasn’t bold enough. It had launched the IoT strategy with four minimum viable products (MVPs) but soon found that this narrow focus wasn’t improving performance as much as expected. A cadre of IoT leaders pushed against voices of caution and expanded the number of MVPs to 11. Executives also found that giving managers a larger number of IoT projects (and products) to oversee focused their attention, creating a bias toward action. That momentum built on itself as the company’s best talent wanted to be part of the innovative push. A broad base of 30 IoT scrum teams, meanwhile, helped loosen bureaucratic decision-making rules. Finally, unexpected efficiencies turned up as engineers were able to use similar data architectures for multiple offerings and found numerous synergies among the digital end products. The more aggressive use-case strategy produced in excess of $1 billion in new revenue.
IoT is one of today’s most promising (and exciting) technologies. But people create the conditions for value creation. IoT has often been portrayed primarily as a technical-implementation challenge, with the drive for adoption spearheaded by specialists in the CIO function. Yet time and again we see that deriving real business gains from IoT efforts requires changes to a business process—the hard job of modifying the way a company does things. Connecting production equipment to the internet, for example, will allow a company to manage usage more effectively and predict when maintenance is needed. However, if the surrounding business processes aren’t modified and optimized, then value won’t be maximized.
Those second-order challenges were manifest at one metals manufacturer. The company had connected three rolling mills with sensors in an IoT deployment. The goal was to capture and analyze previously unused data from the machines. Executives were pleased that they were able to get the system up and running in just three weeks, to help solve nagging capacity constraints at the facility. However, there was a problem: the insights generated by the system weren’t being used by the frontline employees.
The management team responded by modifying a range of plant-floor processes. For starters, they simplified the complex analytics that the system was churning out, synthesizing the output into one number that measured operator wait time. This change enabled line operators to recognize immediately when bottlenecks in the process were forming. The company then changed the inspection routes of plant-area supervisors, whereby they circled back to bottlenecked lines four times daily, checking in with the operators on how many times they had to wait—and why. Those discussions resulted in a change to daily plant-area “huddles” that included the operators, who were given greater latitude to adjust frontline processes to resolve underlying issues before they caused product flow backups. The IoT-informed process changes had a big effect. Operators were able to identify several hidden causes of slowdowns and stoppages, issues that earlier problem-solving efforts had missed. Overall equipment efficiency increased by 50 percent, saving hundreds of millions of dollars in planned capital expenditures.
This metals manufacturer learned that, in order to maximize IoT value, people have to behave differently, make decisions differently, and operate in a new normal of rapid information flow. It’s not surprising, then, that IoT leaders were three times more likely than IoT laggards to claim that having a strong ability to manage business-process change was a top-three IoT capability.
As we noted earlier, companies need to be attuned to other reasons why IoT deployment may fall short. For one thing, if the CEO and top team aren’t focused on potential IoT gains, providing visible encouragement (and adequate resources) for the efforts, they are likely to stall. Leaders need also to be mindful that IoT increases the potential for privacy breaches and data-security risks, since there are many more information nodes for hackers to penetrate. These risks need robust and continuous management, and those costs need to be incorporated into projected returns. Finally, even companies with a good IoT track record shouldn’t think they can go it alone. Technical IoT ecosystems are growing—and improving—by the day. Collaboration, often with smaller players that have high levels of expertise in areas such as software development, will provide a solid source of competitive advantage. That will help companies accelerate their programs and better position themselves to become IoT leaders.January 31, 2019 Business-process optimization has always been a labor- and time-intensive activity. The traditional method for uncovering the root causes of process problems—value stream mapping—involves a team, a room, and a stack of Post-it notes. Mapping the loops and alternative pathways involved in a process such as order-to-cash, claims processing, or source-to-pay can reveal plenty of hidden waste. And bringing different stakeholders together in a room can be an excellent way to create an end-to-end perspective on processes that may involve multiple stakeholders, sites, and business functions.
Traditional process mapping has an important weakness, however, in addition to the many hours of work it requires. It often relies on estimates for how long individual process steps take, or how often variances occur. As a result, these maps inadvertently represent the biases and misunderstandings of their creators. That can lead companies to miss important issues, or to focus too much attention on problems that occur infrequently and cost the business little.
Enter the new digitally-enabled world of intelligent process analytics. Every piece of information that flows through a business today generates its own digital trail, creating a plethora of data revealing where the information went and when. Now, a new generation of smart analytical tools allows companies to use that data to see what is really going on in their back-office operations.
These “process mining” tools can rapidly analyze thousands of transactions to reveal the underlying process flows. More powerfully still, they allow managers to slice business process data in multiple ways. They can show exactly which types of invoices are most likely to require manual rework, for example, or they can automatically generate key performance indicators, segmenting them by task type, customer, or operations team. Or they can monitor the effectiveness of new digital workflows, identifying the categories of task that still escape from digital process flows and demand manual intervention.
These tools can also help with the design of process changes or automation efforts. They allow companies to validate the effectiveness of those changes as they roll out. And because they can deliver useful results quickly and easily, process mining systems are especially useful in agile development environments, where robotic process automation and other new digital approaches are introduced in a rapid, iterative way.
Process mining solves several major challenges. It brings speed, analytical power, and fact-based rigor to the problem of uncovering the sources of waste, inefficiency, and lost value in business operations. But, on their own, these tools can’t do anything about fixing those problems. That’s where the hard work starts.
The smartest of analytical tools can only deliver value if they are used in the context of a wider transformation effort. Companies still need teams of people with the skills, influence and motivation to design effective processes and select appropriate performance indicators, to turn analytical insights into concrete plans of action, and then to test, roll out and sustain those processes. And the cross-functional and interconnected nature of business processes means they will also need to carefully coordinate multiple improvements to avoid introducing new problems and unintended consequences elsewhere.
We are excited about the potential for emerging process mining technologies. We have already seen companies use them to great effect in a number of different sectors. But we also know that a diagnosis is not a cure. Without the right approach, expertise, and energy to transform insights into lasting change, companies risk gaining scant return on their investment in these tools.
The authors wish to thank Klaus Kunkel, Rohit Panikkar, and Samir Singh for their contributions to this blog post.The IMA® (Institute of Management Accountants), the association of accountants and financial professionals in business, held its 2019 Annual Conference and Expo (ACE2019) this past June in San Diego, California. The event officially celebrated the Institute of Management Accountant’s 100-year anniversary with a special Centennial Celebration honoring IMA’s thriving global community of accounting and finance professionals. Attendees had the opportunity to network with other industry professionals, hear presentations from leaders, and choose from more than 75 job-relevant sessions tracks designed for management accountants to customize their learning experience on topics ranging from corporate governance to technology and finance trends for the future.
As a diamond level sponsor, Deloitte had the opportunity to attend the action-packed conference and deliver presentations on specialty topics. Deloitte delivered a specialty breakout session on touchless close as well as a general presentation on the Center for Controllership™ during the IMA annual conference dinner.
To gather some insights and perspectives that may help us with future conferences and projects with IMA, we caught up with our presenters and some of the attendees to hear about some of their highlights from the experience and insights they were able to take away from the conference.Insert Custom CSS fragment. Do not delete! This box/component contains code needed on this page. This message will not be visible when page is activated.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.May 21, 2020 Stefano is a McKinsey Digital engagement manager based in Singapore. He conducts more than 30 interviews a year for both digital and generalist consulting roles. Focusing mostly on campus interviews (e.g., INSEAD), he also participates in experienced professional interviews.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
I love meeting new people through our recruiting process and learning about their backgrounds and experiences, as well as their approach to problem solving. People are what drive the firm, and recruitment is how we attract and hire exceptional talent.
I think of recruiting as a two-way process in which the candidates can learn more about the firm, the kind of work we do and the impact we have, and about the people who may become their colleagues. I am very excited at the end of an interview when the candidate has a chance to ask questions. I see this as an opportunity to get them even more excited about the prospect of joining us.
One memorable moment was when I interviewed a candidate who was at a remote mine site in West Africa, which meant he had to conduct interview via video on his phone. He had to travel to the nearest village to get strong mobile reception, which meant he was going to participate in the interview on the street. It was funny to see other people walking behind him and curiously trying to figure out what the phone call was about. I was impressed and appreciated his willingness to interview in an unconventional setting.
Don’t neglect the personal experience part of the interview. Make sure you prepare as much for that portion as for the case studies. Be sure to focus on experiences in which you were really challenged and stretched, and walk the interviewer through some of the details of your experiences. For example, share what you felt or how you handled a particular situation and bring your leadership, entrepreneurship, and personal impact to life.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Stefano graduated from Florida State University with a Bachelors in Economics. He started his career at BHP Billiton, the mining company, in commercial functions in Singapore as a marketing manager. After six years, he left to pursue his MBA at INSEAD and worked at two consulting firms based in Australia and Singapore. In 2018, Stefano joined McKinsey Digital.
Outside of work, Stefano loves to travel. He enjoys exploring cities he travels to for client work. These days he enjoys playing hide-and-seek with his daughter and watching live streams of the Bolshoi Theater Ballet and the Kruger Park safaris.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.May 13, 2019 When we talk to clients about their hiring process, we often get questions on assessments. In particular, one question we often see is starkly simple yet deceptively difficult to answer—which hiring assessments, among the sea of available options, are best? We believe that this question belies a broader misunderstanding of assessments.
Assessments are simply a standardized means of collecting information about an applicant to help with hiring or promotion decisions. It is a broad category and can take the form of a standardized written assessment, a resume screen or an interview. There is not one assessment that is a gold standard to be used universally across all roles—it depends on what characteristics matter for the role in question (see our previous post for more on that process).
If there isn’t direct science linking the assessment to job performance or to the characteristic that matters for the job in question, don’t use it.
In this third and final part on hiring, we dispel four of the most pervasive, detrimental myths regarding the use of assessments in hiring.
1. The more assessments, the better. Despite what many think, using more assessments is not always better—and can often be worse than using too few. Using additional assessments that do not meaningfully distinguish who is best suited for the job will result in worse hiring decisions than if these additional data points were not used at all. Worse yet, too many lengthy assessments can negatively influence the candidate experience and decrease the size of the candidate pool. In one case, a staffing firm we worked with found that long screening assessments were causing otherwise promising candidates to drop out of the process, thereby driving down the quality of hires.
Using less scientific tools, like an unstructured interview, introduce noise to the decision-making process and may bias against certain types of applicants. Simple advice—if there isn’t direct science linking the assessment to job performance or to the characteristic you’ve determined matters for the job in question, don’t use it.
2. Assessments that use the latest machine learning/AI are better than long established assessments. While we share the enthusiasm for the potential of advanced technologies and techniques (e.g., gamified assessments), we shouldn’t throw the baby out with the bath water.
It is important that new approaches are held to the same standards of integrity to which we hold more traditional assessments. Decades of research has shown that traditional assessments of cognitive ability and personality traits (e.g., conscientiousness) are still some of the best predictors out there.
At a minimum, assessment vendors should have technical documentation describing the reliability, validity and prescribed uses of their assessments. Also pay attention to any information on test bias, administration requirements and potentially available databases for scoring and test interpretation.
3. Hiring assessments are only for hiring decisions. Just because they’re often called hiring assessments doesn’t mean their usefulness stops there. All too often, organizations are sitting on a treasure trove of information about their employees from the hiring assessment process, but once the hiring decision is made everyone forgets about this data.
We maintain that this data can be very useful for onboarding and ongoing learning & development of new hires. Perhaps your organization has hired a new technical product manager who you learned during the interview has less experience in AI products. We highly recommend leveraging this assessment information to create a tailored training plan for their first 6 months on the job.
4. Standardized assessments are less useful for leadership positions. When used in the right way, we have found that assessments have a place across the hierarchy. As with entry-level positions, having a structured approach to gather information on leaders via assessments is helpful. With leaders, though, the degree and type of information needed to make quality decisions is necessarily different. Although a two-hour cognitive ability assessment may be overkill, concrete information about leaders’ interpersonal and working style may be worthy of exploring in a short personality assessment or structured interview.
By tackling these 4 assessment myths, in addition to navigating the 3 main challenges that make hiring difficult and following these 3 concrete steps to improve your hiring process, your organization will be well on its way to winning with talent.August 12, 2019 Imagine if an agency, retailer or bank could map its audience’s journey, fully understanding the experiences, actions and pain points that both drive and undermine the organizational decision-making process. Recent McKinsey research shows that most companies struggle with decision-making—particularly cross-cutting decisions where the process is often not only complex, but also unclear. Our research into the impact of decision-making shows that organizations with high velocity and quality decision-making generate 2.5 times higher growth, two times higher profit and 30 percent higher returns on invested capital. But how to take these insights and translate them into practical, tactical actions for your organization?
This question is what inspired DecisionLab, which was developed to empower organizations to map their most important, value-creating processes and clarify roles and responsibilities through an immersive experience. The objective is to inspire collaboration and help users drill down into their processes to ensure optimal internal operations—ultimately delivering a better experience for those they serve.
A state government agency wanted to implement an agency-wide transformation to modernize the way they work, redesigning processes to provide higher-quality, faster and more efficient services to citizens.
For this particular case, the first task was to prioritize processes for the redesign, identifying the most impactful in terms of volume and citizens served. This involved mapping out the citizen journey, charting actions and decisions at low points in the citizen experience, and spotting problems to solve.
One identified low point was when a citizen appealed an agency decision. Mapping out the process revealed that nobody was taking accountability, and as a result, the appeal process would typically last seven months or longer.
A logical next step was creating total transparency, then immediately moving into process redesign and streamlining by removing unnecessary steps and clarifying decision rights—and accountability—with a RACI framework. The estimated impact is inspiring: The seven-month appeals process is now projected to last just one month.
Another example is a performing arts center that was also grappling with decision-making. It operated in a matrix, struggling with how to prioritize demands on limited resources and lacking clarity on who had final rights for important cross-cutting decisions.
We began by conducting interviews with senior leaders to gather perspectives on strengths, weaknesses and priority processes, and by codifying the current state, including roles and responsibilities as well as pain points.
We then conducted a workshop to test a proposed redesign of a decision-making process. We walked through a scenario with the full executive team, debating key areas of tension, enabling us to adjust in real time.
The result was alignment on the new process as well as roles and responsibilities for improvement. We also equipped the leadership team with a simple framework to establish decision rights in the future.
In a challenging and highly competitive market, a consumer technology company created a new business unit focused on customer experience and shifted to a more formal organizational model. However, the redesign lacked clarity on decision rights among business units, slowing decision-making.
We conducted interviews with leadership to understand the core issues surrounding this ambiguity. We codified the current state in real time and captured where pain points existed. Then, in a workshop with the top team, we co-created life-like scenarios with unclear decision rights.
For example, we explored an internal disagreement on the location and color of a new brand icon on the website. Who takes the decision: the market-specific business unit, or the new customer experience business unit?
The process helped facilitate this conversation and ultimately led to working through challenges differently than leadership had in the past. With the new process in place, the company now makes faster decisions.Maria is the Lead Enterprise Agility Partner in Deloitte’s Consulting Practice in Asia-Pacific. Maria has worked with a wide variety of teams, leaders, and organisations to re-wire their management philosophy and enable the shift in thinking required for her clients across Asia-Pacific to deliver projects better, with more value, sooner, safer and happier. She has been working with her clients to create customer-centric, high performance delivery, and learning ecosystems across industries, particularly with extensive experience in financial services, telecommunications, and energy & resources. Based on her technology delivery background, Maria’s approach to change and leveraging new ways of working is pragmatic and has an effective balance between delivery and an outcome focussed mindset and culture.Nowadays, Agile methodologies have well and truly arrived in most organizations. The complexity of digital opportunities and the unpredictability of customers and competitors are both on the rise, making it impossible to predict what businesses will need in the future. That is why Agile is such a decisive factor to enhance organization’s responsiveness towards volatility. Strategy management has to evolve as well, which is where Agile concepts come into play. More...A blog delivering insights into the latest discussions, trends and lessons from the front line on Agile. Deloitte is a pre-eminent Agile advisor and a leading expert on Agile, providing tailored solutions across various organisations, industries, and projects, at any scale.
Agile is a set of principles and practices based around the concept of iterative and incremental development, with collaboration between teams at its cornerstone. Agile approaches to delivery can increase quality, reduce waste, improve predictability and boost morale in organisations.
Our experts in Agile will provide their views on the latest developments within the Agile community, developed through first-hand experience across a range of industries and services, and will help keep you up to date with the tools and considerations needed for successful Agile development.Searching “what is agile?” we find words like “iterative development, software delivery, self-organising teams, scrum, and sprint”. If you’re reading this blog, you’re probably familiar with most of these terms, and you may even be thinking about Agile at scale, or “Enterprise Agility”. As we start to scale agile, the human aspects tend to be outweighed by a focus on execution. However in our experience, there are a small number of factors that become critical to truly realising benefits as organisations begin to scale Continuous Delivery, DevOps or Agile principles beyond 1-2 teams, and start looking at a whole function or even an entire organisation….
So what do we mean by human aspects? … It’s anything and everything to do with an organisation and its people, how they work together, and its workforce.
In a series of blog posts, we will explore these critical human aspects by asking the question: “What practical steps can we take to start making a difference?” With the first of the series focusing on Leadership.
We are quite excited to see some really informative research around Agile Leadership emerging. The Puppet + DORA State of DevOps Report examines the idea of transformational leadership, and Deloitte’s 2017 Human Capital Trends which explores the idea of “hero leader”, and how it can no longer scale, detailing how the US Military has reinvented itself as a network of teams.
As we begin to explore the idea of Leadership in an Agile environment, we are immediately compelled to examine what leadership means alongside (increasingly) autonomous / self-managed teams. What is the role of leadership in these new ways of working? Is a different type of leadership needed? Are leadership roles needed at all?
Our view is that leadership is becoming more diffused across the organisation rather than the traditional approach where it is distilled in discrete roles at the top of an organisation. More and more, leadership is a capability that is integral to all roles, at all levels of the organisation, irrespective of whether a role has direct reports or not. This means there will be far fewer roles that are considered “only leadership”, and even when these discrete leadership roles exist, what they do is changing significantly.
There are some well documented examples of this in practice; LeLoux explores a number of these in his seminal book: Reinventing Organizations. Atlassian’s (the now famous Australian start-up that even AFR now considers the “coolest company in Australia”) focuses their leadership teams almost exclusively on the “sustainability of the eco-system”. Leaders amplify the company’s vision and purpose, develop “the guard-rails” that enable everyone to deliver great customer outcomes, and identifying potential threats by assessing their ongoing competitive position.
And Microsoft who’s transformation from “a battleship to 3000 canoes”, has been underpinned by leaders who focus on translating customer value into outcomes, challenging the norm, and inspiring people.
One of the key characteristics is authenticity. Authentic leaders communicate their team / organisation’s purpose in a practical way. Their passion for the customer is infectious and creates the oxygen for teams to take meaningful action rather than waiting to be “told what to do”.
This is tightly coupled with coaching. Coaching has become a core tenant of leadership, incorporating both personal recognition of great work, as well as creating an environment of- and space for- continuous development and collective accountability that encourages personal and collaborative reflection in the absence of blame.
Demonstrate empathy, care and inclusion – taking the time to seek out people’s stories and experiences, encouraging them to be themselves at work, and connecting personal interests to organisational purpose and customer outcomes. These leadership behaviours encouraging engagement and wellness that research is showing drives improved performance.
Research from Bersin by Deloitte found that inclusive leadership is one of the most significant driver of employee engagement. This is because when people feel included they feel safe; safety enables people to suspend self-interest, and it’s only when we can suspend self-interest that it possible for effective teams that are focused on delivering customer outcomes.
So on reflection… authenticity, coaching, empathy, care and inclusion; these are not aspects of leadership that most people would disagree with, but neither are the first words that would come to mind if you asked 100 people from a corporate Family Feud audience.
Start with purpose and customer ; have your team members spend (more) time with customers, sharing their stories, and demonstrate your personal connection to customer outcomes.
and ; have your team members spend (more) time with customers, sharing their stories, and demonstrate your personal connection to customer outcomes. Think differently by spending more time conceptualising possibilities, seeking out divergent views, and embracing complexity, and less time formulating specific strategies and plans.
by spending more time conceptualising possibilities, seeking out divergent views, and embracing complexity, and less time formulating specific strategies and plans. Act differently by playing an active role in multiple teams, embracing the Agile tools and ceremonies that your teams are using, and spend more time coaching and less directing.
by playing an active role in multiple teams, embracing the Agile tools and ceremonies that your teams are using, and spend more time coaching and less directing. React differently by explicitly tolerating risk and celebrating experimentation, demonstrating resilience when things don’t work perfectly the first time and consciously not laying blame.
So in summary, as a leader and influencer in your organisation the first port of call to scaling Agile is to take conscious control of your own “leadership style”, start thinking, acting and reacting differently, and you’ll begin to see the benefits we’ve discussed above. This can be the case, even when the rest of the organisation around you hasn’t changed. However to take those benefits to the next level and successfully scale even further, the next factor you would likely consider will be organisational structure. We’ll cover this in our next blog in this series.
You can find further Deloitte thinking and resources here. We would recommend the following further reading:It’s no secret that the success of any program hinges on senior executive ownership, support and their ability to cascade messaging down to all layers of an organisation. What’s also trending in Agile is the movement from leader-led change to intent-based leadership. Leadership should be viewed as a set of behaviours, not only a role. As such, leaders should empower passionate individuals to lead from all levels within the organisation.
Agile requires cultural change, not just technology. Every person up and down the chain should be versed in the language of agile, and be guided by a single framework and approach for doing so. Pilots enable you to slice off a sliver of the business, fundamentally transform this small group’s way of working, demonstrate benefits and then scale. Starting lots of little ‘spot fires’ such as this around the organisation will attract others, and draw them in to the movement.
Wise companies will proactively consider what they can learn from organisation models being created within digital-native companies. Removal of silos and hierarchy, with the blending of roles can help to create autonomous teams. When structures cannot be changed, alternatives such as creating ‘guilds’ – voluntary communities of like-minded people that come together to discuss topics of interest – can help create pockets of agile evangelists.
The ‘spot fires’ mentioned in the point on culture, are also a way of winning hearts when it comes to targets and incentives. Leaders should strive for voluntary participation over mandated participation, so that it becomes every individual’s idea and prerogative to operate in this new way. Key to this is addressing the genuine needs of people – get to the heart of the noble purpose so people are motivated intrinsically.
Only in an environment where people feel safe to play with ideas, and where they are recognised and rewarded for being agile will it occur. Something as simple as buying ‘failure cupcakes’ at the end of a sprint can help set in motion this new paradigm. Building elements of gamification, playfulness and fun into team challenges and goals can also help drive creativity, innovation and agility.
In summary, to make an organisation truly agile, companies need to focus on the five building blocks of an effective environment: leadership, culture, organisation design, targets and incentives, and celebrating outcomes. Get these right, and the rest will follow.Someone posted an article on LinkedIn the other day claiming “Agile is Dead”. The comments that followed were more interesting than the actual article. Many people were bashing agile frameworks. It is no secret that organizations have spend a lot of money on doing agile and many times never really achieved being agile. Right now, SAFe (Scaled Agile Framework) is trending and many of my clients are implementing it. But methodologies and frameworks are nothing more than a set of guiding principles for delivering software. At the end of the day, doing agile comes down to the three things:
A framework is only as good as the people, processes, and organizational structures that use it. Silos with competing goals always trump frameworks. Each silo creates an unnecessary handoff and increases wait time. Too often, additional processes get added to deal with the interaction between silos.
Then there is the people part. I am old enough to remember when all projects managers had to be PMBOK certified which trained project managers how to follow a set of processes and procedures (framework) to navigate the waterfall methodology. When we moved to agile, all these people were retrained and became certified scrum masters. Unfortunately, they still had the old command and control, sequential mindset and most agile efforts became “Wagile” — waterfall with daily standups.
The point here is it takes much more than a few training classes or certifications to change the mindset. This is a transformation and requires an investment in organizational change management to get the value out of the new frameworks.
All the process in the world can’t fix a bad architecture. To do agile, one must have an architecture that supports being agile. Characteristics of an agile architecture include:
Service-oriented — opposite of Monoliths, the system is made up of small parts that can be deployed separately
Testable — system supports testing hypothesis with methods such as A/B testing, feature flags, chaos engineering, etc.
The more a system supports the characteristics above, the more agility can be achieved. Not all systems need to implement all of those characteristics, but each characteristic can reduce manual intervention, allow for more frequent deployments and quicker MTTR, reduce widespread system outages, and provide for better availability. It can also reduce the amount of unexpected work which is probably the biggest single issue all agile frameworks struggle to deal with.
Even if you have an agile architecture and your agile framework is being executed flawlessly, if your operations people and processes are not in alignment, the whole house of cards will come tumbling down.
There is a lot disruption in operations these days. DevOps has played a huge roll in getting developers and operators collaborating better. Operations is now being thought of earlier in the lifecycle and teams are designing for ops. Companies are reevaluating their operating models and investigating newer practices such as Site Reliability Engineering (SRE), accepting that testing in production is a good thing (if done right), moving from reactive to proactive operations, embracing observability, and much more. As we move to more agile architectures, it’s common sense that we need to embrace more agile methods of operations.
The list goes on and on. I have yet to see a framework that even mentions most of these characteristics. The frameworks focus mostly on how to manage backlogs which is important, but if the software and the operations of that software does not promote agility, the framework is not going save you.
Organizations should focus more on being agile rather than doing agile. Being agile requires more than a framework. It is a mindset and it should be applied everywhere, not just in Dev and Ops. The Security and Governance teams need to be agile. Procurement can’t take six months to procure a software product. Decisionmakers need to come to conclusions in a timely manner. Processes that take forever should be redesigned. Approvals should not take forever. You get the point.
Being agile is a cultural issue and should be treated as one. If you want to make your organization agile, adopting a framework is only one piece of the puzzle. In fact, many teams that I have seen that are truly agile use no framework at all. They do a good job of managing a backlog and they do a great job of collaborating, writing good software, automating everything they can, and recovering from issues quickly. At the end of the day, agility can be measured by customer satisfaction. If the customer is getting their demands met, the system is reliable, and issues are resolved quickly, it really doesn’t matter what framework you use.Despite the apparent threat, Enterprise Agility does not spell the end of Architecture but in fact can be a catalyst for change and disruption. Whether a company is Waterfall, Agile or Hybrid, architects will always be required to support technology decisions and align IT to business strategy[2][5]. These outcomes remain as critical as ever, but how they are reached will be vastly different. In this blog we will discuss four ways Enterprise Agility will redefine Architecture. Get ready.
1. Architects will be less involved with delivering things but more involved with ensuring the right things are delivered
There is a misconception that architects spend all of their time ‘doing’ architecture and producing complex diagrams[4]. It’s the organisational decision-making process that the architect must drive before an artefact is delivered, however, that really matters. Reaching consensus on complex decisions involving diverse stakeholders with competing views is where the architect is irreplaceable[12]. Be it navigating emerging technologies, legacy system replacement, or completing post M&A consolidation roadmaps; as Agility scales, the need to make these architectural decisions in a timely manner goes up. The need for Architects to support this goes up.
This doesn’t mean architects won’t produce any diagrams, but enabling the best technology decisions to be made is where the value of architecture will be realised in an Agile Enterprise[3][4]
Intentional architecture is the traditional up-front, plan based architecture that most of us are familiar with. The Architecture is designed and handed over to development teams to build. The more detailed the architecture the more ‘intentional’ it becomes.
There is little doubt that in a fixed-price contract world, having as much detail as possible up front is a necessity. And in general, updates are avoided at all cost for fear of the change request. But in an Agile Enterprise, procurement functions will evolve along with the Architecture function. And through a combination of incentive-based or time and materials contracting[21][22][23], this evolution will permit Product Owners to inspect and adapt.
So for the architect, as agility scales, a degree of up front planning remains essential. But defining detailed architectures across large time horizons is no longer required. Architectural work will be decomposed into smaller packages and managed in a ‘just in time’ fashion[11][12][13]. The Scaled Agile Framework (SAFe) provides an example of this with its Architectural Runway that is used to ensure technical dependencies are always delivered at least one sprint before the application functionality that needs it[10][11][17]Finally, at the core of transforming recruitment, should be the Agile principles. By changing the decision criteria for how you select a new hire, you can prioritise the talent you want most in the organisation. This gives you a workforce of individuals culturally aligned to your strategy and ways of working.
Changing the decision criteria to be Agile involves re-writing position descriptions to be light and flexible. This ensures that you don’t become locked into hiring for a position that, by the time you fill the role, is no longer relevant. Bersin by Deloitte wrote, in a piece titled ‘The end of the job as we know it’, that companies should be hiring “for values, innate skills, and fit, not for experience.” This means replacing your traditional job description with value descriptions instead, speaking to the inherent Agile cultural attitudes required in the position, like agility and comfort with ambiguity. In the Agile Manifesto, this is best denoted by the value of “Responding to change over following a plan”. The focus of good Agile job descriptions, should be on flexing positions, so that HR is building complete teams, rather than attempting to hire the ‘every man’ candidate.
The best example of this is the technology giant Google, who openly targets individuals for a quality called ‘Googleyness’. Head of People Operations, Lazlo Bock , defines this as:
A certain dose of intellectual humility (it’s hard to learn if you can’t admit that you might be wrong),
Comfort with ambiguity (we don’t know how our business will evolve, and navigating Google internally requires dealing with a lot of ambiguity), and
None of those elements would make a classic job description, but they do focus on what Google treasures most, a person’s values. They search for the right fit, not the right set of functional skills.
Applying an Agile mindset to recruitment is not simple. It spans a range of elements from redefining selection criteria, to re-inventing the hiring process. However embedding Agile within your recruitment practices is crucial in supporting an Agile organisation.
Our challenge to you is to look at how your recruiting currently operates, and determine where you can leverage Agile principles to improve the process. Even if it is as simple as giving new hires feedback forms so they can reflect on their experience of the hiring process, you’ll see the benefits that greater transparency and Agile provides.Both agile and mindfulness practitioners place importance on the ability to understand and respond to the needs of others. In an agile context, customers are critical stakeholders requiring compassion, empathy and deep understanding. Mindfulness emphasises the importance of regulation and control of self-emotion in order to better understand and respond to the emotional needs of others, which are relevant skills for an agile team.
Self-organising teams advocate the importance of positive team dynamics as well as the unique contribution of each team member, encouraging collaboration, and face to face communication. Mindfulness can help cultivate team wellness and empathy by encouraging practitioners to control and focus their emotions. This promotes a purposeful, flexible, and open state of attention that ultimately drives intention. By embracing this open attentiveness, mindfulness practitioners increase the likelihood of developing and sustaining positive, respectful, and resilient relationships within their team. This is critical to an effective agile practice, as collaboration, good communication and positive teaming are at agile’s core. Consequently, team productivity can be enhanced by promoting stronger, more engaged, and collaborative teams.
By developing, strengthening and leveraging emotional intelligence through mindfulness techniques, such as focussed attention, agile teams can increase team performance and foster customer empathy through a more in-depth understanding of team dynamics and individual needs.
Simplicity is a fundamental principle of both agile and mindfulness which follows the basic premise: a focus on high value yet simple processes and solutions will reduce waste (e.g. of time, energy, or cost) and increase quality (e.g. of software, communication, or life).
Mindfulness practitioners advocate the importance of de-cluttering to create the emotional and physical space necessary to develop awareness, focused attention, and sustainable living. De-cluttering practices, which can be either physical (such as voluntary simplicity which means to reduce materialism and consumerism, a re-assessment or minimalist re-design of your surroundings, or literally de-cluttering surfaces and spaces in your physical environment), or spiritual (such as letting go of negativity, uncertainty and mental “noise”) ultimately increases quality of life through a focus on value rather than abundance.
In an agile context the focus on simplicity manifests itself in simple design, succinct meetings and communication, continuous integration, story cards, minimal but clear roles, and sprint boards (to name a few). As an example, the physical sprint board puts the agile simplicity principle (“Simplicity – the art of maximising the amount of work not done – is essential”) to practice and facilitates visibility of work not done. The sprint board enables the agile team to organise activities so that those of the highest value are prioritised, reducing waste and maximising efficiency.
Simplicity is a key component in both agile and mindfulness, with focus placed on value and a deliberate effort to remove redundancy. Agile teams can further develop day-to-day simplicity through mindful practices, such as intentional physical and emotional de-cluttering.
Agile enthusiasts embrace changing requirements and environments, those practicing mindfulness also develop the flexibility to accept and respond, rather than react to change.
Mindfulness practitioners advocate that adaptability stems directly from acceptance of the transient and fluid nature of life. The ability to maintain a purposeful, flexible, and open state of attention increases quality of life and sustainability.
Likewise, agile teams maintain the mindset that change is expected and welcome, identifying flexible boundaries, and designing processes and expected outcomes which enable adaptability. Cross-functional, self-organising agile teams that value constant communication, continuous validation, and incremental product evolution are well placed to respond to changing requirements and shifting landscapes.
For both mindfulness and agile, it is communication and contact with the present moment that establishes the foundation for adaptability and increases the likelihood of resilience and stability.
Agile teams can apply their practiced adaptive mindset to leverage mindful techniques, such as acknowledgement and acceptance of change, which can help to remove human emotion (reactive behaviour) from decision making during periods of change.
Another fundamental principle of both agile and mindfulness is controlled and targeted focus on one task at a time. The value and objectives of the focus principle are similar to those of the Simplicity principle – high value yet simple processes and solutions will reduce waste and increase quality.
Mindfulness practitioners advocate the importance of awareness and control in order to focus completely on a single task. Similarly, agile practitioners advocate that productivity is increased through focus on one task at a time, enabled by small engaged teams, short targeted sprints, visibility of activity and direction (agile boards), and regular communication to maintain awareness of blockers and impediments to progress.
Both approaches support the view that the cost of context switching (reduced focus and concentration and ultimately decreased productivity) greatly outweighs any perceived benefit to efficiency or progress.
Agile teams advocate singular focus, however this is not to say that there is no challenge in doing so at an individual level. By using mindfulness practices, such as control of attention, agile teams can turbocharge their ability to filter out distraction, and focus only on the task with the greatest business value.
The core areas of commonality between agile and mindfulness are also some of the defining characteristics of each approach: People, Simplicity, Adaptability, and Focus. Agile teams can leverage the touchpoints with mindfulness to maximise their existing skillsets and ultimately achieve their goals. As an example, mindfulness promises to enhance and enrich interpersonal communication, while agile projects sink or swim on the quality and timeliness of the interactions between all of the project’s stakeholders (including the agile team itself). The two approaches are complementary.
While both agile and mindfulness have been described as “buzzwords” and are being referenced and discussed across multiple forums and platforms, neither introduce any complex or ground-breaking new concepts. In fact, the four principles discussed in this article, which sound very much like common sense, are a reminder that in the 21st century – an era dominated by disruption, technology and immediacy, there is great value to be gained in getting back to basics.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.Developing a successful strategy is essential to simplifying the complexities of transformation. These key areas to consider can empower your transformation strategy and clarify the road ahead for digital controllership.Traditionally, leaders have been encouraged to dynamically reallocate capital to the most pressing and attractive opportunities. This focus remains today, but many companies face a challenge: human capital is now the scarcer of the two main capitals. Companies that manage talent with the same rigor they do financial capital, treating it like the precious resource it is, typically see better results. They reallocate talent to high-value areas and push talent management to the top of their growth ...The IMA® (Institute of Management Accountants), the association of accountants and financial professionals in business, held its 2019 Annual Conference and Expo (ACE2019) this past June in San Diego, California. The event officially celebrated the Institute of Management Accountant’s 100-year anniversary with a special Centennial Celebration honoring IMA’s thriving global community of accounting and finance professionals. Attendees had the opportunity to network with other industry professionals, hear presentations from leaders, and choose from more than 75 job-relevant sessions tracks designed for management accountants to customize their learning experience on topics ranging from corporate governance to technology and finance trends for the future.
As a diamond level sponsor, Deloitte had the opportunity to attend the action-packed conference and deliver presentations on specialty topics. Deloitte delivered a specialty breakout session on touchless close as well as a general presentation on the Center for Controllership™ during the IMA annual conference dinner.
To gather some insights and perspectives that may help us with future conferences and projects with IMA, we caught up with our presenters and some of the attendees to hear about some of their highlights from the experience and insights they were able to take away from the conference.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.Though major crises may inflict significant economic damage, they can also inspire innovation. From digital connectivity to diversity, this issue of Deloitte Review explores innovations that organizations can put to use both now and in the future.Imagine you work for a company that has a busy season—the annual crunch time for achieving results. Everyone works at full stretch for six weeks, and then there’s a lull before the next cycle gets under way. If you’re designing a learning program, when should you schedule it? Most designers would probably say after the rush, when people can spare time out of their everyday routine. But is that the right answer? We don’t think so. With this timing, the next busy season could be eight or nine ...Coleads the Organization Practice globally and is one of the leading experts in transformational change
Coleads the Organization Practice globally and is head of McKinsey’s OrgSolutions group, helping clients organize in an integrated way by applying analytics methodologies and tools to improve culture, talent, change management, agility, and leadership
November 27, 2017 Let’s face it. Our hyper-dynamic, hyper-competitive and hyper-connected world has become a breeding ground for hyper-advice. Over 10,000 business books appear annually (and that doesn’t count the thousands of articles, blog posts, podcasts and video lectures produced). Search the internet for how to motivate employees and hundreds of thousands of results emerge in roughly half a second!
So, why are we at McKinsey & Company launching a weekly blog that risks simply adding to the clutter? We are hopeful that our weekly Insights on Leadership & Organization will be a one-stop shop where leaders can find impactful, fact-based and pragmatic advice – in 600 words or less.
We don’t want this to be run-of-the-mill head-nodding material. All up, as a firm we invest over $400 million annually in knowledge development, and we want you to benefit from that investment by providing genuinely provocative ideas that recalibrate and expand your thinking. Then we want to do that again. And again.
For this blog, we will address a range of both timely and timeless topics related to leading organizations and that apply to every leader, whether you’re a leader in an investment bank or a not-for-profit. Or whether you’re in India or Indiana. Over time, we will explore four principal areas:
Increasing organizational agility to effectively adapt to and shape market changes with speed. This requires organizations to master the paradox of being nimble in innovating and executing rapidly, while at the same time capturing the benefits of stability and harnessing the virtues of size and consistency.
to effectively adapt to and shape market changes with speed. This requires organizations to master the paradox of being nimble in innovating and executing rapidly, while at the same time capturing the benefits of stability and harnessing the virtues of size and consistency. Converting talent to value by combining traditional methods with advanced analytics-based methods to forecast talent supply and demand based on the business strategy; and improving how needed talent is identified, attracted, placed, developed, evaluated and retained—all the way from the front line to the C-suite.
by combining traditional methods with advanced analytics-based methods to forecast talent supply and demand based on the business strategy; and improving how needed talent is identified, attracted, placed, developed, evaluated and retained—all the way from the front line to the C-suite. Managing culture and change to deliver sustainable results and create lasting competitive advantage. This includes the tools and methods to overcome the digital, customer-centric, simplification, risk management, and numerous other large-scale transformation challenges that today’s global enterprises face.
to deliver sustainable results and create lasting competitive advantage. This includes the tools and methods to overcome the digital, customer-centric, simplification, risk management, and numerous other large-scale transformation challenges that today’s global enterprises face. Maximizing merger impact by building M&A capability to be ready to make the right deals happen—and then, once one does, developing and executing the right master plan related to governance, sources of value, organization, talent, capability building, and cultural and technology alignment.
Put simply, our goal is to help leaders lead better so, in turn, their organizations will be more successful and their employees’ experiences more meaningful and fulfilling.JH, a partner at Deloitte Risk & Financial Advisory, Deloitte & Touche LLP, as well as Global Risk Advisory leader for the Financial Services Industry, has more than 25 years of risk management experience within the sector. He has deep experience with the complete credit lifecycle, enterprise risk management, operational risk, and integrated compliance risk management. His extensive experience in the area of credit includes quantitative methodology, portfolio analytics, process, and controls, integrating risk management practices, and addressing and resolving the Options Clearing Corporation (OCC) and other regulatory issues. JH has worked with seven of the top 10 credit card providers, four of the top five mortgage originators and servicers, two of the top three student lending organizations, and three of the top five auto loan financing companies. In addition, he has performed training sessions for the American Institute of Certified Public Accountants (AICPA) and the Federal Financial Institutions Examination Council (FFIEC) regulatory round table on accounting issues and pronouncements facing retail credit organizations.Mark Bethell is a partner in the UK EERM practice. Mark rejoined Deloitte in 2015 after spending four years at a global FTSE 5 company. Whilst working there Mark led the design and implementation of a global third party risk management framework. Mark’s other roles whilst there included membership of the internal audit leadership team with accountability for all internal audit work performed in relation to the extended enterprise (contractors, suppliers and joint ventures). Since returning to Deloitte, Mark has led a number of projects to help clients across many industries manage the risks associated with the extended enterprise. He has helped his clients to design, build, and implement third party risk management frameworks and design and operate large-scale, global programs of third party audits covering a variety of risk types. Mark specializes particularly in the implementation of EERM managed services for his clients, and in the ongoing development of technologies to support automated risk screening and monitoring.Grocery stores have been venturing into the digital world for years now. It’s almost unthinkable to walk into a grocery store without a loyalty card these days. And during this pandemic, we’ve seen how online purchasing of groceries has stepped up and is going to be further refined. These two digital forays alone offer grocers a wealth of personal data to use. The question, then is, should they, and to what extent?With the recent spike in demand for electric vehicles, socially conscious consumers are questioning the provenance of battery materials used to produce these vehicles. Mining companies are under pressure to create a more transparent interface with their customers—an aspect outlined in our Tracking the trends 2019 report.
In this blog, Tim Biggs explains that with the complex supply chains of today, traceability of minerals could be a challenge. He recommends mining companies to invest in technologies like blockchain that can trace a mineral from its origin to destination.As the future of work unfolds, adaptable learning organizations will likely stay ahead of their competition, attract the best and the brightest prospects, and manage market movements with their customer base with more agility. Learning leaders are well positioned to lead the charge to develop an adept workforce that can not only respond to rapid shifts in markets, but also thrive in them as well.
HR professionals use virtual reality to facilitate employee training and increase retention. Sports reporters use natural language generators to automatically recap games and to highlight interesting statistics. Actuaries use cognitive computing to automatically evaluate data, compute results, and predict new patterns. Professionals across many industries engage employers in alternative work arrangements through the gig economy. This future of work is rapidly becoming reality as technology develops exponentially. Exponential professionals are those who capitalize on the shifting workplace by embracing new technology, leave behind traditional automatable tasks, and apply their uniquely human skill set to more high-value, strategic roles.
AI. Automation. Machine Learning. Natural Language Processing & Generation. New technology is rapidly disrupting and transforming the nature of work and the identity of professions by enabling humans and machines to work together, side by side. A new breed of professional is rising to navigate this shifting landscape by embracing technology, leaving behind traditional tasks, and applying a uniquely human skill set to focus on higher-value, strategic roles. Enter the exponential professional.
Is capitalism broken? Rising inequality, high profile corporate failures and the potential for technology to displace millions of workers has prompted many to ask this question. It will be part of the discussion at Davos this week, where world leaders will debate what’s holding back inclusive economic growth. They’ll also question how ready we are for the Fourth Industrial Revolution – the blurring of technology into all aspects of our daily lives – and whether businesses are doing enough to manage the impact of automation on the workforce.
Mornings are easier than ever for me. True, I need to be careful shaving around the RFID chip in my chin. That’s a small price to pay for not having to look around the house for my wallet and keys, which I no longer need because that tiny chip and biometrics lock my front door and start my car, which now drives itself. And if something goes wrong on the road and I arrive at the hospital unconscious, my RFID chip will present my medical history to emergency room doctors.
The rise of robots in organizations has resulted in two schools of thought—those who believe robots will replace humans and those who believe robots will help humans perform better.
Industry has used robots for decades. They were once confined to safety cages in manufacturing facilities, programmed to perform one task perfectly, over and over again.
The future workplace is going to require a change in organizational culture, and this needs to come from the boardroom.
Today’s interview is with Erica Volini, who is the US Human Capital leader for Deloitte Consulting. Erica joins me today to talk about the Future Of Work, the implications for organizations, organizational transformation, Digital DNA and how the employee experience fits into all of this.
Mix smart machines, businesses as platforms, and diverse teams solving complex problems, add a whole lot of uncertainty, and you have a recipe for the future of work. Jeff Schwartz ’87, a principal at Deloitte, discusses how leaders can navigate fast-approaching opportunities and challenges.
By 2025, cognitive technologies — that’s robots, AI, machine learning and automation — will replace 7% of jobs in the U.S. By 2033, economists predict AI could convert 30 percent of full-time jobs today into augmented services completed through a collaboration of human and automated labor.
Your organization, like most of those we see, is probably already incorporating contingent workers in your talent mix, and likely seeing year-over-year increases in the number of contingent workers in your workforce.
We recently sat down with Josh Bersin, the Founder of Bersin, to discuss where he believes the future of work is heading towards, and what the most important aspects to consider within that would be.
The head of one of Australia’s biggest professional services firms believes public negativity and misconceptions are preventing Australia from fully embracing automation. Deloitte chief executive Cindy Hook, who also heads a Business Council of Australia committee looking at the workplace, says business and government “need to change the narrative” that automation, robotics and digitisation will eliminate jobs, “because that’s not the case”.
As organizations navigate technological and societal shifts, corporate boards will have a critical role to play. Diversity of thought—and of people—will be more vital than ever to ensure that boards are considering different perspectives and exploring challenges from every angle.
What skills are essentially human? It’s a question that many HR professionals never thought they’d need to answer. But with the advent of AI, robotics, sensors, and cognitive computing, that’s what every HR professional should be asking—because the future of work is here.
On Tuesday, I participated in a panel discussion hosted by the Organisation for Economic Co-operation and Development (OECD) on the rapidly evolving workforce and the role business can play in navigating these changes.
We are living in an age of disruption. More than 50 years after the formulation of Moore’s law – which holds that computing power doubles on capability every 18 to 24 months – technologies such as artificial intelligence (AI), mobile platforms, sensors, robotics, and social collaboration systems are becoming more pervasive before revolutionizing the way we live, work, and communicate.
As I prepared for my time in Davos, I spent some time thinking about what the biggest takeaways will be. Clearly, based on the recent buzz over the past year, the future of work and how to navigate it is on many people’s mind. The fact is that we are already living this future and to be successful in the next three to five years we will all have to embrace constant change.
The world of work is rapidly changing as we deal with new technologies, AI, generational changes, and a more interconnected organization. What are HR’s mandates in this new world? Moreover, how can HR add value in organization design, driving new models of leadership, driving engagement, and improving organizational culture?
The phrase “Future of Work,” has become a buzz word. (I found 48 million Google hits on the phrase.) There are are suddenly hundreds of conferences, books, and articles on the topic, covering everything from artificial intelligence to robotics to income inequality and contingent labor.You previously joined My Deloitte using the same email. Log in here with your My Deloitte password to link accounts. | | Deloitte users: Log in here one time only with the password you have been using for Dbriefs/My Deloitte.
You've previously logged into My Deloitte with a different account. Link your accounts by re-verifying below, or by logging in with a social media account.Dr. Dhar is Vice Chairman and US Life Sciences and Health Care (LSHC) Industry Leader for Deloitte LLP leading the overall strategic direction for the life sciences and health care practices, including audit, consulting, tax, and advisory services. He is a respected health futurist and sought-after digital disrupter. Asif helps Governments, Life Sciences and Health Care clients reinvent wellness, solve disease, address pandemics and tackle health inequities. He is also Deloitte’s Lead Partner for the Firm’s US Food and Drug Administration (FDA) relationship and responsible for all work Deloitte performs with and for the Agency. His perspectives on real world evidence, regulatory sciences, digital health, and innovation are sought by clients around the world. Asif’s passion for the LSHC industry is evident in all that he does – as a pioneering thought leader who helped establish a framework for the Future of Health, formed ConvergeHEALTH, an award winning life sciences and health care software solution, and helped frame numerous COVID-19 health-oriented reboot and recovery solutions. He advises some of the world’s most innovative companies and Governmental agencies tackling disease and public health.The people who make up Deloitte come from just about every background and area of study and nearly every spot on the globe. Meet our professionals, and learn more about what life at Deloitte is like.Insert Custom CSS fragment. Do not delete! This box/component contains code needed on this page. This message will not be visible when page is activated.The Federal Government just threw $18 billion dollars at the Australian economy between now and mid-2021 – of which a striking $11 billion will be in the pockets of the punters and of businesses in the next three months alone. The Reserve Bank has already cut interest rates, with a further cut in the offing when they meet again in early April. That’s big bucks. But just how much help does that combination deliver to the Australian economy?Governments around the world have responded to the pandemic by borrowing, and spending, on a vast scale, equivalent to 12% of world GDP. Twelve years ago, in the financial crisis, monetary policy did the heavy lifting in supporting growth. Now, with interest rates near zero, the burden has fallen on fiscal policy.
Join our next fortnightly COVID-19 webinar, focussing on building resilience, on Thursday, 5 November, at 13:00 GMT. Register for this and our upcoming webinars.
Governments around the world have responded to the pandemic by borrowing, and spending, on a vast scale, equivalent to 12% of world GDP. Twelve years ago, in the financial crisis, monetary policy did the heavy lifting in supporting growth. Now, with interest rates near zero, the burden has fallen on fiscal policy.
The level of government debt fluctuates over time, with war and recession driving it higher, and faster growth bringing it down. Four decades of expansion after the second world war shrank UK public sector debt from a wartime peak of 250% of GDP to 30% by the mid-1990s, close to the lowest-ever level. Since then it has risen inexorably, to 40% on the eve of the financial crisis and 75% in its wake, 103% today and, on IMF forecasts, a likely 115% in 2023.
This is a historic shift, one which takes debt to levels which have only ever been seen in the wake of the Napoleonic war and the first and second world wars.
The surge in public debt in the financial crisis led, as growth came back, to programmes of tax rises and spending cuts across the West as governments sought to reduce borrowing. A broad coalition of mainstream political parties and international institutions including the IMF and the European Commission favoured curbing levels of debt.
The concern was that high debt levels would make countries more vulnerable to future shocks and make it harder for governments to counter them. Shortly before becoming chancellor of the exchequer, George Osbourne remarked that “while private sector debt was the cause of this crisis, public sector debt is likely to be the cause of the next one”. The widely held view was, as Mr Osborne subsequently put it, “the time to repair the roof was when the sun is shining”.
In the US Harvard economists Carmen Reinhart and Kenneth Rogoff warned that debt-to-GDP in excess of 90% would pose a significant obstacle to longer-term growth. They argued that high and rising debt levels could cause investors to take fright, and demand higher interest rates for holding government debt, which would push up borrowing costs and lead to painful budget cuts. Their research was widely cited by politicians in the West at the time.
Since then public sector austerity has, in many countries, only slowed the rate of growth of public debt, rather than reduced it. Yet there has been no backlash in public debt markets. On the contrary, weak economic activity and low inflation have increased the allure of government bonds to investors, driving interest rates on them ever lower. In the UK the willingness of financial markets to finance government borrowing, weak growth and fatigue with austerity slowed the process of debt reduction. Indeed, the government proclaimed the end of austerity three years ago despite the fact that the UK is continuing to run a budget deficit.
So the pandemic arrived into a world of already elevated government borrowing, where traditional rules of balancing the books held less sway. The pandemic has dealt a further blow to such notions. High levels of public borrowing are here for some time to come.
The zeitgeist on public debt has been transformed. In an inversion of its advice a decade ago, the IMF has been joined by leading central banks in urging governments not to tighten fiscal policy and prematurely cut off the recovery, while the European Commission is embarking on an unprecedented programme of joint-EU debt issuance. There are no signs that voters are keen on either spending cuts or tax hikes to rein in the deficit.
So why, as countries exceed the 90% marker set out by Reinhart and Rogoff, are policymakers not talking about austerity?
Debt financing costs have fallen still further, making it much easier for governments to finance borrowing. The UK government currently pays interest of 0.2% to borrow for ten years, less than a quarter the rate at the start of the year. As a result the UK’s overall debt financing costs are lower now than they were with far lower debt levels a year ago.
In a perilous world the safety offered by government bonds is more attractive than ever. Quantitative easing programmes have made central banks big buyers of government debt, further fuelling demand and driving down interest rates.
As the economy recovers, and the growth rate outstrips the low interest rate on this debt, the ratio of debt-to-GDP should begin to unwind organically. Even if interest rates do rise, the average maturity of UK government debt is 15 years, meaning the overall financing costs are unlikely to
In the higher interest rate era of the 1970–90s it was thought that high levels of public borrowing and spending might ‘crowd out’ private sector borrowing and activity. Today, with activity vastly below normal levels, the problem is of excess capacity and insufficient demand. With the private sector unable to do so, the government becomes, in Keynesian terms, the borrower and spender of last resort.
This story is playing out in the US election, where investors appear to see the benefits of greater fiscal stimulus under a Biden administration more than outweighing any negative effects from higher taxes or greater regulation.
The IMF has observed that the current backdrop of cheap money and insufficient demand creates the perfect environment for greater public investment. The fastest returns come, according to the Fund, from smaller or modular projects like infrastructure maintenance or renewable energy installations that are labour-intensive and can be rolled out quickly. The biggest projects operate with longer leads and carry the risk of cost overruns and delays.
None of this is to say that the limits to public borrowing have been removed. If the economy fails to recover to pre-pandemic rates of growth, the government could be faced with a permanent imbalance between the burden of public debt and the economy’s ability to finance it. The picture could worsen further if inflation were to rise markedly, driving investors to demand higher yields on government debt. Past debt crises have come out of the blue, as bond markets can quickly change their minds about fundamentals.
But for now borrowing and spending is the only game in town. The UK’s new lockdown has already triggered the extension of the furlough scheme. More spending is sure to follow, as it will if Joe Biden wins the presidency and secures the US Senate. The attitude of policymakers has changed. The balance of opinion has shifted to maintaining fiscal support, until the recovery is secure, something which is looking ever more distant. We are in an age of bigger, more activist government.
PS: Joe Biden is the strong favourite to win Tuesday’s US presidential election. The electoral model run by Nate Silver, the US pollster, puts the probability of a Biden win at 89%. The Economist’s model assumes an even higher probability, of 96%. The New York Times estimates that even if the polls were as wrong as they were in 2016 Mr Biden would still win by a wide margin. However, it is quite likely that a clear victor will not emerge on election night, and, possibly for weeks or, indeed, months. Mr Trump has questioned the validity of postal votes and suggested he might refuse to concede defeat. This could lead to days or weeks of uncertainty and legal battles in the case of a close outcome.
As president, Mr Biden would have discretion over trade matters, foreign policy and regulation, areas in which he could reverse many of Mr Trump's policies. But to pass tax and spending legislation, Mr Biden would need the Democrats to take control of the Senate. With a Biden win seen by many as a foregone conclusion the Senate battle is likely to be a major focus on election night. Most forecasters expect the Democrats to take the Senate, though this is likely to be a closer fight than for the presidency. A Biden administration is committed to raise income and capital tax rates on higher earners and partially reverse Mr Trump's corporate tax cuts. A Democrat president and Senate would probably increase public spending significantly, with a pandemic recovery package and a programme of green infrastructure, healthcare, education and R&D expenditure. Other Biden policies would strengthen the position of workers, including a higher federal minimum wage and paid family and medical leave. Our reading is that investors tend to see the beneficial effect of greater fiscal stimulus on the economy under a Biden administration outweighing the drag from higher taxes and increased regulation.Dr. Kalish is the Chief Global Economist of Deloitte Touche Tohmatsu Ltd. He is a specialist in global economic issues as well as the effects of economic, demographic, and social trends on the global business environment. He advises Deloitte clients as well as Deloitte’s leadership on economic issues and their impact on business strategy. In addition, he has given numerous presentations to corporations and trade organizations on topics related to the global economy. He is widely traveled and has given presentations in 47 countries on six continents. He has been quoted by the Wall Street Journal, The Economist, and The Financial Times. Dr. Kalish holds a bachelor’s degree in economics from Vassar College and a PhD in international economics from Johns Hopkins University.Join our next fortnightly COVID-19 webinar, focussing on building resilience, on Thursday, 5 November, at 13:00 GMT: https://event.webcasts.com/starthere.jsp?ei=1365454&tp_key=8f4d835e66&sti=mmb
Governments around the world have responded to the pandemic by borrowing, and spending, on a vast scale, equivalent to 12% of world GDP. Twelve years ago, in the financial crisis, monetary policy did the heavy lifting in supporting growth. Now, with interest rates near zero, the burden has fallen on fiscal policy.
The level of government debt fluctuates over time, with war and recession driving it higher, and faster growth bringing it down. Four decades of expansion after the second world war shrank UK public sector debt from a wartime peak of 250% of GDP to 30% by the mid-1990s, close to the lowest-ever level. Since then it has risen inexorably, to 40% on the eve of the financial crisis and 75% in its wake, 103% today and, on IMF forecasts, a likely 115% in 2023.Canadian retail sales dropped in March. Auto sales fell in April. Households took on more debt in the first quarter, with the debt-to-income ratio rising to 177. Consumer spending is key to the economic recovery. Expenditure is expected to recover, but the pace of growth is likely to be slow.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.New research from Deloitte Access Economics shows that Australia’s economy – and $680 billion in economic potential – relies on climate action (A new choice - Australia's climate for growth).
The research is aimed at flipping the debate on how we discuss climate change to better consider the economic cost of not acting and the costs and benefits of taking action. Essentially, climate change is not a scenario – it is a reality which now must be reflected in the baseline for the economy. This new baseline for the economy has the damages from climate change built in and it shows the extensive, and confronting, costs associated with inaction, against a new growth recovery scenario of net zero.
Taken today , more than 30% of employed Australians and over 30% of national income sit in industries exposed to economic disruption and risk from climate change and unplanned economic transition
, more than 30% of employed Australians and over 30% of national income sit in industries exposed to economic disruption and risk from climate change and unplanned economic transition By 2070 – in the lifetime of Australians in their 20s, 30s and 40s today – the economic cost of doing nothing is an economy which is 6% smaller, a $3.4 trillion loss in GDP in present value terms, and with 880,000 fewer jobs
– in the lifetime of Australians in their 20s, 30s and 40s today – the economic cost of doing nothing is an economy which is 6% smaller, a $3.4 trillion loss in GDP in present value terms, and with 880,000 fewer jobs In contrast, a new growth recovery, delivering net zero by 2050 and consistent with keeping global warming to 1.5°C, could add $680 billion (in present value terms) and grow the economy by 2.6% in 2070, adding more than 250,000 jobs.
There isn’t a ‘no cost’ option. The report sets the benchmark of economic growth – one where damages from global warming are included – against which the cost of inaction or the costs and benefits of action should be assessed.
Principal report author, and Deloitte Access Economics lead partner, Dr Pradeep Philip, said: “The costs of climate change are still rising each year, as are the costs associated with reducing the risks it presents. Climate change is no longer a possibility. It is a reality. Doing nothing is now a policy choice, and it is costly. “
Business is increasingly leading the call for action on climate change, wary of the commercial and economic risks and beginning to understand the calculus of acting versus not acting. This is seen in a variety of areas. Increasingly, investors are calling out the carbon footprint of companies and demanding explanations from boards and management at annual general meetings. This is supported by shareholder activism, and consumer choices, demanding to know the carbon footprint of a company and its product, and that of the supply chain as well.
The report notes that policies aimed at strengthening economic growth can support low-emission pathways, and actions to stimulate investment in low-emission investments can strengthen economic growth job creation.The actions of policymakers have had a catalytic effect on equity markets since late March. We must hope that these actions prove as successful in supporting growth beyond the downturn.
The latest release of our chart book “The COVID-19 crisis: Economic impact and policy responses”, is available. The report aims to provide a graphical overview of the key economic developments of the COVID-19 crisis. Do feel free to use any of the charts in your own presentations.
Join our “Responding to COVID-19” webinar every Thursday at 13:00 GMT. Each week a panel of Deloitte experts are assessing the latest health, business and economic developments and discussing how organisations can navigate the emerging challenges. Register here for this Thursday’s webinar, on 23 April.
Economists are still coming to grips with the reality of a freezing of economic activity. Last week the International Monetary Fund warned that the coming downturn was likely to be the worst for the global economy since the Great Depression of the early 1930s.
On the same day the UK’s official forecaster, the Office for Budget Responsibility, said that a three-month lockdown could cause the UK economy to contract by 35% in the second quarter of this year. This is an astonishing hit, roughly equivalent to unwinding 16 years of growth in just three months. Meanwhile economists at the St Louis Federal Reserve estimate that the US unemployment rate could rise to 30%.
The US S&P 500 index has risen by 28% from the low it hit on 23 March and is only 15% below the all-time peak reached in February. Other major equity indices have seen significant, though lesser gains. After the longest US equity bull market in history, and with the world heading into what looks likely to be the deepest downturn in over a century, the S&P 500 is only back to the levels of last summer.
A vast programme of central bank and government stimulus has bolstered equities even as forecasts for growth have gone into freefall. The boost to global activity from easier fiscal policy, through increased public spending and tax cuts, is far greater than in 2008–09, and especially strong in Japan, the US, Germany and the UK. Governments are seeking to help corporates and households through the crisis with loans, tax holidays and a range of measures to support incomes. Central banks have re-started their programmes of asset purchases to boost liquidity, drive down interest rates and bolster risk assets. The Federal Reserve has gone further, promised unlimited quantitative easing, and, for the first time, promised to buy riskier, sub-investment grade, or junk bonds. The message is that policymakers will do whatever it takes to support growth and markets.
Investors have taken note. Their renewed enthusiasm for equities seems to be predicated on the idea that it is unwise to fight central banks - if central banks want to raise asset prices they have infinite ability to create money, and to make it happen. The hope, too, is that easier monetary and fiscal conditions will ensure that the slowdown is short-lived and that activity, and profits, will bounce back next year. In a world of ever-lower interest rates, equities do offer investors the prospect of long-term income. Markets have probably also taken some encouragement from signs of a peak in COVID-19 infections and a partial and cautious easing of restrictions in some European countries.
Yet, as far as the economy is concerned, we are in perilous waters. The scale of the downturn and the timing, and magnitude, of any recovery, are unknowable. Central banks and governments will not be able to prevent all damage to the productive capacity of the economy. If the legacy of this crisis is deep economic disruption, elevated debt levels and greater caution, long-term growth is likely to suffer.
The actions of policymakers have had a catalytic effect on equity markets since late March. We must hope that these actions prove as successful in supporting growth beyond the downturn.At the start of this journey we recognize that there’s a lot we don’t know and we’ll need input from the best minds—but it’s a journey we’d like you to take with us here and via social media. Think of it as a “making of” documentary—but instead of finding out how that CGI dragon works, we’re sharing the blow-by-blow of achieving a real live, game-changing goal.
Make no mistake, seamless, integrated mobility will be a game-changer and this is a once-in-a-generation opportunity to set it up right. Read on and find out about our first steps in this effort.
Before we even held our first meeting last month to discuss the project, the big question was—who can provide the kind of input we need? Based on Deloitte’s experience and the deep relationships we’ve built across the mobility ecosystem, we know cooperation and collaboration between the public and private sector will be critical to this effort. So it was natural to include representatives from government to offer the citizen perspective. Global leaders in freight and transport could provide a wider and experienced view of the challenges this industry experiences. Cars are a large part of the mobility ecosystem, so auto manufacturers were a must. And to give the project innovative and new thinking, start-ups in the mobility space were also actively engaged.
It’s an exciting and eclectic group we’ve gathered—and to give them full freedom to float their ideas and speak their minds, we won’t name them here. Because candid opinions and open exchange were what we were looking for at our first session (which took place at a Deloitte Greenhouse in Berlin, a space wholly dedicated to spurring innovative thinking). We had a lot to do at this meeting, including pulling together a unified vision for a SIMSystem based on an honest assessment of its potential and feasibility.
To get ideas flowing we used a video Deloitte’s Future of Mobility Practice produced called Ben’s Journey as a jumping off point. It details one possible way, out of thousands, that an average citizen—in this case, Ben—can move from point A to point B in the new mobility ecosystem. It shows how he can seamlessly assemble the transportation options he prefers and how they empower him to tailor the way he interacts and connects with them. It’s an example of a fully realized future state of mobility. A corresponding SIMSystem framework was presented from which the reality of Ben’s journey could be built while also exploring the wider movement of goods and passengers across geographies.
We asked, is Ben’s Journey really feasible? What needs to happen to get a SIMSystem off the ground? The answers, while they became clear after much discussion, are anything but easy. Interoperability, governance, technological capabilities, customer-centric design, data privacy, and cybersecurity—emerged as some serious challenges to be overcome. But some equally serious solutions were also floated, such as public-private partnerships and collaboration, standardized language and data exchanges, and information sharing. If done right, we can help accelerate adoption to connect cities and rural areas and address many of the inefficiencies, friction, and inequities of today’s transportation systems.
Our thinkers then broke into groups to tackle some specific and real challenges that a SIMSystem poses and needs to address. They studied mobility use cases that entailed the coordinated movement of people and products across geographies and during crises. They contemplated the difficulty of taking existing mobility systems and transitioning to a SIMSystem. They examined the ability of local networks to scale up and global ones to scale down. The discussions sought to map the intricacies of these situations—which are substantial once teased out. But more on that in my next blog.
So where did we end up? After dialogue and debate we were able to agree on the basic components of a SIMSystem and its scope. Just as important, we identified the major sticking points and what implementation would need to look like.
While we never thought this would be a ride without bumps, we now understand just how many factors have to be considered to make seamless mobility real (check out our session graphic and you’ll get a feel for the true complexity). But knowing where we are on this road and where we want to go is a good start.Last week, the Federal government released its much anticipated economic and fiscal update. It confirmed what we already knew – that COVID-19 has seen the single largest disruption to our way of life and economy since the Second World War. And this certainly reflected in the figures. Deloitte’s detailed review of the update can be found here.
The official forecasts for growth in the economy very much reflect the COVID recession – real Gross Domestic Product (GDP) is expected to have fallen by 0.25% in 2019-20, with the COVID-hit June quarter more than wiping out previous gains. The economy is then forecast to contract by 2.5% in 2020-21 as the country climbs only slowly out of the COVID hole, and weak consumer and business confidence weigh heavily on activity. This also factors in Victoria’s economy starting to open up again from late August, although a projection that remains highly problematic.
The unemployment rate is expected to peak at around 9.25% in the December quarter of 2020. Unemployment tends to increase faster than it decreases, and as a result, the rate is likely to remain above pre-COVID-19 levels for several years. The loosening of conditions in the labour market will weigh on already sluggish wage gains, which will in turn see little growth in inflation over the next year.The Internet of Things (IoT) can not only help you get ahead today, its powerful outcomes and analytics can propel your business far into the future. Deloitte can help companies harness the power of IoT to deliver transformative outcomes and tangible business value.Innovation, transformation and leadership occur in many ways. At Deloitte, our ability to help solve clients’ most complex issues is distinct. We deliver strategy and implementation, from a business and technology view, to help you lead in the markets where you compete.October 8, 2018 Approximately 70 percent of executives responding to a recent McKinsey Global Industry 4.0 Expert Survey said their organization considers Industry 4.0 as the top priority. Given that a 2015 McKinsey Global Institute report predicted that the Internet of Things—which is just one out of a wide range of Industry 4.0 technologies—could generate $1-3.7 trillion in value for factories by 2025, the business case for prioritizing Industry 4.0 is clear. But the 2018 survey found that progress remains unexpectedly slow.
The reason: Pilot purgatory. As they endeavor to capture trillions of dollars in value, companies worldwide are testing their priority Industry 4.0 use cases by launching an average of about eight pilots. Companies in China and India are pushing even harder, at an average of ten pilots (Exhibit 1).
Exhibit 1 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
But only 30 percent of the pilots end up reaching scale across the entire organization. Put differently, companies are failing to capture value from 70 percent of their pilots (Exhibit 2). Moreover, the pilots are too slow. Some 85 percent of the companies surveyed spend more than one year in pilot mode, while 28 percent spend more than two years. For companies to begin to capture the predicted trillions of dollars in value, they must move more pilots to scale faster.
Exhibit 2 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Companies usually head into Industry 4.0 pilots with the intention of expanding them company-wide. Too often, however, the pilots are essentially one-offs that fail to anticipate critical requirements in expanding from self-contained pilots to enterprise scale. Industry 4.0 (and IIoT) therefore remains in purgatory.
Through our work with clients on the manufacturing front lines, and in a host of realistic learning environments, we have identified three steps that help expand a successful pilot across an enterprise.
Start with the appropriate executive sponsorship and operating model, defining the roles and accountabilities for the business-unit, IT, and operations teams, along with the digital and analytics experts—all of whom need to work together and acquire the right talent.
Choose use cases carefully. Start by identifying the ones that create the most value and are easiest to implement; these can serve as lighthouses to demonstrate technological capabilities and potential impact. Embedding these cases into business routines then ensures that analytic insights don’t end up only in the back office but are used every day by the managers, supervisors, and operators who make the decisions that will enable the plant to run better.
As important as the first two steps are, they’re also conceptually simple, if sometimes a challenge to achieve in practice. It’s the third step in IT/OT convergence that can turn into a high barrier. The complexities of IT/OT technology are genuinely difficult to tackle, especially because on most factory floors, the links between IT and OT tend to be immature in unique ways. We refer to this as the last-mile IT/OT problem.
Within the IT/OT last mile, five issues combine to prevent manufacturers from scaling Industry 4.0 and IIoT.
Complex, heterogeneous environment: A typical medium-size plant has over 200 individual pieces of equipment, purchased at different times from a variety of suppliers. Each supplier has its own automation capabilities, hardware and software platforms, and communications protocols. This context makes it very difficult to collect, integrate, and contextualize data. Moreover, some equipment manufacturers offer data-analytical insights as a value-added service, creating further potential wrinkles in data accessibility. And the industrial-automation stack of hardware and software is itself highly complex, comprising everything from manufacturing-execution systems (MES), maintenance-software packages, production-scheduling software, and distributed-control systems, through to enterprise resource planning and product-lifecycle management.
A typical medium-size plant has over 200 individual pieces of equipment, purchased at different times from a variety of suppliers. Each supplier has its own automation capabilities, hardware and software platforms, and communications protocols. This context makes it very difficult to collect, integrate, and contextualize data. Moreover, some equipment manufacturers offer data-analytical insights as a value-added service, creating further potential wrinkles in data accessibility. And the industrial-automation stack of hardware and software is itself highly complex, comprising everything from manufacturing-execution systems (MES), maintenance-software packages, production-scheduling software, and distributed-control systems, through to enterprise resource planning and product-lifecycle management. Old unconnected machines: It is not uncommon to find aging, uninstrumented equipment on the factory floor, as replacement cycles for heavy assets often last decades. Difficult or extreme operating environments, such as the intricacies of a paint shop, are further barriers for data capture. Finding ways to instrument these assets is therefore an imperative for driving IoT at scale. Also, equipment that has already been instrumented frequently relies on legacy software systems, such as late-90s desktop-based machine-control systems, with data stored offline in spreadsheets. At one site we examined, for example, 90 percent of data from the MES was purged every 30 days (except for parameters required for reporting to major customers).
It is not uncommon to find aging, uninstrumented equipment on the factory floor, as replacement cycles for heavy assets often last decades. Difficult or extreme operating environments, such as the intricacies of a paint shop, are further barriers for data capture. Finding ways to instrument these assets is therefore an imperative for driving IoT at scale. Also, equipment that has already been instrumented frequently relies on legacy software systems, such as late-90s desktop-based machine-control systems, with data stored offline in spreadsheets. At one site we examined, for example, 90 percent of data from the MES was purged every 30 days (except for parameters required for reporting to major customers). Security concerns: Some manufacturers are reluctant to move data to the cloud, preferring an IoT solution that offers a mix of sensor-based edge analytics for critical process control and on-premises solutions for predictive analytics.
Some manufacturers are reluctant to move data to the cloud, preferring an IoT solution that offers a mix of sensor-based edge analytics for critical process control and on-premises solutions for predictive analytics. Limited last-mile OT capabilities at scale: Fundamentally, delivering Industry 4.0 at scale requires the ability to extract, interpret, and harmonize data from disparate systems that were not designed to work together. When building towards an IIoT platform, whether internally or with a third party, organizations must ensure that they can find capable OT service providers—ones that can support plants in locations across a wide-ranging footprint while harmonizing the collection (and connectivity) of data captured in the plant from PLCs, sensors, and historians. Without this step, the best analytic models and user interfaces will not have the data required to deliver the value expected from them.
Fundamentally, delivering Industry 4.0 at scale requires the ability to extract, interpret, and harmonize data from disparate systems that were not designed to work together. When building towards an IIoT platform, whether internally or with a third party, organizations must ensure that they can find capable OT service providers—ones that can support plants in locations across a wide-ranging footprint while harmonizing the collection (and connectivity) of data captured in the plant from PLCs, sensors, and historians. Without this step, the best analytic models and user interfaces will not have the data required to deliver the value expected from them. Poor collaboration between IT and OT: Often the problem is due to the historic lack of connection between IT activities and OT activities, typically by onsite manufacturing process engineers. OT’s goals usually focus on current performance, business-as-usual predictability, and avoiding disturbances to a system that works; IT favors security and trusted technology providers, often those that have a large installed base already. Different levels of focus on user management versus machine management yield very different problem-solving approaches. Consequently, getting the IT and OT staffs working together from the start is a must.
Being aware of last-mile IT/OT issues will help build a technical foundation that supports the full-scale roll-out of Industry 4.0 pilots. But careful planning that addresses the people issues of culture, process, and prioritization is equally important. Indeed, in our work with manufacturers, the specific success factors we’ve seen for sustained value capture point more to the human side of the equation: for example, leaders who are fully engaged, vendors who act as partners, and talent who have (and develop) the right skills.
Manufacturers should reflect on a few essential questions that help address the last-mile IT/OT challenges:
How mature are our plants with respect t0 last-mile IT/OT, and how can we better understand their IT/OT challenges?
How should we balance investment in additional data collection versus in getting more value from the 99 percent of our current data that is likely sitting unused?
How can we use previous industrial-automation investments, in systems such as MES and DCS, to help achieve speed and scale in building our IoT architecture?
To maximize our returns, how much of our last-mile IT/OT investment should be at plant level (sensors, connectivity, edge devices), and how much in broader IoT architecture (platform, cloud, application layers)?
Addressing these questions in the IT/OT context takes isn’t easy, and we’ll discuss them in more detail in our next post. We’ll also provide guidance on designing pilots that not only create tangible results, but also provide a foundation for a repeatable, timely rollout process that delivers value in months rather than years.
The authors wish to thank Ani Bhalekar, Karel Eloot, and Bodo Koerber for their contributions to this post.The Deloitte Digital IoT practice is a dynamic blend of technologists, strategists, and designers who use technology, data, and science to drive major business innovation. By mixing in creative vision and significant industry expertise, our IoT practice is helping our clients reimagine—and rewire—business-as-usual.
Think big. Start small. Scale fast. With us, it all starts with exploring the art of the possible. Once we have options for ideas, we help clients sort through the noise by starting small with a project that offers demonstrated ROI and tangible benefits. Utilizing engineers, cloud-based platforms, and sensor kits we can quickly create mock-ups and prototypes to show clients what’s possible. If the solution seems like it’s working, we iterate on it, tweak it, enhance it, and work with others to scale the project.
Our objective is to use IoT as a medium for helping clients transform their businesses, realize tangible value, and deliver powerful outcomes. We have a network of IoT consultants all over the world focusing on the organizational implications of IoT in areas like security and privacy, technology, strategy, architecture, analytics, and implementation.We approach every IoT project with a value-focused mindset.
Turnkey IoT—A low-cost, low-risk approach to accelerating IoT implementation that combines best-of-breed hardware, software, analytics, security, insights, and implementation strategy services into industry-tailored, pre-configured solutions with a focus on predictive maintenance & asset monitoring, asset performance management, and asset tracking use cases.
Retail 360—Clients can demo a custom solution that provides an omni-channel shopping experience to customers via a mobile app (EngageMe) and in-store inventory management capabilities to retailers via a web app (Store 360°). This helps customers get the experience they desire while retailers meet goals for increased sales and operational efficiency.
Patient 360—This IoT-based, care-coordination platform empowers patients, providers, payers, and the pharmaceutical industry. It can deliver better patient experiences by providing data and analysis to improve patient care as well as productivity in the healthcare marketplace.
Tech Map—To assist clients in evaluating the technology landscape for Smart Cities, we created IoT vendor maps that Deloitte practitioners use as an internal tool to rank vendors within technical categories and highlight the breadth and depth of their capabilities.Karel co-leads the Firm’s Operations practice and Internet of Things (IoT) group in Asia. Since joining the Firm in 1997, Karel has worked across multiple industries including advanced industries, automotive, electronics, energy and materials, technology, as well as private equity.
July 16, 2019 In an earlier blog post, we demonstrated how manufacturers’ efforts to capture value from the Industrial Internet of Things (IIoT) are often stymied by a breakdown at the convergence between their existing operational technology (OT) systems—their things—and the new information technology (IT) systems needed to drive a transformational digital operation.
We refer to this as the “last-mile IT/OT problem,” which results from the failure to properly plan, design, and build an IT/OT architecture from the outset that is capable of driving use-case pilots to scale. We identified the steps manufacturers should take to ensure that their IIoT stack isn’t holding them back, with this post as the first of a series of deep dives into how to put these steps into practice. Bear in mind that the steps aren’t strictly linear: in trying to deliver a whole program of IIoT initiatives, a pragmatic, integrated approach considers steps in tandem as needed to keep initiatives on track and out of one another’s way. But there is a general interplay between them.
Because selecting use cases is the starting point of any transformation, getting this step right is critical (Exhibit 1). All too often we see manufacturers start with technology in mind and then try to build a business case around it, and this sets them up to fail. From the outset, it’s essential for business KPIs to lead IIoT transformations, and for each potential use case to be tested against the business value that it is trying to create. In some cases, the best solution may not be a technology play at all.
Exhibit 1 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
But before making any judgment, bear in mind that it’s also important to avoid looking for business problems only within the four walls of the plant. By extending your gaze all the way from the supply chain to marketing, sales, and after-sales service, you can see opportunities to reinvent the complete value chain through digital technologies, rather than simply installing multiple “point” solutions that convert analog practices into their digital equivalents. It’s the difference between using technology to make an inefficient process run faster, and using technology to create a new process that dramatically opens up new opportunities and increases value creation.
Because use cases are typically selected to address immediate business needs, they are not enough on their own to deliver the sustainable new business model that an end-to-end digital transformation promises. But they are the building blocks of this transformation, and stack enough of them together and you can reap enormous dividends. Use cases also have a second, often under-appreciated, role. Because they solve for a particular problem or business need, they deliver the short-term wins necessary to capture immediate impact and prove the benefits of transformation to everyone from the frontline to the boardroom.
While we recommend implementing multiple use cases to drive a significant business transformation, this is not to say that single use cases or a related group of use cases in one area of a business cannot deliver significant impact. For instance:
A global basic-materials company introduced driverless trucks into several of its larger sites, which not only cut costs and improved safety but also outperformed the manned fleet by an average of more than 10 percent.
An automaker improved job satisfaction and reduced the time workers spent waiting between tasks by more than 75 percent—by teaming workers with collaborative robots on one of the most important assembly tasks for final product quality.
But by multiplying these gains across use cases spread throughout the value chain, the truly transformative power of digitizing operations starts to come into view. The implementation of each new use case also part funds the establishment of the IIoT platform infrastructure by delivering its own positive ROI, so the number of use cases a manufacturer could implement can be quite large.
Once an ambitious list of potential use cases is confirmed, they need to be tested against several criteria in addition to their impact on the business. These include whether technology to drive the use case is mature and readily available from established vendors, and whether the organization currently has the capacity to deliver the use case using that technology. While there are clear benefits to being a first mover, it’s also worth looking at what competitors are doing and whether the use case has been adopted at scale elsewhere in the industry to deliver significant benefit.
One way of testing use cases against these criteria is to feed them into a prioritization funnel with successively tighter filters at each stage. Only use cases that pass through all the filters and emerge from the narrow end of the funnel get sequenced for implementation. Because a typical manufacturer is likely to need 10–15 use cases just to drive the manufacturing part of its IIoT transformation—expanding this to all functions up and down the value chain will require many more—this approach is not for the faint at heart. One manufacturer put around 50 potential use cases through a prioritization tunnel to end up with around 15 use cases they needed to meet their game-changing business objectives around quality and cost optimization, as well as worker productivity (Exhibit 2).
Exhibit 2 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
The prioritization filter should also give a good idea of how to sequence the rollout of use cases. The next steps are to determine which technology solutions from the many options in the tech ecosystem will power them, identify the tech stack requirements for each one, and select the platform that will tie them all together. We will come back to these steps in future articles.Explore the inner workings of the Internet of Things in this deep dive into some of the technologies that make it possible.
If you’ve ever seen the “check engine” light come on in your car and had the requisite repairs done in a timely way, you’ve benefited from an early-stage manifestation of what today is known as the Internet of Things (IoT). Something about your car’s operation—an action—triggered a sensor,1 which communicated the data to a monitoring device. The significance of these data was determined based on aggregated information and prior analysis. The light came on, which in turn triggered a trip to the garage and necessary repairs.
In 1991 Mark Weiser, then of Xerox PARC, saw beyond these simple applications. Extrapolating trends in technology, he described “ubiquitous computing,” a world in which objects of all kinds could sense, communicate, analyze, and act or react to people and other machines autonomously, in a manner no more intrusive or noteworthy than how we currently turn on a light or open a tap.
One way of capturing the process implicit in Weiser’s model is as an Information Value Loop with discrete but connected stages. An action in the world allows us to create information about that action, which is then communicated and aggregated across time and space, allowing us to analyze those data in the service of modifying future acts.
Although this process is generic, it is perhaps increasingly relevant, for the future Weiser imagined is more and more upon us—not thanks to any one technological advance or even breakthrough but, rather, due to a confluence of improvements to a suite of technologies that collectively have reached levels of performance that enable complete systems relevant to a human-sized world.
As illustrated in figure 2 below, each stage of the value loop is connected to the subsequent stage by a specific set of technologies, defined below.
The business implications of the IoT are explored in an ongoing series of Deloitte reports. These articles examine the IoT’s impact on strategy, customer value, analytics, security, and a wide variety of specific applications. Yet just as a good chef should have some understanding of how the stove works, managers hoping to embed IoT-enabled capabilities in their strategies are well served to gain a general understanding of the technologies themselves.
To that end, this document serves as a technical primer on some of the technologies that currently drive the IoT. Its structure follows that of the technologies that connect the stages of the Information Value Loop: sensors, networks, standards, augmented intelligence, and augmented behavior. Each section in the report provides an overview of the respective technology—including factors that drive adoption as well as challenges that the technology must overcome to achieve widespread adoption. We also present an end-to-end IoT technology architecture that guides the development and deployment of Internet of Things systems. Our intent, in this primer, is not to describe every conceivable aspect of the IoT or its enabling technologies but, rather, to provide managers an easy reference as they explore IoT solutions and plan potential implementations. Our hope is that this report will help demystify the underlying technologies that comprise the IoT value chain and explain how these technologies collectively relate to a larger strategic framework.
Most “things,” from automobiles to Zambonis, the human body included, have long operated “dark,” with their location, position, and functional state unknown or even unknowable. The strategic significance of the IoT is born of the ever-advancing ability to break that constraint, and to create information, without human observation, in all manner of circumstances that were previously invisible. What allows us to create information from action is the use of sensors, a generic term intended to capture the concept of a sensing system comprising sensors, microcontrollers, modem chips, power sources, and other related devices.
A sensor converts a non-electrical input into an electrical signal that can be sent to an electronic circuit. The Institute of Electrical and Electronics Engineers (IEEE) provides a formal definition:
An electronic device that produces electrical, optical, or digital data derived from a physical condition or event. Data produced from sensors is then electronically transformed, by another device, into information (output) that is useful in decision making done by “intelligent” devices or individuals (people).7
The technological complement to a sensor is an actuator, a device that converts an electrical signal into action, often by converting the signal to nonelectrical energy, such as motion. A simple example of an actuator is an electric motor that converts electrical energy into mechanical energy. Sensors and actuators belong to the broader category of transducers: A sensor converts energy of different forms into electrical energy; a transducer is a device that converts one form of energy (electrical or not) into another (electrical or not). For example, a loudspeaker is a transducer because it converts an electrical signal into a magnetic field and, subsequently, into acoustic waves.
Different sensors capture different types of information. Accelerometers measure linear acceleration, detecting whether an object is moving and in which direction,8 while gyroscopes measure complex motion in multiple dimensions by tracking an object’s position and rotation. By combining multiple sensors, each serving different purposes, it is possible to build complex value loops that exploit many different types of information. For example:
Canary : A home security system that comes with a combination of temperature, motion, light, and humidity sensors. Computer vision algorithms analyze patterns in behaviors of people and pets, while machine learning algorithms improve the accuracy of security alerts over time. 9
: A home security system that comes with a combination of temperature, motion, light, and humidity sensors. algorithms analyze patterns in behaviors of people and pets, while algorithms improve the accuracy of security alerts over time. Thingsee: A do-it-yourself IoT device that individuals can use to combine sensors such as accelerometers, gyroscopes, and magnetometers with other sensors that measure temperature, humidity, pressure, and light in order to collect personally interesting data.10
Sensors are often categorized based on their power sources: active versus passive. Active sensors emit energy of their own and then sense the response of the environment to that energy. Radio Detection and Ranging (RADAR) is an example of active sensing: A RADAR unit emits an electromagnetic signal that bounces off a physical object and is “sensed” by the RADAR system. Passive sensors simply receive energy (in whatever form) that is produced external to the sensing device. A standard camera is embedded with a passive sensor—it receives signals in the form of light and captures them on a storage device.
Passive sensors require less energy, but active sensors can be used in a wider range of environmental conditions. For example, RADAR provides day and night imaging capacity undeterred by clouds and vegetation, while cameras require light provided by an external source.11
Figure 4 provides an illustrative list of 13 types of sensors based on the functions they perform; they could be active or passive per the description above.
Of course, the choice of a specific sensor is primarily a function of the signal to be measured (for example, position versus motion sensors). There are, however, several generic factors that determine the suitability of a sensor for a specific application. These include, but are not limited to, the following:12
Accuracy : A measure of how precisely a sensor reports the signal. For example, when the water content is 52 percent, a sensor that reports 52.1 percent is more accurate than one that reports it as 51.5 percent.
: A measure of how precisely a sensor reports the signal. For example, when the water content is 52 percent, a sensor that reports 52.1 percent is more accurate than one that reports it as 51.5 percent. Repeatability : A sensor’s performance in consistently reporting the same response when subjected to the same input under constant environmental conditions.
: A sensor’s performance in consistently reporting the same response when subjected to the same input under constant environmental conditions. Range : The band of input signals within which a sensor can perform accurately. Input signals beyond the range lead to inaccurate output signals and potential damage to sensors.
: The band of input signals within which a sensor can perform accurately. Input signals beyond the range lead to inaccurate output signals and potential damage to sensors. Noise : The fluctuations in the output signal resulting from the sensor or the external environment.
: The fluctuations in the output signal resulting from the sensor or the external environment. Resolution : The smallest incremental change in the input signal that the sensor requires to sense and report a change in the output signal.
: The smallest incremental change in the input signal that the sensor requires to sense and report a change in the output signal. Selectivity: The sensor’s ability to selectively sense and report a signal. An example of selectivity is an oxygen sensor’s ability to sense only the O 2 component despite the presence of other gases.
Any of these factors can impact the reliability of the data received and therefore the value of the data itself.
There are three primary factors driving the deployment of sensor technology: price, capability, and size. As sensors get less expensive, “smarter,” and smaller, they can be used in a wider range of applications and can generate a wider range of data at a lower cost.13
Cheaper sensors : The price of sensors has consistently fallen over the past several years as shown in figure 5, and these price declines are expected to continue into the future. 14 For example, the average cost of an accelerometer now stands at 40 cents, compared to $2 in 2006. 15 Sensors vary widely in price, but many are now cheap enough to support broad business applications.
: The price of sensors has consistently fallen over the past several years as shown in figure 5, and these price declines are expected to continue into the future. For example, the average cost of an accelerometer now stands at 40 cents, compared to $2 in 2006. Sensors vary widely in price, but many are now cheap enough to support broad business applications. Smarter sensors : As discussed earlier, a sensor does not function by itself—it is a part of a larger system that comprises microprocessors, modem chips, power sources, and other related devices. Over the last two decades, microprocessors’ computational power has improved, doubling every three years (see figure 6).
: As discussed earlier, a sensor does not function by itself—it is a part of a larger system that comprises microprocessors, modem chips, power sources, and other related devices. Over the last two decades, microprocessors’ computational power has improved, doubling every three years (see figure 6). Smaller sensors: There has been a rapid growth in the use of smaller sensors that can be embedded in smartphones and wearables. Micro-electro-mechanical systems (MEMS) sensors—small devices that combine digital electronics and mechanical components—have the potential to drive wider IoT applications.16 The average number of sensors on a smartphone has increased from three (accelerometer, proximity, ambient light) in 2007 to at least ten (including advanced sensors such as fingerprint- and gesture-based sensors) in 2014. Similarly, biosensors that can be worn and even ingested present new opportunities for the health care industry.
Even in cases where sensors are sufficiently small, smart, and inexpensive, challenges remain. Among them are power consumption, data security, and interoperability.
Power consumption : Sensors are powered either through in-line connections or batteries. 17 In-line power sources are constant but may be impractical or expensive in many instances. Batteries may represent a convenient alternative, but battery life, charging, and replacement, especially in remote areas, may represent significant issues. 18 There are two dimensions to power: Efficiency: Thanks to advanced silicon technologies, some sensors can now stay live on batteries for over 10 years, thus reducing battery replacement cost and efforts. 19 However, improved efficiency is counterbalanced by the power needed for increased numbers of sensors. Hence, systems’ overall power consumption often does not decrease or may, in fact, increase; this is an underlying challenge, as both energy and financial resources are finite. Source: While sensors often depend on batteries, energy harvesting of alternative energy sources such as solar energy may provide some alternatives, at a minimum providing support during the battery changing time. 20 However, energy harvesters that are currently available are expensive, and companies are hesitant to make that investment (installation plus maintenance costs) given the unreliability associated with the supply of alternative power. 21
: Sensors are powered either through in-line connections or batteries. In-line power sources are constant but may be impractical or expensive in many instances. Batteries may represent a convenient alternative, but battery life, charging, and replacement, especially in remote areas, may represent significant issues. There are two dimensions to power:
Security of sensors : Executives considering IoT deployments often cite security as a key concern. 22 Tackling the problem at the source may be a logical approach. Complex cryptographic algorithms might ensure data integrity, though sensors’ relatively low processing power, the low memory available to them, and concerns about power consumption may all limit the ability to provide this security. Companies need to be mindful of the constraints involved as they plan their IoT deployments. 23
: Executives considering IoT deployments often cite security as a key concern. Tackling the problem at the source may be a logical approach. Complex cryptographic algorithms might ensure data integrity, though sensors’ relatively low processing power, the low memory available to them, and concerns about power consumption may all limit the ability to provide this security. Companies need to be mindful of the constraints involved as they plan their IoT deployments. Interoperability: Most of the sensor systems currently in operation are proprietary and are designed for specific applications. This leads to interoperability issues in heterogeneous sensor systems related to communication, exchange, storage and security of data, and scalability. Communication protocols are required to facilitate communication between heterogeneous sensor systems. Due to various limitations such as low processing power, memory capacity, and power availability at the sensor level, lightweight communication protocols are preferable.24 Constrained Application Protocol (CoAP) is an open-source protocol that transfers data packets in a format that is lighter than that of other protocols such as Hypertext Transfer Protocol (HTTP), a protocol familiar to many, as it appears in most web addresses. While CoAP is well suited for energy-constrained sensor systems, it does not come with in-built security features, and additional protocols are needed to secure intercommunications between sensor systems.25
Information that sensors create rarely attains its maximum value at the time and place of creation. The signals from sensors often must be communicated to other locations for aggregation and analysis. This typically involves transmitting data over a network.
Sensors and other devices are connected to networks using various networking devices such as hubs, gateways, routers, network bridges, and switches, depending on the application. For example, laptops, tablets, mobile phones, and other devices are often connected to a network, such as Wi-Fi, using a networking device (in this case, a Wi-Fi router).
The first step in the process of transferring data from one machine to another via a network is to uniquely identify each of the machines. The IoT requires a unique name for each of the “things” on the network. Network protocols are a set of rules that define how computers identify each other. Broadly, network protocols can be proprietary or open. Proprietary network protocols allow identification and authorization to machines with specific hardware and software, making customization easier and allowing manufacturers to differentiate their offerings. Open protocols allow interoperability across heterogeneous devices, thus improving scalability.26
Internet Protocol (IP) is an open protocol that provides unique addresses to various Internet-connected devices; currently, there are two versions of IP: IP version 4 (IPv4) and IP version 6 (IPv6). IP was used to address computers before it began to be used to address other devices. About 4 billion IPv4 addresses out of its capacity of 6 billion addresses have already been used. IPv6 has superior scalability with approximately 3.4x1038 unique addresses compared to the 6 billion addresses supported by IPv4. Since the number of devices connected to the Internet is estimated to be 26 billion as of 2015 and projected to grow to 50 billion or more by 2020, the adoption of IPv6 has served as a key enabler of the IoT.
Network technologies are classified broadly as wired or wireless. With the continuous movement of users and devices, wireless networks provide convenience through almost continuous connectivity, while wired connections are still useful for relatively more reliable, secured, and high-volume network routes.27
The choice of a network technology depends largely on the geographical range to be covered. When data have to be transferred over short distances (for example, inside a room), devices can use wireless personal area network (PAN) technologies such as Bluetooth and ZigBee as well as wired connections through technologies such as Universal Serial Bus (USB). When data have to be transferred over a relatively bigger area such as an office, devices could use local area network (LAN) technologies. Examples of wired LAN technologies include Ethernet and fiber optics. Wireless LAN networks include technologies such as Wi-Fi. When data are to be transferred over a wider area beyond buildings and cities, an internetwork called wide area network (WAN) is set up by connecting a number of local area networks through routers. The Internet is an example of a WAN.
Data transfer rates and energy requirements are two key considerations when selecting a network technology for a given application. Technologies such as 4G (LTE, LTE-A) and 5G are favorable for IoT applications, given their high data transfer rates. Technologies such as Bluetooth Low Energy and Low Power Wi-Fi are well suited for energy-constrained devices.
Below, we discuss select wireless network technologies that could be used for IoT applications. For each of the following technologies, we discuss bandwidth rates, recent advances, and limitations. The technologies discussed below are representative, and the choice of an appropriate technology depends on the application at hand and the features of that technology.
Introduced in 1999, Bluetooth technology is a wireless technology known for its ability to transfer data over short distances in personal area networks.28 Bluetooth Low Energy (BLTE) is a recent addition to the Bluetooth technology and consumes about half the power of a Bluetooth Classic device, the original version of Bluetooth.29 The energy efficiency of BLTE is attributable to the shorter scanning time needed for BLTE devices to detect other devices: 0.6 to 1.2 milliseconds (ms) compared to 22.5 ms for Bluetooth Classic. 30 In addition, the efficient transfer of data during the transmitting and receiving states enables BLTE to deliver higher energy efficiency compared to Bluetooth Classic. Higher energy efficiency comes at the cost of lower data rates: BLTE supports 260 kilobits per second (Kbps) while Bluetooth Classic supports up to 2.1 Mbps.31
Existing penetration, coupled with low device costs, positions BLTE as a technology well suited for IoT applications. However, interoperability is the persistent bottleneck here as well: BLTE is compatible with only the relatively newer dual-mode Bluetooth devices (called dual mode because they support BLTE as well as Bluetooth Classic), not the legacy Bluetooth Classic devices.32
Although Ethernet has been in use since the 1970s, Wi-Fi is a more recent wireless technology that is widely popular and known for its high-speed data transfer rates in personal and local area networks.
Typically, Wi-Fi devices keep latency, or delays in the transmission of data, low by remaining active even when no data are being transmitted. Such Wi-Fi connections are often set up with a dedicated power line or batteries that need to be charged after a couple of hours of use. Higher-cost, lower-power Wi-Fi devices “sleep” when not transmitting data and need just 10 milliseconds to “wake up” when called upon.33 Low Power Wi-Fi with batteries can be used for remote sensing and control applications.
Introduced in 2001, WiMAX was developed by the European Telecommunications Standards Institute (ETSI) in cooperation with IEEE. WiMAX 2 is the latest technology in the WiMAX family. WiMAX 2 offers maximum data speed of 1 Gbps compared to 100 Mbps by WiMAX.34
In addition to higher data speeds, WiMAX 2 has better backward compatibility than WiMAX: WiMAX 2 network operators can provide seamless service by using 3G or 2G networks when required. By way of comparison, Long Term Evolution (LTE) and LTE-A, described below, also allow backward compatibility.
Long Term Evolution, a wireless wide-area network technology, was developed by members of the 3rd Generation Partnership Project body in 2008. This technology offers data speeds of up to 300 Mbps.35
LTE-Advanced (LTE-A) is a recent addition to the LTE technology that offers still-higher data rates of 1 Gbps compared to 300 Mbps by LTE.36 There is debate among industry practitioners on whether LTE is truly a 4G technology: Many consider LTE a pre-4G technology and LTE-A a true 4G technology.37 Given its high bandwidth and low latency, LTE is touted as the more-promising technology for IoT applications; however, the underlying network infrastructure remains under development, as described in the challenges below.
Weightless is a wireless open-standard WAN technology introduced in early 2014. Weightless uses unused bandwidth originally intended for TV broadcast to transfer data; based on the technical process of dynamic spectrum allocation, it can travel longer distances and penetrate through walls.38
Weightless can provide data rates between 2.5 Kbps to 16 Mbps in a wireless range of up to five kilometers, with batteries lasting up to 10 years.39 Weightless devices remain in standby mode, waking up every 15 minutes and staying active for 100 milliseconds to sync up and act on any messages; this leads to a certain latency.40 Given these characteristics, Weightless connections appear to be better- suited for delivering short messages in widespread machine-to-machine communications.
Networks are able to transfer data at higher speeds, at lower costs, and with lower energy requirements than ever before. Also, with the introduction of IPv6, the number of connected devices is rising rapidly. As a result, we are seeing an increasingly diverse composition of connected devices, from laptops and smartphones to home appliances, vehicles, traffic signals, and wind turbines. Such diversity in the nature of connected devices is driving a wider-scale adoption of an extensive range of network technologies.
Data rates : In the last 30 years, data rates have increased from 2 Kbps to 1 Gbps, facilitating seamless transfer of heavy data files (see figure 8 for various cellular-technology generations). The transition from the first cellular generation to the second changed the way communication messages were sent—from analog signals to digital signals. The transition from the second to the third generation marked a leap in capability, enabling users to share multimedia content over high-speed connections.
: In the last 30 years, data rates have increased from 2 Kbps to 1 Gbps, facilitating seamless transfer of heavy data files (see figure 8 for various cellular-technology generations). The transition from the first cellular generation to the second changed the way communication messages were sent—from analog signals to digital signals. The transition from the second to the third generation marked a leap in capability, enabling users to share multimedia content over high-speed connections. Internet transit prices : The Internet transit price is the price charged by an Internet service provider (ISP) to transfer data from one point in the network to another. Since no single ISP can cover the worldwide network, the ISPs rely on each other to transfer data using network interconnections through gateways. 41 Internet transit prices have come down in recent years due to technology developments such as the global increase in submarine cabling, the rising use of wavelength division multiplexing by ISPs, the transition to higher-capacity bandwidth connections, and increased competition between ISPs. 42 In 2003, it cost $120 to transfer 1 Mbps in the United States; as of 2015, the cost has come down to 63 cents (see figure 9).
: The Internet transit price is the price charged by an Internet service provider (ISP) to transfer data from one point in the network to another. Since no single ISP can cover the worldwide network, the ISPs rely on each other to transfer data using network interconnections through gateways. Internet transit prices have come down in recent years due to technology developments such as the global increase in submarine cabling, the rising use of wavelength division multiplexing by ISPs, the transition to higher-capacity bandwidth connections, and increased competition between ISPs. In 2003, it cost $120 to transfer 1 Mbps in the United States; as of 2015, the cost has come down to 63 cents (see figure 9). Power efficiency : Availability of power-efficient networks is critical given the increase in the number of connected devices. Bluetooth Low Energy has a power consumption of 0.153 μW/bit (0.153 microwatts consumed in transferring 1 bit of data; 1 byte = 8 bits), about 50 percent lower than that of Bluetooth Classic. 43
: Availability of power-efficient networks is critical given the increase in the number of connected devices. Bluetooth Low Energy has a power consumption of 0.153 μW/bit (0.153 microwatts consumed in transferring 1 bit of data; 1 byte = 8 bits), about 50 percent lower than that of Bluetooth Classic. IPv6 adoption: Given IPv6’s massive identification space, new devices are typically IPv6-based, while companies are transitioning existing devices from IPv4 to IPv6. In 2015, according to Cisco, the number of IPv6-capable websites increased by 33 percent over the prior year.44 By 2018, 50 percent of all fixed and mobile device connections are expected to be IPv6-based, compared to 16 percent in 2013.45
Even though network technologies have improved in terms of higher data rates and lower costs, there are challenges associated with interconnections, penetration, security, and power consumption.
Interconnections : Metcalfe’s Law states that “the value of a network is proportional to the square of the number of compatibly communicating devices.” There is limited value in connecting the devices to the Internet; companies can create enhanced value by connecting devices to the network and to each other. Different network technologies require gateways to connect with each other. This adds cost and complexity, which can often make security management more difficult.
: Metcalfe’s Law states that “the value of a network is proportional to the square of the number of compatibly communicating devices.” There is limited value in connecting the devices to the Internet; companies can create enhanced value by connecting devices to the network and to each other. Different network technologies require gateways to connect with each other. This adds cost and complexity, which can often make security management more difficult. Network penetration : There is limited penetration of high-bandwidth technologies such as LTE and LTE-A, while 5G technology has yet to arrive. 46 Currently, LTE accounts for only 5 percent of the world’s total mobile connections. LTE penetration as a percentage of connections is 69 percent in South Korea, 46 percent in Japan, and 40 percent in the United States, but its penetration in the developing world stands at just 2 percent. 47 In emerging markets, network operators are treading the slow-and-steady path to LTE infrastructure, given the accompanying high costs and their focus on fully reaping the returns on the investments in 3G technology that they made in the last three to five years.
: There is limited penetration of high-bandwidth technologies such as LTE and LTE-A, while 5G technology has yet to arrive. Currently, LTE accounts for only 5 percent of the world’s total mobile connections. LTE penetration as a percentage of connections is 69 percent in South Korea, 46 percent in Japan, and 40 percent in the United States, but its penetration in the developing world stands at just 2 percent. In emerging markets, network operators are treading the slow-and-steady path to LTE infrastructure, given the accompanying high costs and their focus on fully reaping the returns on the investments in 3G technology that they made in the last three to five years. Security : With a growing number of sensor systems being connected to the network, there is an increasing need for effective authentication and access control. The Internet Protocol Security (IPSec) suite provides a certain level of secured IP connection between devices; however, there are outstanding risks associated with the security of one or more devices being compromised and the impact of such breaches on connected devices. 48 Maintaining data integrity while remaining energy efficient stands as an enduring challenge.
: With a growing number of sensor systems being connected to the network, there is an increasing need for effective authentication and access control. The Internet Protocol Security (IPSec) suite provides a certain level of secured IP connection between devices; however, there are outstanding risks associated with the security of one or more devices being compromised and the impact of such breaches on connected devices. Maintaining data integrity while remaining energy efficient stands as an enduring challenge. Power: Devices connected to a network consume power, and providing a continuous power source is a pressing concern for the IoT. Depending on the application, a combination of techniques such as power-aware routing and sleep-scheduling protocols can help improve power management in networks. Power-aware routing protocols determine the routing decision based on the most energy-efficient route for transmitting data packets; sleep-scheduling protocols define how devices can “sleep” and remain inactive for better energy efficiency without impacting the output.
The third stage in the Information Value Loop—aggregate—refers to a variety of activities including data handling, processing, and storage. Data collected by sensors in different locations are aggregated so that meaningful conclusions can be drawn. Aggregation increases the value of data by increasing, for example, the scale, scope, and frequency of data available for analysis. Aggregation is achieved through the use of various standards depending on the IoT application at hand. According to the International Organization for Standardization (ISO), “a standard is a document that provides requirements, specifications, guidelines or characteristics that can be used consistently to ensure that materials, products, processes and services are fit for their purpose.”49
Two broad types of standards relevant for the aggregation process are technology standards (including network protocols, communication protocols, and data-aggregation standards) and regulatory standards (related to security and privacy of data, among other issues).
We discuss technology standards in the “Enabling technology standards” discussion later in this section. The second type of standards relates to regulatory standards that will play an important role in shaping the IoT landscape. There is a need for clear regulations related to the collection, handling, ownership, use, and sale of the data. Within the context of expanding IoT applications, it is worthwhile to consider the US Federal Trade Commission’s privacy and security recommendations dubbed the Fair Information Practice Principles (FIPPs) and described below.50
Choice and notice: The principle of choice and notice states that entities that collect data should give users the option to choose what they reveal and notify users when their personal information is being recorded. This may not be required for IoT applications that aggregate information, de-linked to any specific individual.
The principle of choice and notice states that entities that collect data should give users the option to choose what they reveal and notify users when their personal information is being recorded. This may not be required for IoT applications that aggregate information, de-linked to any specific individual. Purpose specification and use limitation: This principle states that entities collecting data must clearly state the purpose to the authority that permits the collection of those data. The use of data must be limited to the purpose specified, although this might hinder creative uses of collected data sets in various IoT applications.
This principle states that entities collecting data must clearly state the purpose to the authority that permits the collection of those data. The use of data must be limited to the purpose specified, although this might hinder creative uses of collected data sets in various IoT applications. Data minimization: The principle of data minimization suggests that a company can collect only the data required for a specific purpose and delete that data after the intended use. This necessarily restricts the scope of analysis that can result from slicing and dicing the IoT data.
The principle of data minimization suggests that a company can collect only the data required for a specific purpose and delete that data after the intended use. This necessarily restricts the scope of analysis that can result from slicing and dicing the IoT data. Security and accountability: This principle states that entities that collect and store data are accountable and must deploy security systems to avoid any unauthorized access, modification, deletion, or use of the data.
It is unclear, as of now, who will design, develop, and implement any regulatory standards specifically tailored to IoT applications. There is discussion about the appropriateness of existing guidelines and whether they are adequate for evolving IoT applications. For example, the US Health Insurance Portability and Accountability Act (HIPAA) governs the protection of medical information collected by doctors, hospitals, and insurance companies.51 However, the act does not extend to information collected through personal wearable devices.52
We just discussed the issues related to regulatory standards. Technology standards, the second type, comprises three elements: network protocols, communication protocols, and data-aggregation standards. Network protocols define how machines identify each other, while communication protocols provide a set of rules or a common language for devices to communicate. Once the devices are “talking” to each other and sharing data, aggregation standards help to aggregate and process the data so that those data become usable.
Network protocols : Network protocols refer to a set of rules by which machines identify and authorize each other. Interoperability issues result from multiple network protocols in existence. In recent years, companies in the IoT value chain have begun working together to help align multiple network protocols. One example is the AllJoyn standard established by Qualcomm in late 2013 that allows devices to discover, connect, and communicate directly with other AllJoyn-enabled products connected to different technologies such as Wi-Fi, Ethernet, and possibly Bluetooth and ZigBee. 53
: Network protocols refer to a set of rules by which machines identify and authorize each other. Interoperability issues result from multiple network protocols in existence. In recent years, companies in the IoT value chain have begun working together to help align multiple network protocols. One example is the AllJoyn standard established by Qualcomm in late 2013 that allows devices to discover, connect, and communicate directly with other AllJoyn-enabled products connected to different technologies such as Wi-Fi, Ethernet, and possibly Bluetooth and ZigBee. Communication protocols: Once devices are connected to a network and they identify each other, communication protocols (a set of rules) provide a common language for devices to communicate. Various communication protocols are used for device-to-device communication; broadly, they vary in the format in which data packets are transferred. There are ongoing efforts to identify protocols better suited to IoT applications. Toward that end, we earlier discussed the advantages and limitations of the Constrained Application Protocol, a communication protocol lighter than other popular protocols such as HTTP.
Once devices are connected to a and they identify each other, communication protocols (a set of rules) provide a common language for devices to communicate. Various communication protocols are used for device-to-device communication; broadly, they vary in the format in which data packets are transferred. There are ongoing efforts to identify protocols better suited to IoT applications. Toward that end, we earlier discussed the advantages and limitations of the Constrained Application Protocol, a communication protocol lighter than other popular protocols such as HTTP. Data aggregation standards: Data collected from multiple devices come in different formats and at different sampling rates—that is, the frequency at which data are collected. One set of data-aggregation tools—Extraction, Transformation, Loading (ETL) tools—aggregate, process, and store data in a format that can be used for analytics applications (see figure 11).54 Extraction refers to acquiring data from multiple sources and multiple formats and then validating to ensure that only data that meet a criterion are included. Transformation includes activities such as splitting, merging, sorting, and transforming the data into a desired format—for example, names can be split into first and last names, while addresses can be merged into city and state format. Loading refers to the process of loading the data into a database that can be used for analytics applications.
Traditional ETL tools aggregate and store the data in relational databases, in which data are organized by establishing relationships based on a unique identifier. It is easy to enter, store, and query structured data in relational databases using structured query language (SQL). The American National Standards Institute standardized SQL as the querying language for relational databases in 1986.55 SQL provides users a medium to communicate with databases and perform tasks such as data modification and retrieval. As the standard, SQL aids aggregation not just in centralized databases (all data stored in a single location) but also in distributed databases (data stored on several computers with concurrent data modifications).
With recent advances in easy and cost-effective availability of large volumes of data, there is a question about the adequacy of traditional ETL tools that can typically handle data in terabytes (1 terabyte = 1012 bytes). Big-data ETL tools developed in recent years can handle a much higher volume of data, such as in petabytes (1 petabyte = 1000 terabytes or 1015 bytes). In addition to handling large volume, big-data tools are also considered to be better suited to handle the variety of incoming data, structured as well as unstructured. Structured data are typically stored in spreadsheets, while unstructured data are collected in the form of images, videos, web pages, emails, blog entries, documents, etc.
Apache Hadoop is a big-data tool useful especially for unstructured data. Based on the Java programming language, Hadoop, developed by the Apache Software Foundation, is an open-source tool useful for processing large data sets. Hadoop enables parallel processing of large data across clusters of computers wherein each computer offers local aggregation and storage.56 Hadoop comprises two major components: MapReduce and Hadoop Distributed File System (HDFS). While MapReduce enables aggregation and parallel processing of large data sets, HDFS is a file-based storage system and a type of “Not only SQL (noSQL)” database. Compared to relational databases, NoSQL databases represent a wider variety of databases that can store unstructured data. Data processed and stored on Hadoop systems can be queried through Hadoop application program interfaces (APIs) that offer an easy user interface to query the data stored on HDFS for analytics applications.
Depending on the type of data and processing, different tools could be used. While MapReduce works on parallel processing, Spark, another big-data tool, works on both parallel processing and in-memory processing.57 Considering storage databases, HDFS is a file-based database that stores batch data such as quarterly and yearly company financial data, while Hbase and Cassandra are event-based storage databases that are useful for storing streaming (or real-time) data such as stock-performance data.58 We discussed select big-data tools above; other tools exist with a range of benefits and limitations, and the choice of a tool depends on the application at hand.
At present, the IoT landscape is in a nascent stage, and existing technology standards serve specific solutions and stakeholder requirements. There are many efforts under way to develop standards that can be adopted more widely. Primarily, we find two types of developments: vendors (across the IoT value chain) coming together to an agreement, and standards bodies (for example, IEEE or ETSI) working to develop a standard that vendors follow. Time will tell which one of these two options will prevail. Ultimately, it might be difficult to have one universal standard or “one ring to rule them all” either at the network or communication protocol level or at the data-aggregation level.
In terms of network and communication protocols, a few large players have at hand a meaningful opportunity to drive the standards that IoT players will follow for years to come. As an example, Qualcomm—with other companies such as Sony, Bosch, and Cisco—has developed the AllSeen Alliance that provides the AllJoyn platform, as described earlier.59 On similar lines, through the Open Interconnect Consortium, Intel launched the open-source IoTivity platform that facilitates device-to-device connectivity.60 IoTivity offers its members a free license of the code, while AllSeen does not. However, AllSeen-compliant devices are already available, while devices compliant with IoTivity are expected to be available by the second half of 2015.61 Both platforms are comparable but not interoperable, just as iOS and Android are.62
Concurrently, various standards bodies are also working to develop standards (for network and communication protocols) that apply to their geographical boundaries and could extend well beyond to facilitate worldwide IoT communications. As an example, the ETSI, which primarily has a focus on Europe, is working to develop an end-to-end architecture called the oneM2M platform that could be used worldwide.63 IEEE, another standards body, is making progress with the IEEE P2413 working group and is coordinating with standards bodies such as ETSI and ISO to develop a global standard by 2016.64
In terms of data aggregation, relational databases and SQL are considered to be the standards for storing and querying structured data. However, we do not yet have a widely used standard for handling unstructured data, even though various big-data tools are available. We discuss this challenge below.
For effective aggregation and use of the data for analysis, there is a need for technical standards to handle unstructured data and legal and regulatory standards to maintain data integrity. There are gaps in people skills to leverage the newer big-data tools, while security remains a major concern, given the fact that all the data are aggregated and processed at this stage of the Information Value Loop.
Standard for handling unstructured data : Structured data are stored in relational databases and queried through SQL. Unstructured data are stored in different types of noSQL databases without a standard querying approach. Hence, new databases created from unstructured data cannot be handled and used by legacy database-management systems that companies typically use, thus restricting their adoption. 65
: Structured data are stored in relational databases and queried through SQL. Unstructured data are stored in different types of noSQL databases without a standard querying approach. Hence, new databases created from unstructured data cannot be handled and used by legacy database-management systems that companies typically use, thus restricting their adoption. Security and privacy issues : There is a need for clear guidelines on the retention, use, and security of the data as well as metadata , the data that describe other data. As discussed earlier, there is a trade-off between the level of security and the memory and bandwidth requirements.
: There is a need for clear guidelines on the retention, use, and security of the data as well as , the data that describe other data. As discussed earlier, there is a trade-off between the level of security and the memory and bandwidth requirements. Regulatory standards for data markets : Data brokers are companies that sell data collected from various sources. Even though data appear to be the currency of the IoT, there is lack of transparency about who gets access to data and how those data are used to develop products or services and sold to advertisers and third parties. A very small fraction of the data collected online is sold online, while a larger share is sold through offline transactions between providers and users. 66 As highlighted by the Federal Trade Commission, there is an increased need for regulation of data brokers. 67
: Data brokers are companies that sell data collected from various sources. Even though data appear to be the currency of the IoT, there is lack of transparency about who gets access to data and how those data are used to develop products or services and sold to advertisers and third parties. A very small fraction of the data collected online is sold online, while a larger share is sold through offline transactions between providers and users. As highlighted by the Federal Trade Commission, there is an increased need for regulation of data brokers. Technical skills to leverage newer aggregation tools: Companies that are keen on leveraging big-data tools often face a shortage of talent to plan, execute, and maintain systems.68 There is an uptrend in the number of engineers being trained to use newer tools such as Spark and MapReduce, but this is far fewer than the number of engineers trained in traditional languages such as SQL.69
Extracting insight from data requires analysis, the fourth stage in the Information Value Loop. Analysis is driven by cognitive technologies and the accompanying models that facilitate the use of cognitive technologies.70 We refer to these enablers collectively as “augmented intelligence” to capture the idea that systems can automate intelligence—a concept that for us includes notions of volition and purpose—in a way that excludes human agency but nevertheless can be supplemented and enhanced.
In the context of the value loop, analysis is useful only to the extent that it informs action. “Analytics typically involves sifting through mountains of what are often confusing and conflicting data—in search of nuggets of insight that may inform better decisions.”71 As figure 12 illustrates, there are three different ways in which analytics can inform action.72
At the lowest level, descriptive analytics tools augment our intelligence by allowing us to work effectively with much larger or more complex data sets than we could otherwise easily handle. Various data visualization tools such as Tableau and SAS Visual Analytics make large data sets more amenable to human comprehension and enable users to identify insights that would otherwise be lost in the huge heap of data.
Predictive analytics is the beginning of keener insight into what might be happening or could happen, given historical trends. Predictive analytics exploits the large quantity and increasing variety of data to build useful models that can correlate seemingly unrelated variables.73 Predictive models are expected to produce more accurate results through machine learning, a process that refers to computer systems’ ability to improve their performance by exposure to data without the need to follow explicitly programmed instructions. For instance, when presented with an information database about credit-card transactions, a machine-learning system discerns patterns that are predictive of fraud. The more transaction data that the system processes, the better its predictions should become.74 Unfortunately, in many practical applications, even seemingly strong correlations are unreliable guides to effective action. Consequently, predictive analytics in itself still relies on human beings to determine what sorts of interventions are likeliest to work.75
Finally, prescriptive analytics takes on the challenge of creating more nearly causal models.76 Prescriptive analytics includes optimization techniques that are based on large data sets, business rules (information on constraints), and mathematical models. Prescriptive algorithms can continuously include new data and improve prescriptive accuracy in decision optimizations. Since prescriptive models provide recommendations on the best course of action, the element of human participation becomes more important; the focus shifts from a purely analytics exercise to behavior change management. We discuss this more in the “Augmented behavior” section.
With advances in cognitive technologies’ ability to process varied forms of information, vision and voice have also become usable. Below, we discuss select cognitive technologies that are experiencing increasing adoption and can be deployed for predictive and prescriptive analytics.78
Computer vision refers to computers’ ability to identify objects, scenes, and activities in images. Computer vision technology uses sequences of imaging-processing operations and other techniques to decompose the task of analyzing images into manageable pieces. Certain techniques, for example, allow for detecting the edges and textures of objects in an image. Classification models may be used to determine whether the features identified in an image are likely to represent a kind of object already known to the system. 79 Computer vision applications are often used in medical imaging to improve diagnosis, prediction, and treatment of diseases. 80
refers to computers’ ability to identify objects, scenes, and activities in images. Computer vision technology uses sequences of imaging-processing operations and other techniques to decompose the task of analyzing images into manageable pieces. Certain techniques, for example, allow for detecting the edges and textures of objects in an image. Classification models may be used to determine whether the features identified in an image are likely to represent a kind of object already known to the system. Computer vision applications are often used in medical imaging to improve diagnosis, prediction, and treatment of diseases. Natural-language processing refers to computers’ ability to work with text the way humans do, extracting meaning from text or even generating text that is readable. Natural-language processing, like computer vision, comprises multiple techniques that may be used together to achieve its goals. Language models, a natural-language processing technique, are used to predict the probability distribution of language expressions—the likelihood that a given string of characters or words is a valid part of a language, for instance. Feature selection may be used to identify the elements of a piece of text that may distinguish one kind of text from another—for example, a spam email versus a legitimate one. 81
refers to computers’ ability to work with text the way humans do, extracting meaning from text or even generating text that is readable. Natural-language processing, like computer vision, comprises multiple techniques that may be used together to achieve its goals. Language models, a natural-language processing technique, are used to predict the probability distribution of language expressions—the likelihood that a given string of characters or words is a valid part of a language, for instance. Feature selection may be used to identify the elements of a piece of text that may distinguish one kind of text from another—for example, a spam email versus a legitimate one. Speech recognition focuses on accurately transcribing human speech. The technology must handle various inherent challenges such as diverse accents, background noise, homophones (for example, “principle” versus “principal”), and speed of speaking. Speech-recognition systems use some of the same techniques as natural-language processing systems, as well as others such as acoustic models that describe sounds and the probability of their occurring in a given sequence in a given language.82 Applications of speech-recognition technologies include medical dictation, hands-free writing, voice control of computer systems, and telephone customer-service applications. Domino’s Pizza, for instance, recently introduced a mobile app that allows customers to use natural speech to place orders.83
Availability of big data—coupled with growth in advanced analytics tools, proprietary as well as open-source—is driving augmented intelligence. Typical intelligence applications are based on batch processing of data; however, the need for timely insights and prompt action is driving a growing adoption of real-time data analysis tools.
Availability of big data : Artificial intelligence models can be improved with large data sets that are more readily available than ever before, thanks to the lower storage costs. Figures 13 and 14 show the recent decline in storage costs alongside the growth in enterprise data over the last decade.
: models can be improved with large data sets that are more readily available than ever before, thanks to the lower storage costs. Figures 13 and 14 show the recent decline in storage costs alongside the growth in enterprise data over the last decade. Growth in crowdsourcing and open-source analytics software : Cloud -based crowdsourcing services are leading to new algorithms and improvements in existing ones at an unprecedented rate. Data scientists across the globe are working to improve the breadth and depth of analytics tools. As an example, the number of R packages (a package includes R functions, data sets, and underlying code in a usable format) has increased 40-fold since 2001 (see figure 15). 84
: -based crowdsourcing services are leading to new algorithms and improvements in existing ones at an unprecedented rate. Data scientists across the globe are working to improve the breadth and depth of analytics tools. As an example, the number of R packages (a package includes R functions, data sets, and underlying code in a usable format) has increased 40-fold since 2001 (see figure 15). Real-time data processing and analysis: Analytics tools such as complex event processing (CEP) enable processing and analysis of data on a real-time or a near-real-time basis, driving timely decision making and action.87 An event is any activity—such as stock trades, sales orders, social media posts, and website clicks—that leads to the creation and potential use of data. CEP tools monitor, process, and analyze streams of data coming from multiple sources to identify movements in data that help identify abnormal events or patterns so that any required action can be taken as quickly as possible. CEP tools can be proprietary or open-source; Apache Spark, discussed earlier, is an example of a big-data tool that offers CEP functionality.CEP is relevant for the IoT in its ability to recognize patterns in massive data sets at low latency rates. A CEP tool identifies patterns by using a variety of techniques such as filtering, aggregation, and correlation to trigger automated action or flag the need for human intervention.86 CEP tools exhibit low latency rates—sometimes less than a second—by using techniques such as continuous querying, in-memory processing, and parallel processing.87 Continuous querying works on the principle of incremental processing. For example, once the system has calculated the average of a million observations, the moment the next data point comes in, the system simply updates the value and doesn’t scan the entire data set to calculate the average; this saves computational time and resources. In-memory processing—the process of storing data in random access memory (RAM) in lieu of hard disks—enables faster data processing. Lastly, parallel processing, the processing of data across clusters of computers, is achieved by partitioning data either by source or type.In the banking industry, CEP plays a key role in cross-selling services. A CEP tool can continuously monitor and analyze a customer’s transactions with the bank through various channels. The tool can be used to monitor any large withdrawals through the ATM or check payments. Further, the tool could correlate the transactions with any accompanying bank-branch transactions such as an address change—potentially indicating a house purchase—and present a cross-selling opportunity, say home insurance, before a competitor draws the customer away.88 Such cross-selling recommendations can then be automatically pushed onto web-based banking systems and concurrently used by bankers, tellers, and call-center representatives.
Limitations of augmented intelligence result from the quality of data, human inability to develop a foolproof model, and legacy systems’ limited ability to handle unstructured and real-time data. Even if both the data and model are shipshape, there could be challenges in human implementation of the recommended action; in the next section, on augmented behavior, we discuss the challenges related to human behavior.
Inaccurate analysis due to flaws in the data and/or model : A lack of data or presence of outliers may lead to false positives or false negatives, thus exposing various algorithmic limitations. Also, if all the decision rules are not correctly laid out, the algorithm could throw incorrect conclusions. For example, a social networking site recently featured the demise of a subscriber’s daughter on an automatically generated dashboard. The model was not programmed to recognize and exclude negative events, thus the faux pas. 89
: A lack of data or presence of outliers may lead to false positives or false negatives, thus exposing various algorithmic limitations. Also, if all the decision rules are not correctly laid out, the algorithm could throw incorrect conclusions. For example, a social networking site recently featured the demise of a subscriber’s daughter on an automatically generated dashboard. The model was not programmed to recognize and exclude negative events, thus the faux pas. Legacy systems’ ability to analyze unstructured data : Legacy systems are well suited to handle structured data ; unfortunately, most IoT/business interactions generate unstructured data. 90 Unstructured data are growing at twice the rate of structured data and already account for 90 percent of all enterprise data. 91 While traditional relational-database systems will continue to be relevant for structured-data management and analysis, a steady influx of IoT-driven applications will require analytics systems that can handle unstructured data without compromising the scope of data.
: Legacy systems are well suited to handle ; unfortunately, most IoT/business interactions generate unstructured data. Unstructured data are growing at twice the rate of structured data and already account for 90 percent of all enterprise data. While traditional relational-database systems will continue to be relevant for structured-data management and analysis, a steady influx of IoT-driven applications will require analytics systems that can handle unstructured data without compromising the scope of data. Legacy systems’ ability to manage real-time data: Traditional analytics software generally works on batch-oriented processing, wherein all the data are loaded in a batch and then analyzed.92 This approach does not deliver the low latency required for near-real-time analysis applications. Predictive applications could be designed to use a combination of batch processing and real-time processing to draw meaningful conclusions.93 Timeliness is a challenge in real-time analytics—that is, what data can be considered truly real?94 Ideally, data are valid the second they are generated; however, because of practical issues related to latency, the meaning of “real time” varies from application to application.
In its simplest sense, the concept of “augmented behavior” is the “doing” of some action that is the result of all the preceding stages of the value loop—from sensing to analysis of data. Augmented behavior, the last phase in the loop, restarts the loop because action leads to creation of data, when configured to do so.
There is a thin line between augmented intelligence and augmented behavior. For our purpose, augmented intelligence drives informed action, while augmented behavior is an observable action in the real world.
Machine-to-machine (M2M) interfaces : M2M interfaces refer to the set of technologies that enable machines to communicate with each other and drive action. In common vernacular, M2M is often used interchangeably with the IoT. 95 For our purposes, though, the IoT is a broader concept that includes machine-to-machine and machine-to-human (M2H) interfaces, as well as support systems that facilitate the management of information in a way that creates value. 96
: M2M interfaces refer to the set of technologies that enable machines to communicate with each other and drive action. In common vernacular, M2M is often used interchangeably with the IoT. For our purposes, though, the IoT is a broader concept that includes machine-to-machine and interfaces, as well as support systems that facilitate the management of information in a way that creates value. Machine-to-human interfaces: We discuss M2H interfaces in the context of individual users; business users of M2H interfaces are discussed in the next element, organizational entities. Based on the data collected and algorithmic calculations, machines have the potential to convey suggestive actions to individuals who then exercise their discretion to take or not to take the recommended action. With human interaction, the IoT discussion shifts into a slightly different direction, toward behavioral sciences, which is distinct from the data science that encapsulates the preceding four stages focused on creating, communicating, aggregating, and analyzing the data to derive meaningful insights. 97
We discuss M2H interfaces in the context of individual users; business users of M2H interfaces are discussed in the next element, organizational entities. Based on the data collected and algorithmic calculations, machines have the potential to convey suggestive actions to individuals who then exercise their discretion to take or not to take the recommended action. With human interaction, the IoT discussion shifts into a slightly different direction, toward behavioral sciences, which is distinct from the data science that encapsulates the preceding four stages focused on creating, communicating, aggregating, and analyzing the data to derive meaningful insights. Organizational entities: Organizations include individuals and machines and thus involve the benefits as well as the challenges of both M2M and M2H interfaces. Managing augmented behavior in organizational entities requires changes in people’s behaviors and organizational processes. Business managers could focus on process redesign based on how information creates value in different ways.98
The enabling technologies for both M2M and M2H interfaces prompt a consideration of the evolution in the role of machines—from simple automation that involves repetitive tasks requiring strength and speed in structured environments to sophisticated applications that require situational awareness and complex decision making in unstructured environments. The shift toward sophisticated automation requires machines to evolve in two ways: improvements in the machine’s cognitive abilities (for example, decision making and judgment) discussed in the previous section and the machine’s execution or actuation abilities (for example, higher precision along with strength and speed). With respect to robots specifically, we present below an overview of how machines have ascended this evolutionary path:
In the late 1940s, a few non-programmable robots were developed; these robots could not be reprogrammed to adjust to changing situations and, as such, merely served as mechanical arms for heavy, repetitive tasks in manufacturing industries.99 In 1954, George Devol developed one of the first programmable robots,100 and in the early 1960s, an increasing number of companies started using programmable robots for industrial automation applications such as warehouse management and machining.101
This period witnessed key developments related to the evolution of adaptive robots.102 As the name suggests, adaptive robots embedded with sensors and sophisticated actuation systems can adapt to a changing environment and can perform tasks with higher precision and complexity compared to earlier robots.103 During this period, robotic machines that could adapt to varying situations were used to identify objects and autonomously take action in applications such as space vehicles, unmanned aerial vehicles, and submarines.104
The development of an open-source robot operating system (developed by the Open Source Robotics Foundation) in 2006 was an important driver enabling the development and testing of various robotic technologies.105 As robots’ intelligence and precision of execution improved, they increasingly started working with human beings on critical tasks such as medical surgeries. Following the US Defense Advanced Research Project Agency’s competition for developing autonomous military vehicles in 2004, many automakers made a headway into military and civilian autonomous vehicles.106 Even though the underlying technology is available, legal and social challenges related to the use of autonomous vehicles are yet to be resolved.
With the availability of big data, cloud-based memory and computing, new cognitive technologies, and machine learning, robots in general seem to be getting better at decision making and are gradually approaching autonomy in many actions. We are witnessing the development of machines that have anthropomorphic features and possess human-like skills such as visual perception and speech recognition.107 Machines are automating intelligence work such as writing news articles and doing legal research—tasks that could be done only by humans earlier.108
Improved functionality at lower prices is driving higher penetration of industrial robots and increasing the adoption of surgical robots, personal-service robots, and so on. For situations where a user needs to take the action, machines are increasingly being developed with basic behavioral-science principles in mind. This allows machines to influence human behaviors in effective ways.
Lower machine prices : The decreasing prices of underlying technologies—such as sensors, network connections, data processing and computing tools, and cloud-based storage—are leading to lower prices of robots. Figures 17 and 18 show a decline in the average selling price of industrial robots alongside increasing unit sales.
: The decreasing prices of underlying technologies—such as sensors, network connections, data processing and computing tools, and cloud-based storage—are leading to lower prices of robots. Figures 17 and 18 show a decline in the average selling price of industrial robots alongside increasing unit sales. Improved machine functionality: As discussed earlier, there is a thin line between augmented intelligence and augmented behavior. An underlying driver for the shift in the use of robots from mundane to sophisticated tasks is the development of elaborate algorithms that focus on the quality of fine decision making in live environments, and not simply a binary “yes/no” decision.Typically, robots made force-fitted decisions based on programmed algorithms, irrespective of the situation and information availability. 109 However, recent advances in robotic control architecture prompt the machine to ask for more information if there is an information insufficiency before taking a decision. 110 For example, a robot offers a pill to the patient and the patient refuses; instead of repeating the same instruction, the robot could analyze the patient’s behavior patterns based on his personal data stored on the cloud and try to deduce the reason for refusal. The robot may also deduce from the environment that the patient has a fever and inform the doctor. One of the many techniques under development enables users to train robots by “rewarding” them in cases where they have made the right decision by telling them so and asking them to continue to do the same—a kind of positive reinforcement. 111
As discussed earlier, there is a thin line between augmented intelligence and augmented behavior. An underlying driver for the shift in the use of robots from mundane to sophisticated tasks is the development of elaborate algorithms that focus on the quality of fine decision making in live environments, and not simply a binary “yes/no” decision.Typically, robots made force-fitted decisions based on programmed algorithms, irrespective of the situation and information availability. However, recent advances in robotic control architecture prompt the machine to ask for more information if there is an information insufficiency before taking a decision. For example, a robot offers a pill to the patient and the patient refuses; instead of repeating the same instruction, the robot could analyze the patient’s behavior patterns based on his personal data stored on the cloud and try to deduce the reason for refusal. The robot may also deduce from the environment that the patient has a fever and inform the doctor. One of the many techniques under development enables users to train robots by “rewarding” them in cases where they have made the right decision by telling them so and asking them to continue to do the same—a kind of positive reinforcement. Machines “influencing” human actions through behavioral-science rationale: Literature suggests that creating a new human behavior is challenging. Creating a new human behavior that endures is even more challenging. Nudge techniques—attempts to influence people’s behaviors—involve the design of choices that prompt them to move from “intention” to “action.”112 For example, placing a fruit at eye level is a nudge technique, while banning junk food is not, according to Richard Thaler and Cass Sunstein.113 Choice designs could be built by consciously choosing the options that should be presented to an individual and the manner in which the options are presented. For example, menus sometimes start with expensive items followed by relatively less expensive ones. This makes the customer feel that she is making a judicious choice by ordering any of the latter items, since her reference price is much higher. Furthermore, a health-conscious restaurateur could place the relatively healthful food items at relatively lower prices and, in so doing, “nudge” the customer to order them.In an analogous fashion, IoT devices can “nudge” human behaviors by establishing a feedback loop. A school in California was trying to find a solution to speeding drivers who were undeterred even by police ticketing. The school authorities experimented with a creative signboard that compared two data points: “your speed” (speed of a passing car measured by a radar sensor) against the “speed limit” of 25 miles/hour. Even though the radar signboard offered drivers no new information—as the dashboard display readily provides driver speed—the signboards “nudged” them into reducing their speed by an average of 10 percent, bringing their speed within the permissible limit or sometimes even lower.115 In a similar way, David Rose helped develop an IoT-connected pill bottle equipped with “GlowCaps” that “nudge” the patient with a flash of light at the predetermined time to take a pill.116In addition to influencing the choices of individuals on a stand-alone basis, IoT devices can also drive adoption by “using” social or peer pressure to achieve a desired result. For example, when a fitness device suggests to an individual that it’s time for a workout, the recommendation may go unheard. However, if the device shows how the user is doing vis-à-vis his peers (lagging or outperforming), the user is potentially more likely to act.117 The manufacturer of an electronic soap dispenser fitted its product with a computer chip that records the frequency with which health care professionals in different hospital wards wash their hands; it then compares these results with World Health Organization standards and conveys the comparisons back to the wards at a group level. Such a process of aggregation and comparison effectively makes personal hygiene a team sport: Each worker, in turn, is effectively “nudged” into a greater awareness of his hygienic habits, as he knows that he is a part of a team effort.118
Other examples abound showing how the IoT can influence human behavior to achieve normative outcomes. The larger point, though, is that the IoT may augment human behavior as much as it augments mechanical behavior. And the interplay between the IoT and human choice will likely only evolve and become more prominent in the years ahead.
There are challenges related to machines’ judgment in unstructured situations and the security of the information informing such judgments. Interoperability is an additional issue when heterogeneous machines must work in tandem in an M2M setup. Beyond the issues related to machine behavior, managing human behaviors in the cases of M2H interfaces and organizational entities present their own challenges.
Machines’ actions in unpredictable situations : Machines are typically considered to be more reliable than human beings in structured environments that can be simulated in programming models; however, in the real world, most situations we encounter are unstructured. 119 In such cases, machines cannot possibly be relied upon completely; as such, the control should fall back to human beings.
: Machines are typically considered to be more reliable than human beings in structured environments that can be simulated in programming models; however, in the real world, most situations we encounter are unstructured. In such cases, machines cannot possibly be relied upon completely; as such, the control should fall back to human beings. Information security and privacy : There is a looming risk of compromise to the machine’s security. An example of a privacy concern relates to an appliance manufacturer that offers televisions with voice-recognition systems. The voice-recognition feature collects information related to not only voice commands but also any other audio information it can sense. 120 This raises concerns about the manner in which the audio information collected by the software will be used—both in benign and personally invasive ways. A benign use could include, for example, the personalization of television advertising. A personally invasive use might be the unauthorized sale of such information.
: There is a looming risk of compromise to the machine’s security. An example of a privacy concern relates to an appliance manufacturer that offers televisions with voice-recognition systems. The voice-recognition feature collects information related to not only voice commands but also any other audio information it can sense. This raises concerns about the manner in which the audio information collected by the software will be used—both in benign and personally invasive ways. A benign use could include, for example, the personalization of television advertising. A personally invasive use might be the unauthorized sale of such information. Machine interoperability : Performance of M2M interfaces is impacted by interoperability challenges resulting from heterogeneous brands, hardware, software, and network connections. There is a need for a convergence of standards, as discussed earlier.That machines perform as desired in a particular context is a matter of getting the technology right, which is currently in an evolving stage. Perfecting human behavior is another matter entirely.
: Performance of M2M interfaces is impacted by interoperability challenges resulting from heterogeneous brands, hardware, software, and network connections. There is a need for a convergence of standards, as discussed earlier.That machines perform as desired in a particular context is a matter of getting the technology right, which is currently in an evolving stage. Perfecting human behavior is another matter entirely. Mean-reverting human behaviors : One of the main challenges in M2H interfaces is that, although users have the smart devices, they minimally “follow” the suggested course of action and, eventually, the devices end up serving as “shelfware.” 122 David Rose states that machines cater to human drives; he cites six such drives: omniscience (the need to know all), telepathy (human-to-human connections), safekeeping (protection from harm), immortality (longer life), teleportation (hassle-free travel), and expression (the desire to create and express). Machines serve human drives through one or more of their features (see figure 19). These features also determine the machine’s position in the enchantment hierarchy (see figure 20). The enduring association between the machine and its user is a function of the machine’s position in the enchantment hierarchy, starting from the most basic level of “connection” and going all the way up to “storyification.” 123
: One of the main challenges in M2H interfaces is that, although users have the smart devices, they minimally “follow” the suggested course of action and, eventually, the devices end up serving as “shelfware.” David Rose states that machines cater to human drives; he cites six such drives: omniscience (the need to know all), telepathy (human-to-human connections), safekeeping (protection from harm), immortality (longer life), teleportation (hassle-free travel), and expression (the desire to create and express). Machines serve human drives through one or more of their features (see figure 19). These features also determine the machine’s position in the enchantment hierarchy (see figure 20). The enduring association between the machine and its user is a function of the machine’s position in the enchantment hierarchy, starting from the most basic level of “connection” and going all the way up to “storyification.” Inertia to technology-driven decision making in organizational entities: Decision makers have decades of experience running successful businesses wherein they have primarily relied on professional judgment. They typically encounter resistance to newer developments such as predictive and prescriptive analytics.124 Executives are skeptical of the accuracy and efficacy of conclusions drawn out of statistical analyses, since they view augmented intelligence tools as “black boxes” in which they do not understand how the outcome has been churned.125
To manage these augmented behavior changes in organizations, decision makers could give the new technologies a fair chance to contribute in their decision-making process by setting aside their biases. At the same time, data scientists and developers could focus on two objectives: continuously improving the statistical tools and the algorithms to bring the machine’s decision-making ability closer to reality, and making it easier for business users to comprehend the results through means such as easy-to-use visualization tools. In the current state of affairs, augmented behavior has the potential to grow, with an increasing number of successful use cases over time.
The Information Value Loop can serve as the cornerstone of an organization’s approach to IoT solution development for potential use cases. To transform ideas and concepts discussed earlier in the report into the concrete building blocks of a solution, we posit an end-to-end IoT technology architecture to guide IoT solution development. This architecture links strategy decisions to implementation activities. It can serve as a playbook for establishing the vision for an IoT solution and for converting that vision into tangible reality. The Information Value Loop informs and is present in each phase of this development, whereby ideas are made progressively more specific, and tactical decisions remain consistent with the overall strategic goals. The process of turning ideas into IoT solutions is shown in figure 22.
Our architecture for guiding the development and deployment of IoT systems consists of the following views:
Business. This view defines the vision for an IoT system and covers aspects such as return on investment, value proposition, customer satisfaction, and maintenance costs. Functional. The linchpin of the reference architecture, this view spans modules that cater to high-level information flow through the system. It contains the functional layers for data creation, processing, and presentation. Usage. This view shows how the reference model realizes key capabilities desired in a usage scenario. It may include the detailed use case description, user journey, and requirements. Implementation. A technical representation of usage scenario deployment, this view incorporates the technologies and system components required to implement the functions prescribed by the usage and functional viewpoints. Specifications. Finally, this view captures the complete IoT stack to be deployed. It includes detailed technical specifications for the build-out of the solution, and translates these blueprints into the individual components needed to design, build, and implement the components and interconnections shown in the functional and implementation views.
In the business view, the Information Value Loop stages are utilized to examine the flow of information which guides strategic decisions for the use case at hand. These decisions further help define the overall IoT strategy. An example of how value can be realized using IoT in health monitoring is shown in figure 23.
Prior to the IoT, the patient could wear a heart monitor, but the monitor’s data would usually be communicated to the external world using written records that had to be carried each time. This represented a blockage at the "communicate" step (see arrow "A").
With the introduction of the IoT, data can now be communicated between a patient and the physician using network connections. However, there is still a bottleneck associated with the ability of the smart systems to interface with existing electronic health record (EHR) systems in order to aggregate data. Alleviating this bottleneck is key to IoT applications in the health care industry.
In the “Meet Isabel’ scenario of figure 23, the bottleneck associated with data aggregation and use can be addressed by the “integration” layer wherein standards for sensor management, data transfer, storage, and aggregation come together in an integral fashion. In the earlier part of this report, we discuss “standards” as they relate to specific technologies that fall under the integration layer described further in the functional view.
The functional view categorizes the components of an IoT system across the five value loop stages and five functional layers—sensors, network, integration, augmented intelligence, and augmented behavior. It serves as a guide to the functional considerations and technology choices of an IoT solution (see figure 24).
As discussed earlier in the report, sensors create the data that are sent downstream to subsequent layers of the architecture. Network is the connectivity layer that communicates data from the sensors and connects them to the Internet. The integration layer manages the sensor and network elements, and aggregates data from various sources for analysis. The augmented intelligence layer processes data into actionable insights. Finally, augmented behavior encapsulates the actions or changes in human or machine behavior resulting from these insights. The augmented behavior layer includes an edge computing sub-layer defined by local analysis (near the source of data) and action without the need for human intervention. Aligned with these layers and the value loop stages are standards for sensor management and data management and use, as well as security considerations including end-point protection, network security, intrusion prevention, and privacy and data protection.
The usage view sets up the technical solution by describing the user’s journey through all the steps of the use case being implemented. This view would include the key actors, that may be users and/or machines, and the activities involved. The usage view also describes the use case from the point of view of user needs and system capabilities. Figure 25 illustrates a typical IoT use in a brick-and-mortar store.
The implementation view delves deeper into specific technology choices and the vendor solutions that are used to deploy those choices. It leverages the high-level component view from the functional architecture to frame the specific system implementation.
Our IoT reference architecture describes parameters and benchmark criteria that can be used to identify the best mix of product solutions for an IoT implementation across different layers. Figure 26 shows a representative implementation view for the retail use case example described earlier.
The specifications view captures the final translation of the various viewpoints described above as part of the IoT Reference Architecture into ground-level deployment. It crystalizes the functional requirements and specific technology choices identified earlier into detailed specification definitions that describe how all the selected components must be linked to work together. A sample specifications view is shown in figure 27.
Together, all the myriad viewpoints that comprise the Deloitte IoT Reference Architecture form an end-to-end blueprint for realizing an IoT system from strategy through implementation.
The Internet of Things is an ecosystem of ever-increasing complexity, and the vocabulary of its language is dynamic. As we stated at the outset, our intent in presenting this primer is not to answer every question that a reader may have about the IoT. No single resource could ever hope to achieve that end about anything as elaborate as the IoT. Rather, in developing this report, our objective was to provide a useful top-down reference to assist readers as they explore IoT-driven solutions. In using this primer, the reader should come away with a better understanding of what the IoT is as well as the elements that comprise its constituent parts within a strategic framework.
At this relatively nascent stage, the IoT ecosystem is fragmented and disorganized. Over time, the IoT ecosystem should undergo a streamlining and organizing process and a “knitting together” of its individual pieces. Because the IoT will play an increasingly important role in how we live and run our businesses, Deloitte is undertaking an IoT-focused eminence campaign. This primer will serve as a foundational resource for the campaign that will include thoughtware examining the IoT both from industry- and issue-specific perspectives.
Deloitte’s Internet of Things practice enables organizations to identify where the IoT can potentially create value in their industry and develop strategies to capture that value, utilizing IoT for operational benefit.​
To learn more about Deloitte’s IoT practice, visit http://www2.deloitte.com/us/en/pages/technology-media-and-telecommunications/topics/the-internet-of-things.html.
Read more of our research and thought leadership on the IoT at http://dupress.com/collection/internet-of-things/.
Actuator: a device that complements a sensor in a sensing system. An actuator converts an electrical signal into action, often by converting the signal to non-electrical energy, such as motion. A simple example of an actuator is an electric motor that converts electric energy into mechanical energy.
Analytics: the systematic analysis of often-confusing and conflicting data in search of insight that may inform better decisions.
Application program interfaces (API): a set of software commands, functions, and protocols that programmers can use to develop software that can run on a certain operating system or website. On the one hand, APIs make it easier for programmers to develop software; on the other, they ensure that users experience the same user interface when using software built on the same API.
Artificial intelligence: the theory and development of computer systems able to perform tasks that normally require human intelligence. The field of artificial intelligence has produced a number of cognitive technologies such as computer vision, natural-language processing, speech recognition, etc.
Batch processing: the execution of a series of computer programs without the need for human intervention. Traditional analytics software generally works on batch-oriented processing wherein data are aggregated in batches and then processed. This approach, however, does not deliver the low latency required for near-real-time analysis applications.
Big data: a term popularly used to describe large data sets that cannot be handled efficiently by traditional data management systems. In addition to the large volume, the concept of big data also refers to the variety of data sets—i.e., structured and unstructured as well as the velocity or the rate at which the data are incoming.
Cloud computing: an infrastructure of shared resources (such as servers, networks, and software applications and services) that allow users to scale up their data management and processing abilities while keeping the costs low. A cloud vendor invests in and maintains the cloud infrastructure; a user pays for only the resources and applications he wishes to use.
Cognitive technologies: a set of technologies able to perform tasks that only humans used to be able to do. Examples of cognitive technologies include computer vision, natural-language processing, and speech recognition.
Communication protocol: a set of rules that provide a common language for devices to communicate. Different communication protocols are used for device-to-device communication; broadly, they vary in the format in which data packets are transferred. One example is the familiar Hypertext Transfer Protocol (HTTP).
Complex event processing (CEP): an analytics tool that enables processing and analysis of data on a real-time or a near-real-time basis, driving timely decision making and action.
CEP is relevant for the IoT in its ability to recognize patterns in massive data sets at low latency rates. A CEP tool identifies patterns by using a variety of techniques such as filtering, aggregation, and correlation to trigger automated action or flag the need for human intervention.
Computer vision: a type of cognitive technology that refers to the ability of computers to identify objects, scenes, and activities in images. Computer-vision technology uses sequences of imaging-processing operations and other techniques to decompose the task of analyzing images into manageable pieces. Certain techniques, for example, allow for detecting the edges and textures of objects in an image. Classification models may be used to determine if the features identified in an image are likely to represent a kind of object already known to the system.
Data rates: the speed at which data are transferred by a network. Sometimes termed “bandwidth,” data rates are typically measured in bits transferred per second. Network technologies that are currently available can deliver data rates of up to 1 gigabit per second.
Descriptive analytics: a type of analytics that provides insights into past business events and performance. In a fundamental sense, descriptive analytics helps answer the question “What has happened?” Descriptive analytics tools augment human intelligence by allowing us to work effectively with much larger or more complex data sets than we would ordinarily be able to without such tools.
Extraction, Transformation, Loading (ETL) tools: a set of data aggregation tools that aggregate, process, and store data in a format that can be used for analytics applications. Extraction refers to acquiring data from multiple sources and formats and then validating to ensure that only data that meet a specific criterion are included. Transformation includes activities such as splitting, merging, sorting, and transforming the data into a desired format; for example, names can be split into first and last names, addresses can be merged into city and state format, etc. Loading refers to the process of loading the data into a database that can be used for analytics applications.
Hadoop: an open-source tool that is useful for processing large data sets. Hadoop is a part of the Apache Software Foundation and is based on the Java programming language. Hadoop enables parallel processing of large data across clusters of computers in which each computer offers local aggregation and storage.
In-memory processing: the process of storing data in random access memory instead of hard disks; this enables quicker data querying, retrieval, and visualizations.
Internet Protocol (IP): an open network protocol that provides unique addresses to various devices connected to the Internet. There are two versions of IP: IP version 4 (IPv4) and IPv6.
Internet transit prices: the price charged by an Internet service provider (ISP) to transfer data on a network. Since no single ISP can cover the worldwide network, the ISPs rely on each other to transfer data using network interconnections through gateways.
IP version 4 (IPv4): an older version of the Internet Protocol (IP); IPv6 is a most recent version. IPv4 offers an addressing space of about 6 billion addresses, out of which 4 billion addresses have been used already. IPv4 allows a group of co-located sensors to be identified geographically but not individually, thus restricting the value that can be generated through the scope of data collected from individual devices that are co-located.
IP version 6 (IPv6): a recent version of the Internet Protocol (IP) that succeeds IPv4. IPv6 has superior scalability and identifiability features compared to IPv4: the IPv6 address space supports approximately 3.4x1038 unique addresses compared to 6 billion addresses under IPv4.
Latency: the time delay in transfer of data from one point in a network to another. Low-latency networks allow for near-real-time data communications.
Local area network (LAN): a network that extends to a geographic range of at least 100 meters, such as within a house, office, etc. Devices could connect to wired or wireless LAN technologies. Examples of wired LAN technologies include Ethernet, and fiber optics. Wi-Fi is an example of a wireless LAN technology.
Machine learning: the ability of computer systems to improve their performance by exposure to data, without the need to follow explicitly programmed instructions. At its core, machine learning is the process of automatically discovering patterns in data. Once discovered, the pattern can be used to make predictions. For instance, presented with a database of information about credit-card transactions—such as date, time, merchant, merchant location, price, and whether the transaction was legitimate or fraudulent—a machine-learning system recognizes patterns that are predictive of fraud. The more transaction data it processes, the better its predictions are expected to become.
Machine-to-human (M2H) interfaces: a set of technologies that enable machines to interact with human beings. Some common examples of M2H interfaces include wearables, home automation devices, and autonomous vehicles. Based on the data collected and algorithmic calculations, mJust a few years ago, many people expected the internet of things (IoT) network of interconnected machines, sensors, and other devices to send all its data to the cloud for storage and processing. Today, however, edge computing architecture can place processing and storage closer to the physical sources of data generation. A growing number of IoT solutions now benefit from a combination of edge and cloud computing, which can help to alleviate latency, increase scalability, and enhance access to information to enable better, faster decision-making, among other advantages.
As the amount of data generated by sensors grows tremendously, enterprises are increasingly focused on the amount of time it takes data to move from a connected device to the cloud and then back to the device. In a cloud-only IoT architecture, information typically travels hundreds or even thousands of miles, so if quick, data-based decision-making is vital to an IoT solution’s efficacy, that information can lose value in milliseconds. In such cases, edge computing can dramatically decrease latency and improve response time. According to one estimate, as much as 55 percent of IoT data could soon be processed at or near the source.
Reducing latency is just one considerable benefit of adding edge capabilities to IoT architecture. Others can include more effective bandwidth use resulting from localized data processing; improved network connectivity and security; increased autonomous data processing and storage on everything from vehicles to medical devices; and enhanced data privacy, normalization, and filtering capabilities.
This balance between cloud and edge architecture can dramatically improve the aggregation and transmission of data across a wide range of operations relying on IoT solutions.
Smart factories. Many manufacturers have multiple plants in different locations, each typically with unique characteristics and functional requirements. The more spread out an operation, the more difficult it may be to maintain centralized data analysis capabilities in the cloud or at a corporate data center. While the cloud will continue to play an important role in smart manufacturing—monitoring systems and processes across large or even global portfolios, for example—an integrated edge-cloud architecture can provide the kind of speedy and nearly unimpeded connectivity necessary to support smarter operations on the factory floor.
Smart buildings. IoT-connected devices are transforming some offices, retail stores, hospitals, and other buildings into cost-efficient, responsive environments that can deliver better experiences to their occupants, support digital collaboration, and enable owners to conserve space, energy, water, and other resources. For example, edge computing can transmit occupancy data from strategically placed sensors to a cloud-hosted service that performs specialized analytics. The results can be sent back via the gateway or edge server to alter the schedules of a building’s lighting, ventilation systems, and other connected equipment to improve energy efficiency and lower costs.
Despite the many benefits, adding edge computing in a cloud-based IoT environment can also pose operational and systems design complexities. Some widely distributed sensors or gateways may be scattered and difficult to physically reach or both when placed in offices, plants, and campuses; on pipelines; and in remote field sites, among other locales. An organization may have thousands of devices and hundreds of associated gateways and edge nodes with firmware and operating systems requiring backups, software patches, and other updates. Monitoring these disparate devices and addressing potential problems can require an enormous amount of automation and field service.
In addition, while the cloud offers on-demand scalability and can be readily configurable, automated, and resilient, providing these capabilities at the edge may be costly, requiring significant investment in additional hardware and software and much complex work to enable an increased number of devices and edge nodes.
Extending the cloud and the data center to the edge with multiple endpoints can also increase the surface area for cyberattacks. Insecure nodes and devices can be weak links that leave the entire network vulnerable, so maintaining the physical and cybersecurity position of all edge computing assets is critical.
IoT devices and the data they can provide are changing how enterprises interact with the world as well as how they gather and process massive quantities of business-critical information. While no single solution will suit every organization, a balanced approach to cloud and edge computing will likely play an increasingly prominent role in IoT architecture in the years ahead.Many manufacturers face a range of material, resource and quality constraints that impact productivity and revenues on a daily basis. Since many large production floors can span literal miles, one without IoT enabled technology tends to lack complete visibility into each element of the production cycle, making the factory floor ecosystem rife with inefficiencies. Managers often find it difficult to locate parts in real time as they’re distributed throughout the factory floor, employees wait idly while maintenance is performed on a malfunctioning machine, and overall quality potentially suffers as a result.
This was the norm until the manufacturing industry discovered the power of IoT and began its transition to the smart factory. Leveraging smart technology with IoT capabilities, smart factories enable increased visibility, optimized production and improved quality while minimizing unplanned downtime. In fact, a recent study by Deloitte and Manufacturers Alliance for Productivity and Innovation (MAPI), which evaluated the impact of smart factories on key business metrics such as manufacturing productivity, found that smart factory initiatives could be the key to manufacturing competitiveness in the future.
Until recently, IoT collected data wasn’t actionable for many businesses. The volume of data produced by the manufacturing segment is so large that it’s been difficult for any company to keep the number of physical servers necessary to collect and store this data. Additionally, combing through data for actionable business insights is time consuming. If the investment is made to analyze IoT data, by the time a company receives data-driven insights, they’re typically outdated. Cloud has drastically increased the value of IoT, allowing organizations to process more information than before, at a much lower cost. While IoT sensors have collected data for years, businesses can now see the value of what they're collecting.
Recently, we worked with a large aerospace manufacturer with a widespread and complicated operation, making it a challenge to locate various parts on the shop floor in real-time. Previously, the manufacturer used a schedule that was only updated once or twice per day, which would create delays when there were production changes. IoT technology, on the other hand, enables the data analysis for every part and every piece of data at every moment throughout the cycle, allowing for the utmost flexibility and agility in resource management.
Through IoT enabled technologies, we placed antennas strategically within the factory as well as on machines that could read each part. Then we designed a cloud-based dynamic scheduling system that provided much more visibility into where specific parts were located during its journey.
Now, if parts are delayed, the team is notified in real time in order to create a new expedited order or move forward with another project first. IoT also provides predictive maintenance on the factory floor – monitoring the health of machines and proactively scheduling maintenance ahead of any issues, based on historic data.
Combining IoT technology and real-time data with data in the cloud, Deloitte, in working with AWS, enabled dynamic scheduling of the production facility to automate materials movement. The result for the client has been a significant improvement in overall factory performance.
If your organization is looking to implement a smart factory and apply IoT with cloud for greater visibility into operations, dynamic scheduling and predictive analytics, I suggest a three-step approach to adoption:
Think big: When it comes to making IT decisions, lean into technology purchasing choices that can evolve as your business grows. Don’t let the technology capabilities you have today constrain your plans for growth because technology and business models are constantly evolving, and you have more options than ever before. Start small: You don’t have to apply all technology changes to your business operations overnight. Test innovations on small areas of the business first (for instance, extracting data insights via cloud from the existing IoT sensors on your equipment instead of installing new ones) for a proof of value. Scale fast: Once you’ve proven that the technology you’ve tested is improving operations, scale it quickly. If you’re attending AWS re:Invent 2019, you can learn more about our approach and how we’ve helped companies with manufacturing operations find real business efficiencies with IoT and cloud by visiting our session on Monday, December 2nd at 11:30 a.m. PT.Over the last 25 years, four fundamental forces representing computing concepts and movements have gained momentum. Together, they helped integrate hardware, software, and the physical environment in a way that is intuitive and accessible to a do-it-yourself audience. These forces are:
Objective: To design a system that will monitor the temperature of my home environment and trigger a text message to my phone when the temperature crosses a certain threshold.
Raspberry Pi 3: A credit-card sized computer that has an HDMI port to connect to monitor and a USB port to connect to keyboard/mouse
Node-RED: A visual programming tool for wiring hardware devices, APIs, and online services to facilitate the Internet of Things
Sensors attached to a Raspberry PI 3 continuously monitor the temperature in the surrounding environment; when a predetermined threshold is met, an alert is sent through the IoT platform to the user’s smartphone.
The sensor continuously monitors the environment: Install the operating system on the Pi and connect the sensors IoT platform connects devices and your application: Use the IoT Platform to a) register the Pi b) connect to the Node-RED server-side application
Raspberry Pi with sensor attached The sensor sends data to IoT platform: Write the client-side program (using JavaScript in Node-RED) to process the temperature signals and send it to the IoT platform
Sensor in steady state The application connects to other cloud services as needed: Register the smartphone with the cloud-based communication platform and use those credentials in server-side application to enable sending a text The application sends signals to the user: Start receiving temperature signals from the Pi; this triggers the application to send a text message when the threshold is crossed
Open-source software movement: Remember the battle in the late '90s against the open-source software movement when Linux was called the “malignant cancer?” We’ve come a long way since then. In this project, the same Linux is the operating system on the minicomputer. Linux Foundation 1 estimates the total development cost of its collaborative projects alone is $5 billion. There are many such foundations. Node-RED is part of the JS Foundation, which supports open source projects in the JavaScript ecosystem. And JavaScript itself is developed on an open standard.
Remember the battle in the late '90s against the open-source software movement when Linux was called the “malignant cancer?” We’ve come a long way since then. In this project, the same Linux is the operating system on the minicomputer. Linux Foundation estimates the total development cost of its collaborative projects alone is $5 billion. There are many such foundations. Node-RED is part of the JS Foundation, which supports open source projects in the JavaScript ecosystem. And JavaScript itself is developed on an open standard. Cloud computing: In the early 2000s, Salesforce 2 pioneered the concept of enterprise app delivery via the Internet. Remember the “no software” days? Since then, almost anything tech is delivered “as a service.” Thanks to the cloud delivery model, a cloud-based communication platform, and the entire IoT platform are represented in this project. Worldwide public IT cloud service revenue 3 in 2018 is predicted to be $127 billion.
In the early 2000s, Salesforce pioneered the concept of enterprise app delivery via the Internet. Remember the “no software” days? Since then, almost anything tech is delivered “as a service.” Thanks to the cloud delivery model, a cloud-based communication platform, and the entire IoT platform are represented in this project. Worldwide public IT cloud service revenue in 2018 is predicted to be $127 billion. Maker Movement: In 2005, 4 with the launch of MAKE Magazine, the tech-influenced DIY community has come to be identified as the Maker Movement 5 . Recently I attended a Maker Faire, called the “greatest show and tell on earth," 6 and sat on a 3D printed chair! Affordable, intuitive tools and hardware have fueled the rise of the Maker Movement and enabled DIYers like me to tackle our own technology projects. Pi 7 and Arduino 8 are available for under $50 and frequently used in DIY projects. Industry stats on the movement estimate 9 that makers fuel about $29 billion into the economy each year.
In 2005, with the launch of Magazine, the tech-influenced DIY community has come to be identified as the Maker Movement . Recently I attended a Maker Faire, called the “greatest show and tell on earth," and sat on a 3D printed chair! Affordable, intuitive tools and hardware have fueled the rise of the Maker Movement and enabled DIYers like me to tackle our own technology projects. Pi and Arduino are available for under $50 and frequently used in DIY projects. Industry stats on the movement estimate that makers fuel about $29 billion into the economy each year. Low-code development platforms: A name coined in 2014, these platforms10 represent rapid application delivery with minimal coding, setup, and deployment. To create my project app, the amount of code I had to write in JavaScript was minimal, thanks to Node-RED, a primary example of this trend. Forrester11 estimates that the total market for low-code development platforms will grow to $15.5 billion by 2020.
According to Deloitte, the Internet of Things is taking off in both consumer-focused and B2B industries, and our Tech Trends research has identified the move from sensing to doing. There are multiple platforms of choice and robust offerings from several technology leaders and specialized providers. GE predicts12 investment in the Industrial Internet of Things is expected to top $60 trillion during the next 15 years. The possibilities in the universe of connected things are only beginning to be realized; the real potential lies in making data actionable and uncovering valuable insights.
An iota of that investment is more than enough to start your own prototypes. As you start your next IOT project, may the force(s) be with you!Insert Custom CSS fragment. Do not delete! This box/component contains code needed on this page. This message will not be visible when page is activated.The Internet of Things (IoT) has the potential to offer business value that goes beyond operational cost savings. Providers in the IoT ecosystem have a largely unexplored opportunity to develop compelling IoT solutions that explore how the ability to collect and analyze disparate data, in real-time and across time, might transform the business. These developments will play out within and across enterprises, offering opportunities for sustained value creation and even disruption for those who can imagine possibilities beyond the incremental.
Throughout this paper, we offer strategies—to both enterprise adopters and IoT providers—to unlock the business value of connected devices. For providers, we offer six actionable strategies to create solutions that improve enterprise adopters' business performance, not just in the short term but sustained over time. For enterprise executives, we offer a framework to think about where business value resides and where opportunities might exist for IoT solutions. Learn how IoT solutions can improve enterprise adopters' fundamental business values, not just savings and risk management, but revenue growth and innovation.Since then we realized that some CRE companies may not possess the requisite talent required to process this data. Professionals with the skills required to aggregate, analyze, and manage the data are scarce and the data sets are enormous. How then can these companies crunch the data and generate adequate returns on their investment in IoT technology?
AI could be a potential solution. CRE companies can harness the predictive capability of AI technologies such as machine learning to generate insights and power decision-making. Machine-learning technology “can automatically identify patterns and detect anomalies in the data that smart sensors and devices generate—information such as temperature, pressure, humidity, air quality, vibration, and sound.”2 CRE companies can use AI in this way to drive operational efficiency and tenant satisfaction. For instance, Google’s AI-based predictive tool uses sensor information to forecast pressure and temperature at its data centers. The company has been able to optimize power consumption and reduce cooling costs by 40 percent.
A combination of sensor data and machine-learning solutions may also help improve real-time threat detection and response. As an example, the city of Las Vegas is using AI technology to detect and automate responses to cyber threats.3 Other AI technologies such as speech recognition and computer vision can extract insights from sensor data, which typically require human intervention.
Given the benefits of AI-powered IoT systems, many vendors are now evolving building management systems (BMS) to incorporate AI.5 According to the International Data Corp., AI will support “all effective” IoT efforts by 2019.6 It is also believed that IoT data will have “limited value” without the use of AI technology.7
In summary, CRE executives that are implementing IoT technology should consider AI-powered IoT systems. Owners of existing smart buildings should supplement their buildings with AI technology to mine the data.Although many organizations are investing in technology, they need to adapt their way of thinking quickly in order to avoid key challenges and the risk of getting left behind. Older stadiums are starting to show their age and fall behind in terms of infrastructure and technology. As the price of tickets rise and the at-home experience improves, many teams are seeing their game attendance steadily decline. Teams are gathering data on their players and fans from multiple sources, but these data sources are often not being integrated.
Currently, many teams are implementing IoT capabilities into their stadiums and organizations, but the solutions are often independent and don’t work together, preventing organizations from realizing the full potential of IoT. Unused current assets, limited wearable application, siloed fan experiences, and self-contained operational technology (OT) and IT systems contribute to organizations not being able to fully leverage IoT. Teams and organizations need to recognize the prevalence and real power that IoT can have when it’s integrated and considered on a comprehensive, holistic level.Whilst the Internet of Things has helped to revolutionize the way that people interact with technology, and has become an integrated part of our lives, there still exist serious threats that emerge from these technologies. As the IoT revolution is still in full swing, this article looks at the background of these developments and ensures that security by design/default principles is at the forefront of our minds.
Technological change is the only constant within today’s business world. In both the public and private sector, there is huge potential for integrated data collection, analysis and communication software. The Internet of Things (IoT) provides the means to create value through a new information value cycle – enabling business activities through sensor data collection and analysis, deriving insights and thereafter making decisions and taking action – a circular, additive process. However, there are inherent risks associated with the development of pervasive, smart technologies. This article examines what exactly IoT and cybersecurity threats are, and presents several examples of cybersecurity threats, highlighting the vulnerability of today’s IoT ecosystem. IoT extends beyond mere physical hardware; in effect, it is an integrated approach to, and process by which, data is ‘used’. The increased vulnerability to cybersecurity threats may be linked to three IoT features – ‘smart’ devices, increased connectivity, and a lack of security by design/default. As we move into the future and embrace new and innovative IoT capabilities, attention must be paid to the inherent risks of such an action.
IoT, a term first coined by Kevin Ashton in 1999, is not something that can be easily defined. Any definition will be inherently vague, in order to provide inclusiveness, and not limit the scope of IoT. Deloitte provides a definition of IoT in referring to it as “as suite of technologies and applications that equip devices and locations generate all kinds of information – and to connect those devices and locations for instant data analysis and, ideally, “smart” action.” This description suffices for a number of reasons. Firstly, it refers to the coupling of technology and physical devices. This coupling is important as it means that consideration should not just be given to modern IoT devices such as smart phones, but also to devices that have been IoT-enabled. Secondly, it refers to the “smart” characteristic of IoT devices, and their ability to analyze data. Within a single device, there is the potential to both connect with other devices, thus gathering, and to use the hardware and software capabilities of the device to process. It must be noted that processing in this sense does not only constitute the analysis of the collected data, but also the storage, transfer and modification.
The scale of IoT device prevalence must also be considered when evaluating cybersecurity threats. According to industry reports, the number of IoT-connected devices in 2016 was 8 billion. That figure is expected to rise to 31 billion by 2020. A rising number of IoT enabled devices implies that significantly more, valuable data will be collected and generated, and also that the potential cyber-attack surface will be greatly expanded. The very nature of smart and connected IoT devices seems to be inherently opposed to the primary principles of cybersecurity, such as security by design/default, lifecycle support, testing for scale, 1:1 user access and authentication, or systems isolation.
In order to explain how the Internet of Things (IoT) has developed in such a way that we are now vulnerable to cyber threats, one must first understand what a cybersecurity threat is. Tim Stevens defines cybersecurity in terms of both an offensive and defensive purpose. Cybersecurity protects the members and critical infrastructure of a society, and is the means by which a nation can pursue policies to bring to account malicious actors who exist on the global stage. Kevin Quigley et al. refer to cybersecurity threats as “uncertain risks.” The authors further elaborate that these risks result from the lack of scientific or technical bases for decision making, whereby a risk-modelling framework is unable to anticipate or elucidate risk events. The clear takeaway is that the key components of a cybersecurity threat are both the known and unknown elements – malicious actors use known methods to breach networks and compromise data, whilst 0-day exploits and software bugs may create system vulnerabilities unknown to developers. By its very nature, technological change causes uncertainty. Currently, companies do not know the extent of the additional benefits of IoT and associated revenue streams, nor are possible security breaches, technical difficulties or future regulatory challenges fully understood. One of the important things to remember when examining IoT and cybersecurity threats is that the identified risks are not new. However, the connectivity and ‘smart’ characteristics of IoT have allowed the number of malicious attacks or attempts to subvert systems to increase. Due to the speed of IoT development, basic principles of security may be overlooked, or deemed to be not of sufficient criticality to warrant investment and implementation.
The rapid development of IoT capabilities has meant that both governmentally driven regulations and controls, as well as ‘Security by Design/Default’, are lagging behind. Responsibility for such controls lies both in the public, and private sector, as both governments and businesses have a vested interest in leveraging IoT capabilities, but will do so to different ends. There exists the need to balance the focus upon restricting IoT advancement as it pertains to protecting individuals and reducing risk, while allowing growth and free development. A dilemma exists whereby regulators and developers are both uncertain of what the other is doing, as both are working in an uncertain environment; regulators cannot act without understanding the technology, and developers cannot work with uncertain regulations. However, without cooperative action, IoT will continue to develop in a way which increases vulnerability to cyber threats. The following paragraphs detail three cyber threats which are directly influenced by the development of IoT devices/principles.But it was not all unicorns and rainbows at RIMS. The glaring potential downside risks of IoT were just as present at the conference, giving pause to risk management stewards and conceivably impacting their ability to sleep soundly.
One presenter regaled the audience with a tale of a visit to his dentist, where the receptionist had a smart speaker (which serves as an IoT hub) on her desk. She was clearly not alone in using such a device at the office or when working from home but was most certainly unaware that each time she discussed a patient’s information the device may have been “listening in,” making personally identifiable data potentially accessible to hackers.
Such possible breaches may not appear to be much of a threat on the surface. However, when these Internet-connected devices are assembled into a botnet, the consequences can be ruinous on a significant scale. Thus, many at RIMS expressed alarm not about attacks on individual sensors, but rather that they will be co-opted to execute wider-reaching assaults. From smart microwaves, refrigerators, and lightbulbs to sensors entrenched in smart city infrastructure, the systemic peril was the bigger picture issue worrying risk managers, given the alarming implications for widespread damage and liabilities.
In one such attack in 2016, a Mirai botnet (Japanese malware) exploited insecure IoT devices to scan the Web for open Telnet ports and launched a distributed denial of service (DDoS) attack, essentially knocking out large segments of the Internet in the US.2 Alarmingly, the Mirai botnet has since been updated and gained increased effectiveness.3When it comes to designing an IoT ecosystem, choosing the underlying connectivity solution responsible for the data transfer between sensors and applications is essential. With more and more connected devices, the amount of data generated increases accordingly, which in turn means that a staggering amount of data needs to be transferred to the relevant backend.
By making this transfer possible, the connectivity layer acts as the crucial enabler of any IoT solution, which makes selecting a fitting connectivity solution so important. Nowadays, decision makers are facing a multitude of options and there is no universal best option to be found. Instead, different use cases demand different solutions, each of which brings their own particular advantages and challenges with them.
In our Point of View “The Future of Connectivity in IoT Deployments” we take a closer look at these connectivity solutions and what they entail. Starting by presenting a market overview of current technologies and expected trends, we then delve into a more detailed examination of specific use cases. Additionally, this Point of View also provides an outlook on the future by highlighting long-term implications of upcoming technologies (in particular 5G) and overall business implications.
In order to identify and deploy the right connectivity solution, organizations have to identify and assess their own needs first, as different use cases have wildly differing requirements. In this particular Point of View, we examine the following specific use cases and their implications for choosing a connectivity solution:
Precision Farming - A use case focused on increasing efficiency and reliability in farming through sensors in the soil.
Wearables - A use case considering health tracking with wearables such as smartwaches or sleeptrackers.
Connected Car: Smart Traffic Management - A use case studying the communication between vehicles and their surroundings, especially other vehicles and roadside infrastructure.
Connected Medical Devices - A use case highlighting the use of connected medical devices at patients’ homes.
As the Point of View illuminates, each of these use cases imply specific needs which need to be considered when choosing the correct connectivity solution. Without an appropriate connectivity solution acting as an enabling base layer, a successful wide-scale deployment becomes impossible.
However, when deployed successfully, IoT applications can have a marked impact on businesses in a wide range of industries. With the market of IoT applications and connectivity solutions being as dynamic as it is, this requires an ecosystem-oriented mindset, as with one single application numerous specialized parties come together. In this context, connectivity is just one aspect out of many for a comprehensive IoT solution - but it is without doubt an essential one.This article is a precursor to a more in-depth analysis of Security by Design/Default principles for IoT device producers by proving an overview of the current requirements for security within the expanding IoT industry. The aim is provide some food for thought before delving deeper into the specifics of IoT regulation and legislative control.
As discussed in the blog post Connectivity and Vulnerability: An Examination of Cybersecurity Threats resulting from IoT Development, IoT devices and capabilities will continue to play a significant part in future business capabilities. In addition, due to the complexity of these devices and their capabilities, threats from malicious actors, as well as intrinsic vulnerabilities will exist. The logical approach to ensuring that IoT devices are kept as secure as possible rests upon the premise that security prioritization begins during development and production phases. Security is a particularly difficult measure to implement retroactively, requiring improvements to both software and hardware.
To paraphrase Tim Stevens, risk arises from both known and unknown elements; the onus of protection regarding known risks rests most strongly upon the producers of IoT devices to ensure that they are implementing a satisfactory degree of security in their products, in order to mitigate future unknown risks. However, the conflict between the rapid development of IoT, and legislative regulation, is yet to be resolved to any satisfactory degree.
In September of 2018, The Washington Post reported that a Bill (SB-327) was awaiting the signature of Gov. Jerry Brown (D) of California which would require IoT device manufacturers to implement basic device security measures. At this time, the Bill has been signed and will come into power as of January 1, 2020.The Bill is seen in both a positive and negative light however. The Bill itself states that:
(a) A manufacturer of a connected device shall equip the device with a reasonable security feature or features that are all of the following:
(3) Designed to protect the device and any information contained therein from unauthorized access, destruction, use, modification, or disclosure.
(b) Subject to all of the requirements of subdivision (a), if a connected device is equipped with a means for authentication outside a local area network, it shall be deemed a reasonable security feature under subdivision (a) if either of the following requirements are met:
(2) The device contains a security feature that requires a user to generate a new means of authentication before access is granted to the device for the first time.
The positive aspects of the Bill are that finally, steps are being taken to ensure that there is a legal basis for a minimum standard of protection required for all IoT devices which are manufactured. This will serve to protect those devices which are currently produced without adhering to industry ‘best practices’, and create significant risk for the users of the devices.
The negative takeaway is that the wording of the Bill is rather vague, and seems to leave the onus of determining what exactly can be considered “appropriate”. Additionally, there is no information which sets out clearly defined requirements for what constitutes a ‘security feature’.
It is quite possible that in the near future, there will be a security feature requirements catalogue and certification process for IoT devices. However, this will serve to increase the workload for innovative device manufacturers, and the complexity of the IoT environment. In an International Electrotechnical Commission Whitepaper of 2016 entitled IoT 2020: Smart and secure IoT platform, the problem of governmental control over IoT regulation was already noted. The problem was, that “government bodies strive for regulations that provide a proper balance between supporting helpful innovation and protecting consumers” and that the search for this balance was “causing significant confusion in the marketplace and adding to the complexities of designing, building, deploying and operating both homo- and heterogeneous systems within and across geopolitical boundaries.”
The problem mentioned above is significant when considering the fact that a huge range of business opportunities are arising from the continued, somewhat unhindered (or overly regulated) development of IoT technologies. An excess of regulation stymies development, which restricts market growth, and results in a negative economic effect. Uncertainty between IoT manufacturers and regulators can lead to an environment wherein regulators are forced to play ‘catch-up’ in order to regulate new developments in IoT technology, and manufacturers slow their research and development efforts due to concerns which arise from the unknown of when and how their projects will be impacted by newly implemented regulatory requirements.
As Deloitte, future developments within the IoT industry will require us to adapt service offerings and to cater our approach to the specific needs of our clients. As part of our offerings, we seek to share our experiences and knowledge in order to build awareness. We look forward to delving further into this topic in the next Blog Post and discovering more opportunities together.Machines and other infrastructure components often have a long service life that extends far beyond the tax depreciation period. This is especially true for buildings and facilities for energy supply. These “Legacy Devices” have so far been largely excluded from the Internet of Things, although applications such as predictive maintenance are of great importance, especially in old age. The reason is that digital technologies were not yet available at the time of production and changes to the control systems would often be expensive or would require a new approval of the system. However, the rapid development of sensor technology and electronics has led to high performance and low cost of IoT edge devices. Current gadgets are both cheap and capable of executing complex algorithms for signal processing and pattern recognition in real-time. It is now possible to equip existing Things with a digital heartbeat via minimally invasive sensor technology. We call this Artificial Intelligence of Things (AIoT). In this publication, we describe the idea and basics and show application examples.
Aging technical systems, commonly referred to as “Legacy Devices”, are an integral part of our daily lives. Who does not know the picture of an elevator from the seventies that tries to close its doors in an endless loop? The malfunction is simply caused by dirt on the reflector that triggers the door sensor. House inhabitants only shake their heads and nobody informs property management.
Elevators, finned radiators, kitchen appliances, and even the humans themselves share their fate as "Legacy Devices". This generally refers to "devices" that have no own digital identity on their own. The automatic acquisition and evaluation of data and the corresponding actions or recommendations are therefore not possible, sometimes with fatal consequences.The Internet of Things—sensors and actuators connected by networks to computing systems—has received enormous attention over the past five years. A new McKinsey Global Institute report, The Internet of Things: Mapping the value beyond the hype, attempts to determine exactly how IoT technology can create real economic value.
Our central finding is that the hype may actually understate the full potential—but that capturing it will require an understanding of where real value can be created and a successful effort to address a set of systems issues, including interoperability.
To get a broader view of the IoT’s potential benefits and challenges across the global economy, we analyzed more than 150 use cases, ranging from people whose devices monitor health and wellness to manufacturers that utilize sensors to optimize the maintenance of equipment and protect the safety of workers. Our bottom-up analysis for the applications we size estimates that the IoT has a total potential economic impact of $3.9 trillion to $11.1 trillion a year by 2025. At the top end, that level of value—including the consumer surplus—would be equivalent to about 11 percent of the world economy (exhibit).
Exhibit We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Achieving this kind of impact would require certain conditions to be in place, notably overcoming the technical, organizational, and regulatory hurdles. In particular, companies that use IoT technology will play a critical role in developing the right systems and processes to maximize its value. Among our findings:
Interoperability between IoT systems is critical. Of the total potential economic value the IoT enables, interoperability is required for 40 percent on average and for nearly 60 percent in some settings.
Currently, most IoT data are not used. For example, on an oil rig that has 30,000 sensors, only 1 percent of the data are examined. That’s because this information is used mostly to detect and control anomalies—not for optimization and prediction, which provide the greatest value.
Business-to-business applications will probably capture more value—nearly 70 percent of it—than consumer uses, although consumer applications, such as fitness monitors and self-driving cars, attract the most attention and can create significant value, too.
The IoT has a large potential in developing economies. Still, we estimate that it will have a higher overall value impact in advanced economies because of the higher value per use. However, developing economies could generate nearly 40 percent of the IoT’s value, and nearly half in some settings.
Customers will capture most of the benefits. We estimate that IoT users (businesses, other organizations, and consumers) could capture 90 percent of the value that IoT applications generate. For example, in 2025 remote monitoring could create as much as $1.1 trillion a year in value by improving the health of chronic-disease patients.
A dynamic industry is evolving around IoT technology. As in other technology waves, both incumbents and new players have opportunities. Digitization blurs the lines between technology companies and other types of businesses; makers of industrial machinery, for example, are creating new business models by using IoT links and data to offer their products as a service.
00:00 Audio Getting the most out of the Internet of Things MGI’s Michael Chui discusses how businesses could unlock trillions of dollars in value during the next decade.
The digitization of machines, vehicles, and other elements of the physical world is a powerful idea. Even at this early stage, the IoT is starting to have a real impact by changing how goods are made and distributed, how products are serviced and refined, and how doctors and patients manage health and wellness. But capturing the full potential of IoT applications will require innovation in technologies and business models, as well as investment in new capabilities and talent. With policy actions to encourage interoperability, ensure security, and protect privacy and property rights, the Internet of Things can begin to reach its full potential—especially if leaders truly embrace data-driven decision making.A midstream company was struggling with asset management lifecycle challenges as its aging infrastructure created competing investment priorities. They wanted to refocus their program on leveraging data to improve information management, predictive asset management, asset risk management, and asset management planning.
Discover how we refreshed multiple dimensions of the program using the Internet of Things (IoT) and data-driven approaches.Manufacturing history is a study in evolution, as industry has quickly adopted and adapted to new technologies, from power generation and electrification to automation and the digital age. That’s why the way that cars and other products are manufactured today looks very different than it did when Eli Whitney first developed a simple production line based on interchangeable parts used in the manufacturing of muskets.
In many ways, manufacturing has been part of the Internet of Things (IoT) throughout its entire history. Many companies have been embedding sensor-based technology in their devices for decades without fully realizing their potential. Manufacturing was one of the first adopters of robots and automated processes—many of these machines signaled distress with a sensor providing notification and addressing the problem before the machine stopped working, thereby avoiding downtime.
Today, thanks to the power of IoT, new data processing technologies, and availability of analytical forecasting models, the entire manufacturing value chain, from concept to completion and beyond, can now take advantage of this sensor technology.
For a modern example, some of today’s most sophisticated fighter jets are built almost completely out of outsourced parts. With a digital supply chain supported by advanced predictive analytics coordinating three principal partners, nine countries, 40,000 individual parts, and thousands of suppliers, a major manufacturer of these jets predicts it will soon be able to build one jet per day, a process that used to take months or years.
As this example illustrates, IoT and analytics are innovating manufacturing, improving interoperability across a large set of assets and linking machines, products, computers, people, and analytical resources into one ecosystem.
At the simplest level, IoT and analytics are creating two important buckets of value in manufacturing: growing the business and operating the existing business more efficiently.Financial services have long trafficked in the intangible, from counterparty risk and online bill payment to things that used to be tangible but increasingly are not any longer, such as stock certificates and even money itself.
So all the talk about IoT—a suite of technologies and applications that provide information about, well, things—might not seem directly relevant to the way financial services institutions do business.
But, according to the Deloitte Center for Financial Services research, there are near- and long-term opportunities for the financial services industry to see the benefits from IoT. Read this report for an overview of where IoT is working well, bottlenecks companies could encounter when leveraging IoT data, and potential use cases for future adoption.
Or explore the below infographic, which was created at the BAI Retail Delivery Conference where the Deloitte Center for Financial Services hosted a sponsored session on IoT in financial services. The graphic includes an overview of the findings from the research study and ideas generated from small group discussions on the application of IoT in retail banking through the lens of lending, branch, wealth management, and payments.IoT platforms are emerging that make IoT development and deployment much easier. But just as important is their ability to enhance IoT platform security. With IoT, devices are both smart and connected—gathering and sharing data without the need for human intervention. This enables information to be collected and shared on a massive scale with unprecedented levels of speed, efficiency, and detail.
This also makes it a target for bad actors looking for any little weakness. IoT greatly expands the universe of potential weaknesses—in a particular device, device-to-device communications, or the broader internet. Even a single breach point may be enough to compromise an entire network.
IoT provides a bridge between digital and physical, making it possible for hackers to wreak havoc in the physical world—whether it’s taking control of your vehicle or causing a nuclear power plant to melt down. The World Economic Forum noted, “hacking the location data on a car is merely an invasion of privacy, whereas hacking the control system of a car would be a threat to a life.”1Deloitte's turnkey IoT framework and technology bundles were developed to meet market demand for predictive maintenance and asset monitoring, asset performance management, and asset tracking capabilities, to help deliver significant, fast returns on IoT investment.
Drawing on the industry, functional, and digital experience within Deloitte and our alliance network, we provide a single pre-configured package that includes:
These turnkey IoT solutions are pretested, fully integrated, and shown in production to lower risk and shorten the path to value from months to weeks.
Our turnkey IoT approach can help clients realize the benefits of IoT faster, achieving relatively quick returns in specific high-impact areas of their business while accelerating digital adoption and modernizing operations in general. Clients can accomplish this by replacing legacy systems entirely or by adding new technology for gathering and analyzing data from existing sensors and controllers.The Consumer Electronics Show (CES) is an annual industry extravaganza and it took place, as usual, in Las Vegas earlier this month. This is where all kinds of firms showcase their latest and greatest consumer tech offerings to the world, with the focus typically on one or two big themes. This year was no different.
Much of the excitement at this year’s event was around the Internet of Things, or IoT, as the cognoscenti refer to it.1 The Internet of Things includes anything and everything that is connected to the Internet and able to communicate and share information with other “smart” devices. These may include home appliances, fitness and health monitors, home security systems, light bulbs, audio systems, temperature control equipment, etc.
In keeping with that theme, a number of firms displayed a staggering array of gadgets at this year’s CES, ranging from smart cooking pots and toothbrushes to wearable technologies like watches and clothing.
To be sure, the IoT is not really a new concept. The technology industry has been talking about this for a while now, with some people equating the IoT with the industrial revolution. They claim a profound transformation lies ahead in ways humans and machines interact with each other.2
Estimates of the size of the IoT market vary. For instance, Gartner expects it to include nearly 26 billion devices, with a “global economic value-add” of $1.9 trillion by 2020.3 Others are more optimistic: The International Data Corporation (IDC), for one, estimates that the universe of things connected to the Internet will generate nearly $9 trillion in annual sales by 2020.4
One may wonder whether this is just hype or an inevitable evolution in how people, objects and networks will interact in the near future. Some recent advances suggest this is for real. We already have products that use sensing and communication technologies in a range of consumer sectors, such as self-driving cars and geospatial sensing on mobile phones. We are also seeing applications in business, with supply chain management being a focal area.
An obvious and critical challenge that the IoT industry is likely to face is in the area of security and privacy. With the explosion of devices, cybersecurity takes on a whole new dimension – not just for institutions but also for consumers. Digital vulnerabilities are likely to expand exponentially.
The question for us in the financial services industry is how we should respond to this growing phenomenon. What does the IoT mean for how we communicate and interact with customers? Contrarians may argue we are in the business of providing services, not “things,” so we needn’t pay much attention to this. In my opinion, that might be a short-sighted view.
We are already seeing this concept applied in insurance through telematics (monitoring driver behavior for car insurance). Other potential applications in insurance are life, health and homeowners insurance and worker’s compensation in the commercial arena.
Some applications that come to mind are ATMs, information kiosks in bank branches and credit/debit cards that may use sensing technology to monitor and take action on the consumers’ behalf. Another big potential may be the connection of financial services (such as checking, credit card, or investment accounts) to some of the common household devices.
For instance, imagine a personal health monitor that is also connected to your investment account. At the sign of any serious health hazard (say a heart attack), the investment account could automatically rebalance to limit your downside exposure, or transfer your holdings to more liquid securities, in anticipation of future cash needs. This may sound a bit far-fetched now, but is not completely out of the realm of possibilities.
Other applications may be possible in the middle- and back-office functions at banks, insurance firms and investment management shops that could potentially benefit from the IoT technologies.
Again, such innovations also come with new risks. The deluge of new data is likely to complicate data management for financial services firm. And of course, cybersecurity may become an even greater challenge.
We cannot know all the answers here and now, but my takeaway from this year’s CES is that the financial services industry ought to be proactively thinking about how to deploy the IoT technologies in the way it serves customers.
1Kim Peterson, “’Internet of Things’ all the rage at the Consumer Electronics Show,” CBS Moneywatch, January 7, 2014.
2Steve Johnson, “Internet of Things promises profound transformation, could rival Industrial Revolution," Mercury News, January 8, 2014.
3Peter Middleton, Peter Kjeldsen and Jim Tully, “Forecast: The Internet of Things, Worldwide, 2013,” Gartner, November 18, 2013.
4IDC, “The Internet of Things is Poised to Change Everything, says IDC,” Press Release, October 3, 2013.
As used in this document, “Deloitte” means Deloitte & Touche LLP, a subsidiary of Deloitte LLP. Please see www.deloitte.com/us/about for a detailed description of the legal structure of Deloitte LLP and its subsidiaries. Certain services may not be available to attest clients under the rules and regulations of public accounting.A global telecoms company knew that the Internet of Things (IoT) is taking off in a big way. But since many ‘smart’ products only worked with their associated apps, it’s difficult to build a true ‘smart’ ecosystem.
Our client asked us to do just that—transform the way consumers interact with IoT. Together, we built a new IoT business from the ground up, including technical design and execution for the new platform, onboarding a network of partners and users, and scaling the talent and capabilities to make the new business a success.Can financial services, which deals mostly with the intangible, benefit from Internet of Things technology? Absolutely—and not only from more and better data about clients' physical assets. IoT applications aim to transform finance along with every other sector.
Financial services have long trafficked in the intangible, from counterparty risk and online bill payment to things that used to be tangible but increasingly are not any longer, such as stock certificates and even money itself. So all the talk about the Internet of Things (IoT)—a suite of technologies and applications that provide information about, well, things—might not seem directly relevant to the way financial services institutions (FSIs) do business.
But the IoT may be as broadly transformational to the financial services industry as the Internet itself, and leaders should make an effort to recognize the opportunities and challenges it presents for the financial sector as well as for industries with which FSIs work closely.
Notwithstanding the inevitable hype, many industries see great promise in IoT applications: Analysts and technology providers forecast added economic value of anywhere from $300 billion to $15 trillion by this decade’s end.1 Few analysts seem to expect anything but a transformative effect on just about every dimension of economic activity by 2020. The IoT—based on the concept of physical objects being able to utilize the Internet backbone to communicate data about their condition, position, or other attributes—is likely going to matter a great deal. (For an overview, see Deloitte University Press’s “Internet of Things” collection of articles.2) And FSIs can be active participants in this transformation.
Indeed, FSI leaders can easily imagine the potential benefits accruing from having more comprehensive, real-time data about their own or their clients’ physical assets. Some use cases have already proven themselves: Applications such as auto insurance telematics and “smart” commercial real estate building-management systems offer clear IoT examples of new products or changed processes. Our aim in this report is to go a step further by exploring the IoT’s potential impacts on the financial services industry when those effects are hazier. We also aim to help FSI professionals such as claims administrators, portfolio managers, loan officers, and leasing agents understand how IoT applications may change their jobs in the coming years.
Many analysts view the IoT narrowly, defining it as little more than an extension of related technology concepts, such as machine-to-machine (M2M) communication or big data. But the IoT, and its applications’ potential value, goes far beyond mere data communication or analysis. For the purposes of this report, we will define the IoT as technology that connects objects (including people) to a network (such as the Internet) in order to provide access to information about that object’s condition, position, or movement. Kevin Ashton, generally credited with coining the term “Internet of Things” in 1999, envisioned computers having “their own means of gathering information, so they can see, hear, and smell the world for themselves.”3 Many IoT systems take this vision a step further, either by visualizing that information for decision makers or by providing it directly to computers to enable action in the physical world.
For the financial services industry, how does the flow of IoT-generated information create value for companies and consumers? Many firms are already using sensor data to improve operational performance, customer experience, and product pricing. Perhaps the most mature example involves the development of usage-based insurance, in which sensors in automobiles or, increasingly, smartphone apps automatically provide insurance carriers with information on vehicles’ driving history and therefore their drivers’ performance.4 Using telematics to increase the accuracy of underwriting automobile collision policies, as well as the use of gamification strategies based on those data to change and incent lower-risk driver behavior, has been shown to be quite successful in the still-early stages of deployment.5
Another example is in commercial real estate, where sensors within commercial buildings of all types can help better manage energy usage, environmental comfort, and security.6 For example, motion detectors can control lighting and temperature usage, while smoke and heat sensors can detect the presence of fire and not only set off alarms but also communicate with elevator control systems to prevent usage—a much more effective deterrent than traditional take-the-stairs-during-a-fire signs. Mall operators are currently experimenting with IoT-like applications, such as using cellphone Wi-Fi data to track and analyze foot-traffic flow around and within the mall, that suggest ways to increase certain properties’ attractiveness and thus drive increased rental income and investment activity.7
These examples highlight something that Ashton declared as a premise underlying the IoT concept: For the technology to make a direct impact, a business’s value chain must have a thing that can be measured and enabled to communicate. But for most financial services businesses, the IoT’s impacts could be characterized as having a “derivative effect”: While the IoT is fundamentally about gathering, processing, and creating value from information about tangible physical objects, many financial transactions are based on information from intangible sources that may ultimately have roots in the physical world but that are one level removed from it. No tech startup has yet figured out how to strap a sensor to a company’s profit-to-earnings ratio. But many, even most, pieces of information have roots in the physical world—for instance, a logistics firm’s stock price may depend on the number of packages shipped, while wheat futures may change based on rainfall levels.
As discussed above, FSIs are already using IoT technology to measure and analyze those elements of their business that are directly tied to data about tangible thing—driving habits, health, and so on. Therefore, we see the IoT’s near-term potential in financial services as largely defined by how these existing “tangible” applications may spread. To identify possibilities, one approach would be to consider deployments of sensors of all types and analyze which of these might yield information that could be useful—even tangentially—to the various businesses within the financial services industry. In a sense, since sensors are the IoT’s most physical element, we can use them as a stand-in to measure IoT applications as a whole.
In a recent report, Gartner forecast that, on a worldwide basis, “endpoints of the Internet of Things will grow at a 32.5 percent CAGR from 2013 to 2020, reaching an installed base of 25.0 billion units.”8 Covering more than 200 different categories of sensors, across consumer, business, and vertical-specific categories, the forecast suggests a broad expansion of deployments between now and the decade’s end. Undoubtedly, deployment of 25 billion new endpoints should create considerable business opportunities for companies of all types.
In aiming to assess the scope of the IoT’s nearterm impact on financial services, we used the Gartner forecast as a starting point and took the following steps to generate the numbers used in this section of the report:
Reviewed the more than 200 types of sensors in the forecast and assessed their resulting information’s potential value to financial institutions
Interviewed senior practitioners within Deloitte to gather their views and input on potential use cases
Categorized the detailed list of sensor types into a small number of broad use-case categories with broad appeal to FSIs (See exhibit 1 of the appendix)
Created potential use cases by financial services sector for each use case (See exhibit 2 of the appendix)
Our analysis is meant to be illustrative rather than exhaustive, with the goal of exploring both the IoT’s possibilities and limitations for FSIs between now and 2020.
Whole categories of sensors will likely have little or no direct impact on the financial services industry—just consider education (for example, lab equipment or smart boards) and entertainment (for example, smart TVs or gaming consoles). But as a starting point, our analysis (see sidebar for details) suggests that perhaps as many as one-quarter of sensors deployed in 2013 could be of use to FSIs, rising to one-third in 2015 and then to about 50 percent by 2020. In other words, one could reasonably assume that by the end of the decade, companies will have deployed several billion sensors that could provide data of interest to financial firms of one kind or another.
How might companies use these data, and how could the information be further exploited? Our analysis suggests that sensor deployments may find traction within the industry in more than a dozen different applications (see exhibit 2 of the appendix). Several categories are interesting to consider as further enhancements to existing opportunities. For example, analysts expect deployment of automotive sensors to continue to grow, providing insurers with better data to drive usage-based insurance.9,10 Building-management sensor deployments will likely similarly increase.11
On the consumer side, a significant number of sensors are forecast to be deployed in the home to control utility consumption, provide home security and flood and fire detection, and monitor the dwelling’s overall condition. Google’s acquisition of Nest suggests the potential for combining home automation and analytics into the “conscious home.”12 These technologies could benefit FSIs as well: Lenders could better understand a home’s condition and thus its value during the mortgage origination process (for appraisals and underwriting), and insurers could improve risk management and provide more accurate pricing for homeowner insurance, as they do today for auto coverage.
In commercial applications, we believe that FSIs might benefit from various sensors that monitor the activity and condition of retail industrial and agricultural businesses, such as connected field devices in manufacturing or agricultural sensors that monitor livestock. Both capital market firms and commercial lenders could use the data these sensors generate to support investing or lending activities. Sensors attached to goods in transit—from manufacturing plant to retail outlet—could offer opportunities to banks’ cash management and trade services businesses, better matching flows of payments and goods between seller and buyer.
Apart from augmenting how FSIs provide services, companies can deploy IoT technology to change how they do work internally—a broad category of sensors that addresses the “quantified self.” In the same way that automotive telematics provide input to insurers as well as feedback to drivers, personal sensors may provide information to firms across multiple sectors. Even sensors that simply provide information on location and movement of individuals have been shown to provide rich insights into how employees work, interact, and share ideas.13
Taken together, the analysis we conducted suggests that growth in sensor deployments for FSI examples such as these is certainly robust, ranging from just over 20 percent to 100 percent annually on a compounded basis, depending on the sector (see figure 1).
But gross numbers and growth rates for sensor deployments tell only part of the story. To truly begin to discern the industry potential for the application of IoT-generated data, we should also consider those uses that have not yet become common. To do so, it is useful to consider the value that companies might derive from such usage, as well as bottlenecks that hinder growth in that usage, using a framework known as the Information Value Loop.
The suite of technologies that enables the Internet of Things promises to turn most any object into a source of information about that object. This creates both a new way to differentiate products and services and a new source of value that can be managed in its own right. Realizing the IoT’s full potential motivates a framework that captures the series and sequence of activities by which organizations create value from information: the Information Value Loop.
For information to complete the loop and create value, it passes through the loop’s stages, each enabled by specific technologies. An act is monitored by a sensor that creates information, that information passes through a network so that it can be communicated, and standards—be they technical, legal, regulatory, or social—allow that information to be aggregated across time and space. Augmented intelligence is a generic term meant to capture all manner of analytical support, collectively used to analyze information. The loop is completed via augmented behavior technologies that either enable automated autonomous action or shape human decisions in a manner leading to improved action.
The amount of value created by information passing through the loop is a function of the value drivers identified in the middle. Falling into three generic categories—magnitude, risk, and time—the specific drivers listed are not exhaustive but only illustrative. Different applications will benefit from an emphasis on different drivers.
Using the Value Loop to understand how the IoT uses information to create value, we can see the largest barriers to wider future adoption: the scale and scope of available data. To illustrate the scale problem, one can see how, for most given applications, sensor deployments can inevitably fall short in covering the entire market. Take, for example, the safety issues inherent in cars having improperly inflated tires. Automakers have begun making tire-pressure monitoring sensors standard equipment on vehicles they sell in the developed world, but most cars aren’t new—the average automobile even in the United States today is 11 years old.14 The Gartner forecast we have used predicts about 3.5 billion automotive sensors deployed across many different categories by 2020, when the number of passenger cars in use worldwide could be as much as 1 billion.15 Clearly, then, a significant number of vehicles may still lack the ability to provide the kind of comprehensive safety data of which insurers could make use, even by the end of this decade. The lack of relevant data limits even the “tangible” uses of IoT technology that FSIs already use from achieving their full potential.
For future uses that seek to use the IoT to shed light on “intangible” measures, the data problem is even more pronounced. Here the scope of sensor coverage remains a key issue. As discussed above, monitoring retail business performance in real time may allow analysts to truly understand foot-traffic patterns and compare this information to sales figures to determine which retailer is more effective at converting shopper volume to sales per square foot, which would then influence buy/sell recommendations. Such a real-time capability would likely require an array of different sensor types, including beacons (devices that connect to a mobile phone or tablet to determine positioning and deliver proximity-based content, such as coupons), smart cash registers, RFID tag readers, parking lot sensors, and smart mobile signature devices for home delivery. However, forecasts estimate that the lion’s share of sensor deployments will be beacons that measure only one data parameter: location (see figure 2).
In a similar vein, manufacturer activity may be monitored by devices that observe plant activity of various kinds, industrial controllers and smart robots on the assembly line, smart asset tagging to prevent loss of tools and equipment, and RFID tag readers for finished-goods inventory. Here, most sensors are projected to be connected field devices that monitor general plant activity—again, a valuable indicative input to existing data sets, but currently insufficient to yield the kind of in-depth comparative intelligence that might someday transform the way that lenders, traders, or analysts assess risk or make stock picks. In summary, firms may benefit as these data flows start to come online, but the transformative effect resulting from a more comprehensive picture of business activity may remain somewhat elusive over the next five years.
In the shorter term, sensor data coming online will likely create new information asymmetries that traders and portfolio managers can exploit. Indeed, firms have a vested interest in protecting the status quo of information asymmetry that drives value in the capital markets and, therefore, may resist the kind of radical transparency that might someday emerge from this new source of data.
FSIs will also confront challenges associated with deriving value based on the data’s reliability and accuracy. Not all IoT-generated data will be useful, and so companies will likely need to gain experience with some of these new data types (especially those associated with the “quantified self ”) in order to discern which are predictive in nature, and update their analytical models accordingly.
Especially for the applications imagined for capital markets and investment management firms, then, IoT-generated value will likely accrue much more slowly, since many processes within these sectors are based on the availability of comprehensive and timely market data. Referring back to the value drivers within the Information Value Loop, frequency, timeliness, and latency are therefore an issue, as firms often depend on continuous, realtime data flows, particularly as relating to the equity markets.
Keeping in mind that IoT applications in financial services may increasingly shift from common uses with tangible measures to uses with intangible measures, the question is what path IoT technology will take from here to there.
The answer can again be found in the Information Value Loop. One of the implications associated with the IoT is that a product’s information content is now as valuable as its performance.16 The flow of information around the Value Loop creates value for customers that companies can then capture. Analyzing this flow of information can help companies locate specific strategic and technical challenges facing them in an IoT-enabled world. But information does not flow evenly around the loop: A bottleneck will exist at one stage of technology, which limits the flow and thus the value. Alleviating this bottleneck can increase the flow of information, creating value for customers, and the company that controls the bottleneck is in a place to capture the bulk of value created.17
The uneven progression of sensor deployments highlights the fact that for many emerging applications, the bottleneck is at the create stage of the Value Loop. Until some minimum critical mass of sensors is in the market, more complex uses beyond the few existing tangible examples will be impossible.
Even then, FSIs must clear other hurdles before they can use IoT technology to model “intangible” financials. One hurdle is the availability of these data to FSIs. For example, manufacturers or agribusinesses should benefit from closer monitoring of operations, but they will likely struggle to see the upside of releasing or selling such strategic information to the marketplace, since such data may reveal specific strategies or competitive advantages that companies would prefer not to expose to competitors. Firms—especially commercial lenders—may someday require the release of such information as a condition for granting credit, but these requirements may adversely impact client experience, as customers may perceive those companies that decide to be on this trend’s leading edge as being more difficult to do business with.18 So the next bottleneck blocking the way of more complex IoT applications is in the communicate stage, as companies or individuals may be unwilling to share their data with a financial institution.
Even if the bottlenecks associated with the creation and communication of data were to someday disappear, many FSIs will find aggregating and analyzing the output to be a challenge. IoT-generated data streams will require them to augment their data-management and analytical capabilities. Banks and insurance companies in particular already struggle with the vast pools of data within their legacy systems, and without exercising more discipline toward the specific data they want to capture, the potential flood of fresh information may overwhelm them.
Regulators, aiming to protect investor interests and market transparency, will have their say, and consumers and corporations uncomfortable with the notion of being “watched” will demand limits on the collection and use of sensor-based data. In this new world, clients may be unable to adequately discern the risks of transparency, and one might anticipate that regulators will look for increasing disclosure to protect the interests of clients and markets, as well as monitoring the handling and use of personally identifiable information as a result.19
So what exactly will the future hold if these current applications are able to reach sufficient scope and scale? By introducing enough data about the world, the IoT can help drive the creation of models that approximate the underlying physical drivers of even intangible financial measures. That said, given the accelerating pace of technological development, predictions about how things might evolve in the next 5–10 years are difficult to make. To help gain some insight into future scenarios, we engaged with a group of academics, analysts, and entrepreneurs with expertise in financial services and technology using a crowdsourced model to imagine how IoT technologies might generate new examples over a longer time horizon (see “About the project” for more details).
The insights in this section on future IoT scenarios are based in part on a crowdsourced simulation exercise conducted by Wikistrat on behalf of the Deloitte Center for Financial Services. The project, fielded during July 2015, involved more than 50 analysts across 20 countries. These analysts had varied backgrounds, including technology entrepreneurs; business and technology leaders within the financial services industry; academics with doctorates in economics, business, and technology; analysts in government and research centers; and cybersecurity consultants.
The project was designed to explore the IoT’s long-term potential in financial services. Wikistrat tasked analysts with developing a series of use cases within six specific industry sectors, and with forecasting and describing the opportunities and challenges that IoT technology presents (see exhibit 3 of the appendix for a full list of the scenarios).
Using an online tool, analysts worked collaboratively to develop 44 use-case examples using a wiki-based template designed to identify IoT-related trends and issues, potential opportunities, and risks and challenges.
They then provided a quantitative assessment of the probability that each use case will emerge and its overall impact or importance to the industry.
Wikistrat and the Deloitte Center for Financial Services then reviewed all cases and probability assessments to select 10 use cases for further development.
At a final workshop, participants reviewed and enriched the short list of 10 cases. Enrichment activities included clarification of use cases, provisioning of additional data points, reinforcing potential value for FSIs, and identification of cross-cutting themes and issues.
The sheer number of ideas our workshop generated in a short period suggests that opportunities to capitalize on new information flows may be limited only by our collective imagination.
A few of the workshop’s more interesting use cases provide a glimpse into a future of new opportunities and threats for incumbents, emerging technology–based financial services companies, and regulators alike. Some overall themes emerged from this exercise. In brief, these include:
The emergence of what the panel called “radical transparency” may undermine advantages that come today from information asymmetry. This is particularly true in investment and lending businesses, in which equity analysts, loan officers, and others make decisions based on their unique perspectives.
Data associated with individual (and corporate) preferences and behaviors will likely be at the center of new opportunities and disruptions to the incumbents’ business models.
Risks of various types can emerge along with the opportunities. Protecting data privacy and security should be of paramount importance, especially for financial institutions. But unintended consequences may emerge from automated processing of huge volumes of near real-time data flows. Fraudsters could seek to intercept this information to manipulate markets, or operational disruptions could occur if automated decisions are made based on faulty data or inaccurate analysis.
The ability to access IoT-generated data will likely be a challenge for many firms, which may result in the emergence of a new class of service providers, offering data “subscription” services in the manner of credit bureaus or market data providers. Again, whether it makes sense for the owners of these data to offer this intelligence for public consumption will be driven by many factors, such as whether or not these data provide a competitive advantage to the owners within their own businesses.
The project also yielded some broader implications for the industry at the sector level. These are presented in turn below.
The analysts imagined that IoT applications might help banks improve underwriting processes and reach new markets. They foresaw that physical, performance, and behavioral data generated from biometric and positional sensors for individuals, and shipping and manufacturing control sensors for businesses, could provide new opportunities for credit underwriting, especially for those underserved customer segments lacking a credit history. The challenges here involved developing an understanding of which kinds of data are best predictive of creditworthiness, as well as the potential risk of new forms of redlining based on so-called “pattern of life” (POL) analyses.
Given that banks finance the lease or purchase of many physical items, our Wikistrat panel found opportunities for banks to tap into data from sensors monitoring these goods’ condition to offer customized solutions. For example, lenders could partner with electronics and “white goods” manufacturers to proactively make credit offers to individuals if their purchased items begin to show noticeable wear or face imminent failure. Leasing companies, too, could monitor the condition of leased assets in order to determine a more precise residual value of the asset at lease expiration, or determine with greater accuracy any discounts or penalties for preferred or unacceptable use.
Analysts considered IoT-enabled opportunities to further automate trading and investing activities, driven by continued acceleration in algorithmic trading and the enhancement of this approach through the application of IoT sensor data. The group considered the possibility that, with the removal of the human element in combination with more comprehensive real-time data flows, firms could develop analytics that might better evaluate suspected market bubbles. Others were less sure: While efficiencies would certainly be gained, intelligent agents might be unable to account for shifts in consumer demand or geopolitical events, and thus faulty conclusions could in turn actually create a bubble. There was consensus, however, on the need for firms on both the buy and sell sides to help improve their capacity and capability to gather, store, and analyze huge amounts of real-time, IoT-generated data.
Taking it a step further, crowdfunding and micro-investing opportunities could emerge based on based on analysis of investor behavior. New capital pools could therefore emerge, potentially with new and different systems of rewards. The Wikistrat report suggested that this could significantly shift the way venture capital is sought.
The longer-term impact of the adoption of automotive sensors emerged as one of the more interesting scenarios for insurance carriers. Already, the industry is grappling with the strategic implications of self-driving cars, suggesting a shift from automobile casualty insurance, where the driver is at fault, to product liability insurance, where the manufacturer may be held liable.20 Insurers may gain better information on product-design defects to more accurately price coverage but face the potential evaporation of significant amounts of premium income as accident rates drop and traditional coverages fade away.
A more interesting implication concerns augmented behavior: Usage-based insurance itself may lead to policyholders demanding more on-demand coverage to reduce their costs. For example, in personal life and injury insurance, all manner of risks are covered under a single policy, but with the development of more fine-grained data about personal behaviors, firms could fine-tune coverages to potentially add or eliminate certain risks. In essence, insurance coverages could be unbundled and “decommoditized” to create differentiation from other products in the marketplace. This would make underwriting and pricing a more complex undertaking, but could yield improved customer satisfaction.
On the commercial side, deployment of sensors on shipping containers and transport vehicles may provide insurers with the opportunity to enhance shipping insurance coverage. The ability to better detect and model risks due to theft or damage could move the pricing of these products from an actuarial exercise to one that better assesses risks and losses in real time, while at the same time enabling insurers to more accurately determine responsible parties. In essence, IoT technology could go a long way toward eliminating “proxies” in the risk-assessment process much more broadly than the initial forays seen in telematics today.
The Wikistrat analysts identified ways that investment managers could benefit from modeling the “enthusiastic crowd.” Firms could utilize information from a client’s IoT “ecosystem” to tailor investment decisions and asset allocation based on behaviors, preferences, and location. For example, a more intimate understanding of a client’s interests and purchasing patterns could enhance wealth management. Investment offerings could be tailored based on these data, leading to the extension of concepts similar to socially responsible investing. This analytical approach could also potentially provide a more accurate modeling of investor risk tolerance as well, a part of new-account onboarding that firms have traditionally given lip service through execution of a simple survey. In the new, IoT-enabled world, companies could develop algorithms relying on inputs of POL-based behavioral data to provide a more accurate picture of a new client’s true risk tolerance than a response on a questionnaire.
The analysts also explored the possibilities associated with automating portfolio management. Assuming that firms can address existing constraints around data availability, they could combine real-time data flows from a variety of sensors with cognitive technologies and M2M communication to automate fund management far beyond what is seen today, as with index funds. This could lead to increased differentiation between types of investment management firms, funds, and pricing strategies. Active managers may be forced to specialize in a particular strategy or sector, while automated managers leverage an ability to synthesize huge amounts of data, combined with high-frequency trading technologies, to act faster than any human can today.
The emergence of real-time bidding markets in commercial real estate was another scenario the panel of specialists envisioned. Already, tech startups have emerged to create more transparency in the process of finding and leasing commercial space.21 With IoT technology, firms could combine data from sensors used to manage building energy and security with activity sensors that monitor the level of human interaction within common areas, on elevators, and in the surrounding neighborhood. In this way, analysts could value properties even more accurately. These data flows, if exposed to a public marketplace, could in turn create a kind of trading market, reducing friction in the leasing or buying processes as well as giving investors greater transparency as to property values.
Design and construction of commercial and residential properties could benefit from behavioral analysis as well as the monitoring of construction equipment and materials, some panelists believed. Developers could take advantage of the increasing interest in combined “live/work/play” developments by analyzing foot traffic and other POL indicators to fine-tune their building plans. And engineering and construction firms might be better able to manage projects’ safety and efficiency based on wider deployment of connected construction vehicles and smart asset tags.
Finally, the analysts envisioned “quantified self ” concepts as a way to potentially reduce risk and improve performance. For example, companies might better manage conduct risk by monitoring FSI employees’ stress levels, patterns of movement, and other factors as a way of predicting the potential for internal fraud. Multi-factor authentication in both virtual and real environments could better flag identity theft. For example, retailers could authenticate online chip-enabled payment-card transactions by matching the presence of the card to other physical objects (such as a mobile phone, or even wearables) that are known typically to be within close proximity to the payment device.
Portfolio managers could also improve their performance by understanding how they react during times of stress. Clearly, employees may resist being monitored so closely, but for those in positions of particular importance, such data gathering, kept private and secure, may become a requirement of employment.
Firms should begin planning for this new source of data. As recently as 2012, slightly less than 15 percent of FSIs—and less than 10 percent of insurance carriers—were implementing or planning to implement IoT or M2M-based solutions or applications.22 Firms should start exploring potential impacts and opportunities related to the deployment of IoT technologies, and begin strategizing on how to capitalize on these developments, using the Information Value Loop as a guide. Developing strategic partnerships with IoT innovators across the spectrum, including related technologies such as cognitive computing, will aid understanding of where the market may be headed.
Early experimentation, building off of existing deployments, will help firms with a test-and-learn approach. Certainly, insurance carriers and firms in the commercial real estate industry have a leg up here, but banks may be able to capitalize on the connections between mobile payments, wearables, and sensing devices. Beyond that, firms could start with the assumption that every single object in the day-to-day lives of both customers and employees will soon be able to share data. From that starting point, take an art-of-the-possible approach by identifying the potential opportunities these new data streams could create for them. Indeed, they could consider going beyond test-and-learn, and instead take an approach that embraces the notion of “learn fast, fail fast.”
On a more tactical level, however, firms will need to pay attention to the operational side of the opportunities they may identify. The avalanche of IoT-generated data will dwarf firms’ current data volumes, threatening to overwhelm already-inadequate strategies and technologies in place to manage and capitalize on these data. Accommodating this increased data flow will not come cheap: Both data management and analytical capabilities will require a quantum leap forward. And firms may need to rely on new information brokers to manage and allow centralized access to these data if they are to be of any benefit.
Even though, for most FSIs, the presence of a physical thing is absent from the products they offer and the operations they maintain, the industry is increasingly informationcentric at its core, and has plenty of hard-won experience in information management.
Firms that get ahead of this trend will likely be at an information advantage, where faster, better, and cheaper insight can create opportunities for improved customer experience and operational performance. In many ways, the opportunity for FSIs can be to decommoditize products and services that are differentiated based on their command of these data flows. Regardless of which of the scenarios imagined above emerge, the stark reality is that an increasingly large percentage of the physical world will be connected to computing power of one kind or another, and we’re only at the beginning of what could be a vastly different world from what we see today. Reflecting back on Kevin Ashton’s vision that computers may someday be able to see, hear, and smell the world for themselves, it could be argued that financial services has a built-in advantage.
Deloitte’s Internet of Things practice enables organizations to identify where the IoT can potentially create value in their industry and develop strategies to capture that value, utilizing IoT for operational benefit.​
To learn more about Deloitte’s IoT practice, visit http://www2.deloitte.com/us/en/pages/technology-media-and-telecommunications/topics/the-internet-of-things.html.
Read more of our research and thought leadership on the IoT at http://dupress.com/collection/internet-of-things/.For nearly half a century, technology has underpinned critical business and logistics operations on which FedEx customers depend. Almost a decade ago, we committed to an expansive technology renewal initiative based on an ongoing vision for cloud and everything-as-a-service. We began a journey to simplify and modernize our monolithic legacy systems by creating a collection of orchestrated microservices.
We’re wrapping up the primary phase of the IT renewal initiative, and it’s nothing less than a complete refactoring of legacy software applications that typically have long development, testing, and deployment cycles. Our new service-oriented, cloud-based model is more value-driven. The technology team manages software functions as interoperable microservices that can be used across multiple platforms. They are smaller, incremental, and modular, with iterative delivery cycles that enable us to rapidly adapt to ever-changing business circumstances and help us remain in alignment with our customers as they adopt API- and service-driven architectures and workflows.
As the internet of things (IoT), advanced analytics and blockchain emerged, we were able to leverage them to sustainably develop innovative new products and services for our customers. We’ve been able to position ourselves ahead of the curve on these and other emerging technologies. For example, we developed and are testing small, embeddable IoT sensors—each about the size of a pack of gum—that provide drop-in connectivity using Bluetooth Low Energy (BLE) wireless networks. This allows us to dramatically expand the amount of shipment data we collect beyond date, time, and location stamps to include temperature, speed, and a host of other measurements. The application of real-time analytics to the sensor-collected data improves visibility into the transportation network, automatically predicts the flow of shipments, and optimizes delivery routes by dynamically routing shipments to bypass network clog points.
When IoT and analytics are combined with blockchain, they have the potential to improve existing chain-of-custody systems and processes. Embedded IoT sensors can automatically transmit data to a blockchain ledger as a shipment moves from point of supply to point of demand, enabling carriers, regulators, and customers to track the provenance of goods, combat illegal and counterfeit products, and simplify the cross-border shipping process. Ultimately, we expect the impact of these technologies to extend beyond product shipments to the end-to-end life cycle of a product as it moves through the supply chain.
To stay ahead of the innovation curve, we must be responsive, which requires an agile framework that allows us to rapidly and iteratively adapt, deploy, and pivot when the market demands it. For instance, our experiments with sensor-based logistics stretch back more than a decade with the launch of our SenseAware device. Initially, we deployed sensors that relied on cell phone networks, migrating to BLE network technology when it proved more efficient. Large and expensive, the original sensors had to be reclaimed and reused. As IoT capabilities matured and became more cost-effective, we were able to roll out smaller, less expensive sensors at scale.
We also embrace risk-taking innovation when the potential reward outweighs the risk. For example, we calculated that the cost of experimenting with blockchain—and potentially concluding that it wasn’t useful—would be a fraction of the cost of not making an early blockchain move at all. Our willingness to take an early risk paid off. As a charter member of the Blockchain Research Institute and current standards chair of the Blockchain in Transport Alliance, we have access to invaluable contacts and resources in the blockchain industry.
We know this is a continuous journey—we can’t ever stop transforming. New competitors are agile and technologically savvy, so we plan to continue to evolve our analytics capabilities and to integrate AI into the logistics network. And there are a few more legacy systems whose long tentacles haven’t been fully pried out yet. But because we can’t predict the next innovation or market force, we haven’t locked ourselves into processes, investments, or technologies that aren’t adaptable to future unknowns. I don’t always know what’s coming next, but with an adaptable set of services and the ability to be agile and iterative, I know we’ll be much faster at delivering value.By Amry Junaideen, Risk & Financial Advisory Life Sciences and Health Care leader, Deloitte & Touche LLP
Remember six degrees of separation? This is the idea that every person on the planet is no more than six social connections away from each other. If each person on the planet knows at least 44 others, the number of potential contacts tops seven billion in just six steps (44 to the sixth power).1
Similarly, the Internet of Things (IoT) can connect people, their devices, and their data to clinicians, health systems, pharmaceutical companies, researchers, medical device manufacturers, and other stakeholders via the internet. While this emerging era of interconnectivity could be a huge step forward, it also creates a substantially larger attack surface for cyber-attacks.
I recently moderated a webinar that looked at some of the potential risks created by this cyber-everywhere environment. We also discussed strategies life sciences and health care companies can use to identify and safeguard their digital crown jewels. During the presentation, my colleague John Lu explained that cyber is evolving into a living, learning, interconnected system where all players in the health ecosystem are beginning to work collectively toward a common objective of seamlessly trading information back and forth.
Just a few years from now, as many as 20 billion devices could be connected to the internet (personally, I think this estimate might be a bit low).2 In health care, the information generated by connected devices could generate meaningful data that might help improve medical devices and pharmaceuticals, our level of understanding, and the health of consumers. A digitally enabled pacemaker, for example, could transmit a patient’s data to a physician’s office, which might be integrated with a health system. The data generated by the device might also be collected by the manufacturer, and at some point, that information could become part of a database tapped by researchers or other stakeholders.
In 2017, hackers gained control over an internet-connected fish tank in a Las Vegas casino and used it as a backdoor to enter the casino’s high-roller database.3 Internet-connected sensors regulated water temperature, food, and the cleanliness of the tank. The unprotected device allowed the hackers to access the casino’s database and transmit information to a device in a foreign country. While this might seem like an Oceans 11 plot, it is not. It illustrates that any unsecured internet-connected device could be an unlocked door for someone with criminal intent. This is even more critical as the costs associated with cyberattacks continue to escalate.
The cost of a cyberattack in life sciences and health care can be particularly devastating—especially in markets where revenues are flat or declining—and costs can add up quickly. Across all industries, the average cost of a security breach is about $3.9 million. This assumes an average of 26,000 records per breach multiplied by the average cost of each record, which is about $150. The costs are dramatically higher in health care and life sciences where the average cost of a breach tops $6.5 million.4 That’s 65 percent higher than other industries. This is because patient records contain quite a bit of valuable information that can be exploited.
As I noted in a My Take last May, electronic health records (EHRs) can contain a wealth of exploitable information—everything from demographic information to work history to financial information. This information can be worth substantially more on the black market than financial records and other types of data.5
Additionally, the cost of a breach can be felt for years in terms of fewer patients, lost revenue, and recovery costs. Moreover, in a heavily regulated sector like health care, the costs to respond to questions can be dramatic.
Life sciences and health care organizations have historically viewed cybersecurity as an issue relevant only to the IT department. But as data becomes increasingly interconnected, cyber should be considered a first-order enterprise risk. Moreover, the cyber landscape appears to be evolving more quickly than cyber defenses. During the webinar, we discussed the following topics life sciences and health care professionals should consider when evaluating their cyber strategies:
Define your most valuable digital assets: Organizations need to identify and prioritize their most valuable data that would likely disrupt the business if stolen. This can include patient data, applications, and systems. For hospital systems and health plans, this might be patient/member data. In life sciences, it could be intellectual property.
Organizations need to identify and prioritize their most valuable data that would likely disrupt the business if stolen. This can include patient data, applications, and systems. For hospital systems and health plans, this might be patient/member data. In life sciences, it could be intellectual property. Keep up with cyber-related regulations: Several federal government agencies have taken a renewed interest in cyber and have engaged the assistance of medical device manufacturers and other stakeholders within the health care community. For example, in October 2018, one agency released a revised draft guidance on premarket considerations for medical device cybersecurity. 6 The guidance refines expectations related to the cybersecurity considerations a manufacturer should adhere to during the design and development of a medical device.
Several federal government agencies have taken a renewed interest in cyber and have engaged the assistance of medical device manufacturers and other stakeholders within the health care community. For example, in October 2018, one agency released a revised draft guidance on premarket considerations for medical device cybersecurity. The guidance refines expectations related to the cybersecurity considerations a manufacturer should adhere to during the design and development of a medical device. Build threat intelligence and analytics capabilities: Stakeholders should understand potential threats and develop plans for responding. Consider penetration testing when designing devices or implementing new IT systems. The idea is to try to hack a device or system before it becomes connected to the internet to make sure it is resilient.
Stakeholders should understand potential threats and develop plans for responding. Consider penetration testing when designing devices or implementing new IT systems. The idea is to try to hack a device or system before it becomes connected to the internet to make sure it is resilient. Minimize internal threats: Health care is an industry where people inside the organization pose a bigger threat than outsiders. Nearly 60 percent of cyber-related incidents in the health sector involve someone from inside the organization. According to our research, Communicating the value of cybersecurity to boards and leadership, organizations identified hosting regular cyber threat simulations as a top practice for educating employees.
The internet is making the world a much smaller place by connecting all of us (and our devices and data) in fewer than six steps. While the benefits of a cyber-everywhere environment are enormous, cyber risk is now one of the biggest threats our health care and life sciences clients face. Once stakeholders understand the potential risks in this digital world, they can be better positioned to safeguard their data, their customers, and consumers.
3. Is your fish tank listening? A roadmap to dipping your toes in the IoT waters, TechTarget, November 10, 2017
6. Statement on FDA’s efforts to strengthen the agency’s medical device cybersecurity program, October 1, 2018Help clients understand the strategic context and full economic picture before embarking on an IoT journeyAfter years of hype, anticipation, and steady uptake, the Internet of Things (IoT) seems poised to cross over into mainstream business use. The number of businesses that use the IoT technologies has increased from 13 percent in 2014 to about 25 percent today. And the worldwide number of IoT-connected devices is projected to increase to 43 billion by 2023, an almost threefold increase from 2018.
This level of uptake is both a result and an impetus of the developing technologies that underpin the IoT. For one, technological advancement means that IoT technology will become easier to implement, opening the door for a wider variety of companies to benefit from IoT applications. Indeed, although large enterprises began to invest their sizable resources in IoT technologies years ago, the beneficiaries of this latest wave of IoT maturity will be small and medium-size enterprises. While they may not have the means to execute bespoke implementations, they can still invest in easy-to-use IoT solutions.
As frequent investors in midsize companies, private equity (PE) funds should re-evaluate the IoT as a sector that can help create significant value. To that end, this article will serve as an overview of the growing market for the IoT, the technology’s major applications, and the elements within the IoT technology stack. These insights can then be translated into business benefits for PE funds interested in becoming involved with the IoT as investors, owners, and partners.
Sidebar Varied growth within the IoT depending on underlying technology Because IoT technologies are at different levels of novelty, they are projected to grow at different rates. Wide-area IoT networks extend over large geographic areas, in which connected objects typically communicate at a low data volume. The number of associated devices is projected to grow at 30 percent per year from 2016 to 2022. Wide-area IoT is expected to benefit from the rollout of 5G technology, which will rapidly increase bandwidth and improve network performance. In addition, emerging low-cost alternatives to cellular technologies will facilitate the growth of new wide-area IoT networks. Short-range IoT networks cover small areas. They are primarily found in applications for Industry 4.0 and smart homes and are projected to grow at 20 percent per year from 2016 to 2022. Smartphones, a mature product category, are projected to grow at 3 percent per year. The advent of 5G connectivity might elevate growth rates because of demand for new equipment. Personal computers and tablets, another mature category, is stable at 0 percent annual growth. Although tablets still see some uptake in enterprise settings, personal computers are already in decline as a category.
Advanced principal technologies and a proliferation of devices have helped fuel the growth of IoT technologies. In fact, investments in IoT technology are projected to grow at 13.6 percent per year through 2022 (see sidebar “Varied growth within the IoT depending on underlying technology”). Further growth in the coming years will be possible thanks to new sensors, more computing power, and reliable mobile connectivity.
Sensor technology—embedded in IoT devices—will continue to become cheaper, more advanced, and more widely available. In turn, this availability and cost-effectiveness will make new sensor applications possible, including large-scale monitoring and detection. Meanwhile, computing power has increased about 100 times in the past 15 years. Applications such as real-time analytics and artificial intelligence can thus shift activity from local devices toward cloud and edge computing solutions. In addition, improved mobile connectivity with the advent of 5G will allow new applications for experiences such as augmented and virtual reality.
Finally, the IoT market will grow because existing IT devices will need to be linked to the IoT. Growth in traditional connected IT devices is admittedly moderate—about 2 percent per year. However, the installed base of more than five billion smartphones, two billion personal computers, and one billion tablets indicates a massive market for device integration.
Sidebar IoT solutions at two private equity–owned companies Two companies had recent successes improving their business operations with IoT tools. One pest-control company deployed a fully automatic solution that uses cellular connectivity to continuously monitor and control pest activity. This solution’s features made it more effective for customers than conventional pest-control services and was highly profitable for the provider. Ultimately, the IoT tool replaced the standard physical and manual pest-control tools, avoided the use of pesticides, and generated data and documents required for regulatory compliance. Similarly, a specialty-chemical company used a suite of IoT solutions to improve its manufacturing and supply chain performance. The company was able to track overall equipment effectiveness online, eliminating bottlenecks in its operations, which led to significantly improved output. These companies’ results are typical. Implementing IoT solutions often generates efficiency gains of 20–30 percent by improving performance in areas such as delivery time and pricing for tailored opportunities. In addition, these solutions can help position private equity owned companies for their next phase of growth and new investors.
The IoT already numbers more than 200 known applications in enterprise settings, but IoT adoption isn’t limited to large companies. And early adopters have moved beyond pilots to scale IoT solutions across their businesses. Indeed, IoT technologies have already given rise to a number of landmark applications in sectors as diverse as Industry 4.0, smart cities, smart homes, connected cars, and e-health. Furthermore, advances in the technologies that contribute to the IoT mean that all affected sectors can now access functionality that did not exist five years earlier. For instance, B2B companies have started using Industry 4.0 technologies to maintain direct connections to their products in the field. This constant monitoring makes predictive maintenance possible and improves efficiency and equipment uptime (see sidebar “IoT solutions at two private equity–owned companies”).
The IoT technology stack has advanced over the past five years—in the meantime, each layer holds significant market growth opportunities. Device-enablement platforms have an especially strategic advantage of enabling related IoT growth while still in their own growth phase.
Smart devices—the foundational layer of the IoT technology stack and the most mature product category—are dominated by large manufacturers and specialist suppliers and enjoy healthy market growth (Exhibit 1).
Exhibit 1 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
The connectivity layer of the IoT technology stack is most tightly bound to mobile-network operators that offer standard cellular connectivity. A small number of well-financed start-ups have targeted this layer of the stack and have made progress in subsegments such as low-power wide-area connectivity. Connectivity technology occupies a still-growing market that’s strongly influenced by international standardization in this technology layer.
In the third layer of the stack is cloud computing (which facilitates central processing and storage of data) and enablement platforms (which facilitate access to devices, data across devices, and connectivity standards). Complementary analytics and computational tools have emerged to interpret, visualize, and produce insights from device data. Together, these platforms have proliferated and developed over the past five years and now simplify device integration and application implementation—a favorable growth outlook for key players.
The final and top layer, business applications, will continue to be highly fragmented, with many disparate solutions and established companies coexisting with significant start-up activity. Because of its relatively early life, the largest IoT financial opportunities will likely come from this layer of the stack. However, cloud computing and device-enablement platforms will also be technologically and financially important.
Cloud platforms, the hardware and operating environments of web-based data centers, developed quickly over the past half-decade and now grow at a CAGR of 18 percent. During that time, large technology providers contributed their data-storage capacity and computing power as crucial fuel for the growth of IoT applications, which helped create numerous sophisticated functionalities for security and analytics. These functionalities were aided by strategic, technical partnerships between providers of specialized services that further augmented the value of cloud computing. For instance, a provider of cloud infrastructure might partner with a supplier of analytics solutions. In that vein, advances such as mobile edge computing (which reduces network congestion and improves application performance) can make IoT solutions easier to implement and use.
Sidebar Applications of device-enablement platforms Device-enablement platforms make many uses of the IoT technologies possible. This role has made them a lynchpin of the technology stack. Some of the most important IoT applications of device-enablement platforms, which are now worth €2.1 billion in revenues, include the following: Device connectivity, or basic data connections through a platform, plus troubleshooting for all IoT devices Remote monitoring for real-time status monitoring Remote control for IoT devices Incident management allowing for automatic reset and repair procedures for malfunctioning equipment However, device-enablement platforms are also still heavily used for traditional IT equipment, even though the offerings for the IT market and IoT market tend to come from different companies. The most significant capabilities of device-enablement platforms for IT, a €8.3 billion revenue market, include the following: Unified support plays a role in troubleshooting IT equipment, access management, and file transfers.
Remote access allows users to access and directly control IT equipment, including local data and software tools. In small- or home-office and small and medium-size enterprise settings, users generally use standard platforms; meanwhile large enterprise customers might use proprietary solutions and customized versions of standard platforms.
IT management involves monitoring and error detection, patch management, over-the-air updates, and data backup.
Augmented reality field support is training, instruction, and direct online support for field professionals (such as repair technicians and machine operators).
Device-enablement platforms—connecting devices, cloud providers, and applications for optimal processing in IoT settings—are a notable source of growth and value. In a nutshell, device-enablement platforms improve financial performance across cost, revenue, and operating efficiency, especially for midmarket companies (see sidebar “Applications of device-enablement platforms”). These platforms’ ease of implementation helps midmarket companies take advantage of IoT opportunities, even as these companies have fewer resources for bespoke solutions compared with major enterprises.
Our research indicates that as device-enablement platforms become more important, in part due to uptake among small-to-medium-sized enterprises and small- and home-office users, their corresponding revenue pools will continue to grow at an average CAGR of 24 percent, 48 percent for the IoT use cases (Exhibit 2).
Exhibit 2 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
The majority of the device-enablement value pool is based in the Americas, where it was worth €5.5 billion in 2018. Device enablement’s importance to the IoT and its global revenue growth also means that both technological and business opportunities will be almost geography-agnostic and grow at similar rates. And although enterprise customers will remain the largest customer segment, device-enablement platforms will see fast uptake among small and mid-sized customers.
The growing market for IoT technology reflects some of the ways in which maturing technologies have begun to fulfill the promises of the IoT. PE funds should evaluate opportunities to leverage IoT in their portfolio companies and look for emerging investment opportunities in both the IoT market and in sectors that can reap outsized benefits from these technologies.​Companies often see Internet of Things (IoT) projects stall or fail despite increased spending on these initiatives. However, improvements in areas such as security, data management, and performance could help companies better manage their investments.
While enterprise spending on Internet of Things (IoT) technology is growing briskly, many projects have struggled. The good news: Steadily improving technology is helping to overcome some of the barriers to IoT adoption. The five vectors of progress laid out here aim to help business and technology leaders time their investments effectively.
In the last two years, vendors have brought to market numerous solutions designed to protect IoT devices from attack at both the hardware and network levels 1
Major IoT platform providers now boast dozens of partnerships and integrations with providers of IoT component technologies
Low-power wide-area networks are providing low-cost connectivity for IoT devices in nearly 100 countries 2
Launches of hardware and software products that support “edge computing”—analyzing data close to where it is generated rather than in the cloud—are up more than 30 percent so far in 2018 compared to all of 20173
Enterprises are investing big money in Internet of Things technology. One three-year projection foresees companies spending nearly $15 billion on IT consulting and systems integration services to build and implement IoT solutions.4 As this market develops, it is becoming increasingly specialized. Each of the major market segments—enterprise/industrial, consumer, and services/public sector—presents distinct opportunities to create value through diverse applications. (See table 1.)
Learn More ​Explore the Signals for Strategists collection ​Subscribe to receive updates on Internet of Things
The IoT is advancing along a bumpy road, however, with technical challenges keeping many initiatives from achieving their goals.5 In a 2017 survey, more than 1,800 IT and business decision-makers in the United States, United Kingdom, and India reported that close to three-fourths of their IoT projects were failing.6
The reasons are various. Multiple enterprise surveys identify security as a top IoT deployment challenge.7 Other challenges include implementation complexity and costs8 and lack of talent with necessary skills.9 Going to the heart of the value of the IoT, some enterprises are finding it hard to manage, analyze, and derive benefit from IoT-generated data,10 and they struggle to process it in real time to gain actionable insights.11 Fortunately, progress in IoT technology is helping to overcome these obstacles.
We see further adoption of IoT technology propelled in part by progress along five vectors, each of which addresses an important challenge. These progress vectors are not all applicable to every industry or application type. But collectively they will likely continue to help drive adoption of IoT solutions and create new possibilities for business and technology leaders.
New device hardware is helping to overcome the technical challenges of securing IoT devices, while machine learning is helping to secure the networks that connect them. Earlier generations of IoT devices often lacked the necessary computing and battery power to run traditional cybersecurity applications and protocols, leaving them vulnerable to attack.12 But recently, microprocessor manufacturers have introduced low-power hardware products that embed security features—such as providing trusted identities to certify devices on networks—directly into IoT devices.
Securing IoT networks has also been a challenge in part because existing security tools designed for corporate IT networks were poorly suited for recognizing threats in networks of IoT devices. But cybersecurity solutions tailored for IoT networks are becoming widely available. Some use machine learning to recognize IoT devices’ unique network activity and behaviors to spot anomalies and potentially compromised devices; the city of Las Vegas, for instance, is using machine learning-based threat detection to monitor its smart city infrastructure for possible intrusions.13
Things are getting easier for companies looking to develop and deploy IoT solutions, thanks to the introduction of IoT platforms: software that makes it easier to integrate IoT hardware, networks, and applications.14 Providers are mitigating the complexity of building solutions by preintegrating third-party technologies through vendor partnerships.
Over the last two years, leading IoT platform providers have launched and expanded their partner ecosystems and now boast dozens of major vendor partners each. To illustrate how preintegrated components can accelerate the development of IoT applications, several platform providers report helping clients get proofs of concept and pilots up and running in a matter of weeks through their partner ecosystems.15 IoT platforms are already a common element of enterprise IoT deployments: In a recent survey, 57 percent of IT decision-makers said their companies already used them for their IoT projects; another 35 percent said they planned to.16
In addition to IoT platforms—which provide “horizontal” capabilities that can make it easier to build a wide variety of applications—“vertical” IoT solutions continue to arrive on the market.17 These offerings preintegrate sensors, devices, analytics, and other components to create complete solutions. Manufacturers have taken advantage of such turnkey IoT solutions, but they are spreading to more industries. One luxury clothing retailer deployed a platform with preintegrated software, sensors, in-store analytics, and RFID tags from different vendors to gain insights on shopper behaviors and real-time inventory visibility.18 (To learn more about the turnkey IoT trend, see Turnkey IoT: Bundled solutions promise to reduce complexity and accelerate ROI19.)
Low-power wide-area networks (LPWANs) are proliferating worldwide, providing connectivity at low cost and with low power requirements, a crucial advance for a major class of IoT application that relies on battery-powered sensors and spans large geographical areas.
Major telecom players have launched more than 40 LPWANs.20 Smaller LPWAN specialists are also expanding their proprietary networks globally; networks based on the LoRaWAN standard now cover 100 countries around the world.21
Batteries powering LPWAN sensors can last for years, with the networks providing connectivity for IoT devices for as little as $3 per year.22 In comparison, cellular connectivity for IoT devices can cost at least a few dollars per month.23 Rapidly falling LPWAN module prices can also help reduce implementation costs; some are already less expensive than traditional cellular modules.24 ABI Research predicts that LPWANs will connect more than 4 billion IoT devices by 2025, making it the fastest-growing IoT connectivity option.25 (To learn more about how low-power wide-area networks enable IoT adoption, see Internet of Things: Dedicated networks and edge analytics will broaden adoption26.)
The growth of these LPWAN networks is helping drive adoption of IoT-based devices for applications such as condition-based monitoring and optimization of capital assets in smart cities, smart utilities, and smart agriculture projects. One industrial equipment maker is using LPWAN technology to remotely monitor connected boilers, for instance, which would have been too costly with other connectivity options.27 And an Asian water utility firm is using LPWANs to connect smart water meters, gaining better access to meters located underground and in basements than cellular options could deliver.28
AI technologies such as machine learning and computer vision are increasingly being used to analyze IoT-generated data and automate operational decision-making. Nearly every major IoT platform vendor has now augmented its offerings with AI capabilities.
The rich insights and self-learning that AI can provide enhances the value and utility of the IoT in applications such as process optimization, predictive maintenance, dynamic routing and scheduling, and security. For instance, machine learning can reveal hidden patterns in airplane engine performance to make predictive maintenance feasible.29 Seeing new patterns in changing data can be crucial in applications that monitor and respond to changing conditions such as weather in agricultural settings, vital signs in health care, and operating parameters in industrial settings. (To learn more about the convergence of IoT and AI technologies, see Intelligent IoT: Bringing the power of AI to the Internet of Things30.)
Analysis of data generated from IoT devices is increasingly occurring not in the cloud but at the network “edge,” physically close to where the data is generated—on local servers, micro data centers, or even on the device generating the data. New hardware and software product launches related to edge computing and the IoT have increased more than 30 percent so far in 2018 compared to the entire year of 2017.31
Analyzing data at the edge sidesteps the latency associated with transmitting data between the sensors that generate it and the cloud-based applications that analyze it. Lower latency makes it possible to generate real-time alerts and insights that can improve operational safety and performance in industrial, enterprise, and smart city settings, among others. For instance, performing analytics in micro data centers positioned near its plant, a major chemicals manufacturer gained real-time visibility into plant operations, enhancing fire safety and equipment uptime.32 Analyzing data at the edge can also help reduce data transmission and storage costs. A major European rail operator pre-processes data on smart sensors before sending it to the cloud for predictive railway maintenance to save on data transmission costs.33
Additionally, AI technology is increasingly making its way onto edge devices. Major cloud providers have been tailoring their AI solutions for on-device deployments, while manufacturers are embedding AI capabilities directly into smaller, low-power chips designed specifically for smart sensors, cameras, and other IoT devices. Deploying AI at the edge may help avoid running afoul of data privacy regulations and reduce dependency on unreliable network connectivity in remote areas.
Gartner predicts that the majority of industrial IoT data analysis will happen at the edge by 2022, up from less than 10 percent last year.34 (To learn more about how edge computing empowers IoT applications, see Internet of Things: Dedicated network and edge analytics will broaden adoption.35)
The five vectors of progress described above are increasing IoT technology’s value in many industries: reducing risk in health care36 and banking,37 improving operational costs and uptime in mining38 and energy,39 enhancing service delivery in utilities40 and retail,41 and more. This progress is making it easier in some instances for executives to make a sound business case for investing in an IoT solution. As barriers to adoption of IoT technology in the enterprise continue to fall, business and technology leaders would do well to keep an eye on these vectors of progress.Leads the firm’s global work in digital manufacturing and collaboration with the World Economic Forum on technology adoption
April 16, 2018 Pilot purgatory sounds like a hectic aviator schedule, but with the Internet of Things, it signals pilot programs traveling at a snail’s pace – if at all.
While most businesses with pilots believe in IoT’s economic potential, a McKinsey survey in May 2017 found that less than 30 percent of pilots are starting to scale. Eighty-four percent of companies were stuck in pilot mode for over a year and 28 percent for over two years.
Pilots that scale successfully possess common success factors (see figure above). Here are seven based on our research and observations:
Secure CEO support. IoT projects that scale positively have a CEO leading the push. Support from the CEO shepherds a project past the bumpy spots and defends it throughout the organization. Start simple, execute relentlessly. Sustaining momentum requires wins. Be wary, though, of declaring victory too early. Pick a simple use case and follow through relentlessly until you capture value. Successes help land support of frontline employees and expose vulnerabilities around the need for process reengineering, talent, culture and alignment, and go to market. Ponder outcome vs. technology. Rather than becoming enamored by technology, ask more nuanced questions around the business model before choosing a pilot: Value proposition: What is the offering? What user needs does it address? Why is it better? How does it create customer value?
Delivery model: What is the go-to-market model? What parts of the value chain and functions must change? Which ecosystem partners must unite to deliver this?
Economic element: It is easier to see the link to value for operational use cases (e.g., smart factory-related) than it is for companies seeking to drive revenue growth through IoT offerings. Our research shows most value created becomes consumer surplus, leaving a portion for a provider ecosystem to capture. Companies must ask: What portion of this value will the customer share? How many people in the value chain will lay claim to this? What portion of this value flows to the bottom line? What are direct and indirect ways to monetize this? During the pilot stage, testing the business model and the technical viability will improve confidence in delivering value. Focus on people. Companies that scale IoT enlist employees with an entrepreneurial bent and who embrace change. They help set a transformation’s pace and tone. Also required: cross-functional collaboration among those with deep process knowledge, analytical acumen, and digital and IT experience. “Business-building leadership” assists in translating technology to business outcomes and commercial opportunities. Recruiting and retaining this talent is hard, especially in bureaucracies. Treat data as a transformational asset. Properly used data creates a sustainable business advantage and innovative business models. But consider the data sources. One company couldn’t perform analytics on its equipment because it didn’t own the data. Bring clarity around your technology stack. With today’s plethora of IoT platforms, picking the right one proves hard. Ask a set of clear questions around five areas – applications, data management, infrastructure needs, security and edge process/control – to select the right platform. Build an ecosystem of tech providers, not a logo collection. Few website logos reflect meaningful relationships. One company invested $1 million in a test plant after a handshake between its CEO and technology provider. The result: a science experiment that could not scale. Meaningful relationships require a clear value proposition for each party, skin in the game, common objectives, and successes in delivering joint value.
IoT trials get stuck in purgatory for many reasons. This starter list reflects what we see as emerging success criteria.What makes the Internet of Things (IoT) different from the traditional Internet? People, for starters. The IoT doesn’t rely on human intervention to function. With the IoT, sensors collect, communicate, analyze, and act on information, offering new ways for technology, media and telecommunications businesses to create value—whether that’s creating entirely new businesses and revenue streams or delivering a more efficient experience for consumers.
But this also creates new opportunities for all that information to be compromised. Not only is more data being shared through the IoT, among many more participants, but more sensitive data is being shared. As a result, the risks are exponentially greater.
Take the smart home as an illustrative example. Imagine a garage door opener with the added functionality to deactivate the home alarm upon entry. This is a convenient feature for a homeowner entering their home in a hurry. However, now the entire alarm system could potentially be deactivated when only the garage door opener is compromised. The broad range of connectable home devices—TVs, home thermostats, door locks, home alarms, smart home hubs, garage door openers, to name a few—creates a myriad of connection points for hackers to gain entry into IoT ecosystems, access customer information, or even penetrate manufacturers’ back-end systems.
Many technology, media and telecom companies are already grappling with these cyber risk challenges. What are they finding? In this issue of Flashpoints, we’ll take a closer look at some of the more notable developments in the battle to combat cyber risks and take advantage of new opportunities as the IoT expands its reach:NEW YORK, Oct. 24, 2019 — With the number of connected Internet of Things (IoT) devices anticipated to swell beyond 41 billion by 2025 according to a forecast from IDC estimates and the number of cyber attacks on such devices growing exponentially by the day, organizations should put security at the forefront of their priorities around IoT solutions. In an effort to help organizations shore up their security postures, Deloitte offers five tips to address IoT security in the products that organizations deploy in their environments and encourages manufacturers that make connected products to take a secure-by-design approach.
From cameras to toothbrushes, thermostats to hospital infusion pumps, connected devices are actively being targeted by cyber adversaries determined to compromise corporate and individual privacy, construct botnets, place malicious software and steal intellectual property.
The risk of compromise to a connected device is too great to ignore and often too late to reactively respond to. Organizations should adopt a proactive, secure-by-design approach while strategically and intentionally working to monitor and patch outdated legacy equipment, software and infrastructure.
—Sean Peasley, partner, Deloitte & Touche LLP, and IoT security leader for Deloitte cyber risk services.
California is leading the charge with a new Internet of Things Security Law taking effect on Jan. 1, 2020, requiring all IoT devices sold to be equipped with reasonable security measures. Consequently, organizations should prepare and protect their companies, customers and communities. The benefits of IoT connectivity far outweigh the investment in cyber measures to ensure the integrity of the devices, networks and programs.
Take note of every endpoint added: The expanse of IoT increases with every endpoint added into a network. This adds more vulnerabilities and has become a more popular and destructive cyber attack. While the adversarial landscape is always changing, Deloitte advises organizations to bring as much of their endpoint footprint under their security management in order to better secure the attack surface. Industry analysts predict that spending on IoT endpoint security solutions will be more than $630 million in 2021. Once these devices are managed, integration of security tools can be a more effective security focus for the organization. As with most domains within cybersecurity, security professionals realize that in order to meet the complex security challenges of their organizations, they should formulate a sound security strategy and constantly evolve by making continuous improvements to best mitigate their risks.
Align operational technology, IT and security: In addition to IoT, enterprises are managing multiple digital transformation initiatives simultaneously. Yet, according to the “Deloitte Future of Cyber” study, less than 10% of cyber budgets are allocated to these efforts. For companies to be successful with IoT initiatives, they need a new approach. One that helps them understand enterprise and cyber risks; develop a plan to prioritize and mitigate those risks; and then operationalize these efforts by obtaining alignment across key stakeholders: operational technology, IT and cybersecurity. Peasley adds, “IoT spans operational environments as much as it includes wearables, connected cars and products. Organizations should proactively plan for how to identify, track, patch and remediate around how it all could impact their organizations and ecosystems.”
Know the players in your ecosystem: Since the interconnectivity of third-party hardware, software or services may be the source of a security breach, it’s imperative to consider how a covered device interacts with such third parties. Ideally, contracts with third, fourth, and fifth parties should address security updates and concerns. Organizations should establish a third-party risk management program to evaluate the cyber risks of their third parties and supply chain partners.
Employ AI and ML to detect anomalies that humans can’t: You can’t prevent what you don’t know about. Artificial intelligence for IT operations (AIOps) has grown from an emerging category to an IT necessity. AIOps platforms are uniquely suited to establish a baseline for normal behavior and detecting subtle deviations, anomalies and trends. This is significant as IoT turns much of the physical world into robots powered by AI. Organizations should take both a secure by design (DevSecOps) approach in tandem with an AIOps approach to both prevent and identify cyber attacks.
Conduct vulnerability assessments on devices: As cyberattacks continue to grow, organizations should have confirmation that their connected devices — and the environment in which they’re deployed — have been designed, built and implemented with security in mind. Whether through basic testing or a bug bounty program, testing can provide assurance around the security posture of an organization’s devices.
Deloitte’s Cybersphere is a state-of-the-art destination to help organizations explore their most pressing cyber challenges. The Cybersphere features a 24/7 threat monitoring and reconnaissance “Watch Floor,” and labs designed for cyber teams to increase capabilities and confidence as they face ever-evolving cyber threats. It also features a Cyber IoT Studio where organizations can test the security of their connected devices on their networks to help identify whether their most critical assets are secure.
Technical testing services for IoT devices — from autonomous cars and connected medical devices, to industrial control systems, building automation and smart cities.
A center of excellence that provides leading practices for device security testing and certification readiness methods.
Diverse IoT ecosystems to architect and test heterogeneous technologies for a multitude of industry-specific, use-cases with the latest security and control solutions for on-premise and cloud integrations.
Deloitte provides industry-leading audit, consulting, tax and advisory services to many of the world’s most admired brands, including nearly 90% of the Fortune 500® and more than 5,000 private and middle market companies. Our people work across the industry sectors that drive and shape today’s marketplace — delivering measurable and lasting results that help reinforce public trust in our capital markets, inspire clients to see challenges as opportunities to transform and thrive, and help lead the way toward a stronger economy and a healthy society. Deloitte is proud to be part of the largest global professional services network serving our clients in the markets that are most important to them. Our network of member firms spans more than 150 countries and territories. Learn how Deloitte’s more than 312,000 people worldwide make an impact that matters at www.deloitte.com.Regulations should do more than tell companies what they can’t do—rules should help guide corporate players through minefields of uncertainty. It’s a lot of responsibility, especially when it comes to still-developing IoT technology that holds great promise—and real risks.
Imagine Pandora sitting and staring at her box. In a few moments, she will open its bronze lid and release fear, death, and plague into the world . . . but right now she is wracked with uncertainty. What’s inside? The box might contain untold riches to help her new kingdom—but Zeus warned her never to open it. Should she open it and risk punishment, or leave it shut and possibly leave valuable resources untapped?1
In many ways, the story of technological change and regulation is Pandora’s story—technology can be understood only through the lens of risk and uncertainty. Technological change by its very nature causes uncertainty: How could this new technology be used? How might it improve people’s lives? How may it harm those same lives? With the Internet of Things (IoT) at the peak of its hype cycle, these questions are swirling more than ever.2 The challenge is the risk that accompanies all of this uncertainty. Like Pandora, companies looking to implement IoT solutions are facing a box that may contain significant new revenues—and, quite possibly, technical difficulties, future regulatory challenges, or security breaches. Do they risk opening the IoT box and facing these uncertain regulatory issues, or do they leave it closed and risk missing out on the potentially most transformative technology since the Internet?
One key to making an informed decision and ameliorating risk is to reduce uncertainty—in particular, uncertainty about future regulation that may affect IoT practices. For regulators too, pressure is mounting to protect consumers even while IoT technology itself is still developing.3 But with the often-blunt instrument of regulation, this could become a catch-22 of inaction: Regulators take no action because they are uncertain about the technology, so companies take no action because of uncertainty about regulation, slowing technological adoption . . . and further slowing the action of regulators (see figure 1).
But it takes only a shift in perspective to break this catch-22. Consider that government’s relationship with IoT technology goes beyond regulation—agencies are also consumers and developers of IoT infrastructure and applications. In these two roles, government can influence the development of IoT technology, guiding it toward safe, secure, and responsible uses—and saving regulation for indisputably necessary areas such as critical infrastructure or health systems (see figure 2).
To illustrate exactly how governments at all levels can help to guide the IoT’s development—protecting citizens while still encouraging technological growth—this article makes use of a body of industry-specific use cases. The goal: to reduce overall uncertainty, allowing policymakers to understand this complex issue and businesses to see where government action is likely, thereby reducing the risk of their investments in IoT technology.
The first step to reducing the uncertainty and risk around the IoT is to get a better picture of what it is, and how government agencies may need to interact with it. The IoT is the architecture and suite of technologies needed to create, communicate, aggregate, analyze, and act upon digital information in the physical world (see figure 3).
With such a broad definition, the applications and impacts of connected technology on the public sector can cover an equally wide spectrum. Utility providers have created mesh networks of smart meters capable of hosting other communications.4 Automakers and tech companies are investing in autonomous vehicles that may require new public infrastructure.5 Customer advocacy groups are calling on government to create strenuous security and privacy standards for new connected devices.6 Even with this bewildering mix of uses, roles, and industries, agencies’ interactions with IoT technology can be grouped into three categories:7
Government as IoT end user. To the extent that reporters and academics have addressed the government’s relationship to the IoT, articles (including our Anticipate, sense, and respond 8 ) have focused on the question of how government can harness connected technology to better provide services. These address how schools, public utilities, law enforcement, and other government functions can take advantage of the new technologies to break traditional trade-offs and find innovative ways to serve the public. In the interest of space, we will address less commonly discussed roles of government.
Government as infrastructure provider. The investigation of what government policies or regulation may be necessary for effective use of IoT technology begins with understanding connected infrastructure. Just as governments are responsible for building and maintaining their countries’ highways for vehicles, they may be called upon to provide the infrastructure for the IoT. However, with so many different types of communications mechanisms and protocols within the IoT stack, it is unclear at this point exactly what is required to create foundational infrastructure for IoT.
Government as regulator. New technologies necessarily bring with them new uncertainties about their use. These uncertainties represent a risk to the public, which governments at all levels are responsible for ameliorating. Complicating this issue is that, at the emergence of a new technology, the full array of its eventual possible uses cannot be known. Therefore, it can be quite difficult to forecast the potential dangers that such technologies pose to the public.
Already from these three roles, we can see a tension forming in governments’ goals with relation to new technology. As an infrastructure provider, governments seek to support and incentivize further technological development to create new value and new public goods. On the other hand, governments have a duty to protect the public from the risks of both the known and unknown uses of those new technologies. Striking the right balance between these goals, and then crafting appropriate policies to achieve them, is the chief challenge facing officials dealing with emerging technologies.
The first step in order to strike that balance is to understand what the IoT needs in order to reach its full potential. To do so, we’ll look at some industry-specific case studies that reveal the key bottlenecks impeding the IoT from creating new value.
The IoT is fundamentally about bringing the benefits of information to the physical world. Therefore, for the technology to create value for customers, companies, or society at large, the information created by sensors needs to reach those individuals or machines that can take informed action on it. In other words, information must be able to complete the Information Value Loop. In this sense, the race to create IoT solutions is really a race to alleviate a series of bottlenecks that restrict or stop that flow of information. Understanding where and how these bottlenecks are restricting the flow of information, then, can help companies and government alike understand what is holding back the development and implementation of IoT technology as a whole.
Through an extensive IoT research campaign, Deloitte has built up a large collection of use cases, with IoT examples in every industry.9 In analyzing these use cases, we found that once companies began generating data with IoT technology, the most common bottlenecks arose in the communication, aggregation, and analysis of that data.10 By looking at each of these bottlenecks, we can begin to sketch out where government action is needed and where it may be counterproductive. (See figure 4.)
At least as far back as the Industrial Revolution, there has been a clear role for governments to coordinate, if not directly provide, the basic infrastructure needed for economic development.11 When infrastructure meant highways, bridges, canals, and airways, the government’s role was rather clear: In situations where private industry could not or would not act, the public sector would provide the physical roads, ramps, and rails over which the traffic of commerce could move.12 Same with power lines and gas connections, and with telephone lines and submarine communications cables: The government has an interest in linking citizens, even in rural areas that companies might find unprofitable to service.
But when it comes to the Internet of Things, government’s role is less clear—as are its possible actions as an infrastructure provider. After all, with IoT technology, it is information—not trucks, planes, or rail cars—that creates value.
No question, though, that government does play a key role. While you may not be able to see it, information still travels via public-sector infrastructure much as cars traverse highways. For example, every smartphone is able to deliver driving directions only because of the multibillion-dollar government investment in GPS satellites13—not to mention the electromagnetic spectrum, a finite resource that government regulates to carefully share among competing public, private, and even military uses. With the number of IoT-connected devices expected to increase by 3 to 30 times over the next 15 years, the strain on existing spectrum allocations is enormous.14 So it is perhaps unsurprising that governments around the world are taking steps to open up more spectrum to wireless uses. Whether allocating previously unused spectrum to IoT applications or repurposing spectrum from older uses, governments are working to provide the raw materials that connected technology needs to grow.15
Perhaps most interestingly, where paving highways and laying track cost taxpayers millions, allocation of spectrum is technically free—save for the time it takes to do the work. In fact, the potential IoT-based advances mean that governments can in some cases actually generate significant revenue from reallocating portions of spectrum. Recently, both US and Canadian telecom regulators were able to raise billions of dollars from spectrum auctions, with the 2015 Canadian sale raising more than $2 billion and the US auction a year earlier generating a record $44.9 billion.16 In exercising its role as IoT infrastructure provider, a government may be able to efficiently allocate scarce wireless resources and, in the process, create benefits for both companies and taxpayers.
For connected technology to create real value, it should be able to sense not just one particular piece of data but data from multiple sensors and sources. In reality, this means that different devices from different manufacturers often must be able to seamlessly communicate and share data. To do so requires common standards for data format and communications protocols. At first glance, this represents a great opportunity for government to intervene in its role as regulator to create one common standard and accelerate the IoT’s growth.
However, government action on standards may be superfluous or even counterproductive. Industry is not insensitive to the need for standards and has formed a number of competing groups aimed at designing the standards of the future.17 While none of these standards has yet won out, that is more a function of the continuing development of the technology and market, rather than intransigence of the groups.
In fact, with many of the underlying standards in place for communication protocols, such as 4G and Wi-Fi, and device addressing, such as IPv6, the situation resembles the early days of mobile operating-system competition.18 In that arena, it was not government regulation but, rather, a dominant player creating a superior platform that created the de facto standard. Industry leaders produced winning mobile OS platforms that unified many elements of a fragmented technology landscape to produce industry standards.19
A similar process may be under way with IoT technology, leading both government and industry leaders to conclude that government regulation of IoT standards would be a mistake.20 While there may be a role for agencies to play in setting out IoT guidelines for specific critical industries—such as ensuring interoperability of electronic health data—full regulation of IoT standards may actually slow innovation rather than accelerating it.21
This is not to say that there is no role for government in its capacity as a regulator. The IoT’s expanding implementation means more and more data being generated about things and people. Companies aim to combine and analyze all of this data to create new insights and provide services to consumers. The catch: In the process, IoT technology may expose individuals’ privacy in new ways. Research shows that it can take as few as four data points from mobile communications to individually identify an individual.22 In analyzing data such as purchasing history or speed patterns of your connected car, an IoT system can unintentionally reveal sensitive private information such as attendance at a particular church or movements of a competitor’s sales force. Apart from obvious security concerns from such data attracting criminals and identity thieves, breaches may leave users justifiably uneasy.23
In the interest of building confidence in connected technology, there is an undeniable need for government to regulate the IoT from the perspective of consumer protection, especially as it relates to security and privacy. The difficulties will sound familiar to anyone involved in government regulation of technology: IoT applications are fast proliferating—with new technologies, processes, and uses emerging almost daily—while traditional regulatory processes are often measured and slow, with publishing a new rule in under three months usually possible only in an “emergency.”24 This is to say nothing of the legislative gridlock that can stall for years the authority to even make those new rules in the first place.25
Even beyond the general difficulties in regulating fast-moving technologies, privacy presents special challenges. As digital information moves rapidly around the globe, it can encounter many different regulatory regimes. Sure, companies can aim to comply with each nation’s privacy rules, but these different rule sets are often built upon entirely different legal conceptions of privacy, resulting in at times contradictory rules, making compliance with all rules impossible.26 If the IoT is to reach its potential, it will almost certainly involve collecting and transmitting data across national borders. Decades and centuries of transnational trade have firmly established regulation across borders, but data is both different and intangible, and nations’ underlying differences on the core concepts of privacy make such regulation highly unlikely for IoT technology. Issues with transnational fragmentation await resolution in a way that both protects consumers globally yet allows connected technology to thrive.27
In this way, we have returned to Pandora’s box—the fundamental issue of regulating new technology. Governments should step in to protect consumers in some way, despite uncertainty about rapidly changing technology. Similarly, companies working to develop IoT applications face uncertainty around potentially impactful regulations. That said, however new and expansive IoT technology might be, these uncertainties shouldn’t dramatically hold up development of either applications or regulations. For one thing, as we have seen, only a few areas actually demand regulatory intervention. Second, the consumer privacy and security issues raised by connected technology are not new. While the mobile nature of IoT technology may cause these issues to pop up in new and unexpected places, governments and companies are well equipped to deal with security and privacy issues once identified. In the United States, agencies such as the Consumer Protection Bureau and legislation like the Fair Credit Reporting Act are empowered to act to protect consumers from IoT-based security and privacy challenges, even if the pace of new IoT developments may require these familiar actors to pick up some new tools.
If regulation’s ultimate purpose is to encourage companies and others to take into account externalities such as security and privacy, there can be a number of effective tools that can accomplish this.28 Two untapped tools for governments at every level are their actions in other roles relating to IoT technology—namely, user and infrastructure provider—which, again, offer more certain and stable starting points than trying to hit the moving target of regulating a rapidly changing new technology. Agencies can use their activities as IoT users and infrastructure providers to help guide and shape the development of connected technology.
Set a good example: government as an IoT user. First and foremost, governments exist to provide services to citizens. Given the IoT’s tremendous power to increase efficiency and provide new services, it is no surprise that much of the discussion center on how agencies can use connected technology to better serve citizens. Hardik Bhatt, CIO of the state of Illinois, summarizes: “The first and very active role of government is government as a customer.”29 It is exactly by being large-scale consumers of connected services and technology that agencies can influence IoT development through buying power, not regulations. By setting responsible requirements and buying secure, privacy-respecting solutions, government can, as Bhatt describes, “start being the role model of how the Internet of Things technology can be used.”30
The impact of a public-sector role can go beyond the economic impact of the dollars that agencies spend to set up IoT solutions. It can extend to the heart of the technology itself. Humans can be both incredibly creative and also incredibly lazy, and programmers are no exception. As a result, once a programmer finds a successful solution to a certain problem, others tend to copy that code and paste it into new applications, skipping the usual rounds of testing. The jumbled result, dubbed “spaghetti code,” can introduce unintended bugs and flaws,31 and with fast-moving technologies, this problem has the potential to quickly spread security holes. While spaghetti code is a problem in every industry, government’s open, public-service nature may put it in a unique position to help the situation: By creating good, solid code and making it publicly available, an agency can be the source or seed for other organizations using connected technology more responsibly.
Reduce function creep: government as infrastructure provider. There’s no question that function creep—a product being used in unanticipated ways—can be an incredibly powerful tool for innovation, such as when a teacher noticed that a wallpaper cleaning putty made a good toy, giving birth to Play-Doh. But function creep can introduce critical security and privacy flaws into new technologies,32 exacerbated by a lack of purpose-built tools, forcing developers to plug in close-enough hardware and software. Government can play a strong role in limiting function creep—and thereby reducing the likelihood of security and privacy vulnerabilities—by making available stable infrastructure for connected technology.
Enable transparency: government as both user and infrastructure provider. The IoT-based distributed denial-of-service attack that shut down Internet access to millions of people on October 21, 2016, highlights a key vulnerability of connected technology. Many people whose devices were compromised by the Mirai malware that launched the attack were unaware that their devices’ security might be substandard; in fact, many did not even know their devices had been compromised.33
Whether dealing with security or privacy, transparency is a critical virtue. In the United States, for example, privacy is governed largely by contracts and user agreements, an arrangement that is untenable if companies conceal their usage of consumer data. Similarly, both governments and companies are powerless to begin to plug IoT cyber vulnerabilities unless they are aware of the basic state of their hardware and software. And when that hardware and software is compromised, each party needs to be able to share information about the attacks and signatures with each other.
In its dual role as IoT user and infrastructure provider, government can help to lay the foundation for this needed transparency.34 Transparency is a critical unsolved challenge in IoT technology, since there’s no practical way to adequately inform consumers about all the uses of their data stemming from potentially hundreds of small devices. Agencies can serve as a model of transparency by finding new ways to solve this challenge, clearly and concisely communicating to users what data is collected and how it will be used.
Similarly, as infrastructure providers, governments can begin to create stakeholder groups and information-sharing venues that can allow for the transparency necessary to combat cyber threats. Here companies can share information on attacks and threats, preemptively benefiting from shared information and concerns—better for everyone than regulators requiring them to reveal data losses. Finally, given the continued threat posed by botnets such as Mirai, governments should consider establishing a security rating system or evaluation organization for new hardware and software products. A public-private working relationship on the model of Underwriters Laboratory may be an effective model for quickly and efficiently establishing the baseline of transparency required for IoT security.35
These same principles can have a double impact at reducing uncertainty: Not only do they help governments act amid uncertainty around connected technology—they can help companies understand how regulators are likely to respond to IoT-related issues. These seemingly small actions can give companies the confidence to innovate and drive the technology further, while protecting citizens’ rights and personal information.
In this way, the IoT resembles Pandora’s box less than it does Schrödinger’s box:36 You can never know ahead of time whether the cat is alive or dead—if the technology will be a boon or a hazard—so you need to plan for both eventualities and try to build in as much certainty as possible. Of course, unknowns are inevitable and not necessarily fatal—after all, uncertainty around the state of the electron did not stop Erwin Schrödinger and others from building modern electronics; in fact, chances are that the touchscreen of the laptop or phone on which you are reading this article harnesses exactly those quantum effects.37 And for government, the key to ameliorating uncertainty, encouraging corporate innovation, and protecting citizens is to consider IoT technology as both user and regulator.The number of cyberattacks, data breaches and overall business disruption caused by unsecured IoT/IIoT devices are increasing because many companies don’t know the depth and breadth of the risk exposures they face when leveraging IoT devices and other emerging technologies.
IoT and IIoT are a set of business and technology innovations that offers many compelling benefits, but they also present significant cybersecurity risks and a greatly expanded attack surface. Mitigating these risks by understanding IoT/IIoT platform security can help organizations realize greater potential and benefits of these innovations.
The following top risks were outlined by leaders from Deloitte Risk & Financial Advisory’s cyber practice and Dragos in a recent Deloitte Dbriefs webcast, The Internet of Things and cybersecurity: A secure-by-design approach:
Not having a security and privacy program Lack of ownership/governance to drive security and privacy Security not being incorporated into the design of products and ecosystems Insufficient security awareness and training for engineers and architects Lack of IoT/IIoT and product security and privacy resources Insufficient monitoring of devices and systems to detect security events Lack of post-market/ implementation security and privacy risk management Lack of visibility of products or not having a full product inventory Identifying and treating risks of fielded and legacy products Inexperienced/immature incident response processes
Security needs to become embedded into the DNA of operational programs to enable organizations to have great products and have peace of mind. Today all sorts of products are becoming a part of cyber: from ovens to instant cookers, 3D printers to cars. Organizations need to consider what can actually go wrong with what is really out there and look at those challenges as a priority.
—Sean Peasley, a partner in Risk & Financial Advisory and the Consumer & Industrial Products leader and Internet of Things (IoT) Security leader in Cyber Risk Services at Deloitte & Touche LLP
Organizations need to think through this. There are a lot of requirements and they need to figure out a strategy. When looking at product security requirements, I see this as a challenging aspect as organizations get a handle around what they are manufacturing. There are organizations for example in industries such as health care, medical devices, and power and utilities that are starting to ask questions of their suppliers as they consider security before they deploy devices into their customer ecosystem. Where I see a lot of organizations struggle is in understanding system misconfiguration or not having the architecture they thought they did in order to make sure their manufacturing environment is reliable.
More than 4,200 professionals across industries and positions participated in and responded to poll questions during the Deloitte Dbriefs webcast, “The Internet of Things and cybersecurity: A secure-by-design approach” held May 30, 2019. Answer rates differed by question.
A majority (81 percent) of respondents indicated that information security is accountable for the securing of connected products in their organization. The information security team is still primarily where boards look to drive their cyber agenda but as the 2019 Future of Cyber survey indicates, cyber is becoming everyone’s responsibility. It is critical to understand that if you are the plant manager you likely have the responsibility to the safety and liability of the operation. But the challenge is that everyone does have a role to play. Ultimately, the CEO is going to be held accountable.
How confident are respondents that their organizations’ connected products, devices, or other "things" are secure today? Not very. More than half of respondents (51 percent) were somewhat confident, while 23 percent were uncertain or somewhat not confident, with only 18 percent feeling very confident in their organizations’ ability to secure connected products and devices. This may be as a result of there being an overall lack of standardization across industries for security and awareness of cyber risks and connected devices.
A positive revelation in the poll results was when 41 percent of respondents indicated that they look to industry and professional organizations for guidance in driving security-by-design within their organizations. Another 28 percent said that they look first to regulatory bodies and agencies that set the standards; and 22 percent indicated their leading practices were developed internally for providing that guidance in driving security-by-design.
According to Peasley and Lee, it is a favorable strategy for organizations to understand leading practices and standards of peer organizations first, and then look to the regulatory bodies that are starting to shape standards and regulations and help inform the standards and regulations that are to come.
These results conflict with another question regarding whether their product teams use a defined set of product cybersecurity requirements as input for requirements selection. Twenty-eight percent use an industry defined framework, and 41 percent indicated a custom framework, while 30 percent of respondents indicated “No” that they didn’t use a defined set of requirements. The results of this question indicate there is still much work to do across the industry to influence and inform on standards for cybersecurity.​Enterprises are increasingly complementing their cloud-based IoT solutions with edge computing to accelerate the pace of data analysis and make better decisions, faster.
Just a few years ago, many expected all the Internet of Things (IoT) to move to the cloud—and much of the consumer-connected IoT indeed lives there—but one of the key basics of designing and building enterprise-scale IoT solutions is to make a balanced use of edge and cloud computing.1 Most IoT solutions now require a mix of cloud and edge computing. Compared to cloud-only solutions, blended solutions that incorporate edge can alleviate latency, increase scalability, and enhance access to information so that better, faster decisions can be made, and enterprises can become more agile as a result.
Learn more Read more from the Internet of Things collection Explore the Emerging technologies collection Subscribe to receive related content from Deloitte Insights
That being said, complexity introduced by edge computing should justify the objectives at hand, which include scale, speed, and resiliency. A choice that goes too far in one direction typically introduces substantial operational complexities and expenses. Ultimately, the enterprise should take into consideration a full range of factors that reflect its own particular objectives in designing and building an IoT solution in the first place.
In this article, we discuss when and how enterprises can optimally make use of both the edge and the cloud in their IoT solutions. We explain the roles edge and cloud computing play, why the edge may be needed, and how to approach selecting a solution. We also explain some of the complexities with edge computing and provide some use cases.
What is edge computing Edge computing is a distributed architecture functionality, such as processing and storage, that is located closer to—even on—the very source of the data. Examples include cameras with on-device vision processing and wearable medical devices that send data to a mobile phone via Bluetooth. Given these qualities, making a balanced use of both edge and cloud computing is now often considered a key requirement of designing and building enterprise-scale IoT solutions. The key representative functionality often used at the edge can be seen in figure 1.
We have experienced a veritable explosion of cloud adoption in the past decade—the IT functionality of many modern companies exists exclusively, or in large part, in the cloud.2 Among the many benefits of the cloud infrastructure are cost effectiveness, scale, self-service automation, interoperability with traditional back-office systems, and centralized functionality.3
At the same time, the amount of sensor-generated data has grown strongly too, and this trend is expected to continue in the years ahead.4 Because data can become essentially valueless after it is generated, often within milliseconds, the speed at which organizations can convert data into insight and then into action is generally considered mission critical. Therefore, having the smallest possible latency between data generation and the decision or action can be critical to preserve an organization’s agility. However, as the speed of data transmission is inviolably bounded by the speed of light, it is only by reducing the distance that data must travel that the latency challenge can be mitigated or avoided altogether. In a cloud-only world the data ends up traveling hundreds or even thousands of miles, so where latency is critical to a solution, edge computing can become key.
According to one estimate, as much as 55 percent of IoT data could soon be processed near the source, either on the device or through edge computing. Indeed, scale plays a big role in this likely shift—growing data demands will likely put the focus on latency, and decreased latency could dramatically improve the response time, thereby saving both time and money.5
Latency is just one of the many reasons to drive the addition of edge functionality to an IoT solution. A fuller list of the potential benefits of edge computing is given in figure 3.
In bringing edge and cloud computing to life, an understanding of real-world cases can go a long way. Constant technology evolution, such as the eventual availability of 5G, often affects the cost/latency/balance equation. As such, it is pertinent to consider current conditions in making decisions rather than simply defaulting to previous choices. Being mindful of all drivers while designing an IoT solution is important, as multiple drivers may apply in a given situation.
The IoT can have a dramatic effect on an organization’s ability to be more agile. Given below are some ways in which the edge and cloud help aggregate and transmit data on behalf of enterprises connected by the IoT.
Enterprises are quickly moving toward an event-driven architecture and real-time automated digital processes.10 But when you consider that many manufacturers have multiple plants across geographies—each typically with unique characteristics and functional requirements— the challenge to maintain an exclusively centralized data-analysis capability in the cloud or at a corporate data center becomes apparent.
To be sure, cloud computing offers a number of benefits and it most certainly has a role in smart manufacturing. With data in the cloud, a centralized operations facility can monitor systems and processes across a large, possibly global, portfolio. It is also possible to undertake comparative analysis across the full portfolio that can determine potential for optimizations.
Still, we envision that an integrated edge–cloud architecture would provide the kind of speedy and nearly unimpeded connectivity that smart factories require.
Figure 4 illustrates how the edge and cloud typically work with sensors and devices on a manufacturing floor.
The device layer represents individual pieces of equipment that are connected to local operational technology and IoT capabilities for immediate interactions. At this layer, machine learning (ML) scoring or inferencing is done that is based on ML models trained in the cloud. Significant amounts of raw device data are also stored here.
represents individual pieces of equipment that are connected to local operational technology and IoT capabilities for immediate interactions. At this layer, machine learning (ML) scoring or inferencing is done that is based on ML models trained in the cloud. Significant amounts of raw device data are also stored here. While the device layer provides visibility and control of individual pieces of equipment, the plant apps layer provides visibility and control across all connected pieces of equipment in a plant. The edge connectivity layer provides the necessary connectivity between the individual pieces of equipment and the plant apps.
provides visibility and control across all connected pieces of equipment in a plant. The provides the necessary connectivity between the individual pieces of equipment and the plant apps. The enterprise layer, which is cloud-hosted, provides primarily visibility, and some control, across multiple plants—a portfolio view. Enterprise analysis and ML algorithms are developed in this layer to predict and provide actionable intelligence—the ML models trained and re-trained here make use of data from across the whole portfolio of plant equipment and are then “pushed” to the edge and eventually to the IoT software at each piece of equipment, making operations smarter with the information.
The rise of smart, connected IoT devices and ubiquitous connectivity has created an opportunity to transform buildings—whether they are offices, retail stores, factories, or hospitals—into cost-efficient, responsive environments for delivering exceptional experiences to their occupants.11 Smart buildings are digitally connected structures that combine optimized building and operational automation with intelligent space management to enhance the user experience, increase productivity, reduce costs, and mitigate physical and cybersecurity risks. Smart, digital buildings span industries and uses, but all of them can provide the same basic capabilities: They connect humans; they provide better control of facilities and operations; they support ways to collaborate digitally; and they enable owners to conserve resources, including space, energy, water, and employees. Each of these four capabilities can form the basis for creating a smart building strategy that can deliver measurable benefits. Figure 5 illustrates some of the different types of sensors and applications that can be utilized in a smart building.
For example, 75–80 percent of a building’s life cycle costs are related to building operations. All existing commercial and large residential buildings have some form of building automation (or management) system which controls such things as HVAC. In order to introduce smart building features, such as smart lighting with embedded occupancy sensors, and have these interact with the main system, at minimum a gateway is required with some additional capability that would usually come with an edge server.
The edge capability would provide data (occupancy data, for instance) from strategically placed sensors to a cloud-hosted service that performs some specialized analytics. The outcomes from these analytics can be sent back, via the gateway or edge server, to alter the schedules of equipment connected to the main system in order to optimize operations. This configuration is also necessary to obtain a portfoliowide view of building operations and conditions. Edge computing and cloud enable smarter management of resources.
While edge computing offers solid benefits, it can also introduce operational and design complexities. Edge processing is highly distributed and often includes far-flung and/or difficult-to-access locations, including sensors/actuators and gateways in offices, plants, at campuses, on pipelines, and in various remote field sites. Any given organization can have thousands of devices and hundreds of associated gateways. All these edge nodes have firmware, operating systems, some form of virtualization and containers, and software installed, some of which are provided by manufacturers and some by solution providers. These need to be properly managed and maintained by the owner/manager of these edge nodes, mandating an enormous degree of automation (such as for backups, patching, updates, and monitoring).
The number of potential problems is enormous, and troubleshooting can be very challenging and complex in a highly distributed model. In many cases, field service technicians are required to be regularly onsite to address issues that occur as a result of upgrades or even general maintenance. These drivers also tend toward the need for a widespread “software defined everything” approach, as software upgrades are more easily and conveniently achieved than hardware upgrades.
Despite its challenges, cloud computing obviates concerns with many key IT issues, providing a degree of self-service and automation. Edge processing requires common data center operations (provisioning, updating, change management, and monitoring) in addition to the other higher-level functions (device management, updating machine-learning models, etc.) to be undertaken and replicated to all of the edge nodes and clusters. This is a heavy undertaking, requiring the enterprise to shift the focus from business needs to some extent.
Policies and practices used in traditional data centers are often not readily applicable to edge deployments, which are distributed across multiple locations and considerably more dynamic than traditional data centers. Undertaking the operational management of such a system is a complex challenge.
While the cloud offers on-demand scalability and is readily configurable, automated, and resilient, providing for these capabilities at the edge can be costly and complex. Accommodating the expansion of an existing edge deployment to allow for an increased number of devices and edge nodes can involve significant investment in additional hardware and software, and much complex work.
Extending the cloud and the data center to the edge with multiple nodes and devices exponentially increases the surface area for cyberattacks. Insecure endpoints, such as devices and edge nodes, can be used as entry points to valuable assets within an enterprise network and for other nefarious purposes, such as distributed denial-of-service attacks. Maintaining the physical and cybersecurity position of all assets in the edge is a complex and critical challenge.
Including unnecessary complexity in a solution can be costly, risky, and wasteful, so whether to add edge processing to an IoT solution is a decision best taken with care and based on a risk/reward assessment. To that end, figure 6 offers some guidelines that may help.
In many IoT use cases, the edge is simply a necessary or mandatory part of the solution, given the already existing operational technology. Adding a cloud-hosted component of an IoT solution requires some degree of edge-computing presence, even if primarily a gateway. Similarly, the desire to add smart capabilities to existing building management system infrastructure and provide for a cloud-based real estate portfolio view necessitates use of some edge-processing capability.
IoT scaling challenges with use of only edge or only cloud Designing a large IoT solution that does essentially nothing at the edge and sends all data for action to the cloud often presents scaling challenges in terms of bandwidth usage, possibly necessitating upgrades to networking infrastructure. Additionally, as the solution scales, exclusive use of the cloud could require reconfiguring ingestion engines and load balancing through manual intervention. The complexities of an exclusively edge-based distributed architecture (especially one that may involve distributed processing) are no less, and they increase with scale. Systems and application management are highly complex, and tools needed for these have yet to mature. In many cases, edge deployments do not adequately consider expandability, complicating the support of more devices and more data.
The first step is to assess whether edge computing is needed at all. It may well be that the best solution is a purely cloud solution. The next step is to determine the capabilities needed at the edge, and followed by determining the most appropriate deployment model, given that edge processing can be on devices, gateways, edge servers, possibly in multiple tiers, or micro data centers. There can be large variations in compute capabilities, responsiveness, and placement.
In some cases, preconfigured solutions, packaged into a single, integrated product, can offer simplicity, but at the possible expense of flexibility. The capability provided by the flexibility of self-constructing from best-of-breed components is attractive, though it comes at the expense of software/product development and stabilization, which lengthens the time taken to deliver a solution and brings a number of inherent risks.
Paying attention to the changes in the edge compute landscape is important, as is conducting a proof of concept with the relevant deployment design in order to finalize the best fit choice for the use case involved.
There is another variable worth noting—the edge-computing vendor landscape. It is undergoing rapid change. Most IoT infrastructure or platform vendors recognize that edge computing is an important part of many IoT solutions and delivery hardware, such as gateways or servers, with some data processing, analytics, and local storage capabilities. These hardware vendors tend to rely on others for device management, protocol handling, and conversion, in addition to other capabilities. Significant consolidation is likely to occur in this space as vendors seek to offer end-to-end solutions.12
IoT devices and the data they can provide are changing the world and how we interact. Much of the connected-consumer IoT world resides primarily on the cloud largely because of its copious benefits. However, in most cases an IoT solution will involve some mix of the edge and the cloud. Bringing it to the edge can alleviate latency, boost scalability, and increase access to information so that better, faster decisions can be made, and organizations can become more agile as a result.
While deciding on the right balance of edge and cloud functionality in an IoT solution, it is helpful to keep in mind that edge computing has various configurations, and all can bring their own benefits, but they also can present unique challenges. Substantial operational complexities and expenses can emerge in in no time, so enterprises should take into consideration a full range of factors while designing and building any given IoT solution.
Even then, an IoT solution should be only as simple as it needs to be, and no simpler. Conversely, it should be only as complex as it needs to be, and no more complex. These seemingly straightforward, yet essential, points can make a difference in the success of a solution.
Clearly, there is no single correct answer in the cloud vs. edge assessment in an IoT context. Every situation is unique. What is clear, however, is that a balance between cloud and edge computing will likely make up tomorrow’s IoT architecture.The IoT is getting smarter. Companies are incorporating artificial intelligence—in particular, machine learning—into their Internet of Things applications and seeing capabilities grow, including improving operational efficiency and helping avoid unplanned downtime. The key: finding insights in data.
With a wave of investment, a raft of new products, and a rising tide of enterprise deployments, artificial intelligence is making a splash in the Internet of Things (IoT). Companies crafting an IoT strategy, evaluating a potential new IoT project, or seeking to get more value from an existing IoT deployment may want to explore a role for AI.
Venture capital funding of AI-focused IoT start-ups is growing fast: In the first eight months of 2017, this group of start-ups raised $705 million 1
Acquisitions of AI-focused IoT start-ups are on the rise: 21 in the first eight months of 2017 and 24 in 2016, up from 11 in 2015 2
Vendors of IoT platforms—including Amazon, 3 GE, 4 IBM, 5 Microsoft, 6 Oracle, 7 PTC, 8 and Salesforce 9 —are integrating AI capabilities
GE, IBM, Microsoft, Oracle, PTC, and Salesforce —are integrating AI capabilities Large organizations across industries are already leveraging or exploring the power of AI with IoT to deliver new offerings and operate more efficiently 10
Gartner predicts that by 2022, more than 80 percent of enterprise IoT projects will include an AI component, up from only 10 percent today11
Artificial intelligence is playing a growing role in IoT applications and deployments,12 a shift apparent in the behavior of companies operating in this area. Venture capital investments in IoT start-ups that are using AI are up sharply. Companies have acquired dozens of firms working at the intersection of AI and IoT in the last two years. And major vendors of IoT platform software are now offering integrated AI capabilities such as machine learning-based analytics.
AI is playing a starring role in IoT because of its ability to quickly wring insights from data. Machine learning, an AI technology, brings the ability to automatically identify patterns and detect anomalies in the data that smart sensors and devices generate—information such as temperature, pressure, humidity, air quality, vibration, and sound. Companies are finding that machine learning can have significant advantages over traditional business intelligence tools for analyzing IoT data, including being able to make operational predictions up to 20 times earlier and with greater accuracy than threshold-based monitoring systems.13 And other AI technologies such as speech recognition and computer vision can help extract insight from data that used to require human review.
The powerful combination of AI and IoT technology is helping companies avoid unplanned downtime, increase operating efficiency, enable new products and services, and enhance risk management.
In a number of sectors, unplanned downtime resulting from equipment breakdown can cause heavy losses. For instance, according to one study, such losses average $38 million annually for offshore oil and gas operators.14 Another source estimated that for industrial manufacturing in total, unplanned downtime costs $50 billion per year, with equipment failure being the cause for 42 percent of the outages.15
Predictive maintence—using analytics to predict equipment failure ahead of time in order to schedule orderly maintenance procedures—can mitigate the damaging economics of unplanned downtime. In manufacturing, for instance, Deloitte finds that predictive maintenance can reduce the time required to plan maintenance by 20–50 percent, increase equipment uptime and availability by 10–20 percent, and reduce overall maintenance costs by 5–10 percent.16
Because AI technologies—particularly machine learning—can help identify patterns and anomalies and make predictions based on large sets of data, they are proving to be particularly useful in implementing predictive maintenance. Leading South Korean oil refiner SK Innovation, for example, expects to save “billions of won” by using machine learning to predict failure of connected compressors.17 Similarly, Italian train operator Trenitalia expects to avoid unplanned downtime and save 8–10 percent on its €1.3 billion annual maintenance costs.18 Meanwhile, French power utility EDF Group has already saved over $1 million with machine learning-driven early warning on equipment failure.19
AI-powered IoT can do more than help avoid unplanned downtime. It can also help improve operational efficiency. This is due in part to the power of machine learning to generate fast and precise predictions and deep insights—and to AI technologies’ ability to automate a growing variety of tasks.
For example, for Hershey, managing the weight of their products during the production process is critical: Every 1 percent improvement in weight precision can mean more than $500,000 in savings for a 14,000-gallon batch of product such as Twizzlers.20 The company used IoT and machine learning to significantly reduce weight variability during production. Data is captured and analyzed by the second, and weight variability can be predicted by machine learning models, enabling 240 process adjustments per day, compared to just 12 per day before the ML-powered IoT solution was installed.21
AI-based prediction is also helping Google cut 40 percent of data center cooling costs. The solution, trained on data from sensors in the facility, predicts temperature and pressure over the next hour to guide actions for limiting power consumption.22
Machine learning produced insights that persuaded one shipping fleet operator to take a counter intuitive action that saved them big money. Data collected from ship-board sensors was used to identify the correlation between the amount of money spent on cleaning the ships’ hulls and fuel efficiency. The analysis showed that by cleaning their ships hulls twice a year rather than every two years—and thereby quadrupling their cleaning budget—they would end up saving $400,000 due to greater fuel efficiency.23
IoT technology coupled with AI can form the foundation of improved and eventually entirely new products and services as well. For instance, for GE’s drone and robot-based industrial inspection services, the company is looking to AI to automate both navigation of inspection devices and identification of defects from the data captured by them. This could result in safer, more precise, and up to 25 percent cheaper inspections for the client.24 In health care, Thomas Jefferson University Hospital in Philadelphia seeks to improve patient experience with natural language processing that will enable patients to control room environment and request various information with voice commands.25
Meanwhile, Rolls-Royce aims to soon introduce a new offering featuring IoT-enabled airplane engine maintenance services. The company plans to use machine learning to help it spot patterns and identify operational insights that will be sold to airlines.26 And automotive manufacturer Navistar is looking to machine learning analysis of real-time connected vehicle data to enable a new revenue stream, in vehicle health diagnostics and predictive maintenance services. According to Navistar technology partner Cloudera, these services have helped cut downtime for nearly 300,000 vehicles by up to 40 percent.27
A number of applications pairing IoT with AI are helping organizations better understand and predict a variety of risks as well as automate for rapid response, enabling them to better manage worker safety, financial loss, and cyber threats.
For instance, Fujitsu has piloted the use of machine learning to analyze data from connected wearable devices to estimate its factory workers’ potentially threatening heat stress accumulated over time.28 Banks in India and North America have begun evaluating AI-enabled real-time identification of suspicious activities from connected surveillance cameras at ATMs.29 Vehicle insurer Progressive is using machine learning analysis of data from connected cars to accurately price its usage-based insurance premiums and thus better manage underwriting risk.30 And the city of Las Vegas has turned to a machine learning solution to secure its smart city initiatives, aimed at automatically detecting and responding to threats in real time.31
For enterprises across industries, AI has the potential to boost the value created by IoT deployments, enabling better offerings and operations to give a competitive edge in business performance.
Executives contemplating new IoT-based projects should be aware that machine learning for predictive capabilities is now integrated with most major horizontal (in other words, general-purpose) and industrial IoT platforms, such as Microsoft Azure IoT,32 IBM Watson IoT,33 Amazon AWS IoT,34 GE Predix,35 and PTC ThingWorx.36
A growing number of turnkey, bundled, or vertical IoT solutions take advantage of AI technologies such as machine learning.37 For instance, for connected-car use cases, BMW’s CarData platform gives access to data shared by vehicle owners and AI capabilities from IBM Watson IoT.38 In consumer products and retail, a number of replenishment automation and optimization solutions use machine learning to predict demand and optimize inventory levels.39 Providers of telematics solutions for the auto insurance industry are integrating machine learning to create more accurate risk models and predict claims behavior.40
It may be possible to use AI technology to wring more value from IoT deployments that were not designed with the use of AI in mind.41 For instance, a Hungarian oil and gas company applied machine learning to sensor data that was already being collected during diesel fuel production. The analysis allowed the company to more accurately predict the fuel’s sulfur content and helped identify process improvements that are now saving the company more than $600,000 per year.42 The major horizontal and industrial IoT platforms—which enterprises may already be using—are offering new AI-based capabilities that might help boost the value of existing deployments.
It may soon become rare to find an IoT implementation that does not make some use of AI. The International Data Corp. predicts that by 2019, AI will support “all effective” IoT efforts and without AI, data from the deployments will have “limited value.”43 A growing number of IoT vendors are offering at least basic AI support. Vanguard companies across industries are already reaping the benefits of AI in their IoT deployments. If your company has plans for implementing IoT-based solutions, those plans should probably include AI as well.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.Each week watch Deloitte Consulting Chief Futurist Robert Schmid, aka “Mr. IoT,” interview guest specialists across the burgeoning IoT space about the technologies you want to know more about.Nowadays, Agile methodologies have well and truly arrived in most organizations. The complexity of digital opportunities and the unpredictability of customers and competitors are both on the rise, making it impossible to predict what businesses will need in the future. That is why Agile is such a decisive factor to enhance organization’s responsiveness towards volatility. Strategy management has to evolve as well, which is where Agile concepts come into play. More...Andy is a principal in Deloitte Consulting LLP and leads the Internet of Things practice. He has worked in the high-tech industry for 25 years, advising clients on the strategic use of technology to optimize their businesses. Andy specializes in advising executives on the practical applications of emerging technologies, effective management of IT organizations, and execution of complex, transformational, technology-enabled projects.The increasing number of Internet of Things devices demands for a central approach of managing complex systems with a large number of services and things. This management of IoT devices and services, management of workflows and capabilities as well as automated reactions to incidents and events, are key aspects provided by ServiceNow.
The goal of implementing ServiceNow as an IoT solution is to take a long-term view and to enable your business with the necessary tools to manage the complexity of IoT systems, things, and related services. Having a robot broadcasting data sets the basis for starting a process, which is simplified by ServiceNow as implemented in our PoC: the data is analyzed and appropriate actions are derived from the analysis, which are accomplished by technicians with necessary skills and proximity. All done without unnecessary, time consuming, time-lagging, manual work.
As a tool for Asset & Configuration Management, Service & Issue Management, and Discovery & Orchestration, ServiceNow offers reduction of downtimes, automation of (production) processes, and increase in up-times and utilization for predictive maintenance - in particular service requests and automation in the cloud. The whole end-to-end process is scalable and can be applied from one machinery to a globally distributed network of plants.
Automation is simply necessary for the next step in the IoT implementation efficiency and Deloitte ServiceNow team has the tools to help you transform your business into a highly automated and efficient one. We support you from the first idea of bringing IoT and automation into your organization to the management and continuous improvement of your IoT and ServiceNow solution.As airports become more digitally connected, the Internet of Things (IoT) can open up a world of opportunities. Much more than merely improving efficiency, IoT can transform the traveler experience and generate new revenue.
Digital technology seems to connect everything today. So it is perhaps no surprise that airports—the infrastructure that helps billions of travelers connect across the globe each year—are themselves becoming more digitally connected. The connected, or smart, airport brings together a variety of technologies through the Internet of Things (IoT), with the goal of strategically differentiating an airport, including via improved traveler experience, and tapping into monetary benefits through greater efficiencies and new revenue streams. Achieving this end goal requires significant collaboration between stakeholders, and airports should carefully craft implementation strategies that aim for incremental quick wins over “big bang” transformations.
While awareness of IoT across the aviation ecosystem is high, its knowledge of how to harness and maximize IoT’s capabilities within an organization is much lower. In our survey of the industry, only 12 percent of airport representatives reported that their organizations are very prepared to benefit from IoT applications, and another 10 percent felt that they were not even exploring IoT yet. So if they want to create the connected, smart airport, the logical starting point is by beginning with the basics of what IoT is.
Methodology of this study Funded by the Airport Cooperative Research Program of the Transportation Research Board of the National Academies of Sciences, Engineering and Medicine, researchers from Deloitte and Texas A&M Transportation Institute produced a primer on smart airports and IoT.1 In the context of this report, the term “airport” is not limited solely to airport operators, but refers to the complex network of stakeholder interactions that goes into getting aircraft safely in the air and travelers and cargo comfortably to their destinations. The report drew on a variety of research methods including: Literature review. The research team reviewed existing academic, business, and technical literature on IoT’s background, concepts, technological architecture, and value propositions. The team also reviewed lessons learned from IoT applications outside an airport environment.
The research team reviewed existing academic, business, and technical literature on IoT’s background, concepts, technological architecture, and value propositions. The team also reviewed lessons learned from IoT applications outside an airport environment. Stakeholder interviews. The team conducted 18 interviews with industry stakeholders representing IoT experts, airports, airlines, aviation industry associations, federal agencies, vendors, and intelligent transportation system/transportation providers.
The team conducted 18 interviews with industry stakeholders representing IoT experts, airports, airlines, aviation industry associations, federal agencies, vendors, and intelligent transportation system/transportation providers. A stakeholder survey. The team conducted an online survey of 103 industry stakeholders representing airports, airlines, airline vendors, aviation industry consultancies, IoT suppliers, and other consulting organizations.
The team conducted an online survey of 103 industry stakeholders representing airports, airlines, airline vendors, aviation industry consultancies, IoT suppliers, and other consulting organizations. Case studies. The research team conducted 11 case studies, eight in an airport environment and three in other industries.
IoT is not a technology itself but rather a technology architecture—that is, IoT is more than the sum of its component parts. IoT is a way of bringing together different enabling technologies in a specific way to do something new. But how exactly do enabling technologies come together to form an architecture? IoT’s architecture is explained conceptually using the information value loop (figure 1). However, perhaps the best way to understand how these technologies come together to create value is through an example from an airport:
The airport needs to locate its nonmotorized ground service equipment to maintain it more regularly. GPS tags affixed to the equipment function as sensors to create a thread of digital information about the location of a specific piece of the equipment. A network of radios communicates that information back to a central server. The server aggregates the location of one cart with the location, type, and maintenance schedule for all of the other carts. All this data is analyzed together to create a plan for which carts need to be retrieved today and undergo maintenance. With that information in hand, workers act, bringing in the right pieces of equipment for maintenance on time.2
When workers use the information created by IoT to take a new action, the digital information has created value in the real world—in this case, allowing for proper maintenance and greater uptime for ground service equipment. Because IoT is an architecture, what is important is not the specific technologies involved but rather the flow of information through the steps of the information value loop. Since that information can be about anything, the exact amount and type of value created by IoT are limited only by the business problems airports need to solve.
We see three principal classes of benefits from IoT, and, in selecting the IoT capability or set of capabilities that are “right” for them, airports should consider their goal(s) for IoT implementation:
IoT is already in use in airports in many different ways, such as in traveler information systems, traveler traffic monitoring, baggage systems, and facilities management. Most of these uses focus on increasing efficiency. Other uses of IoT, such as enhancing security effectiveness, can improve both efficiency (maintaining throughput with fewer machines or staff) and differentiation (shorter and faster lines for a better traveler experience). Finally, still other use cases can directly generate new revenue such as the use of geofencing to gather fees from rideshares. As a result, these three categories help us understand what IoT can achieve at an airport.
The majority of current airport uses of IoT focus on operational efficiency. For example, an airport representative shared that one airport has “a new online inspection system that uses a tool provided to maintenance grounds crew and connected to the Internet with GPS functionality. The purpose of this tool is to digitally connect maintenance crew inspection findings to a map of the airport grounds.”3
Another airport is planning a smart bathroom pilot test. The airport will install IoT sensors on various bathroom assets, including faucets, toilets, lighting, soap dispensers, air fresheners, toilet paper dispensers, and other equipment, in one of its busiest bathrooms. These sensors will transmit data to facilities management to alert it in real time of various shortages and breakdowns. As part of this pilot, the bathroom will have a people counter and a customer input button to capture perceptions of bathroom cleanliness, which will enable facilities management to gauge perceptions of cleanliness against actual use. This may enable greater efficiency for maintenance staff while also providing a better traveling experience.
The long-term horizon for IoT applications supporting efficiency at airports may include autonomous vehicles, tenders, and baggage carts. If integrated with other data sources such as schedules, push-back times, and gate numbers, this data could fully automate a tarmac where robots and autonomous vehicles deliver baggage, fuel planes, clear debris, and perform other tasks—all faster and to closer tolerances than human workers. The result would be that airports could conduct surface operations more efficiently, allowing more flights in and out of the same physical ramps and taxiways. While something like the fully automated tarmac is still years away, the technology needed for such uses is already in action on roadways today.4
While gains in efficiency can be significant, airports that use IoT can also provide a more differentiated product or better customer experience than nonsmart airports. However, differentiation can be much broader, especially for airports where the greatest competition comes not from other airports but from other modes of travel. For example, limiting greenhouse emissions, reducing noise levels over neighboring areas, or even responsibly maintaining an airport’s open space can all be differentiators that make the airport an attractive brand as well as an integral part of the community. In fact, smart products used as part of IoT can even gather information about customer preferences, providing a deeper understanding of what does and does not differentiate travel options.
Differentiation is often a watchword for advertising or customer experience, but it is actually much more. Differentiation is fundamentally about how an airport provides distinctive value to important stakeholders—stakeholders that include groups that range from airlines to travelers to retail tenants to local communities. Differentiation can underpin and support the brand of an airport. IoT applications that support differentiation can come in many different varieties, aimed at traveler satisfaction or even environmental causes. For example, Heathrow Airport set the goal of reducing nitrogen dioxide emissions to help improve local air quality. The airport realized that a major—and avoidable—source of ground-level nitrogen dioxide emissions is aircraft parked at the gate that use auxiliary power units (APUs) instead of plugging into the power grid. As a result, Heathrow Airport deployed an IoT solution to help improve air quality. Microphones positioned around the apron pick up the telltale sound of APUs running. These data are cross-referenced against schedules and other data to determine whether an aircraft is running its APU instead of using the power grid. The airport can then share this data with airlines and remind aircraft to plug in and switch off the APU—not just saving money for the airline but also improving local air quality for all.5
IoT can also create new sources of revenue. This can come from creating new products or services to attract new customers or by using IoT to sell more to existing customers. While IoT solutions aiming to generate new revenue are often the largest and most complex, they can also build upon existing solutions that generate efficiency gains to help ease implementation. Our interviews with subject matter experts indicate that airport stakeholders do see the value in such uses and may pursue them in the future. Use cases being investigated include variable rates for advertising and off-airport transit recommendations personalized to an individual traveler. However, because these revenue-generating use cases may involve the greatest number of stakeholders, they are often the hardest to pursue.
That said, just because use cases that create new revenue are hard to create does not mean that they have to be technologically advanced. One airport used Wi-Fi access points as sensors to measure the location and dwell time of people as they moved through the terminals. Armed with this data, the airport was able to put signs and advertising in places most likely to be seen by the right people. So while earlier, very few sales were made to landing travelers, this airport was able to place signs for the products those travelers may want to buy before departing the airport where they would be likely to see them. The result was increased sales to a previously untapped group for retailers, and through them, increasing the airport operator’s landside revenue.6
Industries generally have a typical development progression with IoT. The expected benefit of an IoT application varies with the scope, and therefore difficulty, of the project. As a result, most industries begin by pursuing small-scope IoT projects aimed at efficiency since these can often be managed entirely within an organization. Therefore, in most industries, IoT applications aimed at efficiency are the most common, followed by differentiation and then new revenue.
In one recent survey, 34 percent of companies—the top response—said they anticipated gains in efficiency from IoT technology.7 On the other hand, only 6 percent—by far the lowest response—anticipated realizing new revenue thanks to IoT technology. Another survey of companies already using IoT found similar results: 52 percent used IoT to improve efficiency versus 40 percent that used customer-facing IoT applications for differentiation and generating new revenue.8
Overall, airports follow these trends in IoT adoption as well. In our survey, 76 percent of respondents using IoT indicated they used it for efficiency/optimization, compared with 58 percent for customer experience/differentiation and only 35 percent for new revenue.
However, while many airports may follow the typical IoT development trends (moving from efficiency to differentiation to new revenue), unique forces in the aviation industry also open other pathways to IoT adoption. The aviation industry has traditionally set a very high standard for traveler experience, with leading airports designing truly tailored experiences that reflect not only the bespoke expectations of their global travelers, but the uniqueness of the local region as well. Therefore, while IoT applications that improve traveler experience at an airport may be more difficult to implement than those dealing only with internal efficiency, airports may find it easier to begin with differentiation and move to internal efficiency. As aviation entrepreneur and indoor mapping expert Jack Loop puts it:
"Very often, [airports] begin with the consumer-facing side. Consumer-facing projects need to meet a higher bar of usability, so it is actually easier to take a slick consumer-facing project and use it internally than it is to take a purely functional internal tool and bring it up to consumer-facing standard.9"
So while past IoT developments may have focused on efficiency, as airports develop future IoT solutions, they may tend to skew more toward differentiating the airport by improving traveler experience. These sentiments were echoed by other interviewees from airlines and airports, who indicated that future IoT plans were largely focused on improving customer experience.
As we saw, airports can use IoT to improve efficiency, differentiate their strategy, and generate new revenue. These benefits of IoT can be applied to any aspect of airport operations. Since airport operations are typically split into two, air side and land side, we will explore how IoT can impact both below.
IoT can be applied at every stage of a traveler’s journey from arrival curb to gate (figure 2). For example, IoT way-finding applications could be relevant at the parking and arrival stage and the check-in stage. Figure 3 maps common IoT solutions to each stage as well as the airport stakeholders involved in the implementation.
Much like a traveler’s journey, operations at an airport can also be seen through the lens of an aircraft’s journey from arrival to departure (figure 4), and IoT implementations can similarly be mapped across each stage and the stakeholders involved for each stage (figure 5).
With so many technological options, IoT can quickly overwhelm even the most tech-savvy managers. However, a structured planning process can help airport leaders navigate all the options and gain confidence that the end result will support the airport’s business goals.
Determine the technical and organizational maturity needed to successfully implement the chosen solution
The process begins with selecting a potential IoT project. This can be done with either a top-down approach or a bottom-up approach.
Based on the goals in their strategic plan, airports should select the right set of IoT capabilities. Different goals for an IoT solution can often call for radically different technology and organization to support them. As a result, the overall strategic goal for IoT drives the infrastructure requirements needed for a successful IoT implementation.
Airports can also identify promising IoT opportunities by examining the existing IoT solutions— or, if there are no true IoT solutions, the existing sources of data—currently operating in their airport, and then identifying areas where these solutions can be extended across or beyond the airport to further meet the airport’s strategic goals. This exercise also shows where other stakeholders may have data or expertise that can help an airport achieve its goals.
The result should resemble a matrix of IoT applications, stakeholders, and the impacted stages of traveler or operations journey, as depicted in Figures 2, 3, 4, and 5. As in the top-down approach, this assessment of the infrastructure requirements for an IoT solution can help the airport gauge the feasibility of a project. However, the map created by the bottom-up approach has an additional benefit: It can help identify other stakeholders who may be able to provide some of the capabilities needed—in effect accelerating an airport’s IoT project adoption by tapping into existing tools or infrastructure.
Whether using the top-down or bottom-up approach, airports assess their overall digital maturity versus the desired end state of a successful IoT implementation.
The data (size and complexity), communications, and infrastructure required for the potential solution(s) versus what the airport already possesses;
Stakeholder groups that can achieve benefits from the potential solution versus the security/privacy procedures that must be in place to secure their cooperation or use.
Assessing potential IoT solutions against these qualifiers can confirm (or disprove) the overall fit of that solution for the defined needs of the airport before moving to implementation. More importantly, the gaps between required and current capabilities in each of these criteria can guide the first steps to developing an implementation road map as airports pursue digital maturity (figure 6).
Even with all the right tools and information, implementing IoT solutions can be a significant undertaking filled with new challenges for even the most digitally mature organizations. We look at some of the broad challenge areas below.
Safety, security, and privacy. In the aviation industry, safety is an inviolate standard. No new technology, no matter how efficient or cost-saving, can be introduced if it compromises safety. When physical objects are connected digitally, the compromise of digital data can have real-world consequences. Therefore, as IoT gains in adoption, safety, cybersecurity, and data privacy are all increasingly linked.
In the aviation industry, safety is an inviolate standard. No new technology, no matter how efficient or cost-saving, can be introduced if it compromises safety. When physical objects are connected digitally, the compromise of digital data can have real-world consequences. Therefore, as IoT gains in adoption, safety, cybersecurity, and data privacy are all increasingly linked. Technology and infrastructure. Large IoT implementations involve numerous, disparate systems and devices, which all need to connect and operate together. Very few out-of-the-box IoT solutions for airports are currently on the market. This can make it hard to figure out what is needed to support an IoT ecosystem.
Large IoT implementations involve numerous, disparate systems and devices, which all need to connect and operate together. Very few out-of-the-box IoT solutions for airports are currently on the market. This can make it hard to figure out what is needed to support an IoT ecosystem. Talent. As IoT gains wider adoption, the roles and responsibilities of airport employees may change as they have more interaction with technology. To keep up with this trend, airports should prioritize addressing talent and skill gaps by implementing training programs for existing employees, expanding hiring for new technical roles, and changing the way leaders manage and organize work groups.
As IoT gains wider adoption, the roles and responsibilities of airport employees may change as they have more interaction with technology. To keep up with this trend, airports should prioritize addressing talent and skill gaps by implementing training programs for existing employees, expanding hiring for new technical roles, and changing the way leaders manage and organize work groups. A compelling business case. In every industry, concerns about return on investment (ROI) are among the top barriers to implementing IoT. Both upfront and continuing costs can vary widely, depending on the specific IoT application. Since IoT has few test cases, the ROI for any IoT investment is not fully certain, with the result that cost can quickly become a deterrent. However, careful consideration of the factors that drive costs and ROI in IoT can help leaders narrow down options and structure their decision-making.
In every industry, concerns about return on investment (ROI) are among the top barriers to implementing IoT. Both upfront and continuing costs can vary widely, depending on the specific IoT application. Since IoT has few test cases, the ROI for any IoT investment is not fully certain, with the result that cost can quickly become a deterrent. However, careful consideration of the factors that drive costs and ROI in IoT can help leaders narrow down options and structure their decision-making. Funding and financing. Even with a solid business case that promises a clear and acceptable ROI, airports can struggle to find the upfront funding needed to begin a project. Given the thin margins of many airport operators, finding extra dollars to finance an IoT project can induce fear in any airport executive. Taking a structured approach to understanding funding and financing options by asking question about the goal, timeline, and stakeholders involved in a project can help reduce uncertainty and encourage adoption of IoT.
Every IoT solution is unique and, therefore, the funding needs of each solution are likely to be unique as well. But there are a few variables common to every project that can help airports think through which types of funding or financing may be most applicable (see Figure 7 for one example):
What is the goal of IoT solution? How will success toward that goal be measured? Size of investment. What is the upfront investment required for IoT? What are the recurring costs?
What is the upfront investment required for IoT? What are the recurring costs? Timing of return. When can an airport expect a return from an IoT solution?
When can an airport expect a return from an IoT solution? Where costs and benefits accrue. Do benefits from IoT help one segment of the organization while the costs must be borne by another?
Overall, barriers to implementing IoT solutions can seem overwhelming. However, with the right team, a thoughtful plan, and supportive buy-in, airports can use IoT to create a better, more profitable operation.
Regardless of the technology or application involved, IoT can have the biggest impact on airports when the technology is incorporated into the core business model. For example, IoT might be used to facilitate a seamless door-to-door experience for air travelers: A single platform that can order and pay for rides on rail or taxi, handle travel documents, and order additional services could open up entirely new business opportunities for airport operators currently dependent on retail sales and parking receipts and greater customer interaction for airlines and other stakeholders. This mobility-as-a-service approach is exactly the type of IoT-based new business model that could deliver a new future to airports. Other opportunities may include biometric check-in, variable services or prices based on wait times, and individualized boarding processes.
However, only time—and the detailed picture that IoT data can create—will tell what the future holds.10The connected vehicle has been the most visible and familiar example of Internet of Things technology. But as cars become increasingly software-driven, the real IoT developments in the auto industry are behind the scenes, as automakers and software providers both lay claim to the driver’s seat.
Our cars have been connected for years, in ways that by now seem routine: They seamlessly link to our smartphones, register real-time traffic alerts, stream our Spotify playlists, and offer emergency roadside assistance at the touch of a button. Indeed, automakers began linking vehicles to information streams back in the early days of the Internet. When it comes to connecting drivers and technology, the auto industry has a longer and richer track record than any other sector.1
True, automakers have yet to turn the “connected car” into a significant revenue generator or a key driver of vehicle sales: Despite two decades of TV ads promoting advances in in-vehicle connected services, drivers have resisted paying extra for those features, either not understanding the new technologies or simply seeing little value in the services offered.2 But this—and a great deal more—is about to change.
Indeed, the auto industry is on the brink of a revolution, and the driving force is the suite of technologies known as the Internet of Things (IoT). With IoT applications—grounded in advances in everything from sensors to artificial intelligence to big-data analysis—all manner of objects, from wristwatches to road signs, can be not only connected but also “smart.” And both industry insiders and everyday drivers will soon see a fundamentally different world of mobility.3
Analysts differ in their estimates, but all agree that the prospects are staggering. Gartner predicts that by 2020, more than 250 million vehicles will be connected globally, with the number of installed connectivity units in vehicles worldwide increasing by 67 percent and consumer spend on in-vehicle connectivity doubling. Deloitte’s consumer research suggests that drivers of the next generation want their cars to act as smartphones on wheels, like to remain connected and productive while on the go, consider fully connected vehicles among the most beneficial futuristic technologies, and are ready to pay a sizeable amount for a vehicle that meets all their technology needs and wants.4 We expect the impacts on the industry to be transformational, not incremental.
As ever, new opportunities bring fresh challenges. As IoT technologies and services transform the automobile, the ecosystem is witnessing a steady influx of new players and the continued evolution of the roles of key stakeholders and the balance of power among them. Of particular interest is the evolving relationship between automakers and software providers. Each has a viable claim on the driver’s seat in the rapidly changing auto-industry ecosystem, even as each new generation of services promises to throw into question just how long whoever might have their hands on the wheel can keep them there.
The connected car has evolved in distinct stages, or phases, over the last few decades that show advances in both technology and the ecosystem in which that technology functions. At each stage, not only are new features and services added to the growing connected car product portfolio, but also new ecosystem players as well as, in many cases, new business models and supporting technologies. That’s why the best way to fully perceive the complexity of the playing field is to use the past as prologue, tracking the evolution of the connected car from its earliest stages to where it is today and where it’s going. Figure 1 outlines these phases of evolution.
Since as far back as the mid-1960s, automakers have looked for ways to enhance the driving experience with information. General Motors’ Driver Aid, Information and Routing (DAIR) initiative sought to provide everything from directions to current road conditions and accident reports.5 Far ahead of its time, DAIR never got out of the R&D stage, mostly because the technology of the day simply wasn’t up to the task. Punch cards provided information for turn-by-turn directions; radio relay stations and magnetic sensors buried in roads communicated additional data. For such a system to be useful, it would have required ubiquitous availability—in other words, deployment on roads across the country or, at least, a substantial geographical scale—at the time, cost-prohibitive and commercially unworkable, which is why we classify DAIR as Phase 0, a connected car before connections truly existed.
Conceptually, however, we can think about this effort in terms of how the information creates value and therefore assess DAIR in those terms. The Information Value Loop describes the stages through which information must pass to create value, the technologies required to push information around the loop, and the characteristics of the data that drive value (see inset on page 5).
By connecting the vehicle with in-road sensors, DAIR created and communicated information, analyzing it to provide an augmented response—action—in the form of navigation and traffic information. In closed test environments, the value was visible as information completed the trip around the value loop. At commercial scale, however, the cost of putting the expensive sensor technology in place across large stretches of road created too tight a bottleneck for DAIR to be feasible. It did not help that, for a single-company initiative, there was no larger ecosystem in place to spread the costs around. Even for the GM of the 1960s, DAIR was too great a dare.
The suite of technologies that enables the Internet of Things promises to turn most any object into a source of information about that object. This creates both a new way to differentiate products and services and a new source of value that can be managed in its own right. Realizing the IoT’s full potential motivates a framework that captures the series and sequence of activities by which organizations create value from information: the Information Value Loop.
For information to complete the loop and create value, it passes through the loop’s stages, each enabled by specific technologies. An act is monitored by a sensor that creates information, that information passes through a network so that it can be communicated, and standards—be they technical, legal, regulatory, or social—allow that information to be aggregated across time and space. Augmented intelligence is a generic term meant to capture all manner of analytical support, collectively used to analyze information. The loop is completed via augmented behavior technologies that either enable automated autonomous action or shape human decisions in a manner leading to improved action.
Getting information around the Value Loop allows an organization to create value; how much value is created is a function of the value drivers, which capture the characteristics of the information that makes its way around the value loop. The drivers of information value can be captured and sorted into the three categories: magnitude, risk, and time.
When GPS technologies were opened up to civilian use in 1996, GM announced OnStar in collaboration with EDS and Hughes Electronics.6 As originally introduced, every connected car would have a digital communication module (DCM), essentially a phone embedded in the vehicle, responsible for communicating information wirelessly to a telematics service provider (TSP) or the automaker itself. In a breakthrough we categorize as Phase 1, this connected the car to information and services from the outside world to enable a safer and easier driving experience.
OnStar’s success is clear in terms of its ability to effectively push the right kinds of information around the Value Loop. For example, safety services leverage sensors embedded in the vehicle—aggregating information that the car creates and communicates associated with safety-related events and emergency situations. Navigation services use GPS technology to ascertain the auto’s location. Analysis of the information enables the provider to use augmented-behavior technologies to act on the customer’s behalf—from dispatching emergency services to the site of a crashed vehicle to providing live concierge services over the in-vehicle phone.7 The timeliness, reliability, and accuracy of information are the most critical value drivers, due to the importance of rapid response in emergency situations and the legal implications of safety failures.8
The automotive ecosystem was becoming more than just the car and its maker. Unlike the closed DAIR ecosystem, OnStar’s ecosystem brought in two new players: the hardware providers and Tier 2 chip providers that supplied the DCM devices and the TSPs that provided the core services. The new hardware providers, operating similarly to existing Tier 1 providers, fit within existing power structures. The TSPs, however, represented an important shift: Automakers’ introduction of embedded safety services expanded their business models beyond product manufacturing and retail into service provision, touch-points across the customer lifecycle, and the ability to collect recurring revenues. The communicate stage was an important bottleneck that TSPs were key to relieving. As a result, TSPs possessed two critical pieces of value in the partnership: the customer data related to the services provided and the actual interactions with customers themselves.9
After a century of carmakers’ unquestioned industry dominance, other players were staking a claim to ownership of the overall relationship with the customer. But the potential power struggle had to take a back seat to the fundamental problem of consumer adoption: Notwithstanding industry hype, consumers were slow to comprehend the new services being offered and the benefits of such connectivity; the high prices of these services proved a particularly big speed bump.10
Even just the two data points provided by DAIR and OnStar illustrate a trend: Communication-based technologies often require an expanded ecosystem to function effectively and affordably, appeal to customers, and offer opportunities to generate value. But while enlarging an ecosystem enables a given value loop to create more value, it poses additional challenges for the players involved when it comes to capturing that value.11 The continued evolution of the connected car has played out according to these same rules.
By the mid-2000s, the near-ubiquity of mobile phones and the rapid rise of smartphones prompted the introduction of “infotainment” applications within the vehicle.12 These applications were built on a driver’s “brought-in” phone (using a phone’s cellular connection to stream data to the vehicle via Bluetooth) rather than embedded hardware (as with DAIR or OnStar). The connected capabilities within the car aimed to duplicate entertainment and features a driver could get elsewhere (at home or on their phone) rather than providing a wholly new stream of features—and new kinds of value. Even so, this signaled a new phase: a shift from creating value through technology to creating value through information, and expansion of connectivity to better integrate with the customer’s out-of-vehicle life.13
Infotainment services introduced two new categories of players to the ecosystem—software providers and third-party content and app providers—and consequently set off an important shift in the power equation in the industry, even as players within these categories proliferated and the Silicon Valley giants began to make their presence felt.14 Blackberry’s QNX, Google, and Apple all released proprietary software platforms in an effort to establish themselves in this market.
As access to content has increasingly shaped customers’ in-vehicle experience, who owns the customer’s experience—a key question in this phase—has grown more important.15 In other words, in the case of infotainment, value is captured by those who can aggregate—and thus control—the data that drivers create and communicate. With software providers taking on that role, automakers saw their own ability to capture value from data beginning to diminish.
The entry of the big Silicon Valley firms created something of a dilemma for the carmakers: The mass appeal and cross-industry possibilities of Google’s Android Auto and Apple’s CarPlay were offset by the fact that, in such a partnership, both players are competing to completely own the customer experience and customer data. No surprise that automakers—which consider the customers their own and want to retain control over the center stack—find this precedent troubling.16 Automakers fear that, should they lose control of the customer to software providers, cars could become commodity devices secondary to the software they run. Some carmakers have chosen to instead build or retain their own proprietary platforms,17 or to limit the data they share with their technology partners.18 Others are exploring innovative ways to bridge this gap and collaborate with software providers. Together with another major automaker, Toyota has opted for an open platform with BlackBerry’s QNX that can support not only a larger number of apps19 but also greater freedom for user-interface customization.20
On the whole, the infotainment era renewed interest and adoption in the connected car. However, monetization of services continued to be an issue—as customers grew accustomed to accessing music and other entertainment on demand, often for free, they resisted paying extra for those services in their cars.21
For several years, players debated whether to create systems around embedded or brought-in technology and services, and that debate drove the scope of the connected-car ecosystem and the struggles over value capture. The last couple of years, however, have seen the development of a “hybrid model” that combines the two—and opens the door to the introduction of a host of applications and opportunities for value capture.22 High-tech innovation from outside the automotive world is bleeding into it, making the current period one of intense activity and excitement, with many new entrants, startups, VC investments, and M&A movements. It is no surprise, though, that this is further muddying the ecosystem’s waters. At the heart of these hybrid solutions are multiple sensors embedded not only in the vehicle itself but in all manner of smart devices across the IoT landscape—from wearables and Dedicated Short-Range Communications devices to smart-home gadgets to infrastructure—that can communicate with and share data with the vehicle through what is being called V2X integration.23
The breadth of devices and sensors available create a tremendous scale of data based on a wide scope of detected events, and that in itself is responsible for much of the value being seen in this phase. An IoT system can communicate the generated data to a common platform, where it may then be aggregated with data originating from other sources, including third-party content and social media, and analyzed, generating a response that is then delivered through the vehicle or other designated output device. This triangulation of data coming from these myriad devices is where the greatest value lies: firstly, in making sense of the data to paint a complete picture of both the customer’s behavior and the surrounding context to generate insights, and secondly, to even enable this aggregation in the first place in a way that is interoperable across devices and provides a comprehensive and cohesive customer experience.24
A platform that can aggregate and analyze all this data represents a complex undertaking, as it involves cooperation and collaboration between multiple stakeholders from multiple industry sectors. The aggregate and analyze stages are the real bottlenecks for this phase of connectivity, and this is what positions software providers at the center of value creation in this ecosystem, since they, and they alone, hold the wherewithal to deliver such a platform.
It should be noted that with great power comes great responsibility. The increasing scale and scope of data from the vehicle and connected devices represents a tremendous revenue opportunity for the players that own and control this information, but it raises the stakes for these same players in ensuring that the data remains secure. Car hacking has grown as a concern over the last few years, with several digital-security studies revealing the dangers of vehicle security breaches: Protected personal information could be stolen; hackers could potentially even seize remote control of a vehicle, with dangerous consequences.25 In light of such possibilities, the players that own and operate on the data expose themselves to significant legal liability, an additional consideration that they will have to take into account as they look to establish their positions in this space.
The notion of adding vehicles to the ever-widening ecosystem of interconnected devices heralds a significant shift: the treatment of the vehicle as just another connected device—albeit a powerful and multi-functional one—in a significantly expanded ecosystem. The implications for the balance of power between automakers and software-platform providers are still unfolding: Indeed, software providers may gradually supplant carmakers as the center of the ecosystem and the owner of customer data and experience.26
Naturally, automakers hope to retain control over the automotive ecosystem; they continue to make big IoT investments and work to stake a claim beyond the car. One automaker has launched a series of 25 “experiments” worldwide that showcase V2X connectivity, from testing out electric bikes and urban-mobility options to data-driven health care and insurance, as well as car-sharing, 3D printing, and biomimicry.27 Mercedes-Benz also co-hosted Hack with the Best, a hackathon to develop new IoT and wearable concepts for the company’s vehicles.28
Who will ultimately sit in the driver’s seat remains unclear; for now, at least, there are several pairs of hands on the wheel.
The same cultural, ecosystem, and technological changes that affect automakers’ competitive position affect manufacturing considerations and processes as well. Indeed, when it comes to manufacturing, many foresee the auto industry’s recent challenges persisting for the foreseeable future:
Customers opting out of owning. For many customer segments, behavior has changed dramatically with the rise of car-sharing and alternative travel methods, making car ownership less appealing. “Total cost of ownership” has also increased, pushing customers to choose less expensive new cars or opt for used vehicles instead. This has directly impacted carmakers’ profitability, and this trend is expected to continue; for the companies, customer satisfaction and loyalty, along with the ability to convert prospects, are increasingly important.
Faster design cycles. Interaction between people and devices has increased massively over the last 10 to 15 years, and the connected car comes with tremendous business potential. But beyond market share, the implications of connectivity extend to development. Rapid advances in technology have forced a continuous reduction in the time it takes to bring a new product to market: While mobile-device makers typically issue annual updates, the automotive development cycle is far longer—about six to seven years, with a market lifecycle of seven to fifteen years. In other words, cars take longer to develop and last far longer than the software, smartphones, and other connected technology with which they need to work, meaning that automakers face the additional challenge of ensuring upgrades can be accommodated, so connected cars don’t become obsolete long before consumers are ready to replace them.
Building in upgradability. With the shorter lifecycles of electronic software and hardware, consumers increasingly expect that their cars will seamlessly accommodate the latest gadgets and automatically update them whenever needed. Today, the technology exists to update a vehicle’s features by delivering a software upgrade over the air, but this system requires the vehicle to have processing and memory capabilities that can accommodate for scaling, to prevent the vehicle from becoming obsolete. Given the rate of technology development, this can pose a real challenge. With these challenges in mind, carmakers are exploring new ways to reduce overall product costs, shorten time to market, build in greater flexibility, and distinguish their vehicles in an era in which software is fast becoming as key a differentiator as body design and fuel economy. Indeed, several automakers have begun redesigning the product-development process by focusing on standard components and technology. The ratio of standard components will increase, reducing the product-development process per car (for example, time to market) and decreasing production costs. Automakers are also working to increase production flexibility and more efficiently leverage production capacities. Virtual car development, integrated production planning, data integration, and extensive data analysis will also further streamline the process.
Carmakers can also leverage the data generated by the connected car and apply increasingly sophisticated analytics capabilities to guide their internal decision processes, from better understanding and predicting customer preferences to driving design, testing, flexible production planning, and quality assurance. The automotive industry already has a long history of leveraging cutting-edge, cross-industry technologies in design and production, from digital technology to augmented reality to 3D printing. Smart infrastructure and wearables integration are the next step.
Automakers will continue to face many of the same challenges they always have: managing complexity and quality, improving flexibility and process optimization, conserving resources, and ensuring profitable growth. And while connectivity and mobility will change automotive business models—perhaps dramatically—they can also support many traditional functions and help improve companies’ overall competitiveness.
The key is settling on the right strategy. In this case, as always, it is better to be the leader than the follower.
Even as V2X ramps up and an increasing number of well-resourced and well-positioned players vie for dominance, the automotive industry is already looking ahead to the next phase and beyond: the autonomous or self-driving car. Automakers and software providers alike are pouring in R&D investments into self-driving technologies,29 and prototype self-driving vehicles are already on the road. As technology obviates human drivers, new interior designs for automobiles will create space and opportunity for passengers to enjoy greater productivity and personalization of experiences, while passenger data create ever-expanding sources of potential value. In addition, self-driving vehicles may encourage a further shift away from vehicles as owned assets—a self-driving Uber model, so to speak. Many observers look ahead to a not-too-distant future where shared vehicles operate autonomously, rarely crash, and provide true multi-modal transport options.30
Some foresee enormous benefits from this transformation: Morgan Stanley expects “full automation” by 2022, creating $1.3 trillion in value in the United States alone.31 The benefits will be accrued by businesses across a gamut of sectors even outside of automotive: cities, governments, and municipalities; customers themselves; and society at large.32
Self-driving cars require multiple connected technologies to work: GPS technologies to support navigation and routing; sensors including radar, lidar, high-powered cameras, sonar, and lasers that create and communicate a continuous, three-dimensional, omnidirectional view of a vehicle’s surroundings; sophisticated software that analyzes this information, including artificial intelligence that allows for self-learning capabilities; and technologies that translate the information collected and processed into action, including accelerating, braking, and steering.33
Google’s Self-Driving Car project, which the company expects to be commercial by 2020,34 exemplifies all of these capabilities. Google began by retrofitting a Toyota Prius with driverless technology and has moved on to its own designed prototype vehicles, with neither steering wheel nor pedals. The car is driven by sensors that can detect objects and steer around them: Google Chauffeur artificial-intelligence software processes the sensed information, predicts how these objects might behave, and makes decisions on how the car should respond.35 The car’s self-learning capabilities allow it to identify, respond to, and learn from new situations.
The vehicle’s functioning is based on its ability to respond instantly to stimuli and make decisions that drive the right response: that is, the timeliness, accuracy, and frequency of communication and processing of the information. At the same time, with little direct human control over the vehicle, security of the data communicated will be a critical value driver. And as connectivity expands and the vehicle is increasingly integrated into a broader ecosystem of other devices and infrastructure, still other capabilities will likely arise, such as smart traffic routing of self-driving vehicles, aimed at improving roadway efficiency.
The scope of the technologies involved appears to imply, as it has in the past, an expansion of the ecosystem needed to enable this Value Loop and a consequent further shift in the balance of power among the relevant players. However, the potential impacts on the automotive business model in this case indicate a more fundamental and widespread transformation of the industry itself. In one scenario, the power lies firmly with the software-platform providers, and the vehicle is just a conduit that acts on the information it is given—and is only as powerful as its operating system. In this way, it becomes little different than a smartphone or smart thermostat, chosen less for its own merits than for its operating system and its compatibility and interoperability with other connected devices that run on the same platform. Here, the majority of value is captured by players in the ecosystem that have the ability to use information generated by the vehicle and its surroundings—but none more so than the software providers that aggregate all of that data.
Many analysts predict significant impacts, not all positive for automakers: Barclays forecasts that shared driverless cars entering the market could cut total U.S. auto sales by 40 percent, meaning that automakers “would need to shrink dramatically to survive.”36 Automakers must make very deliberate choices today about the role they would play and how they would work within this ecosystem, if they are to survive in such a future. GM believes that it has designers, engineers, and scientists who “are working at the cutting edge, and we’re confident GM will be very successful.”37 Essentially, this creates a vision of OEMs not as carmakers but as tech companies that solve mobility problems.38 In other words, rather than lose their longstanding positions to software providers, automakers are themselves making a brave push into the software space, to ensure they can maintain more control over their vehicles—and customers—and capture IoT value as well. If you can’t beat them, join them? Only time will tell who will win this particular power struggle—the tech giants trying to be carmakers or the automotive giants trying to be tech companies.
Remember when a customer simply wrote a check and drove her new SUV off the lot? Those days are numbered, as connected cars suggest ongoing customer relationships. Considering that increased connectivity is, in turn, powered by increasingly sophisticated software technologies, automakers may look to software revenue models for ways to monetize. For example, software-as-a-service can enable pay-per-use models for in-vehicle services; licensing can allow for tiered services based on a customer’s selected level of service; ad-supported content can subsidize delivery of in-vehicle services; and other software-industry concepts can be leveraged to drive in-vehicle service adoption.
Similarly, several of the other challenges the automotive sector faces now bear closer resemblance to those faced by software providers: Vehicle security and customer privacy may go hand-in-hand with developments in software and mobile-device security; the regulatory environment may more closely resemble the software industry; data and intellectual-property ownership may reside primarily in the hands of the software providers; technical governance and integration may reside with the software players as well; and so on. It may not be a stretch, in fact, to reclassify the automotive industry of the future as a software-driven mobility industry.
The Internet of Things enables transformational change, and there is no question that the automotive sector is changing extremely rapidly. IoT-related technologies will draw the map for the industry to follow, and the connected car will play a major role on the roads and in the economy of the future.
The power struggle between automakers and software developers is a symptom of the ongoing transformation, like birth pangs as the industry reinvents itself. We are moving from an age of products to an age of services and experiences, from hardware to software, from functionality to information as the key object of value creation, and from industry silos to intricately connected ecosystems and value loops. It is no surprise that carmakers find themselves navigating new terrain within an ever-expanding ecosystem of players, all of which are trying to capture value, and where players that control the aggregation and analysis of this information—the software providers—steadily gain ground.
As automakers consider their place in this changing industry, they can consider several approaches to strengthening their position:
Align on a vision of the role that the business will play in the ecosystem, understanding and accepting the transformational impacts this may have on the business and on the “old ways of thinking.”
Develop a clear mapping of where data originates—and, consequently, who owns it—for each of the services delivered, to better understand where value can be captured.
Develop a roadmap for shifting to a more service-oriented approach as an entire organization, not just in the connected-vehicle divisions, to enable ongoing interaction with customers throughout the entire lifecycle.
Accept new capabilities that need to either be built internally or acquired externally. Seek greater involvement in—and ownership of—in-vehicle software-platform development.
Consider ways to address manufacturing/lifecycle challenges by working closely with technology providers to more closely integrate development processes and software-driven feature rollouts and updates.
Identify and build strategic partnerships with key players across the ecosystem, including with emerging smart-device manufacturers, and work across the value chain to build a broader, more holistic brand experience enabled through connected technologies.
The road ahead for the industry is open and lined with opportunity. It’s time to shift into high gear.
Deloitte’s Internet of Things practice enables organizations to identify where the IoT can potentially create value in their industry and develop strategies to capture that value, utilizing IoT for operational benefit.​
To learn more about Deloitte’s IoT practice, visit http://www2.deloitte.com/us/en/pages/technology-media-and-telecommunications/topics/the-internet-of-things.html.
Read more of our research and thought leadership on the IoT at http://dupress.com/collection/internet-of-things/.Inputs devices and sensors: Devices and sensors begin the IoT cycle by gathering and sharing modality-specific data. IoT platform: To communicate with each other, the devices are integrated on an IoT platform that provides the infrastructure and standards/protocols for seamless connectivity. Artificial intelligence: Sophisticated machine-learning loops that interpret the data, derive insights, and determine responses have long replaced linear if-this-then-that logic. Actionable feedback loops: The AI engine activates automatic responses (e.g., through an effector arm) and/or synthesizes insights for human interpretation or future machine learning. User interfaces: Finally, users interact with the devices and consume the information and insights generated by the IoT ecosystem.
In-home automation is an example of how these five components are brought to life. Smart home devices (e.g., smart light bulbs, thermostats, locks, refrigerators, garage doors) are connected to a home automation platform. This allows an AI engine to combine data from multiple devices and drive actionable feedback loops. For example, when the AI engine recognizes that the garage door has been left open, it might use motion-sensor data and geofencing (smart phone GPS location) to determine that (a) the home is vacant and (b) that nobody is likely to return in the immediate future based on prior patterns. The system determines the best course of action is to shut the garage door for security and send an update memo to the home owner.
Similarly, the digital health ecosystem abounds with opportunities to advance care and improve the health experience. Real-world data generated by the health IoT is becoming increasingly abundant and accessible. A recent Deloitte survey found that consumers are becoming more interested in technology such as wearables and mobile apps, for health purposes. Specifically, 60 percent of respondents said they are willing to share data gathered from wearable devices with their doctors.1 Health-related IoT ecosystems have the potential to generate profound insights and enhance patient care—even within the home.
Consider patients who are living with diabetes. A health IoT ecosystem might enable more precise glucose control, which could help improve short- and long-term health outcomes. The input and output devices for this particular ecosystem (a digital glucose monitor, an automatic insulin pump, a smart watch, and a smart pill box) connect through an AI-enabled diabetes management platform. On its own, the continuous glucose monitor could make insulin dosage recommendations. But the digital ecosystem becomes even more powerful when data—including patient activity levels and smart pill uses—is added (e.g., heightened stress, changes in physical activity or forgetting to take medication). By tapping into historic activity patterns, the system could further refine the recommendations. For example, by prompting the user to decrease his insulin dosage on Saturday mornings when he plays basketball with neighbors. With the patient’s verbal confirmation, the adjusted insulin dose would be administered. An ecosystem like this—in which real-time data feeds are processed and combined with predictive models—enables truly personalized health interventions when properly integrated, optimized, and monitored.
Health care organizations that want to take advantage of IoT and virtual health will likely need to work through some key steps to realize this digital health ecosystem vision:
Inputs and platforms: Integrating multiple inputs onto a single platform, or compatibility across multiple platforms, can be challenging. Many companies have a proprietary strategy for delivering IoT, which means users are restricted to a list of devices that are compatible with the platform they choose. Health care organizations that want to build an IoT platform should first consider the standards through which the devices can be accessed and how the devices will communicate and interact with other components of the ecosystem. More specifically, these organizations will likely need to determine whether the platform is capable of supporting data from multiple existing and future inputs. Organizations should consider the extent to which the platform is customized in-house vs. relies on standard configurations by the platform vendor. In health care, there are few clear IoT standards and protocols. 2 Although some partnerships are being formed to develop standards, work still needs to be done to foster true interoperability and increase industry adoption. 3
Integrating multiple inputs onto a single platform, or compatibility across multiple platforms, can be challenging. Many companies have a proprietary strategy for delivering IoT, which means users are restricted to a list of devices that are compatible with the platform they choose. Health care organizations that want to build an IoT platform should first consider the standards through which the devices can be accessed and how the devices will communicate and interact with other components of the ecosystem. More specifically, these organizations will likely need to determine whether the platform is capable of supporting data from multiple existing and future inputs. Organizations should consider the extent to which the platform is customized in-house vs. relies on standard configurations by the platform vendor. In health care, there are few clear IoT standards and protocols. Although some partnerships are being formed to develop standards, work still needs to be done to foster true interoperability and increase industry adoption. AI and data management: Data is the backbone of the IoT ecosystem. Without data, AI cannot perform analytics and generate actionable feedback loops. Data security is paramount when handling PII/PHI (personally identifiable information and personal health information). Data that circulates between distributed devices and end-users is especially vulnerable to security breaches and unauthorized access. Developers should take proper measures around encryption, access control, and traceability, and overall compliance with HIPAA requirements (for example not all consumer electronics are HIPAA compliant!). Organizations should ensure that data security and integrity is ensured throughout acquisition, processing, storage, transfer, and use. 4 Similarly, special attention should be placed on any AI engine’s ability to meet pertinent standards and requirements (which can vary with geography and the regulatory regime under which the solution falls).
Data is the backbone of the IoT ecosystem. Without data, AI cannot perform analytics and generate actionable feedback loops. Data security is paramount when handling PII/PHI (personally identifiable information and personal health information). Data that circulates between distributed devices and end-users is especially vulnerable to security breaches and unauthorized access. Developers should take proper measures around encryption, access control, and traceability, and overall compliance with HIPAA requirements (for example not all consumer electronics are HIPAA compliant!). Organizations should ensure that data security and integrity is ensured throughout acquisition, processing, storage, transfer, and use. Similarly, special attention should be placed on any AI engine’s ability to meet pertinent standards and requirements (which can vary with geography and the regulatory regime under which the solution falls). User interfaces: Particularly in health care, simplicity and user-friendliness are paramount to promote adoption and prevent possibly severe health implications. Challenges include limited IT literacy among users, which can lead to difficulties related to installing, configuring, or integrating the devices.5 Organizations that want to build IoT devices should consider developing a friendly, easy-to-comprehend user interface and user experience (UI/UX) that will help address this common adoption barrier. When building the user interface, health care organizations should pay close attention to accessibility (e.g., for elderly or disabled patients), expandability (the ability to add other devices and functionalities), and engagement (capabilities like gamification and nudging that use behavioral economics to improve well-being). Deloitte and the Perelman School of Medicine at the University of Pennsylvania recently published the results of their STEP UP study, which highlights that gamification combined with wearable fitness trackers can lead to sustained results (more steps).
Health care organizations should build IoT into their broader virtual health strategy, specifically geared toward patient engagement and care management objectives. To achieve IoT’s potential, health care organizations should consider the following seven questions:
Where is IoT likely to have the biggest impact on the quadruple aim (i.e., enhance the patient experience, improve the health of populations, reduce costs, and enhance the caregiver experience)? In which ways can IoT solutions radically re-imagine patient engagement and care management? How can organizations manage implementation to maintain patient safety and improve the patient experience during the transition?What additional inputs might need to be combined with the existing digital/virtual health infrastructure to integrate IoT into care management plans, thereby creating an ecosystem powered by multiple devices What additional inputs might need to be combined with the existing digital/virtual health infrastructure to integrate IoT into care management plans, thereby creating an ecosystem powered by multiple devices? How should the organization source its IoT platform? What existing platforms and solutions can accelerate the journey to implementation? How can the organization address physician resistance to technology adoption in the clinical setting and generate insights that physicians will trust? To further enable IoT adoption, how can the organization align its consumer and physician-engagement strategy with user-friendly interfaces? How can an IoT platform reduce total cost of care, become self-funding, and free up resources for investment in other critical capabilities?
Most health care organizations are in the early stages of developing a health IoT ecosystem. As they embark on the journey toward the future of health, they should acknowledge that the true strength of IoT resides in creating an ecosystem that brings together multiple devices to create insights and outputs that improve health.Think about this: There are now more than a half a billion types of medical devices manufactured around the world.1 Through the Internet of Things (IoT), a growing number of these devices are collecting, analyzing, and transmitting health data or images to the cloud or to internal servers. Over the next decade, as many as 50 billion medical devices will connect to clinicians, health systems, patients, and to each other.2
Last month, our UK Centre for Health Solutions released a report that examined connected medical devices and their potential to transform health care. Within the next five years, medical technology companies anticipate that 68 percent of their devices will be connected through IoT, up from 48 percent now, according to an online a survey Deloitte conducted with 237 companies. Within five years, 44 percent of respondents predicted that all of their devices will be connected, according to our research.
Devices that diagnose, monitor, and help treat patients touch every part of health care. The connected-medical-device market is expected to more than triple, from $15 billion in 2017 to $52 billion by 2022, according to the research firm MarketsandMarkets.
Our research identifies eight challenges that medtech companies should consider addressing as they transition from being suppliers of innovative products to insightful partners in health care.
Developing an in-depth understanding of end users: As the idea of value-based care gains more traction in health care, stakeholders will likely push medical technology companies to demonstrate the value of their products.
Solution: Manufacturers of connected medical devices should forge closer ties to health system leaders, clinicians, and to patients who rely on their products. They should build new business models and scenarios that demonstrate how their devices can improve patient outcomes and create value to stakeholders. Nearly 40 percent of medtech companies are, to a large extent, taking a value-based approach to their pricing, according to the results of the survey.
Building funding, business, and operational models: Only about half of surveyed medtech companies say they are implementing new business models to a large extent, while just 10 percent of respondents said they are not adding any new models.
Solution: The fee-for-service payment model does not reward health systems or clinicians for their ability to prevent illnesses or to avoid long-term costs. We are probably still years away from having a value-based health care system that effectively rewards innovation, but the industry is working toward it. We recently worked with the Advanced Medical Technology Association (AdvaMed) to launch a strategic value initiative—a framework that assesses the value of medical technologies that can be adopted by medtech companies, health systems, health plans, and other industry stakeholders. Innovation will likely require different business models, and progress will depend on medtech companies developing new ways to take on risks and rewards.
Improving interoperability: If health care stakeholders are to take full advantage of connected medical devices, interoperability could be critical. Interoperability can be a significant barrier to creating a patient-centered, digitally-enabled health care ecosystem. There are privacy and security challenges associated with the exchange of health information, and there is no single standard for electronic health records (EHR) systems. There is also little incentive for the private sector to move toward a more interoperable system.
Solution: Open platforms, based on open-data standards, could allow health plans, health care providers, and technology vendors to come together to make data more available to each other. Stakeholders should work toward developing a unified platform through which clinical data can be shared. They also will likely need to develop a consensus for interoperability standards.
Maintaining cybersecurity: Nearly 70 percent of medical device manufacturers say an attack on their medical devices is likely, but just 17 percent of those companies are taking significant steps to thwart cyberattacks, according to research from the Ponemon Institute.
Solution: Our survey results indicate that most medtech companies are working to maintain the security of their connected devices. More than 80 percent of respondents said they were “reasonably well prepared” (44 percent) or “very well prepared” (37 percent) to protect their devices. Just 14 percent of respondents indicated that they were “not very well prepared,” or “not at all prepared” to protect their devices from a cyberattack. Medical device manufacturers should consider adopting a “security-by-design” approach where a device is built from the ground up to be secure, rather than having security features added after it has been delivered and deployed. Navigating regulatory change: A variety of security issues related to connected medical devices has prompted new regulations and guidelines that medtech companies need to navigate.
Solution: Survey results indicate that medtech companies are prepared to comply with regulatory changes. Forty-three percent of respondents said they were “reasonably well prepared,” while 39 percent said they were “very well prepared.” Medtech companies should build strategies to engage with regulators on their innovation models. They should also consider involving clinicians and patients when designing products. The US Food and Drug Administration’s (FDA) initiatives to develop a more collaborative approach to innovation could provide a path for regulators outside of the US to follow.
Attracting digital talent: There is some concern among stakeholders that they might lack the skills needed to deploy connected devices, which could hinder market growth. To stay competitive, medtech companies should build a tech-savvy workforce.
Solution: Nearly 80 percent of surveyed medtech companies said they are prepared to build digital capabilities within their companies. Resourceful recruitment and retention strategies could include collaborations and partnerships with a diverse range of existing and emerging players (e.g., academia, engineering companies, technology firms, and innovative new start-ups).
Maintaining trust in a digital age: The success of connected medical devices can hinge on the willingness of patients to share their health data. This is probably less likely to happen if patients aren’t sure how their data will be used. As more devices become connected, medtech should be vigilant in protecting patient data. In a My Take a year ago, I wrote why medtech companies need to make sure patient data are secure.
Solution: Medtech companies should earn the trust of providers and patients by developing strong privacy and security arrangements through the use of data encryption and authentication mechanisms. They should also give patients control over their own data (including the right to keep it from being shared), and allow the patient to see who is using data and for what purposes. Nearly 70 percent of surveyed medtech companies agree that patients will eventually own their health data. Embedded blockchain-like technology could offer a real-time mechanism for tracking how data are processed.
Improving the adoption of medical technology: More than 70 percent of medtech companies said health care systems and clinicians are not yet prepared to use data generated from connected medical devices. According to our recent surveys of US health care consumers and physicians, half of consumers use technology to track their health information and 53 percent said they shared this information with their doctor. However, only nine percent of providers have implemented technology for remote monitoring and/or integration of data from wearables, and just 27 percent intend to add this capability within the next couple of years.
Solution: Medtech companies should provide health care stakeholders with robust and reliable evidence that the data generated by their devices can reduce costs, improve efficiencies, and lead to better patient outcomes. They also should demonstrate that the devices are intuitive and easy to use, and, when necessary, offer training and support to staff.
As connected medical devices become more sophisticated and mainstream, we can move closer to having an interconnected health care system. Along with allowing clinicians to change how and where medical care is provided, connected medical devices have the potential to gather, analyze, and share data that could help improve our understanding of patients and their diseases.In our sixth Internet of Things Newsflash we cover recent news and updates from the international IoT space. Both HPE and Microsoft provided Edge computing news while the IIC announced a new testbed and Telefónica and ASTI Mobile Robotics made their cooperation public. Additionally, a NelsonHall study examined the current state of IoT projects and a survey by Plataine/ SME.org highlighted current digital factory trends.
HPE to invest $4 billion in intelligent edge – Hewlett Packard Enterprise (HPE) announced a four year plan for investing $4 billion in intelligent Edge technologies and services built on data insights. As part of the announcement Antonio Neri, HPE’s president and CEO, stressed the importance of data in today’s business and provided an outlook for edge-to-cloud architecture.
Microsoft makes Azure IoT Edge generally available – Microsoft announced that Azure IoT Edge is now generally available (GA) globally for their enterprise customers. In addition, IoT Edge is now open sourced and available on Microsoft’s recent acquisition GitHub.
IIC announces Smart Printing Factory testbed with Fujifilm – The Industrial Internet Consortium (IIC) announced the Smart Printing Factory (SPF) Testbed led by Fujifilm and supported by Fujitsu, IBM, Real-Time Innovations and Toshiba. This testbed and its Smart Printing Factory Platform are intended to automate print production as well as provide predictive maintenance for factory-based printing equipment.
Telefónica and ASTI Mobile Robotics team up – The two companies signed a collaboration agreement focusing on industrial IoT as part of the “Logistics 4.0” field. The collaboration consists of both a technological and a commercial component, which means that Telefónica and ASTI Mobile Robotics intend to develop both new products in the field of LTE networks as well as new business together.
NelsonHall study “IoT Services: Continued Focus on Use Cases” – The new NelsonHall study examined the current state of implemented IoT projects across organizations. The report found that most organizations are focusing on incremental adjustments rather than transforming entire business models. Improving operations and enhancing existing offerings have been identified as main goals of current IoT projects.
Digital manufacturing survey by Plataine and SME.org – The joint survey conducted by IIoT solution provider Plataine and SME.org questioned 400 C-level members of the manufacturing industry and illuminates current trends in Industry 4.0 and the digital factory environment.Deloitte Consulting Chief Futurist Robert Schmid, AKA “Mr. IoT,” interviews guest specialists across the burgeoning IoT space. They’re taking deep dives into the world of connected technologies and in particular the human impact these technologies have on how we live and work.
Guests include current and former luminaries of the digital world, including Deloitte leaders and practitioners who have worked on IoT projects, clients who have implemented IoT, and collaborators from our alliance network. Topics have covered Industry 4.0, smart buildings, smart cities, connected home and medical devices, digital supply networks, industrial IoT, AR, AI and machine learning, virtual assistants, standards, and more.
Check back each week for new episodes. You can also view episodes of Coffee with Mr. IoT as a video series on YouTube.During the rise of the Internet, communication services treated their network providers as little more than “dumb pipes,” providing bandwidth. The IoT revolution, requiring a dramatic increase in strong, secure communication links, offers providers an opportunity to not only play a larger role but to create new value.
The Internet of Things (IoT) has become increasingly visible thanks to the rise of intelligent thermostats, interactive fitness trackers, and the promise of autonomous vehicles. Such technologies are compelling because they make the things around us smarter and more interactive. In the words of one commentator, we need no longer settle for dumb tools but can instead look forward to “enchanted objects.”1
The sensor technologies that make things “smart” are only part of the IoT, however. Connecting all these devices is what turns isolated pockets of technology into a network that generates and pools data in ways that lead to valuable insights.
Thanks to the central role of communications in many IoT deployments, how companies create value is often a function of the interaction between sensor technology and the network layer. Linking new and legacy sensors within an IoT ecosystem often means that companies seeking to realize value from the IoT need to work closely with their communication services providers (CSPs).
In the words of one commentator, we need no longer settle for dumb tools but can instead look forward to “enchanted objects.”
Such collaboration is unlikely to come easily to either party. Consumers of communications services can easily overlook the challenges associated with creating the sort of connectivity required to realize the full benefit of IoT technology. With “Internet” in its name, the IoT connotes that the advancing legions of smart devices need simply plug into the existing infrastructure: Just give everything an email address and we’re good to go. In this scenario, CSPs aren’t indispensable partners—they’re mere vendors.
Providers of network services can be expected to have their own biases to overcome. The rise of the Internet separated communications services from the communications network they ride over. There was a tendency among CSPs to resist the claim that they provided little more than “dumb pipes,” a term that belied the industry’s technological sophistication. Yet the economics of the asset intensity implied by building out near-ubiquitous, high-bandwidth, reliable, and secure wireline and wireless networks rewarded the large-scale deployment of relatively undifferentiated services. Shifting to a more nearly bespoke set of solutions means going against a grain that runs deep.
To help companies and CSPs think more carefully about how they work together and overcome any legacy of benign mutual neglect, we are well served to consider how sensor technology and network systems relate within different IoT deployments, the nature of the value created, and what that means for the collaboration required.
The rise of smart, connected things—from wearable activity trackers to connected cars to the electrical grid—allows companies to compete not only on the functionality and performance of their products or services but also on the information created by the use of these products or services.2 Where supply chains determine functionality and performance, the value created by information is captured by the Information Value Loop (see inset).
The suite of technologies that enables the Internet of Things promises to turn almost any object into a source of information about that object. This creates both a new way to differentiate products and services and a new source of value that can be managed in its own right.
Creating value in the form of products and services gave rise to the notion of a “value chain”—the series and sequence of activities by which an organization transforms inputs into outputs. Similarly, realizing the IoT’s full potential motivates a framework that captures the series and sequence of activities by which organizations create value from information: the Information Value Loop.
Note first that the value loop is a loop: an action—the state or behavior of things in the real world—gives rise to information, which is then manipulated in order to inform future action. For information to complete the loop and create value, it passes through the stages of the loop, each stage enabled by specific technologies. An act is monitored by a sensor that creates information. That information passed through a network so that it can be communicated, and standards—be they technical, legal, regulatory, or social—allow that information to aggregated across time and space. Augmented intelligence is a generic term meant to capture all manner of analytical support, which collectively are used to analyze information. The loop is completed via augmented behavior technologies that either enable automated autonomous action or shape human decision in a manner that leads to improved action.
Getting information around the Value Loop allows an organization to create value; how much value is created is a function of the value drivers, which capture the characteristics of the information that makes its way around the value loop. The drivers of information value can be captured and sorted into the three categories: magnitude, risk, and time.
The value loop begins with creating and communicating information in entirely new contexts. Sensor technology enables actions in the world to give rise to data—the create stage. Networks, often provided and managed by CSPs, link create and communicate, liberating data and enabling the rest of the value loop. It is at the interface between the two that the opportunity for new forms of collaboration arises.
When the Internet emerged, most online services connected people, and there was a relatively high tolerance for low or variable quality because people are good at coping with latency, errors, and/or failure. Unlike people, even smart machines are poorly equipped to deal with these same communication issues. In other words, dumb pipes are sufficient when connecting people; smarter pipes become more important when connecting things.
More demanding still, some companies are deploying a much larger number of sensors—connecting tens of billions of things rather than “merely” hundreds of millions of people—and many companies are placing those sensors in harsh environments or mission-critical situations that put new stresses on how these devices need to communicate. Consequently, there is no one-size-fits-all combination of sensors and network connectivity. What is being connected (that is, the nature of the sensors) and how it is connected (that is, the nature of the network) have a real impact on how value is created. At first principles, the differences turn in many cases on a choice between new and legacy sensors, and between “best efforts” and managed communication.
In weighing how to incorporate IoT technology and applications, few companies today are starting from scratch. Many industrial activities, for instance, have long had sensors generating data, at central plants and remote locations, at customers’ homes and main assembly lines. These sensors, often installed decades ago, typically have limited communication or autonomous operation capabilities—they rely on human operators for activation and data collection-much less the capacity for analysis and action. So the first key decision is whether to augment existing sensors or to replace those sensors with smart, connected devices.
As with many technologies, prices of IoT-enabled sensors are falling. In commercial applications, replacing existing sensors nevertheless can be expensive. More daunting, wholesale replacement can require rethinking a business process. This combination of cost, asset life cycle, and inertia means that many solutions will rely on existing sensors augmented with either communication capabilities or additional sensors. (As a company rolls out new business assets, those can be outfitted with new sensor networks.)
In contrast, consumer applications often require new smart sensors—either as standalone additions to an existing asset or to be embedded in a replacement asset. Current standalone examples include smart thermostats and security systems. Sensors are also being embedded in cars, domestic appliances, and consumer electronics. These solutions’ functionality—and business models—are still in flux, leaving similarly undetermined the relationship between the capabilities of the sensors and the networks they require. In other words, consumer-facing businesses don’t know yet what IoT-enabled products customers will buy in the coming years, or exactly how those products will function, so it is next to impossible to determine ahead of time what communication networks will be necessary.
In a best-efforts communication network, the customer essentially gets what is available. There are no guarantees on data speed, responsiveness, availability, error rates, or other performance attributes. For some services, such as downloading or streaming content, this can prove bothersome: Almost everyone has experienced delays while the viewing software waits for the missing bitstream to arrive, or been forced to reboot when an Internet-based application freezes. To compensate, many customers end up buying more bandwidth—capacity and speed—than they actually need and hope that in most circumstances this will enable a reasonable service level.
Currently, almost all wireless connections provide a best-efforts approach to communications3—in other words, the availability, data transfer rate, packet loss rates, and latency are subject to the vagaries of contention for capacity between users, interference, and radio propagation.
In contrast, a managed-communications solution shifts to the CSP the burden of ensuring a reliable bitstream, opening the door to customer applications that demand reliable real-time or near-real-time connectivity over wide distances or other similarly demanding constraints. The International Telecommunications Union identifies three dimensions of managed services:4
Grade of Service (GoS) : This defines the physical connection’s availability and performance and measures attributes such as coverage, capacity, and the probability of a network outage.
: This defines the physical connection’s availability and performance and measures attributes such as coverage, capacity, and the probability of a network outage. Quality of Service (QoS) : This defines the traffic flow’s performance and allows an application to specify its needs according to attributes such as latency, jitter, dropped packet performance, error rates, and guaranteed throughput (bit rate).
: This defines the traffic flow’s performance and allows an application to specify its needs according to attributes such as latency, jitter, dropped packet performance, error rates, and guaranteed throughput (bit rate). Quality of Experience (QoE): This relates to users’ experience of using a service and is beyond the scope of this article. It is a subjective assessment of the end user’s experience with the service and thus brings in the communications network, the terminals, ease of use, and so on.
When connecting sensors to networks—that is, when linking the create and communicate stages of the value loop—lost information and transmission delays can generate a variety of undesirable outcomes, especially when IoT-generated data are driving the operations of heavy equipment or public utilities. Closer collaboration between network users and network service providers can help avoid such difficulties because the technologies enabling each IoT deployment can be configured to address the specific GoS and QoS performance levels required. (QoE tends to take center stage when we get to analyze and act.)
On the downside, managed solutions can be comparatively expensive to construct and operate—certainly more so than ad-hoc best-efforts wireless systems—but they can solve legacy issues such as requesting sensor data, managing the relationship between multiple sensor data streams, and understanding whether a sensor has failed or is just unable to communicate.5 The communications network can take responsibility for managing the collection cycle (a pull approach), providing time and device stamping of sensor information, and ensuring device functionality and security.
Mapping the options for sensors (legacy versus new) and communications networks (best-efforts versus managed) reveals four categories of IoT deployments, each defined by the primary dimension of value most affected by the relationship between the company deploying an IoT solution and its CSP (see figure 1). Locating a given IoT deployment and its associated value loop provides a roadmap for assessing the viability and advisability of evolving current solutions to potentially more valuable—even if more demanding—configurations.
By examining each quadrant through the lens of a specific use case, we can begin to understand the value that each combination can create, as well as the implications for collaboration between a company and its CSP.
The current IoT emphasis on cost savings and IP-based solutions, with a heavy reliance on wireless communications (typically a best-efforts network), has resulted in very few examples of customization, which relies on managed communications. Among those that have come closest so far are some industrial point solutions such as German automation manufacturer KUKA’s connected robots, part of a 1,444-node network linking around 60,000 devices.6 One such deployment is in the new Jeep Wrangler production facility in Toledo, OH, where 259 robots are connected through 33 control points and are able to produce 830 car bodies for eight different vehicles every day.7 The connections between these industrial robots have traditionally been hardwired local area connections.8 Since each of these solutions has been contained inside a single facility, requiring a full private network, the companies have not engaged CSPs. This self-contained approach is representative of highly customized solutions. IoT systems that require high security, uninterrupted connections, and the latest technology are typically deployed in circumscribed environments running proprietary protocols over a hardwired network.
As quality improves and prices fall, more companies will likely find customized solutions, implemented in collaboration with a CSP, increasingly attractive.
Such a “closed shop” is unlikely to persist indefinitely, as two forces drive more companies to engage CSPs even when developing customized solutions. First, as firms implement IoT solutions in a wider variety of contexts, the performance benefits of customized sensor/network combinations will become clear, as will the flaws of many work-arounds based on existing best-efforts infrastructure. Early IoT solutions aimed to solve point problems, such as how to make a machine more productive or autonomous; the next step is using the IoT to make a system, with multiple machines, work in concert, and this requires managed communications. Second, the communications technologies required today for customized solutions are likely to follow in the footsteps of previous telecom technologies: falling costs and increasing modularization.9
As quality improves and prices fall, more companies will likely find customized solutions, implemented in collaboration with a CSP, increasingly attractive. Consequently it makes sense to explore the other three categories of IoT communication deployment not only in terms of how firms are currently using the technology but also in terms of how companies might migrate their current approaches to this more demanding, but more rewarding, configuration.
Furthermore, since few companies will have the luxury of starting over with their IoT strategies, unencumbered by legacy systems or budget constraints. So, in addition to describing how a company and CSP collaborate in the other three quadrants, we will explore how applications starting in each quadrant can make the migration to customized solutions, with an emphasis on how each application’s starting point affects its path forward.
Unsurprisingly, cost reduction characterizes many companies’ current priorities for IoT deployments, which in many cases consist of comparatively rudimentary sensors linked by a basic Wi-Fi network.10 Especially with large, established organizations—particularly those with huge investments in existing machinery—we see numerous situations in which equipment is already instrumented but executives have not yet moved to integrate the resulting data into an automated workflow: the value loop’s communications, aggregation, analysis, and action stages.
Consider the mining industry, where most large mine vehicles have been fitted with sensors since before anyone spoke of an Internet of Things. Caterpillar’s Vital Information Management System,11 for instance, collects data on more than 250 attributes such as payload, engine RPM, brake condition and use, structural stress, and replaceable-part condition (for example, air filters) from the massive haul trucks. This information is used to assess the truck’s health, increase vehicle uptime, maximize route and payload efficiency, and even provide data on the condition of the haulage road the mining truck is using. Initially, this system was designed to enable data download from the vehicle; now Caterpillar can link it to a system such as MineStar12 that allows fleet management and vehicle health monitoring over a radio link—usually 802.11 b/g, a best-efforts Wi-Fi connection.13
The bottleneck in the create phase is the cost and complexity of measuring new vehicle attributes and fundamentally changing vehicle sensors. Since a large mine haulage truck typically costs between $500,000 and $5 million and lasts perhaps 20 years, operators will likely opt, for now, only to augment existing sensor capabilities. But this will necessarily limit the potential value from IoT solutions.
As companies look to exploit IoT capabilities more fully, one way forward is to migrate to more carefully managed networks: With long-lived assets—such as haul trucks, with sensors built into the engine—it is easier to upgrade the network than the sensors. For example, some mine haulage companies are beginning to deploy autonomous vehicles by retrofitting14 additional sensor systems (collision-avoidance sensors and positioning systems) and networking them through a managed communications system. The companies’ CSP partners add significant value and control two bottlenecks: the deployment of managed networks and the ability to manage legacy sensors more effectively to improve asset performance and lower operating costs.
There are already mining applications emerging for which companies are deploying localized managed communications. For example, in many underground situations, companies deploy a wired and wireless data network for telemetry, monitoring, and limited remote operations. But these private networks, while built to a high standard and with extensive redundancy built in, cannot truly offer fully managed communications. As mining moves to more automated solutions, with a shift from simply improving the performance and safety of manned machines (for example, having an operator manage a machine by remote control) to machines working in harmony to create an autonomous mining system, communications networks will require total control, to ensure the system’s safety and efficiency. As with other firms and industries with IoT deployments in the cost quadrant, mine haulage companies moving toward customization demands both upgrading to new sensors and working with CSPs to implement a managed communications system.
Some companies, working with last-generation sensors installed years ago, have moved to convert their existing connections into IoT functionality by dramatically upgrading the communication links between their sensors, working with CSPs to improve and control communications.
For example, in managing its wind turbines, GE tapped its existing range of sensors, including lasers that measure the wind heading for the turbine and sensors in the turbine linked to others at the wind-farm level, at the storage system, and in the distribution grid.15 Using its highly developed communication system to meet demand, the wind farm analyzes information to optimize power production, operations and maintenance costs, and flexibility. The system analyzes tens of thousands of data points every second to integrate hundreds of megawatts into the grid. The GE system has six interconnections that communicate with each other: turbine to turbine, farm to farm, farm to grid, turbine to remote operations center, turbine to battery, and turbine to tech.16 Through these communications—achieved using reliable fiber and wireless IP communications—the system is able to optimize power output and management for grid operators. These solutions are largely focused on improving the generating capabilities of an individual wind farm.
The next step for GE, and for other companies with legacy sensors and managed communications, is moving to wide-area managed communications and broader sensor networks. Since wind power is less reliable and predictable than traditional fossil-fuel generation, power grids that aim to integrate it often struggle to match supply with demand. Grid operators’ technical challenges can result in voltage and frequency management issues: In essence, a grid runs in a situation where demand and supply are exactly balanced; if demand begins to exceed supply, the frequency of the grid will fall, and power-plant operators have a series of approaches to resolve this situation.
Managed wide-area communications will clearly help deal with wind power’s unpredictability, but very low latency can enable wind power to play a more significant role in frequency management. The bottom line: As wind power becomes a more significant component of power generation, wide-area managed-control networks will likely be necessary to effectively integrate this new power source.
So in the case of mining operations, the shift to managed communications offers significant benefits; the key tradeoff appears to be deploying a local private network or purchasing managed communications from a CSP. In the wind-turbine situation, the choices are the same, but the wide-area nature of the communications means that a CSP solution likely makes more sense.
Consumer-oriented IoT devices are a recent development, so naturally the sensors at the heart of their functions are more nearly up to date. But since at least some customers will use these appliances across networks managed by different CSPs, the devices’ connections can’t be as heavily managed as sensors that operate solely within the orbit of a single provider.
An example is the Fitbit fitness band, the latest iteration being the Surge,17 which measures exercise activities, heart rate, steps, and route information (for example, distance, pace, gain). Usually, it connects via Bluetooth to the user’s smartphone and thence to the Internet, updating the user’s Fitbit account every 20 minutes or less. This limited communications does not impede the device’s functionality in its current role: primarily, recording exercise data.
However, those limitations may hamper efforts to integrate the device into a personal health-and-fitness ecosystem. Today Fitbit can be integrated with other analytics and sensors systems, but this relies on the user to create the integration and offers limited increased functionality. For example, a user can manually link her Fitbit to a Weight Watchers, MyFitnessPal, or Endomondo application,18 or to other IoT devices such as a Withings body analyzer (measuring weight, BMI, fat mass, and air quality). While part of a sophisticated ecosystem of analysis, a Fitbit band is nevertheless hamstrung by best-efforts communication.
With more sophisticated communication links, a Fitbit would be able to interact with other sensors and actuators. In a gym workout situation, it could pass a user’s heart rate, exercise levels, and body temperature to smart climate-control systems to modulate the air-conditioning system in real time. Similarly, if multiple gym users are wearing the same technology, their sensors could interact in real time to allow for direct competition or to create overlays of historical data with information from the sensor—for example, overlaying the user’s current workout with a historical performance: How does my time compare to Jesse Owens’? Finally, the Fitbit could interact with the exercise machine for more sophisticated workouts. Thus it is likely that at least some companies will shift some consumer applications from best-efforts communications to managed situations, allowing for much more complex interactions between devices and for consumer devices to take on more critical functions.
Even so, making such a shift requires careful consideration: for many consumer applications, a shift from best-efforts to high-powered, top-security managed communications would be both impractical and overkill. The basic functionality envisioned for a smart refrigerator or thermostat is not materially compromised by the momentary hiccups and delays of a Bluetooth or Wi-Fi connection, and no hacker would bother attacking such a small target. Also key: Consumer-device manufacturers sell highly standardized products to a global market, with no control over which networks consumers may use for their new IoT devices, making managing those communications problematic at best. Some consumer-facing companies will be able to make the move to the customization quadrant; many will not.
Obviously, companies constitute only half of the partnership that can get them to the customization stage, with managed communications to link and draw value from new IoT sensors. CSPs—soon to be tasked with connecting millions of new devices and users, carrying both sensor data and sensitive information19—will play an important role, one that both requires more from them than in the past and offers far greater opportunity to create value.
In the IoT world, CSPs’ biggest challenge is to shift from an environment in which they charge based on volume of traffic and connections to one in which they charge based on level of performance. These firms, long relegated to a back-office function, will have to take unaccustomed risks to create networks in which they can guarantee that a particular data communication will take place—every time—with the latency, speed, and error rate that the customer has demanded. This represents a major shift, since today, even in managed networks, CSPs either set the bar low on performance guarantees or make only limited, aggregated performance promises.
CSPs also face a major technological challenge, the one that makes high-level IoT applications function: the actual work of collecting and processing information from multiple sensors and devices—and standardizing it, even as technologies continue to evolve. In order to do this, CSPs will need to implement their QoS capabilities in a standardized way that makes it easier for sensors and applications to take advantage of them. This means driving customer loyalty and differentiating their services based on performance, rather than aiming to lock customers into a proprietary interface.
In general, IoT devices generate limited volumes of data traffic, so the capacity of the pipeline is far less important than for, say, streaming video—in the IoT, the relationship between traffic flows is where the value lies. In a model where carriers charge for traffic, the revenue uplift from handling IoT-based data will be less than those carriers might hope, especially as data prices continue to fall. Thus, charging for QoS performance and delivering on performance guarantees creates a mechanism by which CSPs are able to grow revenues and sustain investment in their networks. Indeed, the importance of carriers correctly pricing managed services is key—too often, they charge too little to cover the enormous costs of serving clients and prioritize attracting new customers over asking premium prices for premium services.
For convenience and cost , standards are key, so CSPs should implement QoS in a standardized form that smoothly links applications and services.
and , standards are key, so CSPs should implement QoS in a standardized form that smoothly links applications and services. For companies implementing a control -based solution, CSPs need to consider managed services and IoT applications as a way to link the communications network to end-user applications, not just a form of short-term differentiation.
-based solution, CSPs need to consider managed services and IoT applications as a way to link the communications network to end-user applications, not just a form of short-term differentiation. When defining a customization-based solution, CSPs need to understand the benefits of an industrial IoT solution moving to a managed wide-area communications system and, then work with IT services, device providers, and customers to deliver on the plan.
We have seen that close connections and structured, predictable relationships between an IoT system’s sensors and actuators can allow companies to expand processes’ efficiency and capabilities. Take, for example, security. In an IoT ecosystem, security is not a single problem or a single solution—rather, it must be included at each layer of the stack from physical to application layer. The strongest passwords and credentials for an application are useless if hackers can intercept the data as they travel across a network. Researchers have also recently succeeded in wirelessly stealing many decryption keys based only on the emissions from a computer’s processor, meaning that devices now too must be designed to strict security standards.20 To do so, CSPs and their partners at every level must collaborate closely to ensure proper functionality.
However, the challenges for users can be substantial—in particular, the cost and complexity of partnering with CSPs to engineer managed communications networks, especially on a wide-area basis. Without the capabilities of a managed network, companies will find their IoT applications’ value generation limited to processes that are not dependent on instant communication and near-total accuracy.
For many IoT deployments, both the key driver of value creation and the main determinant of value capture lie at the intersection of create and communicate. These stages draw upon sensor technologies and communications networks, respectively. The degree of collaboration with its CSP that a company considers will be a function of the way in which it hopes to create value now and in the future.
When cost is paramount, a traditional working relationship can be entirely adequate. CSPs can focus on economies of scale; IoT deployments can exploit well-understood, standardized solutions. Convenience-driven solutions in the consumer sector are largely similar, with the possible exception of a greater willingness by companies to accept lower performance from their CSPs than in commercial applications, in the interest of greater innovation. Exploiting such opportunities requires not so much deep collaboration as sufficient insight into a CSP’s technology roadmap so that new functionality can be exploited as quickly as possible.
When control is central, companies should at least be open to collaborating more closely, leaning on cutting-edge CSP solutions to compensate for legacy and retrofit sensor technology. Such solutions often create knock-on problems around, for example, security, and CSPs can be well positioned to address such issues.21 In the early days of such deployments, the CSP may well be relieving the bottleneck to value creation, and so close collaboration might also be key to value capture. However, the CSP should not charge too much for its capabilities, since doing so could create financial incentives for companies to create private networks or stronger standalone capabilities.
Today we have examples in which closed private networks can deliver better results with a similar level of automation: For example, KUKA claims that its factory produces a Jeep Wrangler in 13.57 man-hours, 1.5 fewer than any other Jeep plant. But just imagine what efficiencies could be achieved with wider-area communications enabled by a CSP that link information from point of sale of the vehicle through the entire supply chain. In the case of GE wind turbines, we see how wider-area managed communications can simplify the task of frequency control; in the case of mining, a wide-area (CSP-provided) solution would allow vehicles to easily move from mine to mine and potentially lower the overall communications costs for many mines. And more examples, both successes and failures, will come forward as more companies expand their IoT deployments.
Whatever the challenges, the opportunities are there for CSPs and companies seeking to capture the full potential of the IoT to become closely aligned partners. It is by deploying managed communications at reasonable price premiums in ways that work today while opening a path to tomorrow that CSPs and companies relying upon them to deploy IoT solutions can move beyond the dumb pipe, creating an IoT that is smart at every level.
Deloitte’s Internet of Things practice enables organizations to identify where the IoT can potentially create value in their induastry and develop strategies to capture that value, utilizing IoT for operational benefit.​
To learn more about Deloitte’s IoT practice, visit http://www2.deloitte.com/us/en/pages/technology-media-and-telecommunications/topics/the-internet-of-things.html.
Read more of our research and thought leadership on the IoT at http://dupress.com/collection/internet-of-things/.The third part of the IoT Newsflash series illuminates the possibilities of IoT in the healthcare industry and thereby provides an overview over the most recent publications of renowned research institutes.
The adoption of the Internet of Things is speeding up across all industries. Therefore, the third IoT Newsflash picks and covers insights and use cases from the healthcare industry.
Here, the impact of IoT solutions comprises not only the improvement of the patient’s experience, but also even the improvement of the health of populations and a reduction of the per capita cost of healthcare. Ranging from strategy topics to concrete market insights for a determined device renowned researchers sum up the evolvement of the so called medtech within their most recent studies:
Deloitte’s study Devices And Diseases: How The IoT Is Transforming Medtech enlightens how IoT technology opens the door to business models in which the devices themselves are not the most valuable piece of the puzzle. In other words, the value provided by the technology can be expanded by embedding it in a more inclusive ecosystem. Providing a framework called the “Information Value Loop”, the study provides recommendations and guiding principles that allow well-established health care players to navigate the turbulent waters of the fast-changing, IoT enhanced medtech market.
In a more detailed and less abstract way, Gartner’s Market Insight(2018) on wearables in healthcare ecosystems predicts a gain of momentum in 2018. Wearables sales topped 155 million units in the past two years. Jumping on this bandwagon, 40 % of large health systems will shift form digital health pilot programs to full-scale rollouts in 2020, compared to 5 % in 2017. Giving concrete best practices, the study concludes, that AI and voice technology will be the most important drivers for accessibility and ease of use of wearables. Furthermore, B2B channel development and the increased acceptance of patient-generated data from wearables in healthcare communities boosts and interconnects the medtech market.
Forrester’s study Virtual Care Enables the Digital Health Imperative (2018) outlines, that virtual care is about to disrupt today’s outpatient visit. A variety of healthcare players is already increasing its investments in new virtual care solutions, realizing that healthcare delivery is shifting from the hospital to home. Another key takeaway of the study is that healthcare organizations, which have consistently failed to deliver high-quality patient care will have to consider crucially the upcoming virtual care solutions. These virtual care solutions are hosted by a multitude of new and established vendors. The following figure gives a broad overview over the relevant players focusing of the different virtual care solutions provided.Even if your devices and products look the same as they did before they got smart and connected, they’re fundamentally different—now they’re members of a larger community of products, processes, and stakeholders. Making objects capable of filling those new roles is a serious design challenge.
Product connectivity has been part of our daily lives for decades. An automated door is connected because a pressure sensor detected the presence of foot traffic and instructed the door to open accordingly—an example of an open-loop connected system. A thermostat is connected because a sensor detected that room temperature was above or below a set point, thereby instructing a furnace to turn on or off depending on the temperature—an example of a closed-loop connected system.1 In the pre-IoT days, these systems were connected in that they performed limited functions based on what a sensor detected. But they did not typically communicate with other parts of a larger ecosystem, and thus companies had trouble collecting data about usage, customer behavior, and performance.
The Internet of Things (IoT) has ushered in an age of connectivity, one that enables objects to function in new, expanded ways. IoT technology allows objects to communicate with each other continuously, forming large, interconnected systems capable of creating, communicating, aggregating, analyzing, and acting on data.2 This, in turn, opens up a world of opportunity for connected objects that can better serve customers’ individual needs3 and gather data to drive the development of more tailored services.4 Developers can use data gathered via IoT-enabled devices for a range of applications, from consumer goods that make a home more efficient to industrial systems that can enhance asset management.5
The casual observer may see nothing different about a product once it becomes “smart.” But that product is fundamentally different: It is now a member of a larger community of products, processes, and stakeholders, expected to do more and fill more roles than ever before.6 IoT technology transforms the product and everything within it.
As connectivity expands a product’s role and functionality, it only makes sense that its original design might prove limiting. And new smart products need to incorporate IoT technology from the beginning. So product design is a way not only to fashion smart products but also to create an effective connected system. An industrial sensor must generate a much broader range of data than pre-IoT models and, then, be able to securely communicate that information. A fitness tracker needs to incorporate sufficient memory and sensors to collect useful data as well as a reliable connection to a smartphone or computer—all while looking and feeling attractive to shoppers.
This article examines four significant ways in which IoT technology has transformed the nature of products and, by extension, product design. We will also identify the accompanying organizational transformations—in terms of people, process, and technology—that are crucial to successful product design in the IoT age.
The Information Value Loop The Internet of Things is a technology architecture. It is a specific way of stitching together a suite of new and existing technologies to turn almost any object into a source of information about that object. This creates both a new way to differentiate products and services and a new source of value that can be managed in its own right. At the same time, it creates challenges for product designers as they seek to create useful—and usable—objects that can accommodate the added complexity that goes along with connectivity. In order to understand the full nature of those design challenges, we must first understand exactly how IoT technology enables those new products and services. Since the value in connected products comes from their information about the world, modeling the flow of information through the system is a good way to illustrate the architecture. Deloitte’s Information Value Loop illustrates how IoT technology links together enabling technologies to create new value for companies and customers (see figure 1). Note first that the Value Loop is a loop: An action—the state or behavior of things in the real world—generates information, which then gets manipulated in order to inform future action. For information to complete the loop and create value, it passes through the loop’s stages, each enabled by specific technologies. A sensor creates information and is communicated within a network, and standards—technical, legal, regulatory, or social—allow the data to be aggregated across time and space. Analytical support is collectively used to analyze information. The loop is completed via augmented behavior technologies that either enable automated autonomous action or shape human decisions in a manner that leads to improved action. The amount of value created by information passing through the loop is a function of the value drivers identified in the middle. Falling into three general categories: magnitude—how much data is needed; risk—how reliable and accurate must that data be; and time—how quickly the data is needed. These value drivers may offer a good starting point for product designers as they begin to unravel what customers truly need in an IoT product, and what may be extraneous features.
Even in the world before IoT connectivity, a product designer had many things to consider: who would be using the product, how, when, and why—and, perhaps, how it might look in a TV ad or on a store shelf. The object’s desired lifespan and any risks associated with its use could also shift design requirements.
IoT connectivity adds to the process an additional layer of complexity and, thus, challenge. Connectivity reshapes the challenges and complexity of product design; the interconnectedness that defines the technology imposes new requirements. We can begin to categorize the impact of IoT technology on products—and product design—into four main transformations:
With IoT enablement of a physical product, embedded sensors are able to capture and transmit data about that product over a network. The system then analyzes the data and, based on that analysis, takes action. The information the product generates is as important as the physical product itself. In that sense, there is a marriage of the physical and digital worlds: Each component is equally essential to the function, and value proposition, of the connected object.
While this union of the digital and physical brings with it a host of user benefits—including more efficient products tailored to the user’s behavior and demonstrated preferences7—it significantly complicates the design process. Connectivity means the product must be able not only to create and communicate information but to act on it autonomously—in turn creating and communicating new information that enable it to learn and adjust.8 Incorporating these capabilities seamlessly into a physical object such that the object can reliably interact with a digital network while still remaining user-friendly—or outwardly relatively simple—is critical to designing a smart object.9
Indeed, the importance of user-friendliness and simplicity cannot be overstated. Even while making an object smart, the designer cannot lose sight of the customer, her mindset, and how she will use the product. One particular concern that derives from the convergence of the physical and digital may be some customers’ wariness of smart objects; IoT-enabled objects can inspire strong psychological reactions in users, who may fear or overcomplicate a high-tech object that is, practically speaking, no more difficult to use than an unconnected object.10 Even the need to learn a few extra steps or deviate from current habits may deter users from purchasing a connected product, much less signing up for the IoT-based system of which the object is a component.11 Thus, keeping the product simple to use—even while its capabilities expand—is a crucial aspect of design. An IoT-enabled thermostat must still function as a traditional device; a smartphone must still serve as an easy-to-use cell phone no matter how many new features developers add; a connected car must drive normally even if the owner elects not to subscribe to all the available navigation and entertainment options.
In the world of connectivity, no product is an island. An IoT-enabled object will necessarily stay connected to a network to facilitate the communication of data. Indeed, that ability to stay connected and communicate data regularly—if not constantly—constitutes much of a smart product’s value proposition. At one level, connectivity invokes purely technical issues for the product designer: choice of network, power-consumption considerations, and interoperability. Designers creating an IoT-enabled object will thus need to account for the need to stay connected.
At a higher level, when a product becomes a part of a larger IoT ecosystem, the components that make connectivity possible are as much a part of the user experience as the physical object itself—and must be as secure and reliable. For all of the value it adds, connectivity significantly adds to the ways that a product experience can fail. If the components in a connected product that communicate information fail, it does not matter that the rest of the device might function perfectly.
And the stakes are higher: Many consumers find malfunctions in IoT-enabled objects particularly disconcerting; they may appreciate the benefits of physical-digital convergence, but they expect connected products to function as reliably as previous versions,12 especially since connectivity implies new susceptibility to outside interference. Individuals may be relatively tolerant of periodic failures in now-familiar web browsers, voice-over IP, or apps—for which periodic service interruptions can seem contextually appropriate—but they tend to apply their same high expectations about the reliability of previously unconnected objects to their newly IoT-enabled counterparts.13
Beyond its impact on customers’ mindset, expectations of always-on connectivity mean that the implications of failures or compromises in connectivity are dramatically more far-reaching and can have more serious consequences than unconnected counterparts.14 With a connected medical device monitoring patients’ vital signs and informing decision making of remotely located health care professionals, a failure in connectivity could place lives at risk. A connected piece of factory machinery may serve as the linchpin of an automated manufacturing process, and a dropped connection might shut down the entire factory.15 A smart lock that loses its connection may refuse to unlock, leaving a homeowner unable to open his front door.
When a product is connected and expected to be always on, product designers must prepare for the consequences of malfunction and connectivity loss. They must do so across multiple dimensions—not only the object itself but its components and, potentially, even the entities with which it interacts. Designers cannot break down the design process and treat each component separately. Rather, they must understand each component’s actions, interactions, and even security and legal implications as a part of the larger whole.16
If the constant connectivity of an IoT system makes it difficult to separate a product’s physical makeup from its digital components, it also introduces wider interactions that complicate design even further. For example, consider just the communications protocols needed to establish the always-on connectivity that IoT technology demands. The manufacturers of a connected product may assemble the hardware and even write some software code. However, in nearly every case they will use an established communications protocol owned by another company or foundation. In many cases, this can mean using third-party signals to take advantage of that protocol.17 As connectivity is central to the function of an IoT-enabled product, this means that most connected products are dependent upon external groups simply to work as designed.
But this external dependency extends far beyond just communication protocols. Even core customer interactions may be mediated by external elements. With typical products—say, a traditional lightbulb—the interaction between customer and company typically ends at the sales counter. A connected lightbulb, by contrast, may be a part of a larger web of interactions between manufacturer, distributor, third-party developers, and customer.18 These new interactions are integral to the function of the product—indeed, the whole value proposition of an IoT-enabled lightbulb in the first place.
This increases the level of contact the company must have with the customer, as well as all the other stakeholders in the system. This, in turn, ups the ante considerably for the manufacturer: Not only must its designers create a product that can interface with digital systems created by many others outside its direct control—they must design a product and process capable of sustaining continuous, ongoing customer-to-company engagement. In this way, the object changes from simply a product into a product and a service—or, increasingly, multiple services.19
The Amazon Echo, for example, is an audio device with a speaker and set of microphones—in other words, a traditional home entertainment gadget. Echo’s value lies in its connected web service and software platform, which, using voice recognition and artificial intelligence capabilities, act as a virtual assistant that engages digital services and other smart home devices upon command. (Devices expected to launch in late 2016, aim for similar functionality.20) Thus, a user can play music, control a connected thermostat, or summon a car via Uber.21 These external connections are core to Echo’s function and value: If the connection to Uber and other services is dropped, the device ceases to “function.” This enhancement of a physical product with diverse—and expanding—digital capabilities is just one such example of how consumers will shift to engage with smart objects and, also, how designers should account for multiple demands and stakeholders. In this case, the value shifts from the physical object to its operating system—and its ability to interact with other connected systems.
Nor are these issues limited to the world of consumer products. Consider Flowserve, which manufactures valves and other fittings for hydraulic lines. Where customer interactions once ended with valve sales, Flowserve now offers sensor-enabled valves along with as-a-service valve status monitoring.22 As with the consumer-oriented Echo, this shift relies on a host of external interactions beyond the physical valve.
With all of these external connections being critical to a connected product’s functionality, its boundaries extend beyond the physical plastic case or steel valve to encompass communications protocols, APIs, and other components that may not be under designers’ direct control. Regardless, designers may need to consider—or at least take into account—these services as they develop products.
In the pre-connected world, a manufacturer designed a product and released it. Based on market conditions, user feedback, and competitive forces, the manufacturer could subsequently design and release updated versions of that product, or discontinue it altogether.23 In the connected world, that sense of control and predictability changes: Now, not only can a manufacturer potentially change the core function of its product at any time via an update—third-party partners can do the same thing to key components, such as apps.24 The forces of change and product evolution are faster, more complex, and further outside the hands of the manufacturer.
For their part, designers are now tasked with designing an object that can not only adapt to unforeseen updates that can change the function completely but can also accommodate mismatched life cycles. This challenge is particularly acute for IoT-enabled objects. While a traditional product’s components may have differing life cycles—particularly in the case of objects with electronic components—the manufacturer has some level of control and predictability, along with component lifespans of at least several years.25 With connected objects, component lifespans can vary much more widely. Take, for example, the connected car. Individuals typically keep newly purchased vehicles for at least five or six years—the average car on an American road is nearly a dozen years old26—but digital developers push updates every few months, or even more frequently.27 Automakers should therefore take into account the full spectrum of life cycles as they consider the design of a connected car, from its durable frame to its ability to accommodate regular technology updates. Designers must even anticipate technological developments that won’t arrive for several years—and, when they do get here, may alter various car features and functions considerably beyond the initial intended use.28
With digital product update cycles becoming ever more compressed, this problem will likely only intensify.29 Many manufacturers no longer have the luxury of time and predictability in attempting to sort out the complex ecosystems in which their products exist. Evaluation and adaptation of design must be a continuous process.30
Across each of these transformations, a common theme emerges: Connected products are part of complex and ever-changing ecosystems that extend well beyond the product itself. Designing IoT-enabled products, therefore, challenges organizations to think beyond the object to understand exactly how those complex ecosystems work. It requires them to adapt—and to develop new capabilities to keep up with the pace of change.
The issue of “designing for the IoT” moves beyond the contours of product design to touch on organizational design. To effectively design a connected product, the organization should first consider how it will handle the transformations that IoT technology imposes on product design. These new requirements can, in turn, result in a shift in design mindset, responsibilities, and design and management workflows.31
To accommodate these shifts, the organization needs to evolve, which can manifest in three broad ways: people, process, and technology. It is important to note that the changes occurring throughout the organization need not be exclusive to just one of these pillars—particularly with a comprehensive technology such as the IoT. Rather, evolutions can span all three, and each can bleed into the other.
As designers begin to think about developing a connected, smart object—or adding intelligence to a previously unconnected product—they will need to develop new skills to enable them to do so. These can include programming capabilities32 or app design—or at least, the ability to consider the need for those features in a product, and the means to find an expert resource to bring those features to life. To this end, organizations will need to develop networks of reliable experts, either within the organization or via external specialists.
IT and product design skills don’t always overlap, and a traditional consumer products company looking to incorporate IoT technology for the first time may need to bring in a wider range of digital skills such as programmers, engineers specializing in artificial intelligence, and other related skill sets.33 On the other hand, a software company looking to launch its first connected object may need industrial designers, materials scientists, or human-factor specialists to deal with the physical aspects of the new product. Always helpful: individuals who can visualize the design in big-picture terms and understand how the components fit together holistically.
As these skill sets and talent needs come to life within an organization, it will then be important to consider how these experts and specialties will work together, and how their design processes will evolve to accommodate new IoT-specific design requirements.
In a connected environment, designers’ concerns hardly stop at the object itself. They should consider the data that usage of the object generates—the lifeblood of an IoT system. The product’s objective is no longer purely physical, and the information it generates helps shape a new value proposition—and can even result in new, ongoing data-based service offerings.34 Reorienting the design process to focus on that data output as a key design objective may also mean working cross-functionally with teams that understand once-arcane principles—for example, data analytics. These teams can thus provide insights as to what data characteristics—frequency, scale, scope, and others—are most important to consider. This can enable design teams to create products capable of creating and communicating the right data effectively and efficiently.35
Sharing and thinking collaboratively and cross-functionally can require shifts that go beyond individual skills to the organization itself. Indeed, management may need to institute processes to enable broader communication across teams, backgrounds, and even geographies.36 This can also impact leadership: Senior executives may need to reconsider how they manage cross-functional teams, think beyond their own areas of expertise, and create a culture that prioritizes innovative product design.37 These changes in team organization, design considerations, and necessary skill sets can encourage designers to incorporate and update venerated design philosophies to accommodate the new demands of IoT technology. (See sidebar, “Applying design philosophies to the IoT.”)
Applying design philosophies to the IoT There are nearly as many design philosophies as there are designers. No single philosophy is intrinsically more valid than any other; the decision to use any particular philosophy depends on the context, and sometimes a design calls for more than one approach. Several philosophies are particularly salient to IoT design: Systems thinking. To bring order to complexity, designers may turn to a design philosophy called systems thinking, which allows engineers and designers to understand the boundaries between different parts of a product, even when those parts can be separated by thousands of miles and owned by different organizations. Systems thinking focuses on looking at the object as part of a larger ecosystem rather than discrete and independent.38 For this reason, systems thinking is well suited to deal with complex ecosystems such as an IoT-enabled system. Design thinking. If systems thinking is fundamentally about understanding the complex ecosystem in which a product operates, design thinking takes this concept a step further, urging designers to picture that system but place a human at its center.39 In doing so, designers can assess the needs, wants, and dislikes of their product’s likely user and meet those needs not only with the product itself but with everything around it: how it is made, packaged, and sold, and all of the other connections that support it. Lean startup. Based on the concept of “fail fast, succeed sooner,” lean startup focuses on rapid iteration—or agile approaches—to better meet customers’ needs.40 In his eponymous book, Eric Ries describes how designers should Build-Measure-Learn quickly and repeatedly in order to meet ever-changing customer needs with the smallest amount of overhead.41 Indeed, one of the principles of lean startup is to produce an optimized design quickly, with minimal waste. No matter which design philosophy best suits the organization, the transformative challenges of IoT technology guide the approach. These design philosophies are like parallel roads to the same city: The exact paths may be different, but the ultimate destination is the same. In IoT product design, that destination means realizing that organizational change is required to meet the complex, changing demands of connected products.
Manufacturers that have traditionally focused on developing purely physical objects—or objects that may be connected in only limited ways—may need to develop or acquire new capabilities to incorporate IoT technology into designs. They can do so on multiple fronts.
First, organizations will need to have the technological resources and capabilities to enable the design of objects containing IoT hardware—such as sensors and other physical components for connectivity—and capable of running the requisite software.
Beyond the object itself, companies should consider how they will manage the resulting information flows: how they will aggregate, analyze, and act on any data these smart objects generate on an ongoing basis as they move from selling simple products to selling products and services.42 Furthermore, because of that potentially valuable user data, products and solutions may at some point need to connect to or communicate with other systems within the organization, such as customer accounts or order management systems, to enable more tailored services or customer behavior-based pricing structures.43 In the case of connected machinery, companies may need to aggregate data with that of other machines to better enable capabilities such as predictive maintenance44—or to inform future designs of the same object.45 Thus, designs may need to be integrated and interoperable with other core IT systems, increasing both design complexity and technological capabilities necessary for not only design and production but ongoing function as well.
Companies can also use these information flows to realize new opportunities, such as continuous improvement of products. Product development does not stop once a product transitions from R&D into manufacturing, and engineering teams have traditionally used reliability testing combined with analysis of field failures to identify design weaknesses that need to be addressed in future releases. Adding connectivity to a product gives designers the opportunity to monitor product performance and failures in real time in their actual environment. By incorporating the ability to monitor critical performance and environmental metrics such as temperature, battery condition, and wireless signal strength, designers can correlate specific conditions with specific failures. The company can then use that data to issue a firmware update to fix the problem in the field, or to construct a targeted set of lab tests that duplicate the conditions that caused the failure. Connectivity gives designers a window into how, what, why, and where failures occur and makes sustaining a product easier—if they have the appropriate technological and organizational capabilities in place to act on the information.
The rapid rate of change in IoT technology and the potential to realize design benefits—such as continuous improvement—suggest that organizations may need additional technological capabilities to push regular software updates to objects as well receive data from them. This is yet another factor for which designers should account as they grapple with multiple life cycles within just one product.
In changing the nature of products, IoT technology unavoidably guides their design. If an organization wants to meet the new challenges imposed by these transformations and successfully design connected products, it should rise to the challenge. As companies focus on readying themselves to design and develop IoT-enabled objects, they can consider the following actions:
Build a talent pool capable of addressing digital and physical issues, such as artificial intelligence, app design, programming, and big data analytics. By combining two disciplines—the digital and the physical—designers can reorient their thinking to account for new, IoT-specific requirements. This may involve upending the design process to start from the premise of the desired information outcome rather than the desired physical form.
Coach designers to know their limitations and recognize when they should engage experts outside their traditional teams. Knowing the possibilities—but also where help is needed—will be important for changing designers’ mindset so they feel comfortable looking to experts with unfamiliar skill sets.46
Encourage cross-functional collaboration to ensure that designers and engineers can share expertise and focus on solving the design challenge together. Rather than continuing to focus on functional specialization—a tenet of traditional design—organizations can promote the creation of design teams with representatives from each function.47 This may help design teams cope with unexpected changes internally and much more rapidly and effectively.48
Train managers to lead cross-functional teams and encourage collaboration. Organizations can consider rotational programs in which leaders and other high-potential employees can gain experience in multiple areas crucial to IoT product design, providing the skills to more effectively manage diverse teams and projects.
Stress simplicity through a digital design approach, even as the object necessarily grows more complex. Designers and engineers should consider expanding their thinking to incorporate a digital approach, including CX/UX approaches used in website and app design. They can include regular testing throughout the design process to help ensure that connected objects, while expanding functionality, retain simple interfaces that make them easy to use.
Bring IT into the picture early and often. In keeping with the more collaborative, cross-functional model of effective IoT product design, including IT experts on the design team can provide much-needed expertise about incorporating often-complex technologies. As Eric Libow, ‎the CTO of Internet of Things Lab Services and Support at IBM, explains, “we recommend that companies considering IoT start with a use case for a line of business but involve the IT group from the start, because you almost always want to use or interface with at least some legacy systems.”49
Develop a plan for accommodating future technological advancements in current designs. To account for future developments, engineers may incorporate modularity in some components, enabling service providers to swap outdated hardware for updated options capable of accommodating next-generation software as it becomes available. Thus, objects meant to have long lifespans—such as automobiles, appliances, grids, buildings, and industrial machinery—can assimilate new technologies with shorter life cycles.
As companies adapt existing products—and create new ones—for a connected world, no single solution or approach is correct in all situations. And since IoT technology is still in a nascent stage of development, the future of connected objects will get only more interdependent and complex, and organizations should consider and prepare for the changes that smart connectivity can bring to their products and their designs.The second Deloitte IoT Newsflash covers relevant news affecting the IoT market, covering Google and their purchase of Xively, the “Charter of Trust”, Qualcomm Wireless Edge Services for IoT as well as Bosch and their new IoT campus in Berlin.
Google announced in February that it will buy Xively from LogMeIn for $50 million. Xively is a tool that enables device designers to build connectivity into the design process while providing a cloud-mobile connection between the end user app and the connected device. With this purchase, Google Cloud adds an established IoT platform to their portfolio and underlines the importance of the IoT market for their business.
Siemens, IBM, Daimler and Deutsche Telekom signed the „Charter of Trust” for more security in IoT infrastructure
Eight companies, part of them are Siemens, Daimler, IBM or Deutsche Telekom signed a „Charter of Trust“ at the Munich Security Conference. The goal of this charter is to define and set binding rules and standards for more cybersecurity along the value chain as well as to build trust in new technical developments.
Qualcomm, one of the biggest multinational semiconductor and telecommunications equipment companies announced wireless edge services. These are software services that are designed to meet the requirements of Industrial IoT customers to provision, connect and manage long life-cycles intelligent wireless devices through their cloud platforms.
Bosch, the Engineering and Electronics Company, is opening its global IoT campus in Berlin. From the start, more than 250 employees from different domains will work at this new site.Like companies, government agencies are striving to deliver quality services in increasingly complex environments. And the public sector is also looking at ways to apply Internet of Things technology to find new value for citizens, aiming to enhance capabilities, streamline processes, and engage partners.
Long before the advent of today’s wrist wearables, Hollywood’s James Bond was using his watch to measure radioactivity and receive messages from headquarters.1 And before any company began prototyping connected cars, he careened through a high-speed chase where he controlled his car from the backseat via mobile phone—augmented by sensors that triggered fixes for safety issues such as flat tires and a video feed that alerted him to obstacles.2 Previously the domain of fantasy, such devices are becoming reality and even mainstream: Smart watches help verify identity and pay for goods, alarm clocks know the current traffic, and smart glasses provide instant access to expert advice.
What were once imaginative toys for a tech-savvy spy may soon be a new class of tools for public servants more generally. As governments work to deliver quality services in increasingly complex environments, devices that have already begun to make life easier and more efficient for companies and consumers can also help create greater public value.
“This wave of technology has more chance of reimagining whole swathes of the world than anything we've seen before.” —Tim O’Reilly, quoted in Chris Witeck, “The Internet of Things (IoT): The best is yet to come,”
However, strategic application of the Internet of Things (IoT)—the suite of embedded sensors and wirelessly connected devices—is still nascent in government. In fact, a recent Brookings Institution report found that not a single federal agency mentioned the IoT in its strategic plan.3 The diverse nature of public sector missions and the citizens they serve frequently complicates attempts to implement new technology. Yet if public sector organizations do not start analyzing the implications of the IoT today, they risk being left behind, making it more difficult to effectively regulate or efficiently deliver services in this shifting reality.
This report aims to help government leaders navigate this emerging reality by providing an overview of how new IoT capabilities can create value, illustrating their impact on three traditional public sector domains (education, public safety, and utilities), and discussing a few considerations as agencies plan for adoption of this technology.
The definition of a “computer” is changing again. The continued evolution toward cheaper processors and faster networks has enabled a shift from desktop workstations to mobile phones and, now, to everyday objects, inspiring the term “Internet of Things.” Almost any device can be Internet-enabled, linking it to additional computing power and analytic capabilities that make it “smart.” The aggregation of outputs from sensors, beacons, machines, and other IoT devices offers far more value than just a better or “smart” product; by connecting these devices and environments, we can understand more about their use, the world, and ourselves—often in real time. As more complex and mature systems take advantage of this connectivity to tap into new capabilities, organizations must think about how these technologies combine to create value in new and different ways.
Many current IoT applications, however, simply enhance existing products and processes rather than rethinking them, creating limited value. Just as the first televised news shows featured an anchor reading the events of the day from a typed paper in his hand—treating television as “radio with pictures”—early IoT applications have considered only how these devices can improve current performance. Ultimately, the IoT represents a new way of working, where—as Kevin Ashton, who coined “Internet of Things,” describes—machines and other devices supplant humans as the primary means of collecting, processing, and interpreting information.4 This breaks many of the constraints that have traditionally defined fundamental business processes—from timing to availability of information—and asks organizations to think differently about how they create value.
Just as the first news shows treated television as “radio with pictures,” many early IoT applications have considered only how these devices can improve current performance.
Doing so may require a fresh approach to information collection and analysis—not simply “Big Data 2.0.” Today, only 8 percent of companies are capturing and analyzing IoT data in a timely way, and 86 percent say that faster and more flexible analytics would increase the value of their IoT investments.5 The current model of mass collection and exploratory analysis is likely unsustainable; instead of collecting all possible information for future analysis, we need to streamline information collection and develop focused rules to make insights actionable now. As Steven Fritzinger, public sector alliance manager for NetApp data management, explains, “Once sensors and networks are cheap, the temptation is going to be to put them everywhere . . . [but] it is going to be much more important to think about the problem.”6
The CheckLight Sports Impact Indicator developed by hardware start-up MC10 provides an example of how tightly focused data collection can create insights and change behaviors. MC10 worked to develop a better way to test whether an athlete may have taken a dangerous hit to the head—and make it easier for coaches to decide whether to pull athletes off the field to check for concussions. CheckLight uses an accelerometer and gyroscope worn on an athlete’s head to collect a few basic data points, and then uses algorithms to detect and determine an impact’s severity. The results are shown through a light at the base of the athlete’s head. A moderate impact triggers a yellow light; a severe impact triggers a red light. When tested with a football team in which coaches would bench players sustaining a red-light impact, MC10 found that the disincentive of sitting out plays changed athlete behavior: Players improved their tackling form, and head impacts decreased over the course of the season.7
Organizations have the same opportunity to improve outcomes using technologies that provide immediate feedback and drive better decision making—but doing so can require that they orchestrate a complex system of sensors, processors, and actuators. The Information Value Loop (see sidebar, “The Information Value Loop—an overview”) offers a blueprint for how the technologies at play in the IoT fit together to generate value. The value loop shifts the focus from what we connect to what we enable, accelerating the relationship between data and action—and enabling governments to more efficiently and effectively drive public value.
Government agencies thinking about how to construct the Information Value Loop should consider five key capabilities: data creation, communication, aggregation, analysis, and action.
Create: Sensors collect data on the physical environment—for example, measuring things such as air temperature, location, or device status.
Communicate: Networks enable devices to share this information with other devices or a centralized platform.
Analyze: Analytical tools help detect patterns that signal a need for action, or anomalies that require further investigation.
Organizations can accelerate the value they get from IoT data by extending this loop (adding capabilities they do not yet have) or addressing bottlenecks (improving existing capabilities).
“If the Internet of Things has to do with home automation or automation of the car [or] controlling devices like security systems through the Internet . . . what does [it] have to do with any of the service-providing departments of government?”8
Just like this respondent in a 2014 GovLoop survey, many people may wonder what the IoT has to do with government.9 Admittedly, it may be difficult to see the immediate relevance of sport sensors or connected appliances, but deriving value from information collection and analysis is central to many government missions. The IoT can increase value by both collecting better information about how effectively public servants, programs, and policies are addressing mission challenges, as well as helping government deliver services based on real-time and situation-specific conditions.
Early government activity has coalesced around a few main areas, including “smart cities” focused on improving citizen services and federal agencies focused on scaling measurement capabilities. Local experiments include “smart parking” that helps commuters find spots (and streamlines city enforcement), and “smart waste” such as Big Belly Solar—Internet-connected trash bins that communicate their status to help optimize collection routes. New York City is even transforming public pay phones into Internet-connected pylons with the potential to someday broadcast emergency messages or provide places where New Yorkers can provide civic feedback on various topics.10 At a federal level, agencies are more focused on scaling measurement capabilities: The Department of Defense uses RFID chips to monitor its supply chain more accurately,11 the US Geological Survey employs sensors to remotely monitor the bacterial levels of rivers and lakes,12 and the General Services Administration has begun using sensors to measure and verify the energy efficiency of “green” buildings.13
As in industry’s early IoT-enabled work, many of these government applications focus on optimizing current operations rather than identifying how faster, more precise, and more reliable information might generate new possibilities for service delivery. To fully reap the IoT’s potential benefits, public sector organizations will need to rethink how they do business—identifying new models for service and adopting the technology and the corresponding organizational structure(s) to support them. We explore the implications for a few classic public-sector domains and posit three ways in which these new tools might redefine work:
Of the 1,025 hours the average American student spends in the classroom each year, more than 300 are likely lost to interruptions. In fact, an estimated one of every five minutes is consumed by “anticipated interruptions”: transitions, materials distribution, and starting or ending class.14 Each minute a teacher spends managing large group procedures takes away from time he or she could spend on student interventions—such as differentiating instruction or developing students’ socio-emotional skills—to help close an achievement gap between rich and poor students that has grown more than 50 percent since the late 1980s.15
How the IoT can help. Connected devices offer the potential to relieve teachers of some of the administrative burden in taking roll or distributing materials, allowing more time to focus on students’ learning needs.
As students take their seats in a connected classroom, attendance could be logged automatically by a wearable “smartband” such as the RFID bands that many theme parks already use to check in to rooms, rides, and even find lost children.16 A beacon might push a warm-up exercise directly to students’ tablets or smart desks. And when it comes to keeping students on task, teachers could send a “haptic” vibration—similar to silent notifications on mobile devices—to a student’s wearable or tablet, redirecting her attention or behavior in a way that limits public embarrassment and reduces direct confrontation.
Teachers, freed from managing many classroom procedures, could focus more fully on students—and perhaps focus more incisively too. Pattern-recognition software or data analytics applied to these new inputs might add to a teacher’s contextual understanding, mapping the record of behavioral incidents against student stress levels, classroom temperature, or even the teacher’s own actions. And IoT technologies could help translate these insights in real time—much like MIT Media Lab’s MindRider, a bicycle helmet that picks up on 10 types of brain waves that signal activities like concentration or stress and produces a corresponding light to make drivers more aware of panic-inducing behavior.17 In the classroom, using similar devices to identify which students are expending higher amounts of cognitive energy on an exercise could help teachers dedicate attention to students who need it the most—not just those who ask for help the loudest. Educators with years of experience often develop an intuitive understanding of such complex behavioral dynamics, but a connected classroom could provide insights even to the teacher just starting out.
Implications. Schools and districts looking to take advantage of these capabilities will need more than new technology—they must start by building a culture of digital literacy that can support greater creation and communication of data, to use the terms from the Information Value Loop. Creating these data requires that teachers use technology as a consistent part of instruction, and schools should empower teachers to decide which devices best fit their specific needs. This approach is a significant change from today’s centralized technology budget and procurement process originally designed around computer labs, but districts that embrace opportunities for decentralized technology procurement—such as Idaho’s cash-poor but forward-thinking West Ada district—have found that it presents an opportunity to encourage bottom-up experimentation and scale what works.18 Perhaps counterintuitively, schools and districts should pair this move toward decentralized applications with investments in shared platforms. By providing common information security, data standards, and system monitoring, these platforms enable effective integration into school records and information management systems—and ultimately help communicate and aggregate IoT data.
Emergency response today suffers from information gaps and asymmetries, driven by how quickly and how well those affected are able to alert authorities. As a result, responders are often delayed; for example, in 2011, only 15 percent of Los Angeles 911 dispatchers successfully alerted Los Angeles Fire Department response units within the targeted 60-second timeframe.19 Waiting for adequate information delays the response, yet responding too early risks endangering underinformed responders or committing unnecessary resources.
How the IoT can help. IoT applications can more quickly aggregate and analyze information about an event, helping responders better identify incidents, decide how to respond, and communicate decisions (and critical actions) to those involved.
Environmental sensors, for example, can register and report early indicators of an emergency or crime; already, devices such as ShotSpotter can detect the sound of a gunshot and pinpoint its location to within 10 feet. By automatically alerting police dispatch, the device can speed reaction time, as well as reduce reliance on witnesses to report crime, helping to detect crimes that might never have been reported. When police started using ShotSpotter in Camden, NJ, they found that 38 percent of gunshots in one neighborhood were not being reported.20 Beyond detecting gunshots, data points from other sensors, cameras, and even databases can be aggregated to reveal incident patterns; much as PredPol or Palantir are used today to “hot spot” where crimes are most likely to occur, similar algorithms working on data from distributed sensors might be able to report that crimes are likely occurring. And these environment-generated alerts can be quickly directed to multiple parties, as PulsePoint, a San Francisco-based nonprofit that uses location-aware apps today to crowdsource CPR skills, does—alerting CPR-trained citizens who are within walking distance of reported incidents and allowing “citizen superheroes” to step in until professional first responders arrive.21
Connected devices can also improve officers’ performance when responding to an incident. Connected firearms, for example, can track when and where an officer removes a weapon from its holster and discharges it. In the moment, pulling or firing the weapon could dispatch additional support; over time, the record could inform coaching and development discussions. Other wearables might augment these discussions, providing similar insight into officers’ behaviors. Sensors that monitor officers’ stress levels, heart rate, or voice volume could alert supervisors or fellow responders to elevated tension or other anomalies that might endanger an officer or bystanders, allowing quick intervention and, later, coaching and training on handling future situations. This has particularly powerful implications, as local public safety organizations increasingly play a role in crowd control or longer incident response.
Beyond enhanced alerts and officer performance, IoT applications can aggregate real-time information to provide greater situational awareness. As more cities incorporate smart infrastructure, for example, iPavement—a Wi-Fi- and Bluetooth-enabled paving material that can be embedded in sidewalks—could send out crime alerts or emergency messages to mobile phones located within a certain distance.22 Or indoor beacons, such as those being deployed in Next Generation 9-1-1 systems,23 could help direct responders to an exact floor and room. Emergency systems could also integrate this precise location data with local video and social media to give responders context well before they arrive at the scene: Local video from nearby cameras might be streamed directly to the dashboard of the responders’ vehicle, and even mapped to streaming social media posts coming from the same area. For example, the police department of one major US city is already experimenting with combining video and social media with facial-recognition or social-network analysis software to help officers better investigate crimes and identify suspects.24 While today this analysis occurs after the incident, IoT applications can provide real-time insight, moving from a model of prosecution to one of prevention—from analysis to action, the final stage of the value loop.
Implications. We rely on public safety officers to act as human sensors, naturally aggregating multiple sources of data to assess a situation. Moving forward, machine sensors will enable public-safety organizations to collect a wider array of real-time data, but effectively aggregating and analyzing this data will require new processes. Where many current processes rely on centralized analysis, for example, organizations may glean greater value by empowering offers to make decisions at a local level based on IoT-generated data. And where current systems assume that information moves in one direction, the advent of localized communications via beacons or Bluetooth can allow dispatchers to engage citizens in the area to help—reframing public safety as a shared responsibility.
Moreover, as public safety networks aggregate information from new sources—transit, utilities, or telecommunications—governments should advocate for and implement common data standards to ensure interoperability. Greater volume of and access to information can eliminate distance and accelerate response, but may ultimately require a more elegant understanding of how to properly bridge dissimilar types of data.
The United Nations’ 2030 Water Resources Group observes that, if current trends continue, the demand for water will exceed supply by 40 percent in 2030.25 Already, in the United States, California is facing an extended drought and recently implemented water rationing, and the Ogallala aquifer that feeds the Plains States’ agricultural communities is at historic lows. However, scaling solutions is difficult in a highly localized and fragmented system of more than 155,000 different US water-supply corporations. Little venture capital or corporate research and development is focused on the water challenge,26 leaving it to government organizations to close the gap between water supply and demand—a task estimated to require $50 to 60 billion in annual investment over the next 20 years.27
How the IoT can help. IoT technology can provide greater comprehension of the complex challenges surrounding water security, enabling governments to better define priorities for water supply, consumer demand, and governance. Like other issues driven by multiple and diverse factors, improving outcomes for water management will require contributions from an ecosystem of partners, many of whom are not even aware of the role they play in water conservation. IoT applications can also help agencies better coordinate response among this set of players by capturing the specific impacts of each policy, not only through predictive models but also through real-time measurement that enables “lean startup”-style A/B testing.
Increasing water supply is often the first option considered as water inventories drop, and traditionally, companies have invested heavily in finding new sources of water—just as Midland, TX, recently spent $197 million to tap into a new source 67 miles away.28 As new sources dry up, however, utilities might instead focus on improving the yield for delivery; more than 40 percent of the infrastructure is over four decades old, and water-supply systems lose 16 percent on average during delivery.29 One of the challenges the IoT could solve is determining exactly where to repair to improve yield—and whether the volume saved for that area will offset the capital cost of repair. Sensors can provide a more precise understanding of water flows and help prioritize improvements, even at the level of individual homeowners not typically engaged with the state of water infrastructure. Stopping or slowing in-home leaks, which can waste up to 10,000 gallons a year, can further boost the yield on sanitized water: Products such as LeakSmart, for example, combine a simple sensor and actuator to detect when a pipe has burst and shut off the water.30
Conserving water by lowering demand can also be a powerful way to extend limited water supplies. Boston provides an early example: When demand outstripped supply in the early 1980s, the city was able to avoid $500 million in capital infrastructure costs through a conservation campaign that led to a 43 percent reduction in water consumption.31 IoT applications promise to make conservation campaigns even easier and more effective by tracking progress and offering—or even automating—new ways to conserve. Simply giving consumers more insight into when or where they use water and how they compare to neighbors can encourage conservation, as the Municipal Water Department in East Bay (California) recently demonstrated. Partnering with WaterSmart, the department saved 5 percent in water consumption by giving 10,000 customers access to a Web portal that showed how each stacked up against families of comparable size, as well as by providing ideas for improving water conservation.32 An IoT system might further support conservation efforts by helping users understand where and how they use water most, and applying rules or reminders to domains such as showers, appliances, or pools. This real-time monitoring might even reinterpret the local “water tower” as a way to create a public display of progress—much like the Southern California Edison energy company distributed “energy joules” that glow different colors to help customers and businesses see the current demand on the grid.33
The greatest savings in water consumption can come from automating agricultural and municipal use: More than 70 percent of water consumption today is for agricultural use,34 and 60 percent of the remainder goes to urban landscape maintenance.35 In both instances, agribusiness companies often irrigate regardless of current conditions, risking overwatering rather than drought.36 Sensors with advanced algorithms can help address both problems, aggregating measurements of soil moisture, heat, humidity, and slope to analyze how much water plants need. One startup, Hydropoint, has partnered with several landscape companies to install these systems for urban parks, golf courses, and corporate campuses. Hydropoint’s system has cut the Los Angeles suburb Santa Clarita’s irrigation costs by more than 25 percent and is projected to save the city approximately 180 million gallons of water annually.37
Implications. By creating greater insight into both supply and demand, IoT applications can help government and utilities work together to improve governance of the water ecosystem. However, information alone does not make the water system more efficient: Localities may need to build behavioral and technical foundations to allow people to act on information. For example, knowing how customers respond to various scenarios can shape tailored prompts and change behavior around water use. Similarly, servo valves can automatically take action to shut off pipes once a rupture or leak has been detected.
Further, IoT-generated information and action can not only directly save scarce resources but also feed better planning and policy—including enabling decision making based on empirical data as opposed to political pressures. And if government officials and water companies can improve operations, they likely can boost profit margins and free additional capital to invest in additional innovation.
The three examples above are predicated on the collection, analysis, and use of large volumes of data, introducing a complex and controversial set of issues: the privacy and security of citizen data. The proliferation of data created by IoT applications will almost certainly continue to generate concern over how government systems and employees handle that data. Early IoT applications have already sparked national debate and Senate hearings on privacy: One such hearing, a 2015 US Senate Committee on Commerce, Science, and Transportation hearing entitled “The connected world: Examining the Internet of Things,” addressed “how to strike the appropriate balance between encouraging IoT innovation and protecting privacy and data security.”38 Driving public acceptance of government application of IoT technology will likely mean proactively framing the discussion of “privacy” around concepts of “value, security, and trust.”
Deliver value to citizens. Our society is accustomed to exchanging data for valuable services. From Facebook to fitness trackers, users continue to grant companies access to their data if they feel they are realizing value in return.39 This seems to hold true for government applications as well: US Customs and Border Protection’s optional Global Entry program, which provides participants an expedited customs experience, has 1.8 million members and receives 50,000 new applications every month, despite requiring sensitive personal information—beyond that required for a passport—to enroll, including fingerprints.40
Make security a priority. Given their intrinsic responsibility to protect the public interest, public sector organizations are uniquely positioned to help develop a secure IoT; where private companies must balance profit incentives, government’s core mission is naturally aligned with safety and security. Gilad Meiri of Neura, a platform designed to integrate the management of IoT devices, agrees: “The market is not asking for security and privacy. Start-ups are focused on acquiring customers over designing for security.”41 To fill this gap, governments should lead, incentivize, and often own the development of airtight solutions that can advance security in both public and private sector applications. As Kerry O’Connor, chief innovation officer for the city of Austin, notes, “This is not a commodity we’re acquiring. This is something we need to design and work iteratively.”42 One potential approach to security that has gained recent popularity—championed by thinkers such as Marc Goodman, author of Future Crimes—is the idea of addressing security in the same way as public health, focusing on educating the public, tracking symptoms, and isolating outbreaks quickly.43 This model looks to improve resiliency by shifting focus from “who’s getting in to what’s getting out.”44
Build trust through transparency. Government organizations, perhaps even more so than industry, have a responsibility to their users, and should offer transparency—for example, being clear on what data are requested, how the data are being used, and who will see the data. A director of policy for one mobile cybersecurity company frames this in terms of “surprise minimization”: the idea that “a user should never be surprised by what an organization is doing with his or her data.”45 Transparency helps users feel they have control over their inputs, and it should also give them a choice over their outputs, which generally makes people more likely to use a service. In fact, in a 2014 study, 80 percent of users said they would be willing to provide personal information to a “trusted brand.”46 Government organizations can look to a few current initiatives for practical ways to build in these concepts while implementing new IoT applications (figure 3).
One thing is certain: Government agencies that adopt a wait-and-see attitude toward the IoT are unlikely to develop the expertise or engender the trust needed to effectively and efficiently deliver services in this new reality and to reassure citizens concerned about how this new technology will affect them.
On an organizational level, public sector leaders ready to start tapping into the potential of IoT technology can begin by identifying specific, pressing mission challenges, and then analyze how more or better information, real-time analysis, or automated actions might help address them. By solving for concrete problems, governments can more effectively identify the technical, organizational, and talent changes necessary to realize new benefits—and scale what works.
At the US federal level, additional changes may include organizations such as the Office of Management and Budget or the General Services Administration working across agencies to avoid creating the siloed or incompatible systems endemic to previous technology transformations. And organizations such as the National Institute of Standards and Technology and the National Information Exchange Model may work with industry to create standards and ensure interoperability, particularly important given that data integration is foundational to the IoT’s value proposition.
Beyond the tactical changes for organizations and broader government policy, governments can be particularly sensitive to the potential social implications of IoT applications. As the data from IoT devices offer new insights, they may also usher in new social complexities. For example, the ubiquity of these data can lead to the potential to discriminate by using algorithms to automatically categorize, make decisions, or treat people differently—without an appreciation for the social, economic, or racial factors at play.47 Understanding such social risks up front is key to the design of effective public IoT applications.
Ultimately, the IoT is not simply a cool new technology but an inflection point in how we do work, structure businesses, and govern the resulting economy and society. David Bray, 2015 Eisenhower Fellow and CIO of the Federal Communications Commission, recognizes the public sector’s crucial role in this transition: “empowering consumers to make choices, encouraging new [IoT] partnerships across private sector and public sector organizations, and exploring new ways to increase [IoT] privacy and resiliency by design [that] will encourage a future with more beneficial opportunities for us all.”48 Government agencies need to be active players to understand and shape this future—and should start today.
Deloitte’s Internet of Things practice enables organizations to identify where the IoT can potentially create value in their industry and develop strategies to capture that value, utilizing the IoT for operational benefit.​
To learn more about Deloitte’s IoT practice, visit http://www2.deloitte.com/us/en/pages/technology-media-and-telecommunications/topics/the-internet-of-things.html.
Read more of our research and thought leadership on the IoT at http://dupress.com/collection/internet-of-things.As the business impact of the COVID-19 crisis mounts, leaders in every industry are moving urgently to protect employees and build resilience. Governments are mobilizing to safeguard citizens and manage the economic fallout. Immediate action is critical, but leaders must also embrace a new agenda—one aimed squarely at what comes next.Tools, game consoles, kitchen appliances—many of the devices we use for work or pleasure already communicate with each other via the Internet. But the Internet of Things (IoT) has only just begun. According to a McKinsey market analysis, around €23 billion will be generated in Germany in 2020 with the intelligent networking of machines and devices. In 2015, annual IoT sales in Germany were still under €10 billion, meaning the potential will more than double within five years. The most important fields of application are the digitalization of production (Industry 4.0) with a potential of just under €9 billion and networked vehicles at around €4 billion.
But even the networked home promises growth. The United States is a prime example. Here, the number of smart homes increased from 17 million in 2015 to an estimated 29 million in 2017. The merging of the virtual and the real world should make life easier for people, save time and money, and ensure more security.
More and more everyday objects which to date have relied on manual control are expected to become “smart” in the future. Estimates from McKinsey expect that by 2020 consumers in Western Europe will spend more than €12 billion annually on smart devices and applications and thus on the Consumer IoT.
The Consumer Electronics Show in Las Vegas held at the start of the year once again showcased numerous IoT innovations ranging from the intelligent hairbrush that draws conclusions on the condition of the hair from brush noises, right up to the athletic shirt that measures the heart rate, records routes jogged with the built-in GPS, and transmits the data to the associated app. Just a gadget? Mere niche products? Maybe. But one thing is already clear: in the years to come, networking is going to gain more momentum with drastic consequences for the entire consumer industry.
The Internet of Things has the potential to fundamentally change business models and value chains in companies. Over the long term, it is no longer going to be just about intelligent fridges or fitness armbands; practically every product can be connected in an economical way with the Internet. Why not, for instance, equip a school backpack with an IoT sensor that measures location (via GPS) and movement (via an acceleration sensor)? This way, parents can track in real time where their child is and where he/she is going. The sensor would also signal falls and other accidents. Technically speaking, this kind of product has been feasible for a long time; the costs for such a sensor are around €10.
Consumer goods companies have no reason to fear the changes on the horizon. On the contrary, the Internet of Things offers them immense opportunities (exhibit):
Exhibit We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Manufacturers of consumer goods usually have little direct contact with customers, apart from user involvement in product development (embedded customer) and product tests. After the sale, if at all, manufacturers often learn only through customer service how their product stands up in daily life.
What are the most common complaints or questions from customers? Which feature is used most? The situation is different with smart products. Here, manufacturers are moving closer to the users, are maintaining contact throughout the entire product life cycle, and are collecting application data on an ongoing basis. How long is the school backpack worn each day? How often is it put down and picked up? The needs of users can be understood and met much better on the basis of the information gathered. But in return, manufacturers have to invest considerably more in the rapport with the end customers. And, ultimately, their greater proximity to the consumers will also fundamentally change their relation to retail trade.
Smart products create more value because manufacturers can generate recurring sales beyond the one-time selling price. One feature for the intelligent school backpack, which is available at an additional charge, is an alarm feature. If the child unexpectedly starts moving more than one kilometer away from the kindergarten or school, the parents are informed immediately. There is a €5 charge every time the alarm goes off. Other features can be added monthly, such as having the sensor automatically open the front door when the child comes home.
Successful manufacturers manage to establish an emotional bond between the customer and the product. This boosts customer loyalty and the recommendation rate. Networked products provide many ways to retain customers: updates allow features to be renewed regularly or expanded by additional ones making the entire customer journey a special experience.
So, the advantages for manufacturers and consumers are immense. Only companies that understand what the market wants and what it doesn’t want will enjoy long-term success with the consumer IoT.
Right now, many customers are still skeptical about the Internet of Things. There are a number of reasons why the consumer IoT has some catching up to do compared to other segments. The main reason is that many of the products offered to date offer no real added value for the majority of consumers. Even though manufacturers are tripping over themselves to network everything under the sun, they are launching some questionable products like the sock gadget that recognizes if you fall asleep in front of the TV and stops the show by way of a signal. Products that solve more pressing customer problems are more likely to be a success.
Many consumers are also hesitant to buy smart devices because they are worried that in doing so they will limit their choices. Today every device has its own specific applications, which don’t run on other devices. A fitness tracker only works with the smartphone app of the manufacturer, and the smart light bulb usually cannot be connected with the intelligent socket of another manufacturer. Here, a consistent separation of hardware and software would significantly improve market conditions. However, this would presuppose industry-wide partnerships and a consistent implementation of technical standards.
A third reason for the ongoing skepticism is that many important questions on data privacy and data security remain unanswered in the eyes of the customers. What is going to happen with my data? Where is it going to be stored? Who does the data belong to? Who has access to it? What is the company doing to prevent access from unauthorized third parties? And it is not just the personal privacy of customers that is at risk. Security breaches can also lead to smart devices being seized and used for digital attacks.
While the consumer IoT promises attractive growth potential, many traditional consumer goods and brand name manufacturers lack the know-how and necessary capabilities to develop a convincing IoT product and to market it quickly. Four success factors have emerged in practice:
Implementing IoT products is demanding and in terms of technology sometimes very complex. Without a closed system of partners, the task is hardly manageable (see sidebar, “Without partners nothing happens”). The partners can be technology or even content partners who deliver corresponding data and contents. Digital pioneers like Facebook, Amazon, or Google have built up entire ecosystems around their platforms with a pool of hundreds of thousands of specialized developers. For its Android ecosystem, Google benefits from 5.9 million mobile developers who target Android, many more than the 25,000 developers Google has in total internally across all their platforms and products, not just Android. Even in traditional industries these kinds of ecosystems are being established. One example for this is the map service, HERE, which a consortium consisting of three German automobile manufacturers bought as a joint asset en route to autonomous driving.
As important as partners are, manufacturers of consumer goods will not be able to avoid setting up their own software and big data capabilities—and far beyond the existing levels at that. They should resolutely follow their goal of transforming themselves into a technology company. In the process, digital capabilities should be set up not just in individual divisions. The whole organization has to understand what the Internet of Things is capable of today and which work methods and capabilities are necessary to use it effectively.
Digital networking should not necessarily be used for the most lucrative product in the portfolio, but, rather, for a niche product, that is ideally geared to technology buffs but also to a fault-tolerant target group. Nevertheless, the goal has to be to thrill the customers with a really revolutionary product. By building on the first customers’ experiences, more and more products can be equipped with IoT applications.
Cooperation is the key characteristic of a dynamic operating model. Cross-functional teams which involve external partners, suppliers, and, above all, customers develop products and services which meet the market demands as quickly as the digital world requires. In the process, innovative approaches like hackathons should be used.
In these events, which originate from the IT sector, employees sit down together in a room to advance new ideas in time-limited sessions or to tweak unclear product ideas by building prototypes. Part of dynamic product development involves having the courage to take risks. Employees need to know that it is ok for ideas to fail, that it is important to try out new things and when successful to consistently push on. And by the way, this applies not only to development, but also to all divisions. In short, when it comes to the production of traditional brand name items, more Silicon Valley is needed in the future.The Internet of Things connects people, places, and products and, in so doing, it offers opportunities of value creation and capture for a full panoply of stakeholders. Organizations, however, should be careful in focusing on IoT initiatives that solve real business problems and create real business value―not just connecting stuff for the sake of connecting stuff.
Learn More ​Subscribe to receive updates on Emerging Technologies ​Subscribe to receive Internet of Things content
Today, it seems easy to imagine a world in which a manufacturing enterprise enjoys complete visibility and monitoring of inventory as it enters the factory, gets processed, and leaves the factory floor. Or a world where it is possible to remotely track and optimize production asset effectiveness—through introduction, maintenance, and retirement—and even detect system failures as they occur to maximize uptime. Or still, another world in which products are given sensor capabilities to detect usage patterns and, on that basis, inspire still more products and revenue streams.
It is easy to imagine these and other such worlds because it is in fact the world of smart connectivity within which we live today—thanks to the capabilities offered by the Internet of Things (IoT).
In 1991, long before anyone ever used the term “Internet of Things,” Mark Weiser, chief scientist at Xerox, imagined a world of “ubiquitous computing” in which all objects could sense, communicate, analyze, and act with respect to other objects and people.1 But it was only in 1999 that the term “Internet of Things” was coined by Kevin Ashton, a technologist specializing in sensors and radio-frequency identification (RFID) tags.2 Over the years since then, we have witnessed various IoT applications evolve from concept to fruition across the full range of industries and use cases.3
This primer provides an overview of the IoT—its market space, key drivers, underlying challenges, potential solutions, and the business value it creates. The piece is intended to help readers understand at a high level why they should proceed in considering the technology's current and potential business applications and associated benefits and outcomes.
There are several definitions of the IoT in technical literature and popular media. Our definition encompasses the key elements as follows:
The IoT is a suite of technologies and applications that equip devices and locations to generate all kinds of information—and to connect those devices and locations for instant data analysis and, ideally, “smart” action. Conceptually, the IoT implies physical objects being able to utilize the Internet backbone to communicate data about their condition, position, or other attributes.4
The IoT focuses on the aggregation and use of information from several sources. Information, however, creates value only when it is utilized for modifying future action in beneficial ways. Ideally, this modified action gives rise to new information, allowing the learning process to continue. Information, then, can create value not in a linear value chain of process steps but, rather, in a never-ending process. One way of capturing this process is as an Information Value Cycle (IVC) with discrete but connected stages (figure 1).
For information to complete the cycle and create value, it passes through the cycle’s stages, each enabled by specific technologies.5 It starts with everyday business activities that generate data. This data is captured by sensors (attached to devices), creating information as a result, along an array of dimensions from vibration to humidity to movement, and beyond. Such information is communicated via a network, aggregated, and analyzed, leading to insights. These insights—sometimes called “augmented intelligence”—may then either enable automated action or shape human decisions (“augmented behavior”) in a manner leading to improved, more competitive business operations, thereby completing the cycle.6
When one thinks at a very high level, IoT market segments can be generally divided into three broad categories: enterprise/industrial, consumer, and services/public sector. Each of these segments is marked by distinct characteristics and market opportunities (table 1).
The enterprise/industrial segment involves relatively complex and rich data sets and far fewer devices relative to the consumer segment. The enterprise/industrial segment tends to also be driven by manufacturing operations and product development within a relatively private cloud environment. In contrast, the consumer segment is typically rooted in customer experience and a more public cloud environment. The services/public sector segment is generally something of a hybrid between the other two segments in terms of richness and complexity of data, number of devices, and a bias toward a particular cloud environment, although it tends to bear a closer resemblance to the consumer segment in terms of experience-driven use cases.
The fastest growing IoT segment appears to be enterprise/industrial, projected to capture slightly more than half of global IoT spending by 2020. A particularly strong driver of growth in IoT spending within the enterprise/industrial segment is digital supply network (DSN) applications. While there is a host of DSN use cases that is driving IoT spending within the enterprise/industrial segment, four seem to stand out in particular:
Condition-based monitoring/predictive maintenance : Monitoring and continuously evaluating key performance parameters of capital assets and, in the process, leveraging advanced analytics to predict failures before they occur
: Monitoring and continuously evaluating key performance parameters of capital assets and, in the process, leveraging advanced analytics to predict failures before they occur Asset tracking: Tracking location and movement of assets and/or materials using location-based sensors, enabling real-time reporting and optimization of system performance
Tracking location and movement of assets and/or materials using location-based sensors, enabling real-time reporting and optimization of system performance Dynamic routing and scheduling : Enhancing the productivity of both individual units and broad networks using deep and broad insights derived from aspects such as visibility on conditions and performance in real time
: Enhancing the productivity of both individual units and broad networks using deep and broad insights derived from aspects such as visibility on conditions and performance in real time Asset and process optimization: Evaluating and monitoring operational data and ambient conditions of critical assets and processes in real time to optimize performance and safety
Manufacturing is a substantial driver of spending within the enterprise/industrial IoT space as well as overall IoT spending.7 This may be attributed to Industry 4.0 and the ensuing wave of digital transformations that will likely drive significant demand for IoT capabilities across a broad spectrum of services within manufacturing. Other key sectors driving enterprise/industrial IoT include oil & gas, power & utilities, life sciences/health care, and transportation.
The IoT is a complex ecosystem—there are different approaches to its market sizing. One of the common ways of describing the market is in terms of connected devices. In 2016, the number of IoT-connected devices was estimated at 18 billion units and is expected to grow at approximately 15 percent CAGR to reach about 31 billion units by 2020.8 Other estimates place the projected number of connected devices at somewhat less than this figure.
Alternatively and without regard to the end-use segment, the IoT market can be characterized in terms of four categories of products―device hardware, systems integration, network connectivity, and platforms/applications/cloud solutions.9 These four categories taken together (which comprise the global IoT market) had an estimated market value of $0.4 trillion in 2015, and is forecasted to expand at approximately 20 percent CAGR to reach around $1.1 trillion by 2020 (figure 2).10 As mentioned, the enterprise/industrial sector is expected to account for by far the largest share of this global IoT market by 2020 at about 50–60 percent of total spending.11
Device hardware: Components used in machines and devices such as sensors and circuits to collect information
Components used in machines and devices such as sensors and circuits to collect information Systems integration: Hardware and software to integrate different proprietary systems with each other and with open systems in order to increase interoperability
Hardware and software to integrate different proprietary systems with each other and with open systems in order to increase interoperability Network connectivity: A host of established network technologies (such as Wi-Fi and Bluetooth) and emerging technologies (such as 5G and Low-Power, Wide-Area [LPWA]) for connectivity among different IoT devices 12
A host of established network technologies (such as Wi-Fi and Bluetooth) and emerging technologies (such as 5G and Low-Power, Wide-Area [LPWA]) for connectivity among different IoT devices Platforms/applications/cloud solutions: Software solutions to facilitate integration of the other three elements in order to provide a secure user interface and drive on-ground applications; includes data aggregation, visualization, and security; analytics; and action management
Among these four major categories, platforms/applications/cloud solutions account for the largest share (40–45 percent over the forecast period). However, the fastest growing segment is systems integration, which is expected to grow at 52 percent CAGR from 2015 to 2020, tripling its share of global IoT spending from 5 percent to 15 percent.13
The growth of the IoT over the last few years can be attributed to a number of beneficial factors, some of which are discussed below:
Bandwidth, data storage, and computing prices declining: Costs associated with transferring, storing, and analyzing data have declined precipitously over the last two decades (figure 3).14
Growing analytics applications driving the use of augmented intelligence: IoT applications are increasingly driven by both decreasing storage costs (figure 3) and volumes of big data (figures 4)—coupled with growth in advanced analytics tools, proprietary as well as open-source, such as the R package (figure 5). We are witnessing applications of augmented intelligence for not just analyzing past business performance but also making predictions about customer demand, supply chain optimization, machine performance, etc.15
Expanding use of augmented behavior from simple automation to complex decision-making: Improved functionality at lower prices (figure 6) is driving higher penetration of industrial robots (figure 7). For situations where a user needs to take the action, machines are increasingly being developed with basic behavioral science principles in mind, allowing them to influence human behaviors in positive and effective ways.16
Sector-specific undercurrents also driving demand: Beyond industry-agnostic technical drivers of the IoT reside sector-specific demand conditions. In manufacturing, for example, a broad digital transformation seems to be taking place under the banner of Industry 4.0 that undergirds the deployment of advanced analytics IoT capabilities. Within the power and utilities sector, a desire to “reach beyond the meter” in optimizing network performance, among other factors, appears to be driving IoT investments. The call for integrated smart city initiatives is likely driving public sector IoT spending. The explosion of health-related data and unyielding demand for health care delivery options “anytime, anywhere” seem to be driving IoT solutions within life sciences and health care. Other examples of sector-specific IoT demand drivers abound.
While we discussed above some key factors that seem to be driving the growth of the IoT, we should be mindful of some of the issues hindering IoT applications, and their corresponding potential solutions. Table 2 offers a set of some of the technical challenges that confront continued IoT development.
Beyond the scope of these technical challenges seem to reside some very real challenges of cultural resistance to the adoption of the smart solutions that IoT offers. Some of this resistance stems from the workforce itself, perhaps slow in accepting a “new way of doing things.” Some of this resistance seems to also stem from a reluctance on the part of organizations that don’t yet understand or are otherwise unable to articulate the IoT value proposition. And, still others believe in the IoT value proposition, but misapply it in ways that merely pursue connectivity for its own sake, without a real plan to address real business problems. We will speak more on this shortly.
The IoT is transforming business models, given its applicability for a wide range of applications in different industries and geographies. A sampling of the current and emerging IoT-related applications is described in table 3 by industry.
The IoT is emerging as an important digital transformation technology irrespective of the industry, business function, or geography. Costs associated with data collection, transfer, processing, storage, and computing have together come down to a point where they can drive significant mainstream IoT applications. With fast-evolving and expanding applications, the IoT seems to be shaping into an increasingly complex ecosystem that offers opportunities of value creation and capture for different stakeholders, including individuals, societies, companies, consortia, and governments. As such, the IoT is increasingly influencing the way we run businesses and live our lives. Additionally, the IoT is also expected to drive and support a number of related yet different technologies such as augmented/virtual reality, automation, and robotics.
All of this said, however, organizations should bear in mind that “connectivity” in and of itself is not a strategy that necessarily provides real business value. Unfortunately, many IoT initiatives end up being “shiny” solutions in search of a problem, concepts that have popular appeal but don’t deliver real-world value. And organizations should be focusing on IoT initiatives that create real business value―not just connecting stuff for the sake of connecting stuff.
Indeed, the real power of the IoT likely resides in harnessing its incredible potential in solving real problems and, in so doing, creating real business value. From asset monitoring and predictive maintenance to fleet management and logistics to smart supply chains to smart mobility and well beyond, the IoT—when used strategically—can help solve some of the most nettlesome challenges that organizations of all kinds face today. As IoT applications are evolving with each passing day, companies may wish to think through their current and future strategic positioning and build product and service offerings accordingly.
And toward that end, companies can adopt a commonsense approach in implementing IoT solutions successfully. First, companies should think big. Push the envelope in developing an ambitious and forward-looking IoT vision that cuts across organizational silos. Second, companies should actually start small. Target the most promising opportunity areas, launch small and swiftly, and go for the rapid wins. Third, companies should scale fast. Once an IoT initiative is proven successful, companies should scale up quickly to maximize benefits. Finally, companies should consider turnkey solutions that may help to jump-start the process—solutions that are geared toward a particular industry or business application in line with the organization’s objectives.
There is no magic formula when it comes to successful IoT implementation. But companies that know what they want to achieve in relying on the IoT—and approach it with a vision that is grounded in real-world issues—may very well have a leg up in achieving strategic objectives.
The next few years will likely be marked with increasing applications of the IoT in different industries. In developing this primer, our objective was to help organizations review the market potential and assess current and potential applications, think through different opportunities for value creation and capture, and address key challenges to adoption. Additionally, as the IoT supports different technologies such as robotics, augmented reality, and automation, this primer should serve as reference material for several other technologies that we will discuss in individual primers.
For more information, including IoT-related industry perspective and use cases, please refer to the Internet of Things collections page on Deloitte Insights.A large US-based airline deployed an Internet of Things proof of concept to provide customers with security wait times. After the initial phase ended, only 1.4 percent of the IoT-interested airline’s target customers had used the technology, and there was no clear path to scale across the organization; it was stuck in “loT pilot purgatory”—a state of ambiguity without a clearly defined strategy to scale.
Here’s the kicker: They’re not alone. Seventy-four percent of IoT pilot programs fail to scale, according to Cisco,1 and those that aren’t immediately abandoned enter IoT pilot purgatory.Smart, connected objects offer tremendous opportunities for value creation and capture, but can also create tremendous risk, demanding new strategies for value protection. A single vulnerable device can leave an entire ecosystem open to attack, with potential disruptions ranging from individual privacy breaches to massive breakdowns of public systems.
A defining element of the Internet of Things (IoT) is that objects are not merely smart—equipped with sensors and processing power—but also connected: able to share the information they generate. What separates the IoT from the traditional Internet is the removal of people. The Internet is powered by humans inputting data: search terms, e-retail browsing, looking up a friend’s social media page. Based upon the answers, they make decisions about how to act: whether to visit the site, buy the sweater, or “like” a friend’s photo.
With the IoT, the role of humans diminishes, to the point that in many cases they are removed from the equation: Machines input, communicate, analyze, and act upon the information. Using sensor detection, machines can create information about individuals’ behavior, analyze it, and take action—ideally in the form of streamlined, tailored products and services or, in the case of businesses, greater efficiencies. This newfound capability is why the IoT enables enterprises and individuals alike to create value in new ways, at a faster velocity than we’ve ever seen (see the sidebar “The Information Value Loop”).
There is a dark side, however: As data are created and transmitted, this represents a new opportunity for that information to be compromised. More data, and more sensitive data, available across a broad network means the risks are higher and that data breaches could pose significant dangers to individuals and enterprises alike. Thanks to the IoT, data security risks will very likely go beyond embarrassing privacy leaks to, potentially, the hacking of important public systems. According to the World Economic Forum, “Hacking the location data on a car is merely an invasion of privacy, whereas hacking the control system of a car would be a threat to a life.”1 Consequently, in addition to new ways to create and capture value through information, the rise of the IoT creates a new need to protect this information-based value.
Secure: In the spirit of “prevention” being worth more than a “cure,” effective risk management begins by preventing system breaches or compromises. The forms that effective prevention takes include controls of many layers, types, and approaches, because the potential attacks are quite effective at exploiting weaknesses never imagined by their creators. We lock our doors because thieves might enter through them. Similarly, we physically “harden” sensors on power plants to protect them from accidental or deliberate assaults, and install software firewalls to keep out hackers.
In the spirit of “prevention” being worth more than a “cure,” effective risk management begins by preventing system breaches or compromises. The forms that effective prevention takes include controls of many layers, types, and approaches, because the potential attacks are quite effective at exploiting weaknesses never imagined by their creators. We lock our doors because thieves might enter through them. Similarly, we physically “harden” sensors on power plants to protect them from accidental or deliberate assaults, and install software firewalls to keep out hackers. Vigilant: Making a system secure is not a once-and-for-all proposition. Both hardware and software degrade over time due simply to age. Worse, the nature and intensity of attacks can change in ways that render previously effective security measures obsolete. And, of course, no level of security is perfect: Best efforts still leave any system vulnerable. Consequently, security must be complemented by vigilance—monitoring to determine whether a system is still secure or has been compromised.
Making a system secure is not a once-and-for-all proposition. Both hardware and software degrade over time due simply to age. Worse, the nature and intensity of attacks can change in ways that render previously effective security measures obsolete. And, of course, no level of security is perfect: Best efforts still leave any system vulnerable. Consequently, security must be complemented by vigilance—monitoring to determine whether a system is still secure or has been compromised. Resilient: When a breach occurs, limiting the damage and reestablishing normal operations are much more easily and effectively done when there are processes in place to quickly neutralize threats, prevent further spread, and recover.
This framework has proved valuable in creating effective risk management systems for IoT deployments. In this article, we will illustrate how to apply it in a newly connected age.
The suite of technologies that enables the IoT promises to turn most any object into a source of information about that object. This creates both a new way to differentiate products and services and a new source of value that can be managed in its own right.
Creating value in the form of products and services gave rise to the notion of a “value chain”: the series and sequence of activities by which an organization transforms inputs into outputs. Similarly, realizing the IoT’s full potential motivates a framework that captures the series and sequence of activities by which organizations create value from information: The Information Value Loop (figure 1).
Note first that the value loop is a loop: An action—the state or behavior of things in the real world—gives rise to information, which is then manipulated in order to inform future action. For information to complete the loop and create value, it passes through the stages of the loop, each stage enabled by specific technologies. An act is monitored by a sensor that creates information. That information passes through a network so that it can be communicated, and standards—be they technical, legal, security, regulatory, or social—allow that information to be aggregated across time and space. Augmented intelligence is a generic term meant to capture all manner of analytical support, which collectively is used to analyze the information. The loop is completed via augmented behavior technologies that either enable automated autonomous action or shape human decisions in a manner that leads to improved action.
An exhaustive itemization and review of the risks arising from all possible IoT deployments is not practical, nor perhaps even possible. The complex and rapidly changing ecosystems and technologies at play demand instead a structured approach to identifying risks and appropriate responses (figure 2). By focusing on some of the defining features of many IoT deployments, we can begin to see how the reinforcing principles of security, vigilance, and resilience can help companies protect the value they create.
Securing data is, of course, critical at every stage of the value loop. In some cases, the security challenges and remedies are very similar to those with which many companies are already quite familiar. For example, a company implementing a supply chain solution within its own factory or warehouse has created a new value loop, but the data being generated and transmitted are conceptually no different than the email or sensitive documents transmitted over the office Wi-Fi network. Similarly, most companies are already grappling with the collection, storage, and retrieval of vast quantities of data. Addressing these challenges effectively is critical, but, as they relate to the IoT, the differences are of degree rather than kind.
There are, however, elements of IoT deployments that give rise to risks that are, for many companies, entirely new. Specifically, what makes the IoT so powerful is the ability to create and communicate data—the first two stages of the value loop. These stages are enabled through sensor technology and, typically, wireless communications networks, and each is vulnerable to security breaches.
For example, sensors are susceptible to counterfeiting (fake products embedded with malware or malicious code); data exfiltration (extracting sensitive data from a device via hacking); identity spoofing (an unauthorized source gaining access to a device using the correct credentials); and malicious modification of components (replacement of components with parts modified to generate incorrect results or allow unauthorized access). Any or all of these compromises would leave the sensors vulnerable. Communication networks can be hacked, allowing data to be intercepted or their flow disrupted through denial-of-service attacks. The following three sources of risk are especially relevant to IoT deployments and can be addressed through the application of specific security countermeasures.
A common feature of many IoT deployments is the creation of an ecosystem that can include many different organizations or other stakeholders. Both upstream and downstream supply chain partners generate data, which extend even to the end-use customer. A large part of the value of IoT deployments stems from an ability to aggregate these data, yet the sensor technologies that various players in an ecosystem use can often be very different. Data are generated in different formats, and sensors connect to different networks via different communication protocols.
The lack of a single, generally accepted standard governing the functioning of IoT-enabled devices is therefore frequently a barrier to the interoperability required to realize the IoT deployments that many envision. The need for such standardization is evident in some device manufacturers’ willingness to join one of the standard-setting bodies devoted to establishing interoperability standards and providing open source software that enables manufacturers to certify their products.2 Unfortunately, even where standards have been adopted, different companies in the same supply chain may well adhere to different standards.
Consequently, companies can find themselves falling back on ad hoc solutions to create the interoperability that a given IoT solution needs. Unfortunately, it can be difficult to invest the time and money required to harden and test these solutions at the same level as formally developed standards, and so they are potentially more vulnerable to attack. Companies therefore face a sometimes-painful trade-off between creating interoperability and adequate security.
In the short run, the commonsense advice is simply to “test and invest” in order to create sufficiently secure case-by-case solutions. The IoT is unlikely to be a short-lived strategic priority, however, and it will therefore often be in a company’s long-term interest to set an active and deliberate standards strategy. This can take the form of promoting the adoption of a single standard within a supply chain; it might mean getting involved in the standard-setting process itself, with an eye to helping shape cyber security standards and promoting their widespread adoption. The temptation to delegate standard setting to others can be strong, but, with so much at stake, it is a temptation worth resisting.
Large, established organizations looking to implement IoT solutions that have already deployed sensors on a significant scale, such as industrial control systems (ICS), often consider adapting existing sensors to the IoT. This can be much more economical than developing new purpose-built technologies and then replacing existing components.
Unfortunately, many of the systems already in place—think of water or gas meters—use sensors with minimal security protocols because they were not designed to be connected to a more generally accessible network. Relying on such devices can only amplify the already-endemic risk associated with any value loop. For example, a manufacturing plant might use sensors to track its equipment’s performance and health, with all of those sensors feeding data to a secure central system. With IoT functionality, information moves in all directions, and the back-end system now aggregates and analyzes all the data. But with so many more points of communication, the older security programs’ simple, shared-system accounts and passwords are no longer adequate: If a malicious actor were able to break into such a system account, he or she could steal sensitive instrumentation data from anywhere in the system or launch a denial-of-service attack, devastating plant operations.
Eventually, however, retrofitting may cease to be a viable option from a security standpoint. Given the rapid pace of innovation, many devices will likely become physically incapable of being upgraded to prevent against the latest threats, rendering them outdated and vulnerable to threats.
Every new device added to an IoT ecosystem adds a new attack surface or opportunity for malicious attack, and each hand-off is a new opportunity for a security breach. This risk can be exacerbated by the lack of sufficient interoperability, which warrants an emphasis on increased security.
Awareness and accurate assessment of the risks arising from retrofitting are crucial to effectively managing them. Whenever possible, companies should err on the side of replacing legacy devices with wholly new purpose-built hardware rather than retrofitting. Failing that, developing purpose-built add-ons that are outfitted with appropriate security measures may be the next best route.
In light of the rapidly evolving technologies that enable many IoT deployments, there is an understandable desire to experiment and keep investment levels low. There is a real danger of overcommitting to technologies and even business models that subsequent innovation renders obsolete. When waiting is not an option but commitment entails material risk, it can make sense to extend the functionality of existing protocols and tools beyond their original design parameters. This allows companies to experiment and then commit as proven designs emerge.
Unfortunately, many of the technologies and protocols that developers are repurposing for the IoT can lack the high degree of native security controls that these new applications might warrant.3 Everything from short messaging service (SMS) to the Internet itself is used in ways that go beyond its original intent, often with negative implications for security. The Heartbleed OpenSSL vulnerability, for example, allowed third parties to steal information normally protected by the SSL/TLS encryption, affecting many IoT devices.4 Estimates suggest that fully eradicating Heartbleed from IoT products may take years, if not decades.5 Similarly, identity management—the authentication and authorization of devices for machine-to-machine communication—is often accomplished by relying on user names, passwords, and basic machine certificates. These continue to be points of compromise, and it is possible that new solutions for machine-level authentication need to be created to more effectively secure the vast array of IoT devices that are being predicted.
As with retrofitting, the practice of extending functionality enlists off-the-shelf communication protocols in ways not originally intended for secure machine-to-machine connections. Thus, to shore up vulnerabilities, companies would do well to take a similar approach to that of retrofitting: by hardening current solutions; designing new, bespoke, IoT-specific solutions; or adding a bespoke security element to protocols repurposed for the IoT.
Developing a security strategy for safeguarding an IoT ecosystem isn’t enough; as the technology evolves, so too will the threats it faces. Therefore, remaining vigilant to new or unexpected challenges is crucial to maintaining security. Two aspects of the IoT that are new to many companies create challenges that warrant an especially attentive, watchful response.
As the technologies upon which the IoT relies improve, so too will the scale and scope of data collected, as well as the frequency with which they are collected. Smaller, cheaper, smarter, lower-power sensors and near-ubiquitous high-bandwidth wireless networks make it possible to know much more about many more things far more often. We can know not just where data are but also their velocity, direction, operational status, and a host of other characteristics.
When it comes to people, the scope of data collection is still more remarkable. The smartphone is already a widely deployed sensor that can reveal all manner of personal behaviors. To that we can add wearables of all sorts, gleaning still further insights into people based on what their things—home, car, and so on—do.
More information creates more possibilities to create value: This is the promise of the IoT. On the other hand, it also creates new liabilities. The quantity and variety of information companies find themselves collecting can make it difficult for companies to know if their data have been breached—a situation exacerbated by the fact that much of companies’ data may be held by third parties, making them even more difficult to safeguard. When dealing with such tremendous volumes of data, it is only too easy for relatively small, virtually unnoticeable thefts to pile up until they amount to a veritable fortune. Worse, the loss of a small amount of data can translate into a threat to an entire system and irreparable tarnishing of an organizational brand. Under such circumstances, the need for heightened vigilance is especially acute.
Companies can address this threat by developing a deep understanding of the data they possess and combining that with analytics to measure against a set “normal.” By establishing a baseline of what “normal” looks like, they can more readily and reliably identify possible abnormalities, triggering further investigation.
The volume and complexity of the data in an IoT deployment are often a reflection and consequence of the variety and complexity of the stakeholders in the ecosystem that enables that deployment. IoT applications—particularly those employed at the enterprise level—can rely on the closely coordinated actions of multiple players, from vendors along the supply chain to clients, transport agencies, the showroom, and end-use customers.
As discussed before, every new device added to an IoT ecosystem adds a new attack surface or opportunity for malicious attack, and each hand-off is a new opportunity for a security breach. This risk can be exacerbated by the lack of sufficient interoperability, which warrants an emphasis on increased security. In addition, a complex ecosystem can diffuse responsibility for monitoring the flow of data around the value loop. This can be especially acute as ecosystems grow and change over time, and originally established responsibilities become less relevant.
As manufacturers extend IoT-enabled processes and systems beyond their own organizations to encompass these additional parties, information flows across multiple external devices and databases, each under the control of third-party organizations. These third parties, however, may not recognize that their secure, vigilant, and resilient strategies—or lack thereof—have implications for the systems of every other stakeholder: The chain is only as strong as its weakest link.
The complex nature of IoT ecosystems may lead enterprises to assume that all the players involved can share responsibility for security. However, it could be a mistake to assume that partners—much less customers—should or will take responsibility for maintaining data confidentiality and guarding against breaches. In other words, enterprises should consider behaving as if the responsibility for security were theirs, and theirs alone.
The smart home provides a particularly resonant example of the risks involved when multiple brands, devices, and stakeholders aggregate and analyze multiple data sets and are knit together to form an ecosystem. Take, for example, the garage door opener. This device provides access to not just the garage but also the primary home. In some configurations, opening the garage door deactivates the home alarm—a welcome convenience to someone coming through the door laden with groceries. This, however, means that the entire alarm system is deactivated if only the garage door opener is compromised.
Vigilance in this case means looking across all the relevant information that can be gathered and analyzing that against a baseline normal before declaring an “all clear.” For example, if neither the owners nor their cars are near the home—determined by using GPS data on registered smartphones and automobiles—then the garage door opening would not only leave the alarm system active but trigger an alarm, along with security cameras and a text message to the registered phones or security services. This is relatively easily done when one security company provisions the entire system. For companies operating as part of an ecosystem, however, it might well make sense to provide for this sort of integration, and even be able to act as the hub for it.6
Companies can remain vigilant for threats in several ways. First, they can develop and maintain clear accounting within the IoT ecosystem, so that each player knows where its responsibilities begin and end, and what each is charged with protecting. Reviewing the responsibilities of all the stakeholders that touch the data in each of your value loops in some way, as well as the measures in place to fulfill those responsibilities, and assessing the potential risks to protect against them are central to effective vigilance.
No amount of security and vigilance can guarantee that there will never be a breach or compromise. Far closer to certain is that some sort of failure will occur at some point. And in the face of almost certain failure, a system’s resilience defines how quickly a realized risk can be addressed and normal operations restored. Consider the following two ways in which the need for resilience is relevant to IoT deployments—one driven by data management, the other by the design systems in the physical world.
Many companies aggregate information of wide scope from multiple devices with the assumption that more data must be better—more valuable, more useful. It is tempting to cast a wide net and operate under a “collect it if you can” bias, believing the data will be useful at some point.7 Advances in IoT technology aid this impulse: Sensors’ low cost and increasing flexibility provide companies with the ability to easily collect more data than they currently need.
Deloitte & Touche LLP’s Cyber Risk Services practice offers a range of services to help our clients establish Secure. Vigilant. Resilient.TM cyber risk programs. Rather than being a necessary burden, the program is a positive aspect of managing business performance. Cyber Risk Program Alignment and Governance services help leaders invest in and manage the cyber risk program. SECURE services help organizations establish risk-focused controls around sensitive assets. VIGILANT services use analytic and correlation technologies to help develop monitoring solutions around critical business processes. RESILIENT services help organizations be prepared for when incidents do occur. Managed Security services help organizations manage controls pertaining to enterprise applications, identity and access management environments, and outsourced security operations. Read more about our Cyber Risk Services practice on www.deloitte.com.
Such practices bring to the fore an often-overlooked domino effect that arises from gathering ever-more diverse data: unauthorized inferences. For example, a customer might be willing to hand over location data and grocery shopping patterns in return for discounts or real-time coupons, but that same person may turn out to be strongly averse to those data being used to infer her health status. Without limitations on how data can be combined, each new data field dramatically increases the transparency of a person’s life to whoever holds that information.
Establishing data governance can help mitigate some of the risks arising from aggregation. Setting limits on what can be collected in the first place can help sidestep many risks altogether, as companies can avoid collecting data they won’t use and collect only those data that will generate enough value to justify the risk. Guidance concerning data ownership (which stakeholder within the ecosystem owns each piece of information) and the length of the data’s life cycle must be established to ensure that data cannot be retained beyond a suitable timeframe or used for nonprescribed purposes. Such measures make it far more likely that as a company collects more and more data, any compromises will be far better contained than otherwise.
Moving from bits to atoms, the value loop is complete when actions are taken based on the data gathered and the insight generated. This often occurs independently of any human intervention. The appeal of many IoT deployments depends on precisely this characteristic, which typically calls for tightly coupled systems. When these work, they work very well, but they are vulnerable to more widespread havoc. In one particularly illustrative case, a German computer science professor, who built one of the very first smart homes, discovered what can happen when one element—in this case a smart lightbulb—goes rogue. Like a string of Christmas lights that goes dark because of one errant bulb, one afternoon his entire smart home failed to respond; only after monitoring his internal home network traffic did he discover that a defective lightbulb had been swamping the automation hub with error messages. The lightbulb had, by itself, created a denial-of-service attack that rendered the entire house nonfunctional.8
This anecdote is a small-scale illustration of a data-chain domino effect: Any element of the system can disrupt the entire system. Avoiding this sort of self-propagating disaster requires fail-safe systems—that is, if there is a system failure, the consequences are not catastrophic and do not trigger knock-on system failures. Thus threats can be contained to a smaller area, averting a more catastrophic failure. In some IoT deployments, this takes the form of loosely coupled systems. In our home automation example, this could have taken the form of implementing stronger security-event-monitoring controls at the hub to effectively shut down the affected smart component in a fail-safe manner, with more effective incident or error handling at the smart-lightbulb component level. These resilient controls would have prevented one element compromising the entire connected home network.
Effective risk management in any IoT deployment will draw on all three factors: secure, vigilant, and resilient. To illustrate the application of these principles, however, we focus below on applications in which each, in turn, is especially salient.
The importance of securing individual sensors is perhaps most important in today’s connected car, which has evolved into a data center on wheels with any number of Internet-connected features. A typical automobile today contains about 70 computational systems running up to 100 million lines of programming code—twice as many lines of code as in the Windows Vista operating system.9 Along with GPS devices that aid navigation and report on real-time traffic and road conditions, diagnostic devices assess maintenance needs and alert authorities in the event of an accident or breakdown. As infrastructure evolves, smart cars will have the ability to communicate with roadside devices such as traffic lights as well. Therefore, they must be designed keeping security in mind at the outset.
It’s no surprise that some automakers might rush to develop and install IoT-enabled features to attract early-adopter customers and aid safety and convenience. In today’s cars, IoT-enabled technologies include power and infotainment systems, remote locking and unlocking, and remote engine start, with data flowing between different vendors. Vehicle-to-vehicle communication spans ecosystems as well—for instance, connecting an automobile to the driver’s home. Through in-vehicle platforms, smart cars can communicate with smart home hubs to open garage doors, unlock front doors, and turn on house lights as the in-car GPS registers that the driver is nearing his or her home. The scope of data communicated between connected vehicles encompasses a wide swath of personal yet highly sensitive information such as driving habits, real-time location, entertainment preferences, and daily schedule.
Much of this communication is accomplished via existing tools that have been repurposed for IoT technologies, including mobile apps, cellular networks, and SMS technologies typically used for casual texting and not intended for secure communications. These extended IoT functionalities leave networks vulnerable to security breaches. Indeed, a recent survey of automakers found that nearly 100 percent of cars currently on the market include wireless technologies that may be inadequately secure, and most automobile manufacturers may not be able to easily determine whether their vehicles have been hacked.10 Hackers, on the other hand, have demonstrated the ability to infiltrate various vehicular systems simply by using SMS texting.11Physical attacks via onboard diagnostic devices have shown it could be possible to manipulate some systems even while cars are moving.12
Further complicating the matter, those managing the development and deployment of these technologies traditionally tend to have less experience doing so, and that, coupled with the newness of the technology, may mean many take fewer precautions to secure data at the device level. Thus manufacturers have yet to develop common security standards, and measures to prevent remote access to an IoT-enabled automobile are haphazard at best. Data transmission between multiple vendors—the automaker, dealership, third-party data centers, GPS and onboard diagnostics systems, smart home devices, and others—creates multiple vulnerable points that should be remotely monitored.13 Hardening the current systems to install more appropriate security measures will be crucial to safeguarding the connected automobile.
The importance of vigilance is perhaps most apparent when it comes to large networked systems such as power grids, transportation systems, and manufacturing plants. IoT integration into these systems promises efficiency benefits. However, remote ICS—once isolated within a factory or out in the field, and now interconnected online—has less of a legacy of mature cyber risk practices, and its developers and owners may have insufficient institutional knowledge to adopt an appropriately vigilant approach to security.
Security for ICS is often governed by cost-benefit analyses that place short-term production needs ahead of safeguarding systems over the long term. Concerns about production loss during maintenance downtime may trump safety concerns, even as production loss in the event of a security breach would likely be much higher. Further complicating the matter, ICS consists of mostly proprietary vendor-certified configurations and may contain components from multiple vendors, making a unified approach more difficult.
Asset age presents further risks. Older systems may have been retrofitted to make them IoT-enabled, a more cost-effective approach than replacing them entirely. However, they run into the same challenges described earlier—a lack of advanced security protections or inadequate safeguards. Enterprises may also be employing traditional information security practices or traditional shop floor measures that simply don’t apply to an IoT-enabled device.
For ICS, one critical factor is the need to maintain 24/7 business operations. This illustrates the importance of having a vigilant security strategy, one that proactively looks for security gaps and anticipates malicious acts to prevent their causing unplanned downtime.
A traditional steel mill in Germany, for example, fell prey to a cyber attack in (probably) 2014 that disrupted internally networked control systems to the point that a blast furnace did not shut down properly, resulting in massive physical damage to the facility.14 While this incident was limited to one mill, as systems grow ever more networked across facilities and span multiple players, the scale of data communicated and thus the risks for disruption on a wider scale grow larger, as well as the need for better monitoring. Indeed, establishing a baseline of “normal” data will help companies recognize when such anomalies arise, to stem the flow before they create a larger catastrophe.
Thus far, even the most personally inconvenient data breaches—for example, theft of credit card information—have left consumers remarkably unfazed.15 But the IoT, by incorporating unique personal information gleaned from sensors, may alter that equation, and companies may find themselves in uncharted territory. Scenario planning, then, is key to preparing for reputation risk management and possible crises based on data breaches or worse. For instance, if a cyber criminal’s work compromises a communication network partner’s information flow, it is useful to have a sense of how to contain the problem, continue operations, and work with partners to restore the network.
Previews of the potential problems have already surfaced: In recent years, several major retailers, victims of high-profile thefts of customer information from infected point-of-sale devices, have been forced into crisis management mode, promising new, stringent security measures from the payment industry. Thus retailers must be resilient, prepared with a security response that enables them to bounce back from a massive data breach.
In addition to safeguarding their own internal data troves, retailers must contend with external supplier risks, including counterfeiting. Retailers will want to avoid being a party to selling faux products that leave customers vulnerable, however inadvertently. In particular, retailers will need to implement product verification to mitigate the risk of counterfeiting wearables, a market in which the buying channels are bigger and therefore prone to cheap imitations with potentially embedded malware.
For their part, consumer product manufacturers should consider their ability to be resilient in the face of a data breach. The range of connectable home devices—TVs, webcams, home thermostats, remote power outlets, sprinkler controllers, door locks, home alarms, smart home hubs, and garage door openers—creates multiple opportunities for hackers to gain entry into home ecosystems, entire customer bases, or even manufacturers’ back-end systems each time data traverse the ecosystem.16
Specific risks from unprotected consumer devices may come in the form of eavesdropping, manipulated data in a man-in-the-middle attack, or data halted entirely due to a denial-of-service attack. An IoT-enabled door lock may allow entry into a homeowner’s house by disabling the alarm and unlocking the front door; and a lock that’s been tampered with, either by including parts corrupted somewhere along the supply chain or via malware, or is counterfeited could offer just about anyone access to a private home—a nightmare for customers and a potentially fatal scandal for an implicated manufacturer or retailer.
With the IoT and its attendant privacy and security concerns still at an early stage, any company’s worst-case breach scenario is just that: a scenario, with no precedent. It’s critical, then, for any firm looking to capture value from IoT technology to consider next steps if a data breach compromises a product or network—not only how to manage reputation risk but also how to continue operations. Establishing governance around which data can be collected, by whom, and how they can be used can help mitigate some of the effects of a breach. Additionally, establishing clear accounting so that each stakeholder understands its responsibilities and what it needs to protect can help further safeguard the system. Loosely coupling devices within the network will also help ensure that an attack on one node won’t spread.
For enterprises and individuals alike, smart, connected objects offer tremendous opportunities for value creation and capture. Those same objects, however, also create tremendous risk, demanding new strategies for value protection: A single vulnerable device can leave an entire ecosystem open to attack, creating the potential for disruptions ranging from individual privacy breaches to massive breakdowns of public systems.
In the face of such challenges, companies can remain secure, vigilant, and resilient by taking several steps to safeguard their ecosystems and the data they create:
Work to define standards for interoperability. Adhering to one standard only or actively getting involved with consortiums to develop a set of standards can help ensure that devices within a network can all communicate and work together safely and effectively.
Use purpose-built devices or add-ons, rather than pre-IoT solutions. Rather than retrofitting or extending functionality of old systems in ways for which they weren’t designed, companies should strongly consider wholly new, secure technologies designed specifically for the IoT. If this is impossible, any add-ons used to retrofit the device should, at the least, be purpose-built specifically for that use, outfitted with appropriate cyber security measures.
Develop clear responsibilities for the players in your ecosystem. Rather than sharing responsibility across a diffuse ecosystem, players must know where their responsibilities begin and end, and what they are responsible to protect. Taking an assessment of all stakeholders and assessing the potential risks at each point—and making sure the stakeholders are aware of those risks—can help make a solution more secure.
Establish a baseline of data. Viewing IoT systems more broadly and monitoring environmental attributes such as usage, location, and access would better enable enterprises to gather a broad enough scope of data to establish a baseline, helping companies to discern what is normal and what constitutes a suspicious aberration. This, in turn, enables enterprises to take appropriate and effective action when data do stray from the norm.
Institute data governance. Enterprises should consider playing a stronger governance role by defining which data to secure, what it means to be sufficiently secure, and, by extension, which products meet that goal. Guidance around how data can be securely collected, used, and stored can help prevent unwanted breaches and prevent a risk event from snowballing into something larger, and can also outline the lines of responsibility in the event of a breach.
Create loosely coupled systems. Ensure devices within an ecosystem are loosely coupled and resilient so that the failure of one device does not lead to widespread failure.
The prospects for creating and maintaining a seamless, secure network—with or without external partners—may seem daunting, considering that vulnerabilities exist on all sides, be they physical or virtual, inadvertent or malicious. Security cannot be an afterthought—it must be integral throughout the design process. IoT solutions will need to blend a deep understanding of organizational operations with knowledge of multilayered cyber risk management techniques, creating offerings that are secure, vigilant, and resilient.August 18, 2020 For the past couple of decades, the emergence of electronic medical records, telemedicine, and big data have held the promise of revolutionizing healthcare for both patient and provider, making it more efficient, effective, and affordable. Yet so far, the payoff has been elusive, with technology arguably causing as many (if not more) headaches in the system as it cures.
Still, there is no doubt that advanced connectivity has the potential to deliver big savings to the healthcare industry by improving productivity and outcomes that in turn will free up money to invest elsewhere in the business. The McKinsey Global Institute (MGI) and the McKinsey Center for Advanced Connectivity (MCAC) estimate that those improvements will add $250 billion to $420 billion to global GDP by 2030, some 80 percent of which can be realized with existing advanced connectivity.
Three use cases in particular—remote patient monitoring, AI-enabled decision support, and integrated command centers—highlight the massive potential value of advanced connectivity in healthcare.
Newly sophisticated and affordable, wearable sensors can deliver information about heart rates, glucose levels, and oxygen saturation to care providers anywhere in real time. This approach to patient care and oversight can reduce the length and number of hospital stays and lower readmission rates, as well as help patients keep chronic diseases such as diabetes and hypertension under control without constant in-person medical intervention. We estimate that such systems running on advanced mobile networks can deliver $70 billion to $120 billion in annual value globally, not to mention lower morbidity and increased patient satisfaction.
Advanced connectivity allows the use of artificial intelligence to learn from large data sets, fueling systems that can collect and update patient histories, evidence-based protocols, and information from patient monitoring. This will allow healthcare professionals to make better decisions and deliver treatment faster, even from far-flung locations. In Birmingham, England, for example, doctors have tested a system using virtual-reality headsets and joysticks to help paramedics take an ultrasound scan with a haptic glove and instantaneously transmit the data back to the doctors for faster diagnosis. These support systems—enabled by high-bandwidth, low-latency networks and advances in computing, storage, and sensors—could unlock $40 billion to $70 billion in efficiencies, including reductions in medical errors.
Capturing information delivered by radio-frequency identification (RFID) and sensor tags installed across a hospital, bar codes from patient bracelets, and other connected devices can radically transform patient care. A connectivity-enabled central dashboard using this data can better manage patient flows, freeing up beds and optimizing staff scheduling. Similarly, advanced connectivity can link multiple healthcare IT systems as well as sensors and tags in a continuum of care. Integrated command centers could generate efficiencies that add $40 billion to $70 billion annually.
These three use cases are just the most prominent examples of how advanced connectivity could dramatically benefit individuals’ healthcare, as well as health systems and even whole economies, within a decade. Connectivity-enabled remote patient monitoring and telemedicine will help people better manage long-term health conditions and gain access to preventative care. Advanced technologies will improve patient outcomes by delivering more accurate diagnoses or rapidly adjusted treatments. Health systems will be able to deploy staff, coordinate patient care, and tap limited resources more efficiently. Israel’s largest healthcare organization, for instance, is already using IoT-based “smart cabinets” to manage its inventory of medical devices and supplies. All of the resulting improvements in population health should ultimately increase productivity and economic growth, potentially adding $2.1 trillion annually to global GDP.
Such achievements, however, require more than advanced connectivity and smart devices. Governments must prioritize funding for healthcare innovations, and insurers must implement clear reimbursement paths for digital offerings. Healthcare systems need to hire for a wide range of new roles, including systems architects, data scientists, and user-experience designers. Common data standards and governing regulatory guidelines will have to be set, just as clear, proven procedures for protecting patient data are paramount. Within and across countries, frameworks to guide investment in technology-driven healthcare services and to test and confirm the validity of connectivity-enabled use cases are essential.
Finally, it is critical that all stakeholders—from providers and systems to payors, employers, and technology/connectivity providers—learn to collaborate, most importantly on solving the issue of interoperability across systems and solutions. Only by moving beyond their traditional silos and working together for the good of the entire system can all these varied players each reap the benefits of connectivity in healthcare while delivering the most crucial reward to patients themselves.
This post was adapted from the recent MGI/MCAC discussion paper, Connected world: An evolution in connectivity beyond the 5G revolution. It is part of an ongoing series.
Sign up here to receive updates on the latest research and insights from the McKinsey Center for Advanced Connectivity.We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Earlier this week, 90 guests, including media, industry, and tech experts, toured the new Digital Capabilities Center (DCC) in Singapore, for a glimpse of the future. The future of manufacturing, that is.
This center, one of five digital model factories, will serve as a showcase and teaching ground for the emerging technologies of “Industry 4.0.”—advancements in data and analytics, robotics and automation, and production methods such 3-D and 4-D printing. Each of these advancements plays a critical role in reshaping manufacturing and operations, and helping companies achieve significant—even sensational—improvements in productivity. For example, Oliver Tonby, managing partner of Southeast Asia, points out that “automation and real-time dispatching in a semiconductor business can ramp up production by up to 50 percent.”
In our recent survey, 90 percent of manufacturers agree that Industry 4.0 technologies will change their operations—yet less than half think they are ready, with the strategy, people, data, or processes in place. To help companies prepare for this sea change, we designed five learning environments to make “the digital as tangible as possible,” explains Jörg Bromberger, the senior practice manager who has led the initiative over the past two years. In addition to Singapore, the new centers will be located in Aachen (Germany), Beijing, Chicago, and Venice (Italy).
Like our existing network of capability centers, each digital center is completely different with a production line tailored to the local client base; for example, “smart” radio-frequency-identification (RFID) wristbands in Germany and iced-tea processing in China. “But they will all share the same 25 digital learning modules—so the person in Venice will have the same learning experience as the participant in Chicago,” says Jörg. “We’ve taken a full production line in each setting and layered it with digital technology - so users can experience the possibilities at every touchpoint.”
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com The Digital Capabilities Center in Aachen, Germany, opened in March 2017.
Each center is connected with a leading industry consortium, government organization, or research institution that serves as the scientific backbone. The centers will be dynamic, updating and adding new technologies on a regular basis—such as artificial intelligence, cybersecurity, and cobots and robots later this year.
The Singapore DCC recreates the environment of a manufacturer of industrial gearboxes. The fictional $2 billion company has 8,000 employees spread across five key geographies. During workshops, participants watch as plant workers use digital technologies to manage scenarios, such as a pending equipment failure or a spike in demand that threatens to overwhelm the supply chain.
As the set of actions unfold, “participants can see the digital thread of communications flashing across the screens, from war-room planning of raw materials all the way to customer service, as the company responds to these situations,” says Alpesh Patel, who leads the Singapore center. The scenarios are drawn from the direct experience of 40-plus aerospace and manufacturing companies who participate in the public-private collaboration behind the center.
In Aachen, the manufacturing line of RFID wristbands is set up to show a “before” and “after” state. Participants start the program observing a fully operating lean-production facility. “Throughout the workshop, they can ‘turbo charge’ the line with a set of digital tools that penetrate—and provide visibility and analytics—into every step of the process,” explains Jörg. “For example, by applying digital condition monitoring, which provides information every few seconds—rather than a once a day—they can reduce equipment downtime by as much as 75 percent.”
The workshops are open to large and small companies and are tailored to the participants’ experience, ranging from an introduction to Industry 4.0 capabilities to running an actual technology pilot to skills building for a large-scale implementation.The IoT revolution has been a driving force for further digitalization in many industries, the development of innovative business models and the building of collaborative ecosystems. IoT use cases differ inherently from web or other digital applications, as IoT combines both the digital as well as the physical world. Therefore, IoT requires a holistic user-centric approach and cross-functional collaboration between design, technology and business.
With this in mind, user-centricity in IoT development is essential in order to provide business value for the targeted users. Design decisions that do not take into account the whole experience of the end user might create an incoherent, or even bad, user experience.
The main idea of user-centric thinking is simple: First, the overall strategy needs to be defined. After user segmentation and pooling, the user needs are prioritized. However, this is not easy. When applying principles of user-centricity to IoT, several questions need to be considered:
Strategy is always first. Before focusing on the user, the strategy needs to be defined and aligned. A clear vision is essential for the overall success. By using methodologies and techniques like design thinking and prototyping and in combination with proven design frameworks like business model canvas or the Deloitte industry print, it is possible to transform IoT use cases into an operable IoT solution.
If the aim is to be more user-centric in IoT development, there is a need to evaluate the user. However, this is not an exercise that should be done only once, at the beginning of a project. Instead, understanding the end user and solving the problem by using IoT needs to be the main priority in all stages of IoT development.
Often initiated out of company’s technology units, with a stronger focus on technological advancement and functionality than business value or user design, IoT use cases sometimes neglect that there is always an end user that should be targeted. From a retail perspective, this might be a customer purchasing and using home appliances. From an industrial perspective, it might be a factory worker handling IoT devices as part of a manufacturing process. The goal is to understand the user’s motives, needs and pains in using a product or service and enhancing the overall experience. It is essential to know who the end user and other relevant stakeholders are, how they interact with the application and what their requirements are.
It is not only important to realize who the end user is and which potential preferences for products and services they have. IoT adds real value when it solves a user problem and enhances a holistic user experience. It is important to understand the user’s whole journey and develop a full view of the problem at hand.
User research can be conducted to gain insights and a better understanding of the end user. While quantitative methods are great for testing hypotheses and processing big amounts of data, qualitative research will uncover hidden user motivations and any pains and gains in the user journey. Methods like defining personas, conducting in-depth interviews or even ethnographic research could all help to better understand users and their challenges.
Ethnographic interviews aim to immerse the interviewer into a subject’s environment and daily routine. Using observation and qualitative interview techniques, IoT developers can gain deep insights on how their targeted user behaves on a day-to-day basis, which user problems are relevant and demand for IoT solutions, and where potential touchpoints with the IoT applications could be implemented. In an industrial setting, factory workers could – for example – be asked about their daily routines, challenging tasks in a typical working day, or how current products and services are used.
Building on these insights, IoT use cases can be defined and embedded in the overall user journey. It is important to make the IoT solution part of the overall experience and create touchpoints, which seamlessly integrate with existing processes or actions in the user journey.
With the user motivations, needs, preferences and user journey touchpoints in mind, these insights need to be translated into requirements in order to set up the IoT use case. It is important to keep in mind that user preferences and touchpoints might also influence underlying systems and processes that are not immediately visible to the end user, but nevertheless contribute to an overall seamless user experience.
The IoT solutions needs to be integrated into the existing technical environment from a functional (e.g. connectivity to other devices/platforms, handling of data streams, etc.), non-functional (security, scalability, etc.) and hardware perspective. User insights might also influence decisions in the realm of business and governance of IoT applications or platforms.
Combining the best of the waterfall and agile approach, the hybrid agile approach allows executing the project on a priority basis, taking into account constraints and dependencies. In addition, the hybrid agile approach focuses on shorter sprints with targeted functionality that enables teams to develop prototypes and to confirm requirements when needed while issues are identified early. Thus, this increases transparency and feedback. The design process of an IoT solution is not linear, rather, fast and iterative feedback is needed to develop valuable IoT solutions and in order to make sure that the proposed use case is relevant and is headed in the right strategic direction.
As emphasized before, it should be the priority to keep the end user at the center of all decisions in designing and developing an IoT use case after the strategy is set. This means that the user insights should be considered at each stage of developing an IoT use case.
A “fail early and fast” mentality is helpful in order to avoid going in the wrong direction. If not tested in early development stages, IoT solutions run the risk of adding limited value and of being used in different ways than originally intended. Prototypes and tests should be used at each stage of IoT development to figure out how users will use the solution. The goal is to explore requirements, develop alternatives on how to implement them in the overall user journey and to choose the alternative with the best usability.
Prototyping and testing are intertwined and work together in iterations. Early prototypes can be used to evaluate function and features, whereas late prototypes are a good indicator to evaluate performance.
Even though the end user is hardly visible in IoT projects in comparison to more traditional areas of user-centric design, they should still be considered and prioritized in the user-centric development of IoT use cases. Of course, applying these principles is not the only approach to ensure that IoT solutions are successful. However, looking into the future as IoT platforms grow together and build ecosystems with partners, it might not be a bad idea to keep the end user in focus.The Internet of Things (IoT) has generated excitement for a few years now, with start-ups and established businesses placing bets on the industry’s growth. Some of the earliest investments have begun to pay off, with smart thermostats, wearable fitness devices, and other innovations becoming mainstream. With new IoT products under development or recently launched—ranging from medical-monitoring systems to sensors for cars—some analysts believe that the Internet of Things is poised for even greater gains.
Semiconductor companies, perhaps even more than other industry players, might benefit from the IoT’s expansion. With growth rates for the smartphone market leveling off, the Internet of Things could serve as an important new source of revenue. Given the size of the potential opportunity, McKinsey recently collaborated with the Global Semiconductor Alliance (GSA) to investigate the Internet of Things more closely, with a focus on risks that could derail progress. In addition to assembling a fact base, we surveyed and interviewed senior executives from the semiconductor sector and adjacent industries, as described in the sidebar, “Our methodology.”
Sidebar Our methodology The joint McKinsey–GSA work, which was led by a steering committee composed of McKinsey semiconductor experts and 11 senior executives from GSA member companies, had multiple components. To gain a leadership perspective on the Internet of Things, McKinsey interviewed 30 GSA members who had leadership roles at semiconductor companies or at companies in adjacent industries that are customers of semiconductor companies and part of the IoT ecosystem, such as network equipment and industrial automation. We also surveyed 229 semiconductor executives at GSA member companies in November 2014 to gain a broader industry perspective. Finally, McKinsey consultants assembled a fact base on the Internet of Things, focusing on issues relevant to semiconductor companies.
Our research suggests that the Internet of Things does indeed represent a major opportunity for semiconductor companies—one that they should begin pursuing now, while the sector is still developing. We also found, however, that the timing and magnitude of the IoT’s growth may depend on how quickly industry players can address several obstacles, including inadequate security protections, limited customer demand, marketplace fragmentation, a lack of standards, and technology barriers. Semiconductor companies, which have encountered similar problems in other nascent technology sectors, are well positioned to serve as leaders in resolving these issues.
Another important insight relates to the nature of semiconductor companies themselves. Their traditional focus on silicon, which allowed them to profit in many industries, may not be optimal for the Internet of Things because chips represent only a small portion of the value chain. Instead, semiconductor companies will be required to provide comprehensive solutions—for instance, those that involve security, software, or systems-integration services in addition to hardware. As with any major change, this move entails some risk. But it could help semiconductor companies transform from component suppliers to solution providers, allowing them to capture maximum benefits from the Internet of Things.
The McKinsey Global Institute recently estimated that the Internet of Things could generate $4 trillion to $11 trillion in value globally in 2025. These large numbers reflect the IoT’s transformational potential in both consumer and business-to-business applications. Value creation will stem from the hardware, software, services, and integration activities provided by the technology companies that enable the Internet of Things.
Analysts also estimate that the current Internet of Things installed base—the number of connected devices—is in the range of 7 billion to 10 billion. This is expected to increase by about 15 to 20 percent annually over the next few years, reaching 26 billion to 30 billion by 2020.
In keeping with these projections, many executives we interviewed stated that the Internet of Things would significantly boost semiconductor revenues by stimulating demand for microcontrollers, sensors, connectivity, and memory. They also noted that the Internet of Things represented a growth opportunity for networks and servers, since all the new devices and services will require additional cloud infrastructure. Overall, the Internet of Things could help the semiconductor industry maintain or surpass the average annual revenue increase of 3 to 4 percent reported over the past decade. These results are particularly significant in light of slower growth in the smartphone market, which has served as the major driver for the past few years.
Our interviews did reveal some ambiguity about whether the Internet of Things would be the semiconductor industry’s top growth driver or just one of several important forces. In particular, interviewees questioned whether the Internet of Things will trigger demand for new products and services, or if there will just be an increased need for existing integrated circuits. Similarly, our survey showed that executives from GSA member companies had mixed feelings about the IoT’s potential, with 48 percent stating that it would be one of the top three growth drivers for the semiconductor industry and only 17 percent ranking it first.
Despite the size of the IoT opportunity, some semiconductor companies have hesitated to make significant investments in this sector. The greatest issue is that products within the Internet of Things tend to appeal to a niche market and generate relatively low sales volumes. With individual products delivering a relatively low return on investment, some semiconductor companies have limited their R&D expenditures for IoT-specific chips, preferring instead to adapt existing products. For instance, wireless system-on-chip players may offer repurposed wireless processors and chip sets for the Internet of Things, while microcontroller players often bundle lower-end processors and connectivity-chip sets to compete for the same opportunity.
As the IoT market matures and increases in scale, semiconductor companies may decide to pursue new approaches more aggressively. Before moving ahead, however, they should first determine which verticals and applications are growing strongly and assess when their markets will be large enough to justify significant investment. While semiconductor companies could potentially capture growth in many IoT verticals, six of the most promising markets—those where we chose to focus our research—include the following:
smart cities, with applications to assist with traffic control and other tasks within the public sector
Like many other high-tech innovations, the Internet of Things is garnering intense interest in the press, with reports of connected cars and smart watches making headlines. Although we do not want to diminish the IoT’s potential, our research suggests that the following six issues could derail its growth:
the proliferation of niche products, resulting in a fragmented market and an unprofitable environment for creating application-specific chips
the need to extract more value from each application by providing comprehensive solutions, rather than focusing solely on silicon
These problems are not insurmountable, particularly if semiconductor companies are willing to take an active role in solving them.
A majority of our interviewees cited security as an important requirement for growth in IoT applications. One called it the “critical enabler,” claiming that many developers and companies initially underestimate its importance when creating IoT devices. He noted, “Security is not a key issue while your application or product has not reached scale, but once you are at scale and maybe have a first incident, it becomes a most important problem.” Our survey results echoed the interview findings, with respondents ranking security as the top challenge to the IoT’s success. Recent hacks to online car systems also highlight the importance of addressing security challenges for connected devices, vehicles, and buildings.
Ensuring security will not be easy, however, given the numerous applications and verticals within the Internet of Things, each with its own quirks and requirements. For instance, fitness wearables might only require relatively basic security measures that ensure consumer privacy, such as software-based solutions. But IoT applications that control more critical functions, including medical electronics and industrial automation, need much higher security, including hardware-based solutions.
Most executives we interviewed believed that the technology needed to secure the Internet of Things was already available. They were concerned, however, with the piecemeal nature of most security products and wanted to ensure that players protected the entire IoT stack—cloud, servers, and devices—rather than focus on only one of these areas. As one executive said, “Overall security is only as good as its weakest point.”
Semiconductor companies can assist with end-to-end solutions by providing on-chip security, partitioning processor functions on chip, or supplying comprehensive hardware and software services, including authentication, data encryption, and access management. Those that specialize in security might be able to use their own products to provide comprehensive solutions, but others will need to undertake M&A or form partnerships with players further up in the stack to gain broader expertise in software or the cloud. For instance, semiconductor companies could lend their knowledge of hardware security to application designers or network-equipment manufacturers, since this information would assist with the design of secure software.
Many of our interviewees envisioned a future in which IoT applications are more common than cell phones are today. Others were more cautious, however, with one noting, “No one really knows when the volume will show up; this is a clear challenge. . . . If you cannot show a $1 billion opportunity, then it’s hard to get attention.”
In other technology sectors, a single groundbreaking application or use case—a so-called killer app—has often spurred explosive demand. Such was the case in 2007, when the introduction of the iPhone triggered significant growth in the smartphone market. While the Internet of Things could potentially follow this path, most of our interviewees felt that growth would stem from a string of attractive but small opportunities that use a common platform, rather than a single killer app.
Some of the most innovative IoT applications—and those most likely to stimulate customer demand—could come from start-ups. Businesses outside the technology sector, such as retailers, insurers, and oil and gas players, might also develop interesting products that appeal to a wide customer base, although some of our interviewees felt that these companies would face tough odds. Semiconductor players could help indirectly stimulate demand for IoT devices if they adopt new strategies to help these players thrive. For instance, start-ups and nontechnical businesses often have limited experience with semiconductors, so they might appreciate simple solutions and more hands-on support, including guidance from dedicated field engineers who assist with board-level design and solution integration (from silicon through applications in the cloud). IoT customers might also prefer one-stop solutions—complete platforms with all relevant elements that an IoT device needs, including connectivity, sensors, memory, microprocessors, and software. For some small businesses with limited funds, such platforms may be the only economically feasible option.
Some layers of the IoT technology stack have no standards, and others have numerous competing standards with no obvious winner. In our survey and interviews, most respondents cited this situation as a major concern, with one executive stating, “What is critical is which standards will win and when this will happen.”
To see how a lack of uniform standards can complicate product development and industry growth, consider connectivity issues. There are competing, incompatible connectivity standards for devices with a low range and medium-to-low data rate—for instance, Bluetooth, LTE Category 0, and ZigBee. With so many options, product designers may be reluctant to create new devices, since they do not know if they will comply with future standards. Similarly, end users may be reluctant to buy devices that may not be interoperable with existing or future products of the same type (Exhibit 1).
Exhibit 1 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Although multiple organizations, including interest groups and industry consortia, are attempting to establish standards, it is impossible to predict which ones will prevail in each IoT vertical. Faced with this uncertainty, semiconductor players should pursue a hedging strategy, focusing on selected standards that are likely to gain widespread acceptance while simultaneously planning for alternative scenarios. In all cases, semiconductor players should actively engage with industry associations or other groups that are trying to develop IoT standards, with the goal of supporting the best ones.
IoT devices have widely varying requirements for power, data-processing speed, form factor, price, and other dimensions. Smart water meters, for instance, need to run for months, if not years, independent of power supply. They also require high-range connectivity, but data rates can be under one kilobit per second. By contrast, IoT devices used for industrial automation typically require a direct connection to a power supply and high data rates, but their connectivity range is lower than that for smart meters.
These variations in device specifications become significant when considering R&D costs for a single chip. Assuming typical integrated-circuit design costs and product lifetimes, semiconductor companies will need to ship 20 million to 70 million chips annually to break even. Only a few segments, such as wearables, are large enough to require so many chips, making it impractical to create customized solutions for individual applications. But rather than abandon the IoT market, semiconductor companies should investigate an approach that involves classifying devices into archetypes based on their specifications and then creating a single platform to cover each one.
Products from multiple verticals can fall under one archetype as long as they have similar specifications. For instance, many low-cost applications have common requirements for short-range, medium-data-rate connectivity and limited data processing. If semiconductor companies create a common platform for applications that fit this archetype, they will simultaneously increase demand and reduce R&D spend. One downside of a platform approach is that the chips may not deliver optimal performance for every application they cover.
Semiconductor companies have a well-deserved reputation and track record for technological innovation, with some of their inventions spurring advances in personal computing, mobile telecommunications, and elsewhere. But they are also known—fairly or unfairly—for failing to extract full value from their innovations, with other high-tech players, such as software firms, profiting most from device enhancements. Our analysis suggests that semiconductor companies might face a similar dilemma with the Internet of Things. One executive we interviewed noted, “Value extraction has always been a particular challenge for semiconductor players, and it becomes particularly challenging in the Internet of Things, as even more players participate in the stack and business models are still immature.” Other interviewees stated that big data and cloud companies were positioned to capture far more value from the Internet of Things than semiconductor businesses.
To tackle this problem, some semiconductor companies have already begun to create complete solutions that cover multiple layers of the technology stack, especially since nontraditional customers—start-ups and businesses outside the technology sphere—prefer this approach. It is still too early to identify winning strategies, but the advantage may go to companies that pursue the following three opportunities (Exhibit 2).
Exhibit 2 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Software. Semiconductor companies have been complementing integrated circuits with supporting software for many years, but this trend will become even more important as the Internet of Things grows. Many semiconductor companies have recently sought to build their software skills through M&A or partnerships, while others have focused on improving their in-house capabilities.
Security. As noted earlier, the Internet of Things requires end-to-end security across the stack. Semiconductor players have traditionally provided chip-security solutions, but they may find additional opportunities in other layers, particularly if they can offer software products.
Systems integration. One interview subject stated, “Today most players have a partial but not full solution for integrated systems, so who is the integrator?” Semiconductor companies could fill this role, especially if they provide system- or application-level software supporting integrated circuits, although some interviewees noted that this might be too much of a departure from their core competencies.
In our survey, two-thirds of respondents stated that technological issues present little to no challenge to the success of the Internet of Things. The remaining respondents were split evenly between those who thought that technological issues were above average in importance and those who considered them a major challenge. Executives may hold varying opinions because technological issues differ by vertical and application. For instance, the interviewees agreed that wearable technology needs improvement. “With wearables, there is a constant issue of charging,” one executive stated. “We need to make devices last for a trip.” By contrast, technology for smart-home applications is well advanced, but there are few standards governing interoperability, which has limited their adoption.
When we asked our interviewees about the most crucial technological innovations for the Internet of Things, most focused on lower power consumption and battery life. A step change in the time between charges will increase demand for existing devices while also enabling product designers to create new applications. Wearable computers, distributed sensors for agricultural applications, and retail beacons are just a few of the applications that require improvement. Innovation in power and battery life will likely come from various sources, such as on-device power management, further advances in storage, over-the-air and wireless charging, and energy harvesting.
Although semiconductor companies that offer leading-edge technological advances will find themselves in high demand, not every player has to focus on innovation. Those companies that offer more dated solutions will still have a role in the Internet of Things, since many applications—particularly the sensors they contain—will continue to rely on existing (albeit highly specialized) technology.
Semiconductor companies that want to capture the IoT’s enormous growth potential might be tempted to move ahead quickly, without changing their existing operating model, but this could be a mistake. The Internet of Things is unlike any high-tech segment that they have previously served, and their traditional strategies may not succeed with the new customer base. With so much at stake, semiconductor companies need to reevaluate all aspects of their businesses and potentially make some significant changes. From a strategic perspective, three tactics will be particularly important.
There are likely to be many profitable I0T niches within the fragmented market, and semiconductor companies will need to identify the most promising ones that represent a fit with their capabilities. The use of a platform approach to cover multiple niches will be important, since R&D costs may otherwise be prohibitive. When companies are selecting the right niches, one of the most important considerations is their own expertise. Semiconductor players that have strong ties to consumer-electronics companies and possesses full-system-integration capabilities might best focus on wearables and smart-home devices, developing silicon, software and algorithms, and device-level designs. They could also potentially provide server-side software, connectivity gateways, and associated infrastructure. By contrast, a company with specific expertise with high-reliability integrated circuits and security might be well suited to provide full IoT solutions for medical applications.
Semiconductor companies are mostly well aware that their chips represent only one small part of the IoT value chain, so they are exploring opportunities in software, the cloud, and other services. But they may also need to consider more radical approaches to improve the value captured, including a shift to new business models. For instance, a move to usage-based pricing would allow semiconductor players to capture revenue for the entire lifetime of a device or service, not just at the time of chip purchase. (This might only be possible if a semiconductor company is willing to provide the full system or partner with a system-level player.) To mitigate risks and avoid moving too far from their core competencies, however, new solutions should be carefully evaluated. The fact that the IoT has many niches will be helpful during the evaluation process, since companies can test solutions in one of them and make necessary adjustments before undertaking a broader rollout.
Operating models focusing on hardware and embedded software helped semiconductor companies thrive in many high-tech segments, but they may not be well suited to I0T customers. For instance, most companies now include a limited number of large business units, a focus on direct sales and field-application engineers, and an emphasis on application-specific R&D programs. A more appropriate organizational structure for the Internet of Things would emphasize a multimarket sales approach and a greater reliance on channel partners, such as distributors, as part of the go-to-market strategy. This arrangement is well suited to the I0T’s fragmented market, which contains very different companies, including many small businesses, with unique needs. Other possible areas for improvement include the following:
R&D. The move from customized chips to a platform approach should occur as soon as possible, but this does not always entail massive internal changes. Instead, companies may be able to license another player’s intellectual property to build a platform—for instance, for image processing—thereby gaining access to new technologies without increasing development costs.
Investments. Rather than making a limited number of large portfolio bets under the direction of a business-unit lead, companies should investigate numerous applications in diverse markets. This approach will help companies avoid the common mistake of allocating most funds to core products, rather than using them to develop new applications.
Change management. If management wants employees to cultivate new capabilities or develop innovative products, they may need to revise their key performance indicators. For example, companies should provide incentives that encourage R&D to develop chip platforms that are appropriate for several verticals, such as connected cars and industrial automation, rather than optimize integrated circuits for a single vertical. Likewise, leaders that want to focus on mergers or other outside alliances must help companies recognize their importance by encouraging such partnerships more aggressively.
Our survey, interviews, and research show that semiconductor executives are optimistic about the Internet of Things and its potential to transform the industry. More important, they recognize its ability to help society as a whole, with one executive calling it “a chance to change and enrich our lives.” The exact form that this change will take is still uncertain, as is the point at which the Internet of Things will be widely adopted. It is clear, however, that the semiconductor sector will play a major role in its ascent. Those companies that take action now, while the Internet of Things is in its early stages, stand to gain the most.In order for IoT to be successful and valued for both companies and consumers, it has to be included as part of a broader information value loop. The graphic above illustrates how its sustainability depends on both parties gaining sufficient value.
Rather than see this value loop as an obstacle, there are limitless opportunities to complete the information value loop with customers. IoT technology is creating opportunities for companies to create and capture this value in unexpected places and ways, including Internet-connected wearable fitness monitors, insurance policies, pill bottles that know when you’ve opened them, retail supply chains, and even tennis racquets. For example, a tennis player doesn’t just value the stiffness of a racquet’s frame, the string tension, and its weight and balance. She might also learn to value it as a source of information about her tennis stroke and how to improve it.
Value capture can also extend to companies in the form of ongoing customer interaction. Smart automobiles now drive off the showroom floor with remote diagnostics and system monitoring capabilities pre-installed. By linking maintenance programming to the dealership, customers are encouraged to return for tune-ups rather than go elsewhere, leading to continued purchases in the long term.
Businesses have some leeway in the give and take of the information value loop depending on the type of data, customer, and industry they are working with. Some areas, such as those included in smart home technologies, face a gridlock of actually aggregating customer data from multiple devices, using it, and applying value for both companies and customers. There are also technological constraints such as interoperability and mismatched technological standards. These complications, not to mention the high cost for adoption and integration, create a barrier for customers to see where the value is for them.
In other industries, like automotive and home insurance, customers have less of a say in how companies use their data. On the opposite side of the coin, some industries such as retail are extremely influenced and potentially restricted by their customers’ say. Marketers should help their companies seek a balance that creates business value while also giving customers, at the very least, a perception of choice and value.
Striking that balance looks different, depending on the industry. Retailers have perhaps tapped into the IoT capabilities of consumer collection with the most enthusiasm—but they are perhaps the most inclined to do so, in an industry where customers have a lot of choice and maintain more power over data sharing. They’ve found balance in the information value loop by offering customers relevant and customized offers and the best available price. The retailer benefits through sales, increased customer satisfaction, gathering more customer data for future shopping encounters, and converting a browser into a buyer—all enabled by the data their customer provided.
On the other hand, for automotive insurance, customers do not have much of a choice in how their data are collected or used by insurance companies. IoT data are more accurate and personalized than the previous forms of data collection used to determine their premium, usually proxy indicators such as credit scores and demographic data, but absent insurers striking a balance in what information they collect and use, customers may potentially still feel violated or out of control of their data, leading to resistance of IoT data collection and hostility toward the company trying to collect it.The Internet of Things (IoT) comprises a rapidly evolving suite of technologies to monitor, compare and act on insights across and within systems that previously operated in digital isolation. Devices now have growing capabilities to communicate with one another, fundamentally changing the way companies run their manufacturing plants, how energy utilities manage demand, and even how families keep their homes safe.
For private companies, the IoT can transform conventional processes, such as supply chain management, into a true competitive advantage. By arming a company’s sourcing, manufacturing and logistics teams with more sophisticated data from IoT-enabled equipment, companies can prevent errors, correct missteps more quickly, identify and alleviate bottlenecks, and ensure they’re not leaving valuable scraps on the factory floor.1
There is incremental opportunity to improve existing systems, such as embedding sensors in baggage and cargo carts at the world’s busiest airports. There is optimization, which can help seaports handle more cargo in a particular location, for instance. There are entirely new business models, such as the case of a major logistics provider that is looking at ways to confirm whether packaged medications already hold certification assurance, which would provide valuable intelligence to both regulators and drug manufacturers.
It’s very easy to get caught up in the hype of the Internet of Things—to chase new gadgets. Instead, we should think about how we actually create value—where should we play and how can we win?
The IoT is revolutionizing the way companies think about information. The increasing arsenal of data on physical objects, employees, customers and other stakeholders can now travel across devices, influence the way people act, and enable a growing range of autonomous actions. While the value of these insights is clear to marketers and product developers, there are concerns regarding stewardship and transparency of the information. Says the University of Chicago economist Richard Thaler, “If a business collects data on consumers electronically, it should provide them with a version of that data that is easy to download and export to another website.”2
Private companies looking at potential avenues for innovation within the IoT also need to stay abreast of privacy rules, as there are times when data cannot be shared at all. For example, the US Health Insurance Portability and Accountability Act (HIPAA) offers protection of medical information collected by health professionals and insurers.3
More broadly, there are challenges in adapting certain ecosystems for an IoT-powered future.4 For technology, media and telecommunications companies, the formerly standalone device is now a potential target for hackers.5 Likewise, dropping sensors into existing systems such as utility meters may expose weak links within older systems with less robust security features. Instead of retrofitting, companies should consider how new technologies specifically equipped for IoT can avoid security lapses.
In addition, there still are no uniform standards governing security and enforcement within the IoT.6 Therefore, it is largely up to business and technology leaders to develop rules to combat security risks in this emergent field.
Despite these concerns, IoT technologies can empower private companies to potentially change lives. The battle against chronic disease is one example. Consider that about half of American adults have one or more chronic health conditions, according to the Centers for Disease Control and Prevention.7 Wearables, monitors and implantable devices can truly maximize their potential when patients and health care providers are able to interpret and use the information they extract from the technology. Potential benefits increase as this ecosystem expands to include payors, but with the trade-off of higher regulatory hurdles, potential risk, and barriers to adoption.
The IoT is helping people modify their own behaviors across a range of activities through social proof, where people feel more confident making decisions that mirror their peers. For instance, one Software-as-a-Service (SaaS) provider is partnering with utility companies to provide graphical- and emoticon-filled alerts on energy usage. Users can see how their consumption compares to that of their neighbors, and even get suggestions on how to cut back on energy costs.8
The IoT is also helping change behaviors in automotive-related industries. The typical car today has 70 computing systems and up to 100 million lines of code.9 To use that data for the collective benefit of motorists, some insurance companies are capturing information and providing peer-to-peer driving comparisons that can ultimately affect premiums.10
Yet another area for opportunity within the IoT is emerging through improvements in supply chain management.11 For example, a large household appliances manufacturer switched to radio frequency identification (RFID) tags to help managers track parts in one of its factories, improving an earlier process that required workers to read paper tags. The company reported that the new system exceeded expectations for ROI through the reduction in cost of the paper tags alone. In another example, shipping companies, for instance, are arming their customers with real-time updates on orders. The tools monitor potential roadblocks such as postal strikes, route closures, natural disasters, and other incidents. Some of the tools can adjust the timing or mode of shipments to minimize the disruption from such events.12
According to a global survey of business leaders, 74 percent of those who implemented initiatives such as sensor-based logistics saw increases in revenue, demonstrating how the IoT can improve efficiency and increase differentiation within supply chains. Some companies are using the sensor-based systems to get around delays, further evidence of the impact of the IoT.13
You can create value in IoT by enhancing the flow of information. You can capture value by controlling the flow of information.
In spite of apparent and often compelling benefits, understanding of the IoT remains uneven. For example, more than one in 10 adult Americans now owns a fitness tracker, demonstrating consumer eagerness to put the power of connected devices to use in their daily lives. However, more than half of US consumers who have owned an activity tracker no longer use it.14
By itself, the IoT is no silver bullet. Private companies can play an important role in exploring how IoT-related technologies can transform the way we work, manage our communities, and play.AI provides the ability to wring insights from IoT data more quickly and accurately than traditional business intelligence tools. Using the two technologies to complement one another can provide significant advantages for businesses, such as:
Predictive maintenance—using analytics to predict equipment failure ahead of time in order to schedule orderly maintenance procedures—can mitigate the damaging economics of unplanned downtime. Because AI technologies can help identify patterns and anomalies, and make predictions based on large sets of data, they are proving to be particularly useful in implementing predictive maintenance.
Predictive maintenance—using analytics to predict equipment failure ahead of time in order to schedule orderly maintenance procedures—can mitigate the damaging economics of unplanned downtime. Because AI technologies can help identify patterns and anomalies, and make predictions based on large sets of data, they are proving to be particularly useful in implementing predictive maintenance. Increasing operational efficiency.
Machine learning can generate fast, precise predictions and deep operational insights. Other AI technologies can automate a growing variety of tasks. Companies such as Hershey and Google have used AI in combination with IoT sensor data to significantly cut operational costs.
Machine learning can generate fast, precise predictions and deep operational insights. Other AI technologies can automate a growing variety of tasks. Companies such as Hershey and Google have used AI in combination with IoT sensor data to significantly cut operational costs. Enabling new and improved products and services.
IoT technology coupled with AI can form the foundation of improved and eventually entirely new products and services. For instance, for GE’s drone and robot-based industrial inspection services, the company is looking to AI to automate both navigation of inspection devices and identification of defects from the data captured by them. This could result in safer, more precise, and up to 25 percent cheaper inspections for the client.
IoT technology coupled with AI can form the foundation of improved and eventually entirely new products and services. For instance, for GE’s drone and robot-based industrial inspection services, the company is looking to AI to automate both navigation of inspection devices and identification of defects from the data captured by them. This could result in safer, more precise, and up to 25 percent cheaper inspections for the client. Enhancing risk management.
A number of applications pairing IoT with AI are helping organizations better understand and predict a variety of risks as well as automate for rapid response, enabling them to better manage worker safety, financial loss, and cyber threats.
For enterprises across industries, AI has the potential to boost the value created by IoT deployments, enabling better offerings and operations to give a competitive edge in business performance.Transportation providers’ customers want more speed, visibility, and customization. Outfitting trucks with IoT sensors was the first step. Next: Companies are moving to create connected ecosystems.
Many companies across industries are feeling the pressure of rising customer expectations for speed, customization, and more1—and looking to their supply chains to meet the new demand. The problem: Most leaders know far less about what’s going on than they would like. Deloitte’s Global chief procurement officer study 2018 found that only 6 percent of organizations have full visibility into their supply chain, and 65 percent of organizations have poor or no visibility beyond their tier-1 suppliers.2
To shed some light on supply chains, transportation providers seem to be embracing Internet of Things (IoT) technologies. The goal is visibility as well as agility—the ability to quickly respond to demand—while ensuring regulatory compliance.
Of course, it’s not as simple as installing a few sensors. Logistics companies are looking to create holistic ecosystems in which the physical and digital worlds are not only constantly exchanging information, but also drive meaningful action. Such a transformation requires moving from a traditional siloed approach to implementing IoT technologies and then to a more holistic, integrated one that aims to manage execution by connecting IoT technologies to traditional systems and other application technologies.3
This article will focus on these IoT-connected ecosystems within transportation and discuss some key strategic considerations for transportation organizations as they strive to successfully design, implement, and operate them in their organizations.
IoT-enabled processes are increasingly common across a range of industries, spurred by the growing availability of cloud storage and faster, more ubiquitous connectivity.4 The global IoT market is forecast to surpass the US$1 trillion mark in 2022,5 and a recent survey suggests that 80 percent of companies expect to adopt IoT technologies over the next five years.6
The transportation industry, for its part, has been moving to incorporate IoT technologies such as telematics hardware and software in trucks, with an estimated spend of US$71 billion in 2019,7 although progress has been uneven. North America has been leading the adoption, with 42 percent of all owned commercial vehicles forecast to have telematics by 2021,8 driven in part by compliance requirements necessitating the use of digital logs equipped with position tracking. Other key markets are quickly catching up, with the penetration for telematics hardware and software forecasted to top 95 percent for all new trucks sold by 2026 in North America, Western Europe, and developed Asia.9 As barriers to implementation fall and deployment proliferates across distinct use cases, the days when IoT-enabled operations offered a competitive advantage in transportation are likely coming to an end.10
More and more, the increased visibility and lower latency provided by IoT systems are becoming table stakes for carriers and others in the logistics space.
Organizations are rapidly adopting digital technologies beyond the IoT, of course. Over the next five years, the adoption rate for robotics and automation could reach 70 percent, with nearly two-thirds of companies deploying predictive analytics and artificial intelligence.11 The growing use of these additional technologies within transportation and logistics creates an opportunity to integrate disparate systems and move to a more advanced stage of digital capability. To truly differentiate and drive value creation for themselves and their customers, transportation providers should embrace the next generation of sensor-based systems: true IoT ecosystems.
Defining an IoT ecosystem An IoT solution consists of sensor networks that generate various types of data that a company can analyze to create insights for making business decisions. An IoT ecosystem links those solutions with other digital tools and technologies to create even greater value for the company and its customers. Today in logistics and distribution, the most relevant technologies for an IoT ecosystem tend to be artificial intelligence (AI), predictive analytics, blockchain, and cloud computing. But the concept of an IoT ecosystem is technology-agnostic: In the future and in other industries, compelling value could be created by integrating edge and quantum computing, augmented reality, and other technologies. Regardless of the specific technologies involved, all elements of the ecosystem work together to ensure the seamless flow of information to action.
To see the power of a truly connected IoT ecosystem, consider the example of connected vehicles. As figure 1 illustrates, today’s connected trucks not only move freight but typically generate vast amounts of data, such as location, engine status (speed, idle time, fuel levels), environmental conditions (temperature, moisture, light exposure), vehicle data (shocks, movement), driver behavior (tiredness, erratic driving patterns), and security (theft, tampering, alarm activations).
Uploading this data from a smart fleet to a cloud-based data system and feeding it into other technologies and transportation processes can support routing, shipment tracking, quality compliance, fleet management, driver performance management, and safety. In an end-to-end IoT-enabled transportation ecosystem, information would flow seamlessly throughout the network creating an information value loop (see figure 2).13
Here, different vehicles’ in-fleet sensors can automatically upload telematics data such as fuel consumption, location, and cargo temperature into connected cloud architectures, which can aggregate the information into structured data sets and feed it into predictive analytics algorithms that leverage AI. The resulting insights on vehicle condition, driver performance, cargo quality, and more, can enable the enterprise’s control center to monitor fleet performance and safety metrics and predict maintenance issues, downtime, cargo problems, and even road accidents. Transportation businesses can utilize these real-time insights to take appropriate action, including route optimization, dynamic scheduling, preventive maintenance, and rapid response in the event of a breakdown or crash.
Terminal operations. With the help of IoT and location tracking technologies such as GPS, terminals (or trucking stations) can get updated information on inbound shipments, such as expected time of docking, shipment quantity, and storage requirements. Combining IoT with AI and predictive analytics enables terminals to use this data intelligently to better plan outbound shipments and manage capacity. Using IoT-enabled dashboards, the terminal can maintain updated metrics on capacity utilization and shipment timing.
Recently, a leading port began testing the use of object detection sensors in order to track cargo-filled trucks lining up at each lane at ports with multilane terminals,15 enabling automated monitoring of congestion at the lane level (see figure 3). This data is uploaded to a cloud-based system. When the congestion threshold—determined using predictive analytics—is breached, a trigger is sent to the controller to redirect and streamline traffic. With the help of an IoT-enabled ecosystem leveraging AI, the port authorities are able to increase lane efficiency, reduce truck turnaround time, and improve operations planning at the terminal.
Transportation safety. Accidents, injuries, ineffective drivers, road safety—and the resulting losses—are some of transportation companies’ most visible and high-risk issues. Relevant technologies in the market focus on improving transportation safety: In-vehicle telematics solutions use accelerometers, trackers, and engine monitors to gather location, fuel consumption, speed, and braking data.16 Aggregated data points are fed to safe-driving analytics applications to monitor digitally calculated safety limits. Connected physical devices (such as mobile phones) provide feedback to drivers and others via alerts when safety thresholds are breached, completing the physical-to-digital-to-physical loop of a complete ecosystem. Analysts expect IoT telematics solutions to reduce both fuel consumption and the cost of incidents and insurance.17
Predictive maintenance. Smart technologies—marrying IoT to safety and maintenance plans within asset management systems—can enable transportation providers to manage asset maintenance holistically.18 Trenitalia has implemented an IoT-enabled solution that uses data-gathering sensors capturing weather conditions and equipment stress in its trains to feed a remote diagnostics platform in real time. Combined with AI and predictive analytics, this can enhance predictive maintenance capabilities to predict impending failures.19 This allows for fixes to be enabled when the asset is being utilized—improving productivity, efficiency, and asset longevity—and is expected to reduce fleet maintenance costs by up to 8 percent.20
Fleet monitoring and routing. The IoT ecosystem enables all points in the network to communicate with each other in real time with integrated communications systems technology. Leveraging low-latency information, a transportation provider can establish a dynamic network that accounts for demand and fleet availability and make real-time decisions regarding fleet routing and management.
For example, for a transporter, an IoT ecosystem consists of connected devices on the on-road fleet, collecting route information and sending constant updates to the cloud. With the effective use of analytics, business owners can take dynamic routing decisions and communicate with the network in real time using integrated communications systems technology.21 In addition to advanced safety and better predictive maintenance, transporters can make use of driver assist technologies to determine conditions suitable for fleet platooning in order to reduce draft and increase fuel efficiency.
DHL’s fleet management solution, SmarTrucking,22 uses sensor-enabled trucks to gather fleet data (location, weather, traffic, and shipment information) and telematics to transmit this data to a centralized control tower. Using predictive analytics, intelligent data science, and onboard diagnostics, the control tower makes real-time decisions on dynamic routing and fleet allocation, resulting in route optimization and efficient fleet scheduling and improved shipment visibility. SmarTrucking is expected to reduce transit times by up to 50 percent and increase real-time tracking reliability to over 95 percent across road networks in India.23
Product life management (cold chain). Traditionally, moving sensitive products through the supply chain (for example, pharmaceuticals or temperature-sensitive food products) has carried a high risk of losses, further magnified by the challenge of measuring these losses during transportation while ensuring compliance with stringent food safety requirements. IoT ecosystems can help improve cold chain transportation efficiency while ensuring product safety and quality—and can pinpoint issues causing product value loss by using analytics on sensor data.24
A leading industry retailer has been testing the use of IoT ecosystems for its cold chain management, with sensors enabling real-time temperature and humidity monitoring during product movement. This enables the company to monitor and distribute products more safely and efficiently and improve delivery quality while lowering loss-based costs and gaining visibility into the cold chain transportation process, with projected annual savings of US$1.3 million in cold chain compliance and asset efficiency.25
IoT ecosystems that stitch together sensor-based data with legacy systems (such as transportation and warehouse management systems) and newer technologies (such as cloud-based storage, AI, and predictive analytics) hold tremendous promise for those engaged in moving goods. And while dreaming big is important, it is just as crucial to understand that mastery takes time. Moving an organization from a world of manual, often paper-based systems to a digitally enabled and fully integrated enterprise happens in steps (see figure 4). In the disconnected state, communication between nodes is manual, with no real-time visibility or traceability. With the addition of tracking and tracing capabilities, the organization is able to quickly detect variations such as delays, breakdowns, and noncompliance. This connected state enables businesses to act on the system’s real-time data. In the integrated state, IoT solutions are used in conjunction with other technologies to predict events and enable real-time dynamic decision-making.
To move up the maturity curve, as with any successful digital transformation, it can be helpful to look at each of three strategic levers: process, people, and technology.
What are your business needs? Assess your current state of operations and identify the gaps between your organization and consumer/industry expectations, by looking at customer metrics and competitors’ technology adoption rates. After aligning on pain points and what you are trying to solve for, identify high-value, target-rich data that is easy to access, available in near-real time, has a large footprint (affecting major parts of the organization or its customer base), and can effect meaningful change in prioritized areas.
What adoption strategy is best suited for your business? Once you have scoped out your needs and goals, chalk out your road map for this journey. Since IoT-driven implementations can be data-heavy, invest your time in understanding the data being collected through IoT technologies and how it can be leveraged by other technologies and processes to create a rich and impactful ecosystem. Use the mantra “Think big, start small, scale fast” to assess your risks and returns while having your goals in mind.
It’s no secret that preparing your talent is a key factor in any successful technological evolution. In a recent Deloitte survey, around 63 percent of the respondents identified hiring and retaining the ideal skilled workforce as the biggest barrier in their respective organization’s transformation.27 Once you have identified the technological requirements (what) for your organization:
Identify your organizational and talent needs (who). Do you need technical resources to support the business? Will you require full-time employees or contractors/partners? Do you need personnel with nontransportation skill sets (analytical, health and safety, etc.)? Think creatively and holistically about what work will need to be done, where, and by whom in the future.
Explore strategies to recruit, retain, manage, and develop those people (how). Recruit the right talent. Invest in the importance of career experience. Create compensation and rewards that are not only competitive among your peers but also among the broader set of employers you may be vying with for talent—including tech companies.28
Most commonly, organizations can run into interoperability problems when overarching, cross-platform, and cross-domain applications are to be built. Given the large number of stakeholders involved, which can include platform and software providers, sensor vendors, developers, and users—not to mention multiple parts of your own organization—setting up an IoT ecosystem requires deep collaboration across the technology stack. Failure can mean lost business opportunities and stifled innovation.29
One effective way for organizations to build their IoT ecosystems is to look for solutions that are specific to your industry and are already rooted in your issues. Solutions that come tailored to industries and sectors are typically able to generate results more quickly than those that have to be reworked to fit your environment.30 For example, transportation companies can look into evolving their current telematics solutions into IoT-enabled ecosystems that can be connected to asset management solutions, resulting in increased asset turns and improved asset safety and security. At the same time, companies should be creative and look into applicable use cases from other industries.
Identify enhancements required to modernize platforms and create an ever-evolving ecosystem in order to harness the power of data to drive smarter, faster decisions.
Look out for potential roadblocks when setting up the information flow (for example, connectivity issues in the communication layer, data volume, and the frequency being transmitted across interfaces).
Leverage scalable solutions through accelerators and aggregators, which can result in eliminating a majority of the development work, hastening ROI, and increasing profitability.
Integrate current frameworks and partner solutions, with data seamlessly flowing through cloud-based solutions.
Technology adoption is an evolutionary process. As logistics and distribution organizations embark on the journey of digital adoption, they should keep in mind these overarching principles:
Focus on the business of IoT, using the technology to create real business value, not just connecting stuff for the sake of connecting stuff. Start with the end in mind.
Logistics and distribution organizations should not stop at embracing digital connectivity. To unlock the full competitive advantage and drive down their operational costs, organizations should think about integrating IoT technologies with automation and analytical capabilities. The advantage to IoT is visibility; the advantages to a connected IoT system are more educated and efficient supply chain decisions that can drive value to the business.
organizations should not stop at embracing digital connectivity. To unlock the full competitive advantage and drive down their operational costs, organizations should think about integrating IoT technologies with automation and analytical capabilities. The advantage to IoT is visibility; the advantages to a connected IoT system are more educated and efficient supply chain decisions that can drive value to the business. Transportation organizations are expected to need to develop alliances and partnerships to be leaders in the years ahead. This will likely require data sharing and a willingness to collaborate to gain higher performance and improved customer service. Companies should choose their partners wisely and leverage their IoT ecosystems to enhance the strength of their networks.
People are critical to your success. Invest in elevating your talent to effectively manage new technologies and processes.Digital has transformed manufacturing over the past decade. The cloud and IoT have helped companies make gains in efficiency and productivity that are nothing short of revolutionary. And the revolution isn't over. In this episode of the podcast, Deloitte's David Linthicum and guests, Deloitte's Subrata Roy and AWS's Michael Garcia, discuss announcements from AWS re:Invent 2019 and Smart Factory Fabric, a new suite of services from Deloitte that enables companies to use IoT and the cloud to reimagine the way they do business. They cover how Smart Factory Fabric works, the expected impact that it will have on manufacturing, and how companies can use Smart Factory Fabric to realize more of what's possible with cloud.
There are several point solutions that are available in the market, but they really do not share the data and the insights that come from each one of them…this product is unique because it brings together people, machines, and materials into one place where you can actually have a full view of your plant and how it is performing.
Subrata Roy is a managing director in Deloitte Consulting LLP's Supply Chain practice focused on AWS. He has 22 years of experience leading large global supply chain digital transformation programs.
Michael Garcia works as a principal product solutions architect at Amazon Web Services where he is part of the IoT (Internet of Things) service team. He helps customers deploy IoT applications while working closely with the IoT service team to improve existing products and launch new ones.​If you love your smartphone's AI-enhanced camera, wait until you find out what edge AI chips could do for enterprise.
Many people may be familiar with the frustration of calling up their smartphone’s speech-to-text function to dictate an email, only to find that it won’t work because the phone isn’t connected to the internet. Now, a new generation of edge artificial intelligence (AI) chips is set to reduce those frustrations by bringing the AI to the device.1
We predict that in 2020, more than 750 million edge AI chips—chips or parts of chips that perform or accelerate machine learning tasks on-device, rather than in a remote data center—will be sold. This number, representing a cool US$2.6 billion in revenue, is more than twice the 300 million edge AI chips Deloitte predicted would sell in 20172—a three-year compound annual growth rate (CAGR) of 36 percent. Further, we predict that the edge AI chip market will continue to grow much more quickly than the overall chip market. By 2024, we expect sales of edge AI chips to exceed 1.5 billion, possibly by a great deal.3 This represents annual unit sales growth of at least 20 percent, more than double the longer-term forecast of 9 percent CAGR for the overall semiconductor industry.4
These edge AI chips will likely find their way into an increasing number of consumer devices, such as high-end smartphones, tablets, smart speakers, and wearables. They will also be used in multiple enterprise markets: robots, cameras, sensors, and other IoT (internet of things) devices in general. Both markets are important. The consumer edge AI chip market is much larger than the enterprise market, but it is likely to grow more slowly, with a CAGR of 18 percent expected between 2020 and 2024. The enterprise edge AI chip market, while much newer—the first commercially available enterprise edge AI chip only launched in 20175—is growing much faster, with a predicted CAGR of 50 percent over the same time frame.
Here, there, and everywhere: The many locations of AI computing Until recently, AI computations have almost all been performed remotely in data centers, on enterprise core appliances, or on telecom edge processors—not locally on devices. This is because AI computations are extremely processor-intensive, requiring hundreds of (traditional) chips of varying types to execute. The hardware’s size, cost, and power drain made it essentially impossible to house AI computing arrays in anything smaller than a footlocker. Now, edge AI chips are changing all that. They are physically smaller, relatively inexpensive, use much less power, and generate much less heat, making it possible to integrate them into handheld devices such as smartphones as well as nonconsumer devices such as robots. By enabling these devices to perform processor-intensive AI computations locally, edge AI chips reduce or eliminate the need to send large amounts of data to a remote location—thereby delivering benefits in usability, speed, and data security and privacy. Of course, not all AI computations have to take place locally. For some applications, sending data to be processed by a remote AI array may be adequate or even preferred—for instance, when there is simply too much data for a device’s edge AI chip to handle. In fact, most of the time, AI will be done in a hybrid fashion: some portion on-device, and some in the cloud. The preferred mix in any given situation will vary depending on exactly what kind of AI processing needs to be done. Figure 1 shows the various locations where AI computing can occur, all of which are likely to coexist for the foreseeable future. The term “telecom edge” deserves some explanation here. Telecom edge compute (also known as telco edge compute)—the “far edge network” depicted in figure 26—refers to computing performed by what are basically mini data centers located as close to the customer as possible, but owned and operated by a telco, and on telco-owned property. They currently use data center–style AI chips (big, expensive, and power-hungry), but they may, over time, start incorporating some of the same kinds of edge AI chips (consumer or enterprise) that we discuss in this chapter. Unlike edge device computing, however, the chips used in telecom edge compute are located at the edge of the telco’s network, not on the actual end device. Further, not all telecom edge computing is AI computing. According to industry analysts, revenues for the telecom edge compute market (all kinds of computing, not just AI) will reach US$21 billion in 2020. This is up more than 100 percent from 2019, and the market is poised to grow more than 50 percent in 2021 as well.7 A precise breakdown of this market by category is not publicly available, but analysts believe that the AI portion will likely be still relatively nascent in 2020, with revenues of no more than US$1 billion, or 5 percent of total telecom edge compute spending.8
In 2020, the consumer device market will likely represent more than 90 percent of the edge AI chip market, both in terms of the numbers sold and their dollar value. The vast majority of these edge AI chips will go into high-end smartphones, which account for more than 70 percent of all consumer edge AI chips currently in use.9 This means that, in 2020 as well as for the next few years, AI chip growth will be driven principally by smartphones: both how many smartphones are sold and what percentage of them contain edge AI chips. In terms of numbers, the news appears to be good. After a weak 2019, which saw smartphone sales decrease by 2.5 percent year over year, smartphones are expected to sell 1.56 billion units in 2020, roughly the same number as in 2018—a 2.8 percent increase.10 We believe that more than a third of this market may have edge AI chips in 2020.
Smartphones aren’t the only devices that use edge AI chips; other device categories—tablets, wearables, smart speakers—contain them as well (figure 3). In the short term, these nonsmartphone devices will likely have much less of an impact on edge AI chip sales than smartphones, either because the market is not growing (as for tablets11) or because it is too small to make a material difference (for instance, smart speakers and wearables combined are expected to sell a mere 125 million units in 202012). However, many wearables and smart speakers depend on edge AI chips, so penetration is already high.
Currently, only the most expensive smartphones—those in the top third of the price distribution—are likely to use edge AI chips. That said, some phones under the US$1,000 price point do contain AI as well. Several AI-equipped phones from Chinese manufacturers, such as Xiaomi’s Mi 9,13 sell for under US$500 in Western countries. Further, as we’ll see below, putting an AI chip in a smartphone doesn’t have to be price-prohibitive for the consumer.
Calculating the cost of a smartphone’s edge AI chip is a roundabout process, but it’s possible to arrive at a fairly sound estimate. The reason one must estimate instead of simply looking up the cost outright is that a smartphone’s “AI chip” is not literally a separate chip unto itself. Inside a modern smartphone, only 7 to 8 millimeters thick, there is no room for multiple discrete chips. Instead, many of the various necessary functions (processing, graphics, memory, connectivity, and now AI) are all contained on the same silicon die, called a system on a chip (SoC) applications processor (AP). The term “AI chip,” if a phone has one, refers to the portion of the overall silicon die that is dedicated to performing or accelerating machine learning calculations. It is made from exactly the same materials as the rest of the chip, using the same processes and tools. It consists of hundreds of millions of standard transistors—but they are arranged in a different way (that is, they have a different architecture) than in the chip’s general processing or graphics portions. The AI portion is commonly, though not always, known as an NPU, or neural processing unit.
To date, three companies—Samsung, Apple, and Huawei—have had images taken of their phone processors that show the naked silicon die with all its features visible, which allows analysts to identify which portions of the chips are used for which functions. A die shot of the chip for Samsung’s Exynos 9820 shows that about 5 percent of the total chip area is dedicated to AI processors.14 Samsung’s cost for the entire SoC AP is estimated at US$70.50, which is the phone’s second-most expensive component (after the display), representing about 17 percent of the device’s total bill of materials.15 Assuming that the AI portion costs the same as the rest of the components on a die-area basis, the Exynos’s edge AI NPU represents roughly 5 percent of the chip’s total cost. This translates into about US$3.50 each.
Similarly, Apple’s A12 Bionic chip dedicates about 7 percent of the die area to machine learning.16 At an estimated US$72 for the whole processor,17 this suggests a cost of US$5.10 for the edge AI portion. The Huawei Kirin 970 chip, estimated to cost the manufacturer US$52.50,18 dedicates 2.1 percent of the die to the NPU,19 suggesting a cost of US$1.10. (Die area is not the only way to measure what percent of a chip’s total cost goes toward AI, however. According to Huawei, the Kirin 970’s NPU has 150 million transistors, representing 2.7 percent of the chip’s total of 5.5 billion transistors. This would suggest a slightly higher NPU cost of US$1.42.)20
Although this cost range is wide, it may be reasonable to assume that NPUs cost an average of US$3.50 per chip. Multiplied by half a billion smartphones (not to mention tablets, speakers, and wearables), that makes for a large market, despite the low price per chip. More importantly, at an average cost of US$3.50 to the manufacturer, and a probable minimum of US$1, adding a dedicated edge AI NPU to smartphone processing chips starts looking like a no-brainer. Assuming normal markup, adding US$1 to the manufacturing cost translates into only US$2 more for the end customer. This means that NPUs and their attendant benefits—a better camera, offline voice assistance, and so on—can be put into even a US$250 smartphone for less than a 1 percent price increase.
Companies that manufacture smartphones (and other device types) can take different approaches to obtaining edge AI chips, with the decision driven by factors including phone model and (sometimes) geography. Some buy AP/modem chips from third-party companies that specialize in making and selling them to phone makers, but do not make their own phones. Qualcomm and MediaTek are two prominent examples; combined, these two companies captured roughly 60 percent of the smartphone SoC chip market in 2018.21 Both Qualcomm and MediaTek offer a range of SoCs at various prices; while not all of them include an edge AI chip, the higher-end offerings (including Qualcomm’s Snapdragon 845 and 855 and MediaTek’s Helio P60) usually do. At the other end of the scale, Apple does not use external AP chips at all: It designs and uses its own SoC processors such as the A11, A12, and A13 Bionic chips, all of which have edge AI.22 Still, other device makers, such as Samsung and Huawei, use a hybrid strategy, buying some SoCs from merchant market silicon suppliers and using their own chips (such as Samsung’s Exynos 9820 and Huawei’s Kirin 970/980) for the rest.
What do edge AI chips do? Perhaps the better question is, what don’t they do? Machine learning today underlies all sorts of capabilities, including but not limited to, biometrics, facial detection and recognition, anything to do with augmented and virtual reality, fun image filters, voice recognition, language translation, voice assistance … and photos, photos, photos. From hiding our wrinkles to applying 3D effects to enabling incredibly low-light photography, edge AI hardware and software—not the lens or the sensor’s number of megapixels—are now what differentiates the best smartphone cameras from the rest. Although all these tasks can be done on processors without an edge AI chip, or even in the cloud, they work much better, run much faster, and use less power (thereby improving battery life) when performed by an edge AI chip. Keeping the processing on the device is also better in terms of privacy and security; personal information that never leaves a phone cannot be intercepted or misused. And when the edge AI chip is on the phone, it can do all these things even when not connected to a network.
If the edge AI processors used in smartphones and other devices are so great, why not use them for enterprise applications too? This has, in fact, already happened for some use cases, such as for some autonomous drones. Equipped with a smartphone SoC AP, a drone is capable of performing navigation and obstacle avoidance in real time and completely on-device, with no network connection at all.23
However, a chip that is optimized for a smartphone or tablet is not the right choice for many enterprise or industrial applications. The situation is analogous to what chip manufacturers faced in the 1980s with central processing units (CPUs). In the 1980s, personal computers (PCs) had excellent CPUs; their high computational power and flexibility made them ideal for such a general-purpose tool. But it made no sense to use those same CPUs to put just a bit of intelligence into (say) a thermostat. Back then, CPUs were too big to fit inside a thermostat housing; they used far too much power, and at roughly US$200 per CPU, they cost too much for a device whose total cost needed to be less than US$20. To address these shortcomings, an entire industry developed to manufacture chips that had some of the functions of a computer CPU, but were smaller, cheaper, and less power-hungry.
But wait. As discussed earlier, the edge AI portion of a smartphone SoC is only about 5 percent of the total area, about US$3.50 of the total cost, and would use about 95 percent less power than the whole SoC does. What if someone built a chip that had only the edge AI portion (along with a few other required functions such as memory) that cost less, used less electricity, and was smaller?
Some already have—and more are coming. Intel and Google, for instance, are currently selling internally developed standalone edge AI chips to developers. Nvidia, the leading manufacturer of graphics processing units (GPUs) commonly used in accelerating data center AI—which are very large, use hundreds of watts of electricity, and can cost thousands of dollars—now sells a customized AI-specific chip (that is not a GPU) suitable for edge devices that is smaller, cheaper, and less power-hungry.24 Qualcomm, the leading maker of merchant market SoCs with embedded edge AI processing cores for smartphones and other consumer devices, has released two standalone edge AI chips that are less powerful than its SoCs, but that are cheaper, smaller, and use less electricity.25 Huawei is doing the same.26
In all, as many as 50 different companies are said to be working on AI accelerators of various kinds.27 In addition to those working on application-specific integrated circuit (ASIC) chips, field-programmable gate array (FPGA) manufacturers now offer edge AI chip versions for use outside data centers.28
The standalone edge AI chips available in 2019 were targeted at developers, who would buy them one at a time for around US$80 each. In volumes of thousands or millions, these chips will likely cost device manufacturers much less to buy: some as little as US$1 (or possibly even less), some in the tens of dollars. We are, for now, assuming an average cost of around US$3.50, using the smartphone edge AI chip as a proxy.
Besides being relatively inexpensive, standalone edge AI processors have the advantage of being small. Some are small enough to fit on a USB stick; the largest is on a board about the size of a credit card. They are also relatively low power, drawing between 1 to 10 watts. For comparison, a data center cluster (albeit a very powerful one) of 16 GPUs and two CPUs costs US$400,000, weighs 350 pounds, and consumes 10,000 watts of power.29
With chips such as these in the works, edge AI can open many new possibilities for enterprises, particularly with regard to IoT applications. Using edge AI chips, companies can greatly increase their ability to analyze—not just collect—data from connected devices and convert this analysis into action, while avoiding the cost, complexity, and security challenges of sending huge amounts of data into the cloud. Issues that AI chips can help address include:
Data security and privacy. Collecting, storing, and moving data to the cloud inevitably exposes an organization to cybersecurity and privacy threats, even when companies are vigilant about data protection. This immensely important risk is becoming even more critical to address as time goes on. Regulations about personally identifiable information are emerging across jurisdictions, and consumers are becoming more cognizant of the data enterprises collect, with 80 percent of them saying that they don’t feel that companies are doing all they can to protect consumer privacy.30 Some devices, such as smart speakers, are starting to be used in settings such as hospitals,31 where patient privacy is regulated even more stringently.
By allowing large amounts of data to be processed locally, edge AI chips can reduce the risk of personal or enterprise data being intercepted or misused. Security cameras with machine learning processing, for instance, can reduce privacy risks by analyzing the video to determine which segments of the video are relevant, and sending only those to the cloud. Machine learning chips can also recognize a broader range of voice commands, so that less audio needs to be analyzed in the cloud. More accurate speech recognition can deliver the additional bonus of helping smart speakers detect the “wake word” more accurately, preventing it from listening to unrelated conversation.
Low connectivity. A device must be connected for data to be processed in the cloud. In some cases, however, connecting the device is impractical. Take drones as an example. Maintaining connectivity with a drone can be difficult depending on where they operate, and both the connection itself and uploading data to the cloud can reduce battery life. In New South Wales, Australia, drones with embedded machine learning patrol beaches to keep swimmers safe. They can identify swimmers who have been taken by riptides, or warn swimmers of sharks and crocodiles before an attack, all without an internet connection.32
(Too) big data. IoT devices can generate huge amounts of data. For example, an Airbus A-350 jet has over 6,000 sensors and generates 2.5 terabytes of data each day it flies.33 Globally, security cameras create about 2,500 petabytes of data per day.34 Sending all this data to the cloud for storage and analysis is costly and complex. Putting machine learning processors on the endpoints, whether sensors or cameras, can solve this problem. Cameras, for example, could be equipped with vision processing units (VPUs), low-power SoC processors specialized for analyzing or preprocessing digital images. With edge AI chips embedded, a device can analyze data in real time, transmit only what is relevant for further analysis in the cloud, and “forget” the rest, reducing the cost of storage and bandwidth.
Power constraints. Low-power machine learning chips can allow even devices with small batteries to perform AI computations without undue power drain. For instance, ARM chips are being embedded in respiratory inhalers to analyze data, such as inhalation lung capacity and the flow of medicine into the lungs. The AI analysis is performed on the inhaler, and the results are then sent to a smartphone app, helping health care professionals to develop personalized care for asthma patients.35 In addition to the low-power edge AI NPUs currently available, tech companies are working to develop “tiny machine learning”: Deep learning on devices as small as microcontroller units (which are similar to the SoCs mentioned earlier, but smaller, less sophisticated, and much lower power, drawing only milliwatts or even microwatts). Google, for instance, is developing a version of TensorFlow Lite that can enable microcontrollers to analyze data, condensing what needs to be sent off-chip into a few bytes.36
Low latency requirements. Whether over a wired or wireless network, performing AI computations at a remote data center means a round-trip latency of at least 1–2 milliseconds in the best case, and tens or even hundreds of milliseconds in the worst case. Performing AI on-device using an edge AI chip would reduce that to nanoseconds—critical for uses where the device must collect, process, and act upon data virtually instantaneously. Autonomous vehicles, for instance, must collect and process huge amounts of data from computer vision systems to identify objects, as well as from the sensors that control the vehicle’s functions. They must then convert this data into decisions immediately—when to turn, brake, or accelerate—in order to operate safely. To do this, autonomous vehicles must process much of the data they collect in the vehicle itself. (Today’s autonomous vehicles use a variety of chips for this purpose, including standard GPUs as well as edge AI chips.) Low latency is also important for robots, and it will become more so as robots emerge from factory settings to work alongside people.37
The difference between training and inference, and what it could mean for data center–based AI The AI enabled by an edge AI chip is more properly known as deep machine learning, which has two components. The first component is training. Training involves repeatedly analyzing a large amount of historical data, detecting patterns in that data, and generating an algorithm for that kind of pattern detection. The second component is inference. In inference, the algorithm generated by training—often updated or modified over time through further training—is used to analyze new data and produce useful results. Until recently, machine learning software used the same standard chips—a mix of CPUs, GPUs, FPGAs, and ASICs—for all their training and inference. These chips are all large, expensive, power-hungry, and produce a lot of heat; consequently, AI hardware built on these chips is always housed in a data center. In contrast, the edge AI chips discussed in this chapter perform mainly (or only) inferencing, using algorithms that were developed by training back in a data center. Although some edge AI chips do training as well, most training still occurs in data centers. Interestingly, although data center chips have historically been used for both training and inference, we are now seeing the development of different flavors of data center chips, with some optimized for training and some for inference.38 The implications of this relatively new development are not yet clear. But it is possible that, due to the emergence of edge AI chips, data centers will see their current mix of training and inference processing shift toward more training and less inferencing over time. If this happens, these more specialized data center chips could be especially useful for flexibility, allowing a data center that sees its ratio of training to inferencing shifting to change its hardware mix accordingly.
Who will benefit from the edge AI chip market’s growth? Obviously, it’s good for the companies that make edge AI chips. From essentially zero a few years ago, they will earn more than US$2.5 billion in “new” revenue in 2020, with a 20 percent growth rate for the next few years, and likely with industry-comparable margins. But that number should be placed in context. With 2020 global semiconductor industry revenue projected at US$425 billion,39 edge AI chips make up too small a fraction of that to move the needle for the industry as a whole, or even for its larger individual companies.
In truth, the bigger beneficiaries are likely those who need AI on the device. Edge AI chips can not only enormously improve the capabilities of existing devices, but also allow for entirely new kinds of devices with new abilities and markets. Over the longer term, edge AI chips’ more transformative impact will most probably come from the latter.
Will companies that make AI chips for data centers be harmed as some of the processing (mainly inferencing at first) moves from the core to the edge? The answer is uncertain. All of the companies that make data center AI chips are also making edge versions of these chips, so the shift in processing from the core to the edge may have little or no net effect. Also, demand for AI processing is growing so quickly that its rising tide may lift all boats: The AI chip industry (edge and data center combined) is expected to grow from about US$6 billion in 2018 to more than $90 billion in 2025, a 45 percent CAGR.40 A more likely potential negative is that the emergence of cheaper, smaller, lower-power edge AI chips may exert downward pressure on data center AI chip pricing, if not units. This has happened before: In the semiconductor industry’s history, the spread of edge processing chips frequently caused prices for mainframe/core processing hardware to fall faster than would have been expected based only on improvements according to Moore’s Law.
Some might also think that moving AI processing from the core to the edge will hurt cloud AI companies. This is unlikely: Recent forecasts for the cloud AI or AI-as-a-Service market predict that its revenues will grow from US$2 billion in 2018 to nearly US$12 billion by 2024, a 34 percent CAGR.41 Perhaps that growth would be even larger if edge AI chips did not exist, but it still means that cloud AI is growing twice as quickly as the overall cloud market, with a predicted CAGR of 18 percent to 2023.42
Equally, some might fear that if edge devices can perform AI inference locally, then the need to connect them will go away. Again, this likely will not happen. Those edge devices will still need to communicate with the network core—to send data for AI training, to receive updated AI algorithms for inference, and for many other reasons. For these reasons, we expect that all or almost all edge AI devices will be connected.
The nature of that connection, however, may be different than what was expected only two to three years ago. At that time, AI inference was restricted to large data centers, meaning that smart IoT devices had to be connected to access those AI inference capabilities—and not just to any old network, but one with ultra-high speeds, guaranteed quality of service, high connection densities, and the lowest possible latency. These attributes were (and still are) only to be found on 5G wireless networks. The natural assumption, therefore, was that all IoT devices that used AI would also need to use 5G, and only 5G.
That assumption no longer holds. If a device can handle a significant amount of AI processing locally, it doesn’t eliminate the need for a connection of some sort, but the connection may not always need to be through 5G. 5G will still be necessary some of the time, of course. And the 5G market is poised to grow enormously, at a 55 percent CAGR—more than US$6 billion annually—through 2025.43 But thanks to edge AI chips, the market opportunity in 5G IoT may be slightly smaller than was expected a few years ago.
The spread of edge AI chips will likely drive significant changes for consumers and enterprises alike. For consumers, edge AI chips can make possible a plethora of features—from unlocking their phone, to having a conversation with its voice assistant, to taking mind-blowing photos under extremely difficult conditions—that previously only worked with an internet connection, if at all. But in the long term, edge AI chips’ greater impact may come from their use in enterprise, where they can enable companies to take their IoT applications to a whole new level. Smart machines powered by AI chips could help expand existing markets, threaten incumbents, and shift how profits are divided in industries such as manufacturing, construction, logistics, agriculture, and energy.44 The ability to collect, interpret, and immediately act on vast amounts of data is critical for many of the data-heavy applications that futurists see as becoming widespread: video monitoring, virtual reality, autonomous drones and vehicles, and more. That future, in large part, depends on what edge AI chips make possible: Bringing the intelligence to the device.Email* Single Sign-On non disponibile per Internet Explorer 11 e Microsoft Edge Per nome e cognome non sono ammessi caratteri specialiIncorporating Internet of Things technology into products and services can represent quite an undertaking: There's a world of sensors and networking technology, plus legacy IT systems that must be integrated. How to get everything up and running quickly? Some companies are turning to bundled IoT systems.
The effort to deploy an Internet of Things (IoT) solution can be massive: Developing and deploying enterprise-grade IoT solutions may involve thousands of sensors, disparate networking and communication technologies, and integration with legacy IT systems. An emerging trend is taking aim at this complexity, however. Vendors are working to meet demand with IoT solutions that bundle and pre-integrate sensors, analytics, a sensor management and data ingestion platform, and user interface tools—and increasingly offering them as a service. While enterprises still need to configure and integrate these bundled solutions with legacy systems, these offerings help streamline the complexity and accelerate ROI for IoT projects.
Venture capital investments in bundled IoT solutions providers increased 85 percent in 2015 versus the prior year, totaling $2.2 billion and accounting for 61 percent of total IoT venture funding.1
Several large technology companies, including Amazon,2 IBM, Microsoft,3 and Hitachi,4 launched bundled IoT solutions within the past year.
Telecom companies, including AT&T,5 Rogers,6 and Verizon,7 are also introducing bundled IoT solutions.
Dozens of enterprises across sectors, such as online8 and offline9 retail, insurance,10 and consumer products,11 have deployed bundled IoT solutions over the last 12–18 months.
Architecting an IoT solution can be daunting, requiring the architect to select from among: hundreds of different types of sensors and devices, at least a dozen commercially available IoT integration platforms, multiple networking technologies, and various communications protocols. The architect then needs to integrate the solution with legacy IT systems and business intelligence tools. (For more of Deloitte’s thinking on IoT technology and applications, see the Deloitte University Press collection of articles at http://dupress.com/collection/internet-of-things.)
Buying and integrating these technologies is only part of the challenge: Conceptualizing the use cases and architecting solutions requires expertise in multiple technology domains to pilot and iterate until successful. Maintaining these systems means additional capital and operating expenditure commitments. For companies looking to deploy IoT applications, realizing ROI can seem risky and a long way off. It makes sense, therefore, that enterprises would welcome solutions that eliminate much of this complexity.
These challenges have created an opportunity for technology vendors, which are increasingly bringing bundled solutions to market. Systems integrators, too, have an opportunity to help enterprises connect those bundled solutions with legacy systems to enhance the level of business insights or achieve greater automation.
What do you get when you buy a bundled IoT solution? Vendors pre-integrate sensors, a sensor management and data ingestion platform, analytics, and user interface tools to work together. This reduces the time, effort, and costs of identifying, developing, and integrating individual technology components. And it reduces the time required to realize value from the deployment. The technology components may be sold directly to the client, but increasingly vendors are offering as-a-service models.
Note that even comprehensive IoT bundles aren’t exactly turnkey solutions: Getting optimal value from bundled solutions may require additional systems integration. This could include ingesting data from internal or external sources and combining these with sensor data to generate better insights. Or it could mean using the insights to take actions such as controlling machines or automatically generating trouble tickets when a threshold is breached. Some change management may also be required to properly embed the new solutions within the organization and ensure that people are using them effectively.
VCs have invested in bundled IoT technology for the last few years.12 But support has expanded dramatically recently, increasing 85 percent in 2015 over 2014, to an annual total of $2.2 billion. To capitalize on the growing importance of bundled solutions, some IoT technology vendors are changing their go-to-market strategies, pivoting from offering technologies to pre-integrated IoT solutions with as-a-service or pay-as-you-go payment models. The idea is to appeal to enterprises that prefer to pay for outcomes rather than technology.13
For example, Airware, a drone software company that raised $39 million in 2016, recently changed its strategy to include hardware, offering a bundled solution on a subscription basis.14 Enlightened, an energy-management-as-a-service provider, offers clients the option of sharing energy savings over a defined period in lieu of deployment costs.15
Some vendors are also incorporating connectivity into their bundled solutions. This makes it easier for enterprises by eliminating the need to negotiate separate connectivity contracts with telcos. For example, Enevo, a Finland-based waste-management-as-a-service provider, bundles connectivity from Finnish telecom operator DNA. Some 145 customers in 35 countries are already deploying Enevo’s solutions, according to the company.16
A review of bundled IoT use cases and vendors shows these solutions to be broadly applicable across sectors. Some are “horizontal” solutions for cross-industry issues such as energy management, supply chain monitoring, and predictive maintenance. Others target specific industries such as health care, retail, industrial, and automotive.
Revenue improvements, by improving customer experience (retail in-store customer navigation, real-time promotions and discounts), creating new services (medication adherence, equipment-as-a-service), or reducing stock-outs (supply chain, reordering services)
Cost reductions, via improved visibility into operations (switching off machines and equipment when not in use, managing capacity, collecting waste only when required), supply chain efficiencies (reducing inventory and spoilage), and cutting overhead expenses (reducing energy usage)
Asset utilization improvements, by reducing downtime (predictive maintenance on equipment), better load management (through better scheduling), and adding tracking (location tagging on expensive, movable equipment)
Vendors generally offer bundled solutions to handle processes that are not considered core competencies (for example, energy management or predictive maintenance on machinery) or to enhance a core capability such as claims processing in home insurance through use of drones. But, as with fully custom solutions, bundled solutions can be employed to differentiate a company from its competitors. For instance, solutions are available to retailers to improve customers’ in-store experience; vehicle monitoring insight solutions enable insurance companies to offer usage-based insurance.
The potential benefits of bundled IoT solutions are clear: faster implementation with less effort and more rapid ROI than either in-house development or piecing together solutions from multiple component vendors. But as always, outsourcing technology carries risks, and companies evaluating bundled IoT solutions need to consider a number of issues:
Data governance and security. As bundled IoT vendors enable new ways of capturing and using data17—think of insurance companies using data shared by smart home service providers to factor risk—enterprises must exhibit extra caution and lay down strong data governance and security policies to ensure safe storage and fair usage.
Risk mitigation. As with any significant IT purchase, buyers should plan ahead to cover the eventuality that a bundled IoT vendor could go bust or get bought—or that the CIO may want to switch to a different or better technology someday. Consider engaging providers that use open standards and publish their data models to retain access to data; failing that, contract for the right to the code in case the vendor goes bust, and for continuity of service in case the firm is acquired.
Competitive advantage. Develop custom analytics on top of bundled solutions and embed them into key decision-making processes to create differentiated, semi-custom solutions. When developing new services or capabilities, enterprises may want to explore including clauses to protect the IP and restrict bundled IoT vendors from replicating or developing similar products or capabilities with competitors.
The growing importance of bundled IoT solutions has implications for specific types of companies as well:
Technology and telecommunications companies may want to explore partnering with or acquiring vendors in order to offer bundled IoT solutions that promise to deliver specific outcomes—for instance, lower stock-outs in retail through intelligent sales tracking and automated reordering. Verizon partnered with rfXcel to launch the Verizon Intelligent Track and Trace solution for pharmaceutical companies; IBM acquired the Weather Company, then launched a weather insights service for insurance providers. Offering new business models for bundled IoT solutions, with low upfront investments along with flexible payment options, can also help drive adoption and create recurring revenue streams.
IoT start-ups should evaluate the opportunity of either creating bundled solutions or becoming part of one. Not only are VCs channeling ever more funds toward these solutions—enterprises are likely to show increased willingness to buy bundled IoT solutions to get going faster and at lower risk.
As has been widely noted, the Internet of Things has the potential to create enormous business value. But this rapidly evolving domain, still short on standards and long on complexity, presents obstacles that cause some enterprises to delay adoption. The emergence and proliferation of bundled solutions present an opportunity for enterprises to pursue the benefits of IoT technology with less complexity and lower risk.The COVID-19 pandemic has wreaked havoc on the economy, no doubt, but it has provided opportunities for companies to modernize their business infrastructure (in some cases just to survive), and therefore, accelerate their cloud adoption. That accelerated adoption is underway. Cloud spending increased by 11% in Q2 2020 over the same period last year.1 Companies that move quickly to follow the cloud adoption trend will have the opportunity to rethink how they operate—and to reshape their business to use cloud as a competitive differentiator.
That reshaping starts with companies moving forward in their cloud journeys from deciding on a horizontal multicloud strategy to building a vertical (full-stack) multicloud solution. Companies must also rethink their security posture—especially vis-à-vis what needs to change in a remote-centric, cloud-centric working environment that will test infrastructure security across a more distributed network. Finally, companies must also embrace new development operations and ways of working—to get applications, and new releases, into production faster and with flexibility given tremendous uncertainty. To do this, organizations will have to coordinate across business and technology leadership to implement effective business transformation with sound technology, security, and operations strategies.
Most medium-to-large organizations have at least a nascent cloud strategy, and some companies are already well on their way in implementing it. They’ve selected their cloud providers, determined which workloads to migrate, and started to understand interoperability issues. For those who haven’t started down the path, the road is paved.
It’s time to put those strategies into action. The next challenge for companies looking to thrive, not just survive, in a post–COVID-19 world will be to manage cloud complexity and build on their strategic foundation by configuring the appropriate tools, software, and technology to deliver and manage an IT infrastructure to power the future.
Build common data services with a single virtual database or by managing data in a distributed way. Develop multicloud solutions that focus on access, network management, operations, and endpoint complexity for a full-stack solution. Extend CloudOps to include AIOps, which goes beyond reactive monitoring to automated response.
Companies that take these steps could see significant benefits, such as the elimination of operational redundancies, improved insights into their data, and enhanced ability to govern that data. They could also achieve more flexible IT resource consumption models and more effectively manage costs.
Because the pandemic has forced companies to abandon physical infrastructure and embrace remote work and distributed infrastructures, security concerns become obsolete in some areas and heightened in others. To address shifting security concerns, companies must change the way they approach security to implement a more federated model across distributed work infrastructures. They must:
Manage federated computing infrastructures down to the endpoint level across tiers and devices (cloud, edge, mobile, IoT).
Use embedded, zero-anonymity security features, multifactor authentication, and privileged access management.
Look to replace perimeter-level security with device-level security; embrace virtualization and remote IoT devices; and secure every component of their environment, including object repositories, network segmentation, and web services.
Shift from single-vendor IM solutions to integrated, federated IM solutions to fully leverage cloud providers’ technology.
Those companies that embrace federated security will be able to increase their situational awareness, better manage attack vectors, and enable more dynamic threat intelligence and remediation. They will also be able to manage their security across an ever-shifting threat surface area. With this comes improved system interoperability, collaboration, and information-sharing.
Security isn’t the only concern in managing a newly distributed workforce and workplace. Companies that migrate to the cloud will need to find new ways of working—especially in terms of core infrastructure and application development to remove development bottlenecks and get new releases out faster.
For many companies, DevOps is one solution. DevOps encourages better communication and collaboration, and when combined with cloud, it is a force multiplier that enables companies to better meet performance demands and customer satisfaction goals. However, when implementing DevOps, companies must focus just as much on the cultural change required to live by DevOps principles as on the technology behind it.
Foster improved communication and collaboration across project teams, departments, and organizations.
Reimagine traditional roles and embrace an IT-as-a-service operating model with cloud architects who understand business as well as technology.
With effective DevOps, companies can align development activities better across full-stack product teams. This will help them react and respond quickly and focus on work that provides tangible, quick value. Development teams can also share knowledge in real time to enable better organizational knowledge management with automated, standardized, and repeatable processes that speed up development, free up workers to focus on more value-added activities, and enhance governance and the end-customer experience.
There will be a postpandemic world. It won’t be anything like the world that came before it, but that actually presents tremendous opportunities for companies that tackle its challenges successfully with technology-enabled business transformation to support the future of work. To meet those challenges, companies must double down on their technology modernization strategies and focus on building full-stack, cloud-enabled business solutions that are secure and enable collaboration and cohesion, no matter the location or device. They must embrace new ways of working that enable faster, better application development to be able to shift developer strategies as business needs change. Those companies that can navigate these layers of cloud complexity will modernize their businesses and most likely thrive. For those that don’t, if they are able to survive, infrastructure modernization will remain a future obstacle, with an even wider competitive gap to tackle.
If you’d like to read more about the future of the cloud-enabled work infrastructure, check out this new Deloitte Insights piece here.
1 Angus Loten, “Cloud spending hits record amid economic fallout from COVID-19,” Wall Street Journal, August 3, 2020.In the oil and gas industry, the promise of IoT applications lies not with managing existing assets, supply chains, or customer relationships but, rather, in creating new value in information about these. An integrated deployment strategy is key for O&G companies looking to find value in IoT technology.
After years of high and rising oil prices led to a longstanding oil price of more than $100 per barrel, new extraction technologies have opened up fresh sources of supply that suggest a new price equilibrium of $20 to $30 less per barrel.1,2 This new normal of lower oil prices not only will lay bare inefficient oil and gas (O&G) companies but will push even the efficient ones to find ways to preserve their top and bottom lines. Luckily for the O&G industry, a new suite of technologies promises to help companies tackle these challenges.
The Internet of Things (IoT), which basically integrates sensing, communications, and analytics capabilities, has been simmering for a while. But it is ready to boil over, as the core enabling technologies have improved to the point that its widespread adoption seems likely. The IoT’s promise lies not in helping O&G companies directly manage their existing assets, supply chains, or customer relationships—rather, IoT technology creates an entirely new asset: information about these elements of their businesses.
In an industry as diverse as O&G, it is no surprise that there is no one-size-fits-all IoT solution. But there are three business objectives relevant to IoT deployments in the O&G industry: improving reliability, optimizing operations, and creating new value. Each O&G segment can find the greatest benefit from its initial IoT efforts in one of these categories, which are enabled by new sources of information. With this in mind, this article provides segment-level perspectives, aimed at helping companies understand how information creates value, the impediments to value creation and how they can be addressed effectively, and how companies can position themselves to capture their fair share of that value.3
Upstream companies (e.g., exploration and production) focused on optimization can gain new operational insights by analyzing diverse sets of physics, non-physics, and cross-disciplinary data. Midstream companies (e.g., transportation, such as pipelines and storage) eyeing higher network integrity and new commercial opportunities will tend to find significant benefit by building a data-enabled infrastructure. Downstream players (e.g., petroleum products refiners and retailers) should see the most promising opportunities in revenue generation by expanding their visibility into the hydrocarbon supply chain and targeting digital consumers through new forms of connected marketing.
The new period of much lower prices is taking hold in the O&G industry, which is putting heavily indebted O&G companies on credit-rating agencies’ watchlists and derailing the capital-expenditure and distribution plans of even the most efficient ones.4 Addressing this structural weakness in oil prices requires more than financial adjustments. It demands a change in the industry’s approach to technology: from using operational technologies to locate and exploit complex resources, to using information from technologies to make hydrocarbon extraction and every successive stage before sale more efficient and even revenue-generating.
Enabling this shift to information-based value creation are the falling costs and increasing functionality of sensors, the availability of advanced wireless networks, and more powerful and ubiquitous computer power, which have collectively opened the floodgates for the amount of data that the industry can swiftly collect and analyze. Sensor prices have tumbled to about 40 cents from $2 in 2006, with bandwidth costs a small fraction of those even five years ago, helping the industry amass individual data sets that are generating petabytes of data.5,6
The industry is hardly resistant to adopting these new technologies. During the past five decades, it has developed or applied an array of cutting-edge advances, including geophones, robots, satellites, and advanced workflow solutions. However, these technologies primarily function at an asset level, or they are not integrated across disciplines or do not incorporate business information. According to MIT Sloan Management Review and Deloitte’s 2015 global study of digital business, the O&G industry’s digital maturity is among the lowest, at 4.68 on a scale of 1 to 10, with 1 being least mature and 10 being most mature. “Less digitally mature organizations tend to focus on individual technologies and have strategies that are decidedly operational in focus,” according to the study.7
O&G companies can reap considerable value by developing an integrated IoT strategy with an aim to transform the business. It has been estimated that only 1 percent of the information gathered is being made available to O&G decision makers.8 Increased data capture and analysis can likely save millions of dollars by eliminating as many as half of a company’s unplanned well outages and boosting crude output by as much as 10 percent over a two-year period.9 In fact, IoT applications in O&G can literally influence global GDP. Industry-wide adoption of IoT technology could increase global GDP by as much as 0.8 percent, or $816 billion during the next decade, according to Oxford Economics.10
Deploying technology does not automatically create economic value. To do so, companies must link IoT deployments, like any technology deployment, with specific business priorities, which can be described, broadly, using three categories of increasing scope. In the narrowest sense, companies seek to minimize the risks to health, safety, and environment by reducing disruptions (improving reliability). Next, companies seek to improve the cost and capital efficiency of operations by increasing productivity and optimizing the supply chain (optimizing operations). At the largest scope, companies seek to explore new sources of revenue and competitive advantage that transform the business (creating new value) (see figure 1).
Upstream players have together taken great strides in enhancing their operations’ safety, especially in the five years since the Macondo incident.11,12,13 Although technologies will continue to play an important role in improving the safety record of exploration and production (E&P) firms, lower oil prices are driving companies to place a higher business priority on optimization where IoT applications are relatively immature. Improving operational efficiency is more complex than ever given the increased diversity of the resource base being developed: conventional onshore and shallow water, deepwater, shale oil and gas, and oil sands.
The midstream segment traditionally has been a stable business connecting established demand and supply centers. Not any longer: The rise of US shale has altered the supply-demand dynamics—including the growing exports of liquids and natural gas—and increased midstream companies’ business complexity. To effectively serve this newly found growth and increased dynamism in the business, midstream companies are focusing on maintaining and optimizing their networks, a priority for which technology exists but that midstream companies have yet to fully integrate across their full network of pipelines and associated infrastructure.
By contrast, downstream players are relatively mature in monitoring risks and optimizing operations because of their standardized operations and long history of automation and process-control systems. But slowing demand growth worldwide, rising competition from new refineries in the Middle East and Asia, and changing and volatile feedstock and product markets are pressuring downstream players to explore new areas of optimization and extend their value beyond the refinery.
Regardless of the business priority served by new sources of data, the way in which the resulting information creates value can be understood using a common analytical framework: the Information Value Loop (see page 6). It is the flow of this information around this loop that creates value, and the magnitude of the information, the risk associated with that flow, and the time it takes to complete a circuit determine the value that is created. Organizations should design IoT deployments to create a flow of information around the value loop most relevant to a given business priority. Impediments to that flow can be thought of as bottlenecks in the value loop, and so a key challenge to realizing the value of any IoT deployment is correctly identifying and effectively addressing any bottlenecks that materialize.
The suite of technologies that enables the Internet of Things promises to turn most any object into a source of information about that object. This creates both a new way to differentiate products and services and a new source of value that can be managed in its own right. Realizing the IoT’s full potential motivates a framework that captures the series and sequence of activities by which organizations create value from information: the Information Value Loop.
For information to complete the loop and create value, it passes through the loop’s stages, each enabled by specific technologies. An act is monitored by a sensor that creates information, that information passes through a network so that it can be communicated, and standards—be they technical, legal, regulatory, or social—allow that information to be aggregated across time and space. Augmented intelligence is a generic term meant to capture all manner of analytical support, collectively used to analyze information. The loop is completed via augmented behavior technologies that either enable automated autonomous action or shape human decisions in a manner leading to improved action.
Getting information around the Value Loop allows an organization to create value; how much value is created is a function of the value drivers, which capture the characteristics of the information that makes its way around the value loop. The drivers of information value can be captured and sorted into the three categories: magnitude, risk, and time.
The fall in crude prices and the push to optimize operations come as E&P players face a period of rising technical and operational complexity. Players are placing more equipment on the seabed and developing systems that are able to operate at pressures of 20,000 pounds per square inch and withstand temperatures of up to 350°F particularly in deepwater; increasing downhole intensity and above-ground activity in shales; moving to hostile and remote locations where safety is key; and producing from old fields that have significant maintenance needs.14
This increased complexity, when captured with the tens of thousands of new sensors now deployed, has driven a data explosion in the E&P segment; by some estimates, internal data generated by large integrated O&G companies now exceed 1.5 terabytes a day.15 This data surge, however, has yet to generate the hoped-for economic benefits. “The upstream industry loses $8 billion dollars per year in non-productive time (NPT) as engineers spend 70 percent of their time searching for and manipulating data,” according to Teradata.16
On the one hand, the growing scale and frequency of hydrocarbon reservoirs data (or physics-based data that follow established scientific principles) are challenging E&P companies’ data-processing capabilities. On the other hand, the rising need to expand the scope of data (inclusion of non-physics-based data independent of scientific principles that add assumptions, conditions, uncertainties, and scenarios and cross-disciplinary data that cut across exploration, development, and production) is restricted by companies’ weak data-management capabilities. “Ample opportunities exists for upstream oil and gas companies to improve performance via advanced analytics, but weak information management is inhibiting the progress for many,” according to Gartner.17
Companies are struggling to alleviate these bottlenecks, in large part due to a lack of open standards that is limiting the flow of data at the aggregate stage and thus analysis. For example, a company operating several thousand gas wells in the Piceance basin in Colorado wanted to upgrade its supervisory control and data acquisition system to manage growing complexity in operations. As the system was using a vendor-proprietary data-communications format, the new vendor had to write a new driver from scratch to communicate with the old system, costing $180,000 to the operator.18 In some cases, not even this sort of additional investment is enough, and data flow comes to a standstill, choking process flows as well. To eliminate such costs across the industry, users, vendors, and industry councils (e.g., the Standards Leadership Council) could collaborate to create open standards, enabling compatibility and interoperability.
In addition, oilfield service (OFS) companies could play a larger role in standardizing and integrating data. Their deep understanding of physics-based data and long history of working with data-management and IT service providers position them well to play a de facto standardizing role in the industry’s value loop. Building on this expertise might allow OFS companies to create a new revenue stream and help them fend off advances from IT service providers that are beginning to vertically integrate and market their developed OFS capabilities directly to E&P companies.19
Delivering insights from aggregated data may have no value if those insights get to decision makers late or if the data overload a company’s infrastructure. The data explosion—coupled with bandwidth challenges—increasingly calls for a complementary, localized data-processing infrastructure that pre-processes information closer to where it is generated and transmits only selective data to the cloud. While moving network intelligence closer to the source has broader uses, it is well suited for remote locations that generate terabytes of data and demand predictable latency.
No matter what data-processing architecture a company erects, it must analyze that data if it is to optimize existing operations and, more importantly, to identify new areas of performance improvement. For E&P companies, the analysis of standardized data will likely most affect production, followed by development and exploration. By some projections, IoT applications could reduce production and lifting costs by more than $500 million of a large O&G integrated company with annual production of 270 million barrels.20 For example:
Production: The opportunity to automate thousands of wells spread across regions (a large company handles more than 50,000 wells) and monitor multiple pieces of equipment per well (a single pump failure can cost $100,000 to $300,000 a day in lost production) makes production the biggest potential O&G beneficiary of IoT applications. 21
The opportunity to automate thousands of wells spread across regions (a large company handles more than 50,000 wells) and monitor multiple pieces of equipment per well (a single pump failure can cost $100,000 to $300,000 a day in lost production) makes production the biggest potential O&G beneficiary of IoT applications. Development: Smart sensors, machine-to-machine connections, and big data analytics can increase active rig time, while a connected supply chain dependent on networked mobility and big data can reduce cost inflation and delays in new projects.
Smart sensors, machine-to-machine connections, and big data analytics can increase active rig time, while a connected supply chain dependent on networked mobility and big data can reduce cost inflation and delays in new projects. Exploration: Advancements in seismic data acquisition (4D, micro-seismic) and computing power have already improved E&P companies’ understanding of subsurface geology by providing more and better data about what lies beneath.22 However, still greater opportunity lies in faster processing of existing seismic data and transforming them into surface models.
Beyond the technical advantages, if common data standards are able to integrate diverse sets of data, companies can likely gain insights into previously invisible aspects of operations and adjust how they make decisions. For example, analytics applied to a variety of physics-based data at once—seismic, drilling, and production data—could help reservoir engineers map changes in reservoirs over time and provide insights for production engineers making changes in lifting methods.23 Similarly, a company could generate savings by analyzing the non-physics-based data, such as the impact that choices made during a well’s development phase would have on the design and effectiveness of production decisions.
For example, Apache Corp., a large US E&P company, in collaboration with an analytics software firm, not only improved the performance of its electrical submersible pumps (ESPs) but also developed the ability to predict a field’s production capacity in three steps. The first step used hybrid and multi-disciplinary data about pumps, production, completion, and subsurface characteristics to predict submersible-pump failure with prescriptions to avoid future failures. The second step enabled Apache to use the additional data generated in the first stage to prescribe the optimal pump configuration for the next well. The third step helped the company to use these additional ESP performance data to evaluate fields’ potential production capacity before acquiring them.24
This “compounding effect,” in which one level of data analytics provides insights that can then lead to additional analytics, promises to give E&P companies new operational insights that simply were never before available or visible.
Since the start of the US shale boom, pipeline companies have seen their business shift from a simple business model—transporting limited grades of liquids and natural gas between fixed supply and demand centers—to a complex and more dynamic model of transporting variable volumes and grades of products from multiple locations to new end users and markets.
This rising business complexity—combined with aging pipeline networks, legacy and manual monitoring and control devices, and the ongoing challenge of service differentiation—presents both challenges and opportunities for midstream companies. With annual losses of approximately $10 billion due to fuel leaks and thefts in the United States alone,25 companies face considerable upside in improving pipeline safety and reliability.
Installing more operational hardware and software with limited pre-defined tags (e.g., pressure, temperature, volume, vibration) and following rules-based approaches (e.g., statistical, historical) would likely do little to reduce risks or improve a network’s reliability. What may be needed is a shift toward data-enabled infrastructure—in other words, getting started on the Information Value Loop by investing in sensors that create new data. “Midstream energy companies lag far behind what other industries invest in information technology,” according to Oil and Gas Monitor.26
Enbridge, TransCanada, and PG&E, for example, are relieving this bottleneck by creating data about potential pipeline breaches from advanced sensors installed inside or outside the pipeline. TransCanada and Enbridge are testing four technologies that essentially see, feel, smell, and hear various aspects of their oil pipelines: vapor-sensing tubes that “see” bitumen spilled by shooting air down a tube; a fiber-optic distributed temperature sensing system that “feels” fluctuations in temperature caused by bitumen leaking into ambient soil; hydrocarbon sensing cables that send electric signals to “smell” hydrocarbons; and a fiber-optic distributed acoustic sensing system that “hears” sound variations and can indicate a pipeline leak.27,28
PG&E, along with research institutions and government agencies, is testing many non-invasive, three-dimensional (3D) imaging technologies such as the 3D toolbox, first developed for the dental industry, which accurately identifies and measures dents, cracks, and corrosion on the pipeline’s outer surface. The system automatically collects and feeds images into calculation tools to generate an assessment within minutes, helping engineers to put together a corrective-action plan immediately. Similarly, PG&E is adapting NASA’s airborne laser-based system for methane leak detection, in which leaks’ GPS coordinates are automatically stored and the data captured can be correlated with variables such as temperature, time, and pipeline configuration for improved monitoring and control.29
Enhancing pipeline safety is in all players’ interest, since a spill by any single operator can lead to higher costs and tighter regulations for the entire industry. As a result, companies are joining forces in developing a data-enabled monitoring infrastructure. Thus, the industry-wide benefit of this collaboration outweighs any single company’s competitive or commercial advantage. Ensuring safety and minimizing risks are table stakes—to truly differentiate itself in the midstream segment, a company often must go further.
In fact, a midstream company would likely accrue a larger competitive and commercial advantage if it analyzes product and flow data more comprehensively all along its network— similar to the way US electric companies are analyzing energy data using smart devices and meters. According to some estimates, every 150,000 miles of pipeline generates 10 terabytes of data, an amount of data equal to the entire printed collection of the Library of Congress.30
The “midstream majors” are well positioned to create insights from this new data of volumes because of their diverse portfolio and integrated network.31 A big midstream company can leverage the data across its pipelines, helping shippers find the best paths to market and charging them differently for having route optionality in contracts. Forecasting algorithms on historic volumes transported can reveal ways in which a midstream major might use pricing incentives that induce producers and end users to smooth volumes.32 Similarly, a real-time analysis of changing volumes across its network of shale plays can alert the company to new price differentials.
The pipeline data, when combined with growing data from an expanding network of export facilities, markets, marine terminals, and product grades in a timely manner, can give rise to a data-equipped midstream enterprise. “Forward-thinking, innovative midstream organizations can take advantage of the unprecedented volume of new types of data. Emerging types of data, such as machine and sensor data, geolocation data, weather data, and log data become valuable at high volumes, especially when correlated against other data sets,” according to Hortonworks.33
Crude-oil refining is a mature business with few recent innovations in processing technology. This, and the highly commoditized nature of petroleum products, make refining the most commercially challenging part of the energy value chain. Consequently, refiners worldwide have traditionally focused on running refineries as efficiently as possible and seeking to increase the yield of higher-value products.
Avoiding shutdowns is a critical part of increasing refinery output. Between 2009 and 2013, there were more than 2,200 unscheduled refinery shutdowns in the United States alone, an average of 1.3 incidents per day.34 These shutdowns cost global process industries 5 percent of their total production, equivalent to $20 billion per year.35 Ineffective maintenance practices also result in unscheduled downtime that costs global refiners on average an additional $60 billion per year in operating costs.36
Typically, refiners schedule maintenance turnarounds for the entire refinery or for individual units on a pre-set schedule to allow coordination of inspection and repair activities and to plan for alternative product-supply arrangements. For individual components, refiners routinely pull devices into the workshop for inspection and overhaul, without much information about a particular device’s expected condition, perhaps wasting efforts on devices that need not be repaired. But now non-intrusive smart devices (sensors), advanced wireless mesh networks (network), open communication protocols (standards), and integrated device and asset-management analytics (augmented intelligence) are driving a shift away from time-based preventive planning to condition-based predictive maintenance strategies.
For example, a crude unit of Phillips 66 was subject to preheat train fouling (accumulation of unwanted material reducing plant equipment’s efficiency). There were no data to quantify how much energy was being lost, or which exchangers to clean or when to clean them. Using wireless temperature and flow-measurement sensors, the refiner was able to predict the health of exchangers by correlating these measurements with production and environmental data. Such integrated analytics helped the refiner quickly spot where and when energy loss could exceed the target, providing estimated annual savings of $55,000 per exchanger. Most importantly, it helped the refiner identify periods of best performance and define best practices by comparing the performance of exchangers across units, which in turn allowed the company to improve performance across the plant.37
This seems like a fairly straightforward example of deploying sensors to create new data and generate value. Despite many similar examples, why have so few refiners thus far failed to fully capitalize on these sorts of IoT-enabled improvements? In many instances, data capture and analytics, or the flow of information, mostly happens at an asset level or, to some extent, at an overall plant level. What has been less common is analysis of data across the system (including pre- and post- links in logistics and distribution) and, moreover, across the ecosystem (adding external variables such as consumer profile and behavior, etc.) (see figure 2).
Optimizing the supply chain by streamlining the planning and scheduling process is one aspect where IT service providers’ automated software and hardware solutions have already made significant inroads. Using the visibility into the fully hydrocarbon supply chain as a system for enhancing refining operations and flexibility is another aspect—integrated information can help create and capture new value for refiners. This, in particular, may make sense for US refiners, which are fast changing their crude sourcing strategy from mostly buying medium and heavy crude under long-term contracts (following a typical supply-chain process) to buying a greater range of light, medium, and heavy crude blends in the spot market (requiring greater supply-chain dynamism to reap benefits).
One US refiner, for example, wanted to properly value its future crude purchases, especially cheap crude available for immediate purchase on the spot market. However, the refiner had limited data on future operating and maintenance costs for the various crudes it processes and buys—varying sulfur and bitumen content in a crude can lead to additional operating and maintenance expense that could nullify the price benefit. The refiner first installed pervasive sensors on refinery equipment, which allowed it to gather data on the impact of processing various crudes. Once collected and analyzed, the data from the sensors was then integrated with market data on crudes (cargo availability, price, grade, etc.) on a central hub, allowing the refiner to effectively bid for its future crude cargoes in a timely manner.38
This analysis, if extended and combined with information on variations in oil delivery times, dock and pipeline availability, storage and inventory levels, and so on (scope), could help the refiner come up with several what-if scenarios, making its crude sourcing more dynamic and competitive.
Changing issues of efficiency and handling data don’t stop at the inbound logistics of crude-oil sourcing—there’s the outbound logistics of product distribution to consider. The distribution ecosystem includes not only refining and marketing companies but the customers to which they sell. The rapid innovation and proliferation of consumer personal-communication technologies—smart handheld devices and telematics systems in a vehicle—have led to the emergence of connected consumers who, by extension, are demanding a connected fueling experience. So how should fuels retailers think about competing in a digitally enabled consumer’s world?
Automotive companies, with a head start on IoT-based connected applications, provide telling clues. Toyota, for example, has developed, with SAP and VeriFone, a prototype solution that simplifies a driver’s fueling experience.39 Currently, drivers need to deal with multiple systems to find the “right” gas station—locating the station, swiping the card, punching in a memorized PIN, and, if required, keeping a record of receipts. The prototype is aimed at providing consumers a one-touch, one-screen solution that can aggregate information on a vehicle’s location, route, and, most importantly, fuel level using the SAP HANA cloud platform and Bluetooth Low Energy wireless standard; the system aims to navigate the driver to the closest “enrolled” gas station, authorize an automatic payment using VeriFone’s point-of-sale solution, and send personalized coupons and offers.
At this level, the challenges faced by companies are large and not entirely technical. While data can be brought together and displayed using existing communication and telematics, the greatest bottleneck is in getting consumers to act. The interface must be designed as augmented behavior complementing natural human decision processes or it risks being rejected by consumers as “dictatorial,” “creepy,” or “distracting.” Beyond mere technical challenges, designing such a system involves deep insight into human behavior.
However, if a company is able to design a workable and secure system, the benefits may be immense. At a minimum, fuels retailers can boost sales of their gas stations and convenience stores by partnering or, at least, enrolling in such connected-car prototypes. At a next level, they can add more appeal to their traditional loyalty and reward programs, which aim to incentivize customers by offering discounts or redeemable points. The use of collected customer information in running analytics is minimal or constrained by limited buying behavior data of any individual customer at pumps and linked convenience stores; aggregating data promises more useful information.
The future of retail marketing can correlate consumer profiles with fuel purchases and in-store purchases across a retailer’s owned stations and franchisees, mash up existing petro-cards data with the data collected by cloud-enabled emerging telematics solutions, and combine data from multiple sources such as status updates and notifications from social-media networks to facilitate behavioral marketing and predictive analytics. By industry estimates, about 33 percent of IoT-derived benefits for an integrated refiner/marketer can come from connected marketing.40
Facing the new normal of lower oil prices, the O&G industry is beginning to see the IoT’s importance to future success. But it’s not as simple as adding more sensors: Creating and capturing value from IoT applications requires clearly identifying primary business objectives before implementing IoT technology, ascertaining new sources of information, and clearing bottlenecks that limit the flow of information (see table 1).
Upstream players focused on optimization can gain new operational insights by standardizing the aggregated physics and non-physics data and running integrated analytics across the functions (exploration, development, and production).
the aggregated physics and non-physics data and running integrated analytics across the functions (exploration, development, and production). Midstream players targeting higher network integrity and new commercial opportunities can benefit by investing in sensors that touch every aspect of their facilities and analyzing volume data more comprehensively all along their network.
that touch every aspect of their facilities and analyzing volume data more comprehensively all along their network. Downstream players operating at an ecosystem level can create new value by expanding their visibility into the complete hydrocarbon supply chain to enhance core refining economics and targeting new digital consumers through new forms of connected marketing.
Investing in IoT applications is just one aspect. Companies need to closely monitor IoT deployments and results to keep applications on track, at least in the initial few years. Both IT and C-suite executives must regularly ask and answer questions as to whether the IoT is creating the necessary momentum and learning across the businesses and employees, what the future costs and complexities associated with retrofitting and interoperability of applications are, and what the security shortcomings are in light of new developments.
For a given company, IoT applications’ self vs. shared development will determine the time to commercialization and the magnitude of realizable benefits. Building proprietary capabilities, although essential for competitive advantage in some cases, can slow down the pace of development and restrict a company to realize the IoT’s transformative benefits. “We can’t do all of this [development of technology] alone. We believe that in the future we will have to be far more collaborative,” said BP Chief Operating Officer James Dupree.41 Collaborative business models can enable the industry not only to address current challenges but also to take the intelligence from fuels to a molecular level and extend the IoT’s reach from cost optimization to capital efficiency and mega-project management in the long term.42
By reinforcing the importance of information for all aspects of the business and elevating information to the boardroom agenda, a company can fundamentally change how it does business rather than just optimizing what it has always done (see figure 3).
Deloitte’s Internet of Things practice enables organizations to identify where the IoT can potentially create value in their industry and develop strategies to capture that value, utilizing IoT for operational benefit.​
To learn more about Deloitte’s IoT practice, visit http://www2.deloitte.com/us/en/pages/technology-media-and-telecommunications/topics/the-internet-of-things.html.
Read more of our research and thought leadership on the IoT at http://dupress.com/collection/internet-of-things/.In the airline industry, the focus on costs rarely wavers and the pace is constantly demanding. However, the ability to network exponential technologies continues to offer a rich potential to improve productivity, derive additional utilization from assets, and lower costs. Airlines need more than another hard-won half a percentage point. They need a game-changer.
The IoT—networks of sensor-equipped, intelligent, exponential technologies that can gather data, interpret it, and take action—may be that game-changer. By streamlining repetitive processes and making people more efficient, IoT can help transform cost-saving from an incremental struggle to a wide-open frontier.
This is already starting to happen. Two-thirds of surveyed airline leaders believe IoT offers clear benefits right now, 86 percent expect identifiable benefits within three years, and 37 percent have begun to explore and implement IoT improvements as a way to confront rising costs. What these first movers are finding is that an investment in smart devices is only part of the puzzle. They must also plan carefully for the architecture that links data, decision, and action into a self-driving loop.It is no surprise then that drone-based InsurTechs have garnered a lot of attention as well as investment dollars from venture capitalists and insurers alike. As many as eight deals were announced in 2018, totaling more than $145 million. Seven out of the eight deals were either later-stage or follow-on rounds of funding, a trend consistent with the one we identified in our recent report, "InsurTech entering its second wave," that investors have started leaning towards more established entities over new InsurTechs.2
This also signals increasing budgetary commitment by insurers to drones as an innovation. As noted by my colleagues Akash Tayal and Nikhilesh Ramani in their report, "Insurance industry drone use is flying higher and farther," with applications spanning the entire insurance value chain,3 many large carriers that piloted the technology in the last two to three years have started ramping up their investments.
The Travelers Companies, which launched its drone program in 2016 to support claims inspection, has completed more than 17,000 drone flights across 48 states4 and employs almost 600 claims professionals who double as FAA-certified drone pilots5, making it one of the largest commercial drone users across all industries in the US. Similarly, Allstate, which began testing drones for property claims in late 2015,6 settled approximately 12,600 claims in 2017 and about 16,500 claims in the first half of 2018 using drones.7
In September 2018, the federal aviation regulator for the first time granted State Farm permission to fly drones over populated areas beyond visual line of sight (BVLOS) in four states to survey losses from Hurricane Florence.8 While it was a one-off approval, BVLOS flights represent the potential for greater drone-driven automation and operational efficiencies in the future.Mastering the development in IoT is a critical challenge for many enterprises. The enablement to connect sensors and devices to vast mass amount of data as well as its analysis to innovate processes and business models is crucial for entrepreneurial success. In the discussion how to make IoT profitable, the focus is rather on data analytics. But: The extraction of strategic and operative relevant data is only one part. Barely recognized and underestimated are functionality and costs of the hardware components, which enable connectivity between sensors and devices.
The core component of every connected sensor or device is the incorporated chip set or more precisely, the functional design of the chip set, the intellectual property cores (IP-cores). Consequently, IP-Cores can be seen as the blue prints of IoT sensors or platforms that allow to define elements like data processing, storage or security.
Besides the technical dimension, there is also a market perspective. For decades, a few commercial intellectual property vendors dominated the market for IP-cores. Since 2010, the open source movement is increasingly changing this market, especially the RISC-V initiative. Both perspectives will be examined in more detail.
IP-cores are pre-fabricated, tested and a partially verified function block of a chip design. They are the basis for new chip designs or integrated into chip designs of other manufacturers. These modular components bring IoT to life since they enable sensors and micro controllers to collect and analyze data. For example, the average smartphone has 14 sensors that detect everything from external temperature to movement. Combined with a micro controller it is possible to give the data an IoT value.
But simple data collection and analysis is not enough. With the growing importance of real-time data analysis and the increasing amount of collected data you need high performing IoT processors to handle the increasing complexity. Moreover, since IoT devices are portable to a large extend power efficiency is also important.
Security is the third big issue that needs to be addressed in the context of IoT. With IP-cores it is possible to embed security features into the hardware by adjusting the hardware source code. This is a highly critical topic for the success of IoT. For example, in November 2017 Intel had to announce a security breach in the management engine (firmware) of their CPUs.
As mentioned before, IP-cores are modular functional blueprints that can be integrated into chip and micro controller designs. The core business model is based on licensing IP-core blueprints for chip manufacturers like Intel, AMD, or Nvidia. The licensing model is done by very specialized IP-vendors like ARM or MIPS. One reason why the market for IP-cores was dominated by a view companies for serval years.
This strong dependency and their lock-on standards raise the desire for an open source approach in order to reduce costs and licensing fees, increase the customization of IoT device functionality and to accelerate IoT diffusion by prototyping. Market players are hoping for an open source movement similar to the development of the open source software industry. Here, the industry changed from a technology-based industry to a service-oriented one. The core of the business model is no longer the source code, i.e. the program itself and its sale, but the services around the software, such as consulting, customer specification, support and maintenance.
The open source movement started 5-10 years ago for hardware development with open source IP-cores around 2010. This movement increases the efficiency and security of embedded micro controllers and it could enhances IoT usage. For example, many manufacturing companies are struggling with the implementation of IIoT use cases because of security concerns, since micro controllers have limited storage and functionality. An open source development of the MIT enables the transmission of the IoT standard security protocol “Datagram Transport Layer Security” (DTLS) to a DTLS protocol controller. In this way, memory capacity has been saved and security has been increased via integration into a chip set.
One of the main drivers of the Open Source IP Core movement is the RISC-V initiative. The open instruction set architecture (ISA) is licensed (Berkeley Software Distribution License). Thus, the open source ISA can be used by anyone to develop or update an open source IP without fee and the duty to republish the new development. Key players like Sifive or Western Digital are already using the RISC-V ISA or are developing respective devices. E.g, Sifive developed the first 64-bit quadcore SoC based on the free instruction set RISC-V. Western Digital also plans to create processors and micro controllers based on RISC-V architecture.
From a future perspective, open source IP will enable the development of customized System-on-a-Chip designs that can perform tasks that are more complex. This can be used in fixed (ASIC) as well as programmable (FPGA) chip sets. A company that is already on this way is CEVA. CEVA uses open source IP-cores in Wifi-boards and Bluetooth chips.
Also, the graphic processing unit manufacturer (GPU) Nvidia gives open access to its general-purpose graphics processing units (GUGUPs) the accelerate the deep learning development for self-driving cars, robots and other high-end autonomous platforms.
Open source IP-cores can improve the collaboration between IoT sensors and embedded micro controllers to drive the right data from the collected data.
Performance and functionality of processors can be customized to the IoT device application. Security components can be adjusted and incorporated into hardware source code. This important issue concerns many companies and industries while implementing Industrial IoT. An open source IP-core approach that addresses these concerns is the DTLS protocol controller developed by the Massachusetts Institute of Technology (MIT). The DTLS protocol controller is a transmission of the IoT standard protocol “Datagram Transport Layer Security” (DTLS). This open source controller can be directly integrated into the chipset and does not need a security software plug-in.
In summary, IP-cores can be the driver for the mass diffusion of IoT. The open source approach is speeding up this change.In order to get value from the Internet of Things (IoT), it helps to have a platform on which to create and manage applications, to run analytics, and to store and secure your data. Like an operating system for a laptop, a platform does a lot of things in the background that makes life easier and less expensive for developers, managers, and users.
In many mature markets, there are often two dominant platform choices and a long tail of smaller players; for example, iOS and Android in mobile, Windows and Mac OS in desktop operating systems, and PlayStation and Xbox in gaming. But not in IoT, not yet. In IoT, sometimes it seems like there may be more platforms than things. Search Crunchbase for venture-funded IoT platforms, and you will get well over 100 hits. And that list doesn’t include many bigger technology players entering the market with IoT platforms like Microsoft, IBM, and SAP or several industrial companies with similar aspirations like GE, Bosch, and Siemens.
There are IoT platforms of every shape and size. There are platforms for specific industries like commercial real estate and family health. Some focus on one type of device: for example, there are at least two platforms focused on augmented-reality headsets. Some are focused on a particular function, like manufacturing. There is an IoT platform for dogs.
Businesses and developers have a bewildering array of platform options to choose from, which may have very different capabilities. The term “platform” is overused to the point where it doesn’t convey much information beyond “more assembly required.”
Most broadly, a platform is software and hardware, which may include an operating environment, storage, computing power, security, development tools, and many other common functions. Platforms are designed to support many smaller application programs that actually solve business problems.
Platforms are helpful because they abstract a lot of common functions away from the specific application logic. For example, regardless of whether you are trying to write an application to optimize fuel consumption or classroom space, a lot of the underlying technology needs are essentially the same. Application developers just want to focus on the specific problem they are solving and use common capabilities for computing power or storage or security. A good platform dramatically reduces the cost of developing and maintaining applications.
In the Internet of Things, platforms are designed to deploy applications that monitor, manage, and control connected devices (Exhibit 1). IoT platforms must handle problems like connecting and extracting data from a potentially vast number and variety of endpoints, which are sometimes in inconvenient locations with spotty connectivity.
Exhibit 1 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Why so many platforms? Look at successful software platforms like Windows for operating systems. Platforms make a lot of money and are high-margin franchises that endure for decades. People and companies don’t switch platforms very often. Often, switching costs are significant and platform choices persist for many years.
As a result, many start-ups aspire to become platforms, because the winners create enormous shareholder value. Their investors push them to market themselves as platforms because winning platform companies can create 100-fold returns.
There are two main problems with this strategy. First, platform companies aren’t as focused on direct customer business value as application companies. A pure-play platform alone won’t solve a business problem; an application is still needed. The platform’s value proposition is harder to explain to business leaders. This translates into a higher cost of sales.
The second problem is that there can only be a small handful of winners in each platform space. Application developers don’t want to learn multiple platforms. Businesses and consumers don’t want to use and pay for multiple platforms. If there are 100 IoT platforms, then there is no platform, just aspirants. The market, over time, decides who the winners are, and the providers consolidate around two or three leaders.
Today, there is no one-size-fits-all best platform for every application. It may be years before the market anoints the winners in the IoT platform derby.
In the meantime, choosing a platform should start with a good understanding of your IoT strategy. Identify the kinds of problems you are trying to solve, get a short list of likely solutions and use cases, and try to determine where you will need specialization and depth. If you have an idea of what kind of business problem you are solving and where the biggest challenges are, you’ll be able to quickly come to a short list of platforms (Exhibit 2).
Exhibit 2 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Avoid the temptation to select a platform simply because it has a particularly interesting initial use case. This would be like choosing a game console because it included a cool game in the box. Included applications matter but are only part of one element of a platform strategy. We have identified the top five characteristics of IoT platforms on which to base an evaluation. While these five are not an exhaustive list, they are the areas most likely to differentiate platforms in an important and sustainable way.
There are three main application considerations when choosing a platform: what applications are available out of the box, what is the application-development environment like, and what are the common enterprise-application interfaces. Many platforms will include one or more applications that may be of some value out of the box, like the stock market or weather apps that ship with iPhones. Sometimes, very simple applications are the most popular. One manufacturing executive once told us, “I’d be thrilled to have an app that just told me what machines were on my factory floor and if they are switched on or off.”
However, you may need to develop sophisticated IoT apps yourself. Platform providers don’t understand your business problems the same way you do. Confirm that the application-development environment included in the platform is compatible with your own developers, or your trusted development partner. Make sure the development environment supports a way to “containerize” applications using a common service so that they can be ported to another platform should you decide to switch. Finally, you may need your platform to interface with large enterprise applications, like common customer-relationship-management or enterprise-resource-planning suites. Some platforms may include connectivity to popular CRM or ERP suites, and this may be an important feature depending on your IoT use cases.
Often, 80 percent of a data scientist’s time is spent combining, formatting, cleaning, and processing data to get it ready for analysis. Other companies have created new roles for data engineers, whose main job is to curate and cultivate data sources. Some platforms contain shortcuts or special tools that allow you to build a robust model of your important data much faster, reducing people costs and time to market significantly. Indeed there are some highly regarded platform companies that specialize in just this capability and use off-the-shelf technology for the other parts of the platform. Apart from the ability to conceptualize the data and understand what it is, also important is the ability of a platform to handle and manage a large number of high-velocity data streams coming from multiple different sources. The ability to handle vast, fast data may be critical, and there are some specialized technologies that focus only on that. Some are being licensed into different platforms.
Big IoT platform providers tend to also offer their own cloud hardware infrastructure (including storage, compute, networking, and data centers). For example, Amazon and Microsoft both provide a software-platform layer with IoT services, as well as a hardware-infrastructure layer that is broadly applicable across public cloud applications. The hardware infrastructure layer is capital intensive, has high fixed costs and significant economies of scale, and tends toward commoditization over time. As a result, most smaller platform players avoid offering it, providing only the software layer. They certify their platform on one or more of the leading public cloud providers. Many of the nascent platform companies may not be certified on all the major cloud providers (and often may run on only one of them). This is relevant for enterprises that may be seeking to standardize on a particular public cloud solution for other reasons. Make sure your IoT platform provider and your broader enterprise cloud strategy are compatible.
You may be content to have your data stored in the public cloud anywhere in the world with standard encryption. Or, it may be that for security or regulatory reasons, your data must be on your premises. Perhaps your data can be in the public cloud but only within certain political boundaries. You may have specific security requirements, either in the cloud or on your remote devices. There may be certain kinds of encryption, access management, or authentication that are required. Blockchain support may or may not be required. IoT platform capabilities vary here. Some are distinctive in certain areas of security.
It is one thing to have a platform that takes data from your things and pipes it all up to the cloud for analysis by humans. It’s another thing to run the analytics at the edge. Sometimes, the communications overhead of moving data to the cloud is onerous; transmitting terabytes of data from a remote mine or a ship at sea to the cloud could be prohibitive. Some platforms have specialized capability in handling this. Sometimes local autonomy is needed; some platforms allow you to take the human out of the loop and allow the platform to autonomously change the behavior of the connected endpoints or shift data only at convenient times. Moving applications from the cloud to the edge, and potentially allowing them to adjust operating variables like fuel flow or direction or temperature, may be a requirement.
To get value from IoT across multiple use cases, it helps to use one (and only one) platform in your organization. The IoT platform market is immature and there are over 150 options to choose from. As this market consolidates, try to find a partner who is either large and will be in it for the long run or highly focused, distinctive, and successful in solving your most difficult problems. Look at the whole technology environment, not just the applications. Your most important requirement may be data wrangling, security, or local automation. Use fungible/off-the-shelf technology for the things that are less critical.
Choosing a platform is an important decision, because whether it is game consoles, smartphones, or the Internet of Things, it’s likely that whatever platform you choose will be with you for a long time.The observation that the Internet of Things encompasses people holds a number of transformative business and societal implications. The data and information flows that continually emanate from people and devices can be aggregated and analyzed to create fundamentally new types of products and services that go with the grain of human psychology.
“We don’t even know what it is yet. We don’t know what it is. We don’t know what it can be, we don’t know what it will be, we know that it is cool.”
The protean inventor Nikola Tesla once made a prediction that must have seemed as fanciful to his Victorian contemporaries as the science fiction of the day. He wrote: “When wireless is fully applied, the Earth will be converted into a huge brain, capable of response in every one of its parts.”2
Today—a century and a digital revolution or two later—there is a sense in which Tesla’s “global brain” is becoming an actuality. Though the Internet is often discussed in terms of aspects of the world entering “virtual reality,” an opposing dynamic is increasingly at play. The Internet is also expanding into the real world thanks to the availability of such inexpensive technologies as wirelessly connected sensors, triggers, actuators, RFID tags, GPS locators, accelerometers, and even printed QR (quick response) codes.3 Everyday objects are therefore increasingly becoming components of the emerging entity known as the Internet of Things (IoT). Roughly five billion of such connected devices will be in use in 2015, increasing to tens of billions in just a few years.4 From smart thermostats in our homes, personal fitness bands on our wrists, observational devices in vehicles to noise, efficiency, and vibration sensors embedded in factory machinery and jet engines, these devices, and the insights and predictions emanating from the resulting analytics, will quite literally be everywhere.
At first blush, the obvious implication is that everyday objects can and will become better, more efficient versions of what they already are. For example, complex machines such as airplanes, automobiles, agricultural equipment, and power plants can be tagged to emanate streams of data used to monitor and predict the time to failure of critical parts—which allows replacements and repairs to be conducted before breakage or failure. Medical cargoes can be monitored for environmental changes and safe transport. Smart streetlights use less energy to illuminate neighborhoods. In short, we can make devices “smarter” versions of their current selves thanks to the information flows enabled by cheap and widespread smart components and interconnectivity.
The linking of devices to networks changes the nature of these devices in at least two fundamental ways. First, data and information—long used to achieve efficiencies in the creation, marketing, and distribution of things—increasingly become imbued in the things themselves. For example, T-shirts, eyeglasses, sports equipment, mobile phones, automobiles, and fashion accessories can double as data-capturing and information-delivery devices. They increasingly become media of data products and services. Second, as things become increasingly networked, the networks themselves emerge as new classes of products and services. It is now meaningful to speak of smart homes, smart farms, and smart cities thanks to the flows of information enabling improved efficiencies and coordination amongst linked devices. This gives product companies new opportunities to become providers of information and services.
The IoT is giving rise to what might be called a “transfiguration of the commonplace,” with all of the societal and business model implications that this implies.5 The nature and functions of everyday things—and the networked environments they comprise—will continue to evolve, thanks to the infusion of data, information, and network linkages into their basic designs. Things change.
As sweeping as it already is, this device-centric narrative omits a crucial point. Namely, people should also be regarded as part of the IoT. The publisher and veteran Internet observer Tim O’Reilly recently made the initially counterintuitive comment that the crowdsourced taxi company Uber exemplifies the types of changes the IoT has in store for business models and societies. In this case taxi drivers and people seeking rides are the IoT “things,” connected via their mobile devices.6
The observation that the IoT encompasses people is deceptively simple. But it holds a number of transformative business and societal implications. First, the data and information flows continually emanating from both people and everyday devices can be aggregated and analyzed to create fundamentally new types of products, services, and business models. Furthermore (as in the case of Uber) these information flows can be bi-directional: multitudes of small signals from thousands of individuals, aggregated, and analyzed to send personalized data products, recommendations, or services back to individuals.
Second, most of what falls under the term “big data” is in fact the “digital breadcrumbs” collected by the IoT as we go about our everyday activities. This IoT-collected data is to the study of people and organizations what the telescope was to astronomy in Galileo’s time. New varieties of data science are coming to prominence in response to this newfound treasure trove, going by such names as computational social science, social physics, behavioral analytics, and people analytics.7 These emerging disciplines afford both deeper and broader understandings of human, organizational, and social network behavior. Domains likely to be affected range from human resources and performance management to behavioral health to employee risk management.
Finally, design thinking—as in behavioral design thinking—is important. The past three decades have ushered in a behavioral revolution in our understanding of the ways people make judgments and decisions. In the wake of these discoveries, there is increasing recognition that products and services are considerably more effective when they are designed to go with, rather than against, the grain of human psychology. To paraphrase Ogilvy’s Rory Sutherland, IoT-connected devices and IoT-delivered services should be designed for the brains of humans, not Vulcans. The IoT is not just about “smart devices”; it is also about devices and services that help us become smarter.
Tim O’Reilly put the matter simply: “The IoT is really about human augmentation.”8 It is time to explore the possibilities.
Early IoT applications have typically focused on efficiency gains. For example, in 2008, UPS gathered data from telematics and mobile devices to better understand where efficiency gains could be made and how to achieve them.9 Using GPS tracking equipment and vehicle sensors, combined with a driver’s handheld mobile device, UPS captured data about each truck’s route, the time vehicles spent idling or maneuvering, and even whether drivers were wearing their seatbelts. This technology has recently been extended under the On-Road Integrated Optimization and Navigation (ORION) program, which now provides real-time route optimization to help individual drivers determine the most efficient way to deliver and pick up packages. Under ORION, a reduction of just one mile per driver per day will save UPS up to $50 million per year when it is rolled out to its entire fleet by 2017. With over 10,000 routes optimized, UPS has so far saved more than 1.5 million gallons of fuel and has reduced carbon dioxide emissions by 14,000 metric tons.
But the opportunities presented by the IoT do not end with the efficiency gains enabled by better monitoring, control, and optimization.10 In The more things change, Michael Raynor and Mark Cotteleer point out that these information flows can be used to create new products, services, and business models.11 One interesting paradigm is discussed by William Eggers and Paul Macmillan under the rubric “billion to one.”12 The idea is that small bits of information emanating from a crowd of individuals can be amassed, analyzed, and used to return customized bits of content or services back to each individual. The transportation app Waze is one example of this model: The app enables drivers (“the billion”) to instantaneously report experiences (such as road hazards, police activity, and traffic accidents) that, when aggregated and analyzed, result in a continuously updated, real-time model of the driving environment. Individuals (“the one”) can use this information to plan and adjust routes and destinations in real time.13
“If you had asked social scientists even 20 years ago what powers they dreamed of having, they would have said, ‘It would be unbelievable if we could have this little tiny Black Hawk helicopter that could be microscopic, fly on top of you, and monitor where you are and who you’re talking to, what you’re buying, what you’re thinking...’”
The “billion to one” model of apps like Waze illustrates one aspect of the IoT that deserves much greater attention than it typically receives. Recall the definition of the IoT as simply the expansion of the Internet into the everyday world. A helpful way of thinking about the Internet is articulated by Thomas Malone, the founder of the MIT Collective Intelligence Center. Malone points out that the Internet enables various forms of “collective intelligence,” which he describes simply as groups of humans acting in ways that seem intelligent.14 As Malone points out, collective intelligence is nothing new: Teams, families, armies, and businesses have displayed varying degrees of collective intelligence throughout history. What is new is the appearance of new forms of collective intelligence that were impossible before the advent of the Internet. Wikipedia is a classic example: a highly refined—quite literally encyclopedic—product that is produced and continually updated by thousands of dispersed individuals operating with fairly minimal central control.15
Because the IoT is the expansion of the Internet into the everyday world, it is reasonable to anticipate new products and services centered around the harnessing of collective intelligence in the everyday world. The “billion to one” logic of Waze illustrates how the bi-directional information flows through mobile Internet devices enable multitudes (in this case drivers) to better self-organize and collectively act in a way that seems intelligent. Uber—and the entire “Uberified” sector of the economy—similarly exemplifies the idea. Indeed an “Uber for parking spaces” would be a natural complement to Waze. Waze currently enables the driver to select the best route to her destination. But once she arrives in that neighborhood she often confronts a wasteful and time-consuming hunt for parking. In the future, parking garages will be able to guide the driver to a specific parking spot. Like birds in a flock, IoT-connected cars and drivers can achieve a kind of collective intelligence.
Of course opportunities for IoT-fuelled innovation are not restricted to the private sector. Consider California’s multiyear drought, which many fear is a permanent feature of the environment. In response, California Governor Jerry Brown announced the first mandatory water restrictions in that state’s history.16 It is likely that the IoT will be part of the solution. A “device-centric” IoT approach would be to attach sensors to elements of the water distribution system to unlock efficiencies akin to those achieved by “smart” hydroponic and irrigation systems. This is yet another example of linking devices to networks to achieve greater monitoring, control, and optimization.
A complementary IoT-enabled idea would be a Waze-like harnessing of collective intelligence: Concerned citizens could install smartphone apps that would enable them to effortlessly report suspected inefficiencies or breakdowns in water distribution and usage to the appropriate authorities. A robust uptick in such signals tagged to a certain location could trigger an investigation. The idea is loosely analogous to the use of Google search data to more efficiently track flu outbreaks.17 Similar crowdsourcing ideas could be employed to flag potentially unsafe roads, buildings, and workplaces; unhygienic restaurants and food trucks; emerging risks in complex supply chains; hot-spots of crime, violence, and human rights abuses, and so on.18
A sign hanging on Albert Einstein’s door read, “Not everything that can be counted counts, and not everything that counts can be counted.” This motto also belongs on the doors of business and public sector leaders. It is a useful corrective to the twin fallacies, more common than ever in the age of big data, that something is important only to the extent that it can be quantified; and conversely that current modes of quantification capture what is important. The IoT is expanding the scope of what can be measured in society, just as the invention of the telescope opened new vistas to astronomers. Important traits of individuals, teams, organizations, and populations that have traditionally been hidden from view are coming to the fore thanks to IoT-collected data. This will give the emerging field of “people analytics” greater scope to improve on unaided judgment in making human resource and other decisions that involve employees and teams.
The premise that the IoT encompasses people has an important implication for the notion of “big data”: Most of the data collected by the IoT are in fact human behavioral data, often collected continually and at vast scales.19 These new sources of data enable new forms of analytics, such as people analytics, social network analysis, behavioral health and precision medicine, and behavioral finance. Sandy Pentland of MIT comments:
The power of big data is that it is information about people’s behavior instead of information about their beliefs. It’s about the behavior of customers, employees, and prospects for your new business. It’s not about the things you post on Facebook, and it’s not about your searches on Google, which is what most people think about, and it’s not data from internal company processes and RFIDs. This sort of big data comes from things like location data off of your cell phone or credit card; it’s the little data breadcrumbs that you leave behind you as you move around in the world.20
Using large volumes of behavioral data to better understand the workings of groups and networks is the domain of an emerging, interdisciplinary field known as computational social science (CSS). The medical professor and computational social scientist Nicholas Christakis summarizes the perspective that motivates much CSS research:
If you had asked social scientists even 20 years ago what powers they dreamed of having, they would have said, “It would be unbelievable if we could have this little tiny Black Hawk helicopter that could be microscopic, fly on top of you, and monitor where you are and who you’re talking to, what you’re buying, what you’re thinking, and if it could do this in real time, all the time, for millions of people, all at the same time. If we could collect all these data, that would be amazing.”21
Christakis’s point is that the IoT makes yesterday’s data-“science fiction” today’s data-science. A study by the Cornell sociologists Scott Golder and Michael Macy illustrates the possibilities for understanding people and populations in new ways. Golder and Macy analyzed millions of publicly available Twitter messages and were able to measure and quantify the degree to which people awaken in a good mood which subsequently deteriorates throughout the day; and the degree to which the happiness of populations is correlated with varying lengths of daylight.22 Of course these findings are intuitive. But the point is that such population-level traits and behaviors are now the subject of scientific scrutiny by means other than surveys. (Recall Pentland’s comment about measuring people’s behaviors rather than their beliefs.)
Similar methods are used in the business world. For example, analysis of social media data is routinely used to measure changes in public sentiment following entertainment events and advertising campaigns. Computational social science also lends itself to innovations in public health. Christakis and Fowler, for instance, have concluded that obesity is “contagious” in social networks: Otherwise similar people are more likely to become obese themselves if they enter a social situation in which they are surrounded by obese people. Similar effects have been posited for teen pregnancy and smoking. Such insights are useful in the design of environments to prompt healthier behaviors.23
Other promising applications of CSS methods in the business world are only beginning to attain prominence. Human resources is a domain that has been notoriously slow to adopt data analytic methods.24 Hiring, evaluation, promotion, and coaching decisions are still routinely made largely based on subjective judgments. Now that it is increasingly possible to collect “digital breadcrumbs” of workers as they go about their daily jobs, data-driven methods might be poised to make inroads against reliance on unaided judgment when making decisions about people and teams.25
While such monitoring understandably strikes many as intrusive or “creepy,” it is worth considering the shortcomings of the alternative. The use of unaided judgment to evaluate job candidates and employee performance is plagued with cognitive biases such as groupthink, halo effects, the tendency to favor people like oneself, and overgeneralizing from easy-to-remember experiences. The implication of the celebrated book Moneyball is that such biases are so endemic to judgment-based hiring decisions that they can lead to inefficient markets for talent. Consistent with this, symphony orchestras began hiring a greater proportion of women after auditions began to take place behind screens so that candidates were evaluated based only on the sound they made, not their appearance.26
One of Sandy Pentland’s projects illustrates a more modern approach. Working for a call center outsourcing firm that wished to improve its productivity, Pentland’s team set up electronic devices, called sociometers, designed to capture speech patterns of the call center workers as they handled their calls. The devices didn’t record the substance of the conversations, only such conversational patterns as tone and pitch. The team found that the degree to which a call center worker’s voice fluctuates (indicative of speaking in an inviting or singsong, rather than authoritative, way) was highly predictive of a call’s success or failure.27
Pentland’s sociometer therefore measures something important that has traditionally been acknowledged only incompletely and inconsistently: the impact of nonverbal communication styles on success. One can envision such technologies being used to coach and train teachers, public safety workers, sales and marketing professionals, and health care workers. Indeed, in his book Blink, Malcolm Gladwell reported a study correlating physicians’ speech patterns with malpractice suits. The study found that physicians who spoke with warmth were sued for malpractice less frequently than physicians who conveyed an air of authoritativeness. Independent of other risk factors, likeable physicians were found to be sued less often than unlikeable physicians.28
Non-verbal communication ability is an example of an individual-level trait that can be better discerned with IoT-generated digital breadcrumbs. It turns out that sociometric data are also predictive of such group-level traits as the collective intelligence of teams. They can capture whether leaders are domineering or inquiring, the degree to which team members speak and listen in equal measure, whether they use helpful body language and other forms of communication, and so on.29 As digital exhaust brings a kind of data-rich, scientific study of teams into the realm of practical possibility, it is possible that organizations will reconsider whether team-level performance—as opposed to individual-level performance—is even the best unit of analysis to focus on when making hiring decisions and evaluating performance.
Consider for example two hypothetical employees, Alan and Beth. On the surface they are comparable in terms of role, tenure, domain, and so on. But less obvious is the fact that their respective network positions are quite different. Alan is central to a tight-knit cluster of workers; Beth is not central to any particular group, but is practically the only employee with strong connections to people in both the IT and marketing departments. On the surface, Beth might actually appear to be the weaker employee: From the perspective of any particular member of any particular group, her contributions might seem modest or intangible. Yet from the perspective of the organization as a whole, Beth, by virtue of her ability to maintain substantive ties to two disparate groups, fills an important “structural hole” that would otherwise exist in the organization’s professional network.30 It is likely that, appearances to the contrary, the loss of Beth to the organization would be more disruptive than the loss of Alan. Typically such facts are at best recognized inconsistently and at worst simply hidden from view when evaluating employees and determining compensation.
Here again, it is reasonable to expect IoT-mediated behavioral data to provide new perspectives. For example, sociometric data, data about who is emailing whom, and other data sources can be combined to create organizational social network graphs.31 The above hypothetical Alan/Beth comparison—novel, objective, and valuable from the perspective of traditional talent management—becomes a straightforward calculation with the social network graph in hand. In this example, Beth’s “betweenness centrality” (a standard metric used in social network analysis) would be much higher than Alan’s. Various measures of connectedness and centrality could also be used to predict attrition and performance, identify isolated employees or groups that could be connected in strategic ways, and so on. While conceptually straightforward, the implications for people analytics are considerable. For example, network size and position are correlated with attrition risk, and are highly relevant to properly recognizing individuals’ contribution to organizational success. Furthermore, email digital exhaust is potentially relevant in the early detection of rogue employees and the prevention of corporate scandals.32
While our discussion has focused on the potential of people analytics for reinventing various HR functions, behavioral digital exhaust and computational social science methods will continue to leave their mark in a wide variety of domains. For example insurers now realize that personal credit data is highly predictive of who is likely to crash their car; supermarket club card data is predictive of such chronic disease states as diabetes. Social scientists are increasingly able to track the spread of behaviors such as diabetes and smoking through populations; marketers can better understand customers using fine-grained data about both individual behaviors and social network position. In each case, digital breadcrumbs captured by the IoT help us do a better job of counting what counts.
The Waze and Uber examples discussed above illustrate the new forms of collective intelligence that can emerge as a result of connecting people (drivers, passengers, taxi operators) to each other and to things (cars, parking spaces).33 The bi-directional information flows that we have called “billion to one” give the individual the real-time information he or she needs to make a more informed decision. Analogous to free markets governed by the price system, individual (micro) utility-maximizing behavior results in crowd-level (macro) coordination.
But “well-informed deliberation” and “utility-maximizing rational choice” do not describe how most people go about their daily lives. In Thinking, Fast and Slow, psychologist and Nobel laureate Daniel Kahneman discusses how human cognition can be described in terms of a kind of “dual mental process” theory. What he calls Type 1 thinking (“thinking fast”), is rapid, automatic, and prone to narratively coherent stories rather than logically coherent analyses of data. Many of the mental shortcuts (“heuristics”) that comprise Type 1 thinking are systematically biased. They are both terrible at statistics and are present-biased in the sense of favoring tangible short-term gains to long-term benefits. In contrast, Type 2 thinking (“thinking slow”) is the logical, utility-maximizing behavior common to homo economicus and Star Trek’s Mr. Spock. It seeks out all available evidence, evaluates said evidence using logic rather than storytelling, and foregoes short-term pleasures to achieve long-term goals.
The Waze example illustrates how the IoT can enable better Type 2 thinking: If an app displays a faster route to work, we are likely to change our plans and take it. Similarly, if it enables us to prepay and be guided to a specific parking spot with the click of a button, there is a good chance we will take the offer rather than search for parking. Waze is an example of augmented intelligence: Presenting someone with the right information will likely prompt an appropriate decision.
But alas, thanks to the ubiquity of Type 1 thinking, not all decisions are so easily improved. Suppose Carl is deciding between an extra doughnut at breakfast and going for a morning swim. And suppose an app on his new smart watch displays side-by-side the number of calories in a typical doughnut together with the estimated number of calories burned by swimming a mile. Will this augmented intelligence prompt Carl to ditch the doughnut and go for the swim? Maybe, but probably not.34 What is needed in this case is not so much augmented intelligence, but augmented behavior. Carl already knows well enough that swimming is the right choice even without the additional quantification offered by his app. Borrowing the influential term of Richard Thaler and Cass Sunstein, a behavioral nudge might prompt Carl to go “the last mile” from intention to action.
A core concept of the science of behavioral nudges is choice architecture: Try to convey information and design menus of choices in ways that go with, rather than against the grain of human psychology. A general theme of behavioral economics is that people’s choices are influenced not only by the available options, but also by the way those options are presented. For example, a diner in a restaurant might be more likely to order a $50 entrée if a $75 entrée is also on the menu: Compared with the more expensive option, the $50 entrée seems like good value. A clever restaurateur might therefore place a very expensive item on the menu as a “decoy,” primarily to serve as a psychological reference point. This simple example illustrates how a certain kind of design thinking can prompt behavior change.35
One of the most powerful findings of behavioral science is that people dislike violating social norms, and often act more on the basis of “social proof” (what others are doing) than stable sets of preferences. The energy company Opower famously uses this insight to prompt more efficient energy usage. Their letters to customers reflect the finding that informing people that they consume more than comparable neighbors is more effective than either economic or environmental pleas.36
Peer comparisons might be similarly effective in prompting California citizens to use less water. This could be a complementary water conservation approach to the connected-device and collective intelligence ideas described above.
In the realm of behavioral health, self-tracking device apps show not only how well people are doing against their goals but how well they are doing relative to their friends.
The automobile telematics data captured by insurance companies to more accurately price insurance policies could be used to give both periodic feedback reports containing personalized driving tips (augmented intelligence), as well as peer comparisons serving as behavioral nudges to prompt safer driving (augmented behavior). 37
The behavioral finance company HelloWallet creates various composite measures of individuals’ financial health and also makes peer comparisons to help guide people to take better control of their personal finances.
The DebMed Group Monitoring System is an electronic soap dispenser equipped with a computer chip that records how often health care workers in different hospital wards wash their hands. It compares these results to expectations based on World Health Organization standards and reports the comparisons back to the wards. Clever “social physics” and nudge thinking is built into the conception: Feedback reports are given at the group level rather than individual level. The insight is that no one wants to be “that guy” who lets down the team.38
Peer comparisons and clever uses of “social physics” hardly exhaust the many varieties of behavioral science thinking relevant to the design of IoT-connected devices. The variety of possibilities defies easy summary. For example, Beeminder connects self-tracking devices with apps that can be programmed with commitment contracts: By committing ahead of time to pay a fine for not complying with your goals, you make it more likely that you will follow through.39 Companies that offer their customers large numbers of choices (such as mutual fund companies or cable TV carriers) can consider creating data-driven recommendation engines or personalized menus of simplified choices to improve customer engagement by avoiding choice overload.40 Finally, health, wellness, and patient compliance is a promising application of digitally enabled behavioral nudge design. For example, Senscio Systems’ IbisCare blends applied behavioral economics, data analytics, and IoT technology to improve the medical compliance of senior citizens suffering from chronic diseases.41 In the same genre is David Rose’s IoT-connected pill bottle equipped with “GlowCaps” that nudge the patient with a flash of light when it’s time to take a pill.42
The implication of the IoT including people is that issues of privacy, transparency, data stewardship, and data ownership are paramount. Many of us enjoy the benefits of smarter homes, cars, and transportation networks. But few relish the thought of Internet companies being able to track our every move and make highly personal inferences and predictions based on the digital breadcrumbs we leave behind as we go about our daily activities. Similarly, customers have long allowed grocery store chains to electronically capture data about shopping behavior in return for personalized promotions and discounts. One could imagine such data also being used for behavioral health and precision medicine applications as well, but many are understandably uncomfortable with the prospect of data brokers or insurance companies being able to amass and analyze such data in ways that are hidden or constantly changing. And more fundamentally, many people simply do not want to live in a world in which their every action is monitored. A trade-off must be struck between the benefits, innovations, and analytic insights that IoT brings with the need to maintain societies that people want to live in.
Observers such as Sandy Pentland and Richard Thaler suggest frameworks for data privacy and ownership that suggest a way beyond this impasse. Pentland calls for a “new deal on data,” which would involve giving people ownership of their data. In Pentland’s scheme, people would possess their data, have full control over how it is used, have a right to distribute the data as they see fit. At the same time, Pentland suggests policies that would encourage individuals to share anonymized data for computational social science applications that promote the common good.43
Richard Thaler, the University of Chicago economist and father of behavioral finance, makes consistent suggestions.44 He says that while issues of data privacy, veracity, and security are important, they do not address the larger issue that people should also be able to access the data collected about them. Thaler proposes the guiding principle that, “if a business collects data on consumers electronically, it should provide them with a version of that data that is easy to download and export to another website.” Intuitively: The individual has lent the company (bank, insurer, mobile phone carrier, Internet service) her data; so she should be able to request a copy for her own use.
Thaler’s ideas are being put into practice. For example the UK government has been encouraging banks, energy companies, and mobile phone carriers to comply with a program called “midata” that was modelled on Thaler’s framework. The government recently decided against drafting new regulations requiring compliance after finding that companies have been voluntarily complying reasonably well.45 In the United States, the federal government’s “blue button” program enables individuals to download their medical records in a standard format to share with medical providers whom they trust.46
If widely adopted, a framework such as Thaler’s could have the dual effect of defusing some of the distrust currently surrounding industrial and governmental efforts to collect and mine data about people while also spurring the new economies dedicated to helping people make the most of their data. “So let’s level the playing field,” Thaler writes. “Why not give you, the consumer, something in return for participating? Require that the supermarket make your purchase history available to you. Before you know it, a smart entrepreneur is likely to devise an app that will direct you to cheap and healthy alternatives that can slim your tummy and fatten your wallet. Apps could not only save money; they could also warn shoppers with allergies, for example, that they are buying foods that contain ingredients to which they are sensitive, like nuts or gluten.”
Such ideas illustrate how innovative uses of data from IoT-connected devices, infused with the right kind of behavioral design thinking, can enable traditionally product-centric industries such as insurance, utilities, and banking to modify their business models in ways that make them more customer-centric and less commoditized. More generally, the combination of data science, digital technology, and behavioral design thinking enables a distinctly modern way of “doing well by doing good.” Used imaginatively, the digital breadcrumbs pulsing through the IoT can be a force for good, helping us stick to our goals, drive more safely, make better medical, diet, exercise, and financial decisions, and use resources more sparingly.
It is fitting to close with another Tim O’Reilly remark: “When you think about the Internet of Things, you should be thinking about the complex system of interaction between humans and things, and asking yourself how sensors, cloud intelligence, and actuators make it possible to do things differently.”47
As O’Reilly suggests, the observation that the IoT includes people implies opportunities for IoT innovation that go well beyond the (already considerable) promise of smarter devices and smarter networks devices. First, the IoT enables new products and services premised around the creation of new forms of collective intelligence; and using aggregated information from “the billion” to provide useful products and services to “the one.”
Second, IoT-mediated behavioral digital breadcrumbs, analyzed with the emerging tools of computational social science, will help us better measure—and therefore manage—hitherto hidden traits of individuals, teams, organizations, and populations. Stay tuned for further innovations from such fields as people (HR) analytics, risk management, population health, and elsewhere.
Finally, we suggest that behavioral design thinking is indispensable when envisioning—and building—the 21st century world of complex systems of interactions between people and things that O’Reilly describes. This world must be designed for the minds of humans, not of Vulcans. The point of the IoT should not be to make smarter machines, but to make people smarter. It’s about us.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.The IoT’s true value lies in its disruptive potential for reimagining business processes and, ultimately, rewiring business, government, and society. Realizing that potential means shifting IoT applications’ strategic focus toward not just sensing, but doing.
Increasingly, forward-thinking organizations are focusing their Internet of Things (IoT) initiatives less on underlying sensors, devices, and “smart” things and more on developing bold approaches for managing data, leveraging “brownfield” IoT infrastructure, and developing new business models. Meanwhile, others are developing human-impact IoT use cases for boosting food production, cutting carbon emissions, and transforming health services. What impact will IoT have on your business and on the people around you? Rapid prototyping can help you find out.
Explore View Tech Trends 2016 Learn more about Deloitte Technology Consulting Create and download a custom PDF of the 2016 report
Like a wildfire racing across a dry prairie, the Internet of Things (IoT) is expanding rapidly and relentlessly. Vehicles, machine tools, street lights, wearables, wind turbines, and a seemingly infinite number of other devices are being embedded with software, sensors, and connectivity at a breakneck pace. Gartner, Inc. forecasts that 6.4 billion connected things will be in use worldwide in 2016, up 30 percent from 2015, and that the number will reach 20.8 billion by 2020. In 2016, 5.5 million new things will get connected to network infrastructure each day.1
As IoT grows, so do the volumes of data it generates. By some estimates, connected devices will generate 507.5 zettabytes (ZB) of data per year (42.3 ZB per month) by 2019, up from 134.5 ZB per year (11.2 ZB per month) in 2014. (A zettabyte is 1 trillion gigabytes). Globally, the data created by IoT devices in 2019 will be 269 times greater than the data being transmitted to data centers from end-user devices and 49 times higher than total data center traffic.2
Even as businesses, government agencies, and other pioneering organizations at the vanguard of IoT take initial steps to implement IoT’s component parts—sensors, devices, software, connectivity—they run the risk of being overwhelmed by the sheer magnitude of the digital data generated by connected devices. Many will focus narrowly on passive monitoring of operational areas that have been historically “off the grid” or visible only through aggregated, batch-driven glimpses. To fully explore IoT’s potential, companies should think big, start small, and then scale fast.
Many enterprises already have unused IoT infrastructure built into their manufacturing machinery and IT software. We call these dormant components “brownfields”: Like roots, bulbs, and tubers in the soil, they need a good “rain” and a bit of tending to begin to thrive. Activating and connecting these brownfield components may help companies leapfrog some implementation steps and give their IoT initiatives a needed boost. In contrast, “greenfields”—enterprise environments with no preexisting IoT infrastructure—require basic seeding and a lot of tending over time to yield a new crop.
The value that IoT brings lies in the information it creates. It has powerful potential for boosting analytics efforts. Strategically deployed, analytics can help organizations translate IoT’s digital data into meaningful insights that can be used to develop new products, offerings, and business models. IoT can provide a line of sight into the world outside company walls, and help strategists and decision makers understand their customers, products, and markets more clearly. And IoT can drive so much more—including opportunities to integrate and automate business processes in ways never before possible.
Often overlooked is IoT’s potential for impacting human lives on a grand scale. For example, in a world where hunger persists, “smart farming” techniques use sensor data focused on weather, soil conditions, and pest control to help farmers boost crop yields. Meteorologists are leveraging hazard mapping and remote sensing to predict natural disasters farther in advance and with greater accuracy. The health care sector is actively exploring ways in which wearables might help improve the lives of the elderly, the chronically ill, and others. The list goes on and will continue to grow. We are only beginning to glimpse the enormity of IoT’s potential for making lives better.3
With so few detailed use cases, the sheer number of IoT possibilities makes it difficult to scope initiatives properly and achieve momentum. Many are finding that IoT cannot be the Internet of everything. As such, organizations are increasingly approaching IoT as the Internet of some things, purposefully bounded for deliberate intent and outcomes, and focused on specific, actionable business processes, functions, and domains.
The time has come for organizations to think more boldly about IoT’s possibilities and about the strategies that can help them realize IoT’s full disruptive potential. To date, many IoT initiatives have focused primarily on sensing—deploying and arranging the hardware, software, and devices to collect and transmit data. These preliminary steps taken to refine IoT approaches and tactics are just the beginning. The focus must shift from sensing to doing. How do inputs from sensors drive closed-loop adjustments and innovation to back-, middle-, and front-office business processes? Where can those processes become fully automated, and where can the core be reconfigured using feedback from connected devices and instrumented operations? What future IoT devices might open up new markets? To yield value, analytics-driven insights must ultimately boost the bottom line.
One strategy involves harnessing the information created by the IoT ecosystem to augment worker capabilities, a process modeled in the Information Value Loop. When built to enhance an individual’s knowledge and natural abilities and deployed seamlessly at the point of business impact, IoT, in tandem with advanced analytics, can help amplify human intelligence for more effective decision-making. For example, the ability to monitor the vital signs of elderly patients remotely and in real time will empower medical personnel to make more accurate care decisions more quickly. Even more profound, automated drug delivery systems may be triggered to respond to complicated signals culled from several parts of the care network.
Likewise, companies may harness data-driven insights to augment or amplify operational activity in the form of transforming business processes, reimagining core systems and capabilities, and automating controls. Eventually, robotic process automation and advanced robotics will monitor events, aggregate sensor data from numerous sources, and use artificial intelligence capabilities to determine which course of action they can take to deliver the most desirable outcome.4
Take manufacturing, for example. At a Siemens facility in Amberg, Germany, machines and computers handle roughly 75 percent of the value chain autonomously, with some 1,000 automation controllers in operation throughout the production line. Each part being manufactured has its own product code, which lets machines know its production requirements and which steps to take next. All processes are optimized for IT control, which keeps failure rates to a minimum. In this facility, employees essentially oversee production and technology assets, handling any unexpected incidents that may arise.5
As organizations work to integrate vast, disparate networks of connected devices into core systems and processes, there will likely be new security and privacy concerns to address. These concerns could be particularly acute in industries like health care—which may be aggregating, analyzing, and storing highly personal data gleaned from sensors worn by patients—or in manufacturing—where risks may increase as heavy industrial equipment or infrastructure facilities become increasingly connected. More data, and more sensitive data, available across a broad network means that risks are higher and that data breaches could pose significant dangers to individuals and enterprises alike.
With IoT, data security risks will very likely go beyond embarrassing privacy leaks to, potentially, the hacking of important public systems. Organizations will have to determine what information is appropriate for IoT enablement, what potential risks the assets and information may represent, and how they can ensure that solutions are secure, vigilant, and resilient.6
Similarly, as companies add additional inputs to their IT and IoT ecosystems, they will be challenged to create new rules that govern how action proceeds and data is shared. Opening up IoT ecosystems to external parties via APIs will give rise to even more risk-related considerations, particularly around security, privacy, and regulatory compliance.
Acting on the information created by the IoT—putting intelligent nodes and derived insights to work—represents the final, and most important, part of the IoT puzzle. Options for achieving this vary. Centralized efforts involve creating orchestration or process management engines to automate sensing, decisioning, and response across a network. Likewise, a decentralized approach typically focuses on automation: Rules engines would be embedded at end points, which would allow individual nodes to take action. In still other scenarios, IoT applications or visualizations could empower human counterparts to act differently.
Ultimately, the machine age may be upon us—decoupling our awareness of the world from the need for a human being to consciously observe and record what is happening. But machine automation only sets the stage; real impact, business or civic, will come from bringing together the resulting data and relevant sensors, things, and people to allow lives to be lived better, work to be done differently, and the rules of competition to be rewired.
With this in mind, organizations across sectors and geographies continue to pursue IoT strategies, driven by the potential for new insights and opportunities. By thinking more boldly about these opportunities and the impact they could have on innovation agendas, customer engagement, and competitiveness (both short- and long-term), companies will likely be able to elevate their IoT strategies beyond sensing to a more potentially beneficial stage of doing.
At a remote mining region of western Australia, the IoT’s lofty potential meets the ground in a fleet of Caterpillar mining trucks—each boasting a 240-ton payload—that operate autonomously, 24 hours a day. These giant, driverless machines are outfitted with a variety of sensors that transmit information on oil pressure, filters, and other truck components via wireless connections (such as satellite, cellular, and others) back to Caterpillar headquarters in Peoria, IL, where an advisor monitors the equipment’s vital signs and can, when needed, make maintenance recommendations to the fleet’s owner.7
Though Caterpillar has been embedding sensors in its products for decades, only in the last few years has the global construction machinery and heavy equipment manufacturer begun exploring their potential application within the context of IoT. Today, IoT—or as they call it at Caterpillar, the “Internet of Big Things”—is a major strategic and technological focus, with the company exploring ways to mine IoT data that can then be used to develop predictive diagnostics tools, design products, and improve product performance.
For example, when compiled over time and analyzed, data generated by sensors embedded in construction-site machinery may be able to help engineers design heavy equipment that can accomplish more work with fewer passes. Fewer passes translates to reduced idle time, less operator fatigue, and lower fuel consumption. Ultimately, operating efficiently can help owners of Caterpillar equipment better serve their own customers.
Importantly, this information—combined with Caterpillar’s domain knowledge about heavy equipment and analytics—may help the company more accurately predict how specific pieces of equipment will perform in different environments and on specific types of jobs. To this end, Caterpillar recently announced it had entered into a technology agreement with analytics vendor Uptake to develop a predictive diagnostics platform to help customers monitor and optimize the performance of their fleets.8 Looking forward, Caterpillar expects IoT to help redefine business processes, drive better engagement with its customers, and evolve its products, services, and offerings.
Some companies in the health care industry—including health plans, providers, medical device manufacturers, and software vendors—are testing the IoT waters with a number of sensor-driven big data initiatives that could transform the way patients and their providers manage acute health conditions.
One leading health care delivery system is currently developing a suite of mobile applications to track, record, and analyze biometric data generated by Bluetooth-enabled sensing devices worn by patients. These apps, each configured to monitor a specific medical condition, will share a common digital platform and feature APIs to encourage external development. Once deployed, they will be able to analyze sensor data and pair them with electronic medical records and other clinical information to help caregivers make faster—and more informed—decisions for patients. For example, a diabetic patient’s glucose readings would be streamed from a monitoring device to a mobile app on his or her phone or tablet, and then on to an integrated big data repository. Care coordinators would be alerted to unusual changes in the patient’s glucose levels so that they can take appropriate action, such as bringing the patient into the hospital for closer examination or adjusting his or her medications.
The organization piloted its diabetes monitoring application with almost 40,000 diabetic patients, demonstrating the viability of the platform. Next on the agenda: Expanding adoption of the diabetes pilot and extending the platform to support other conditions such as congestive heart failure, chronic obstructive pulmonary disease (COPD), and high blood pressure, among others.
It’s morning in Amsterdam. An employee leaves her desk, walking casually toward a break room in the office building where she works. As she approaches, a custom app on her smartphone engages sensors embedded in a coffee machine, which immediately begins dispensing the employee’s preferred blend, complete with the add-ins she desires. When the employee arrives at the break room, her custom brew is waiting.
Welcome to life in “The Edge,” a futuristic office structure widely known as “the world’s smartest building.”9 Completed in 2014, The Edge—which is home to Deloitte Netherlands—is a showplace for leading-edge deployments of green architecture and advanced technology, including IoT applications. The innovative, connected lighting panels do more than sip minute amounts of voltage—they contain some 28,000 sensors that detect motion, light, temperature, humidity, and even carbon dioxide levels. It’s these sensors, providing real-time data, that make The Edge occupant-friendly.
The sensors allow facility managers to assess how and when certain parts of the building are being used. “In our building, IT and facilities management are a combined function,” explains Tim Sluiter, property manager, IT and Workplace Services, Deloitte Netherlands. In the short term, collected information can be used to determine where cleaning is and is not necessary on a given evening. Long term, emerging patterns showing light use in certain locales on certain days can lead to rooms or even entire floors being closed off to save energy.
IoT’s reach within this building extends far beyond lighting sensors. When employees approach The Edge’s high-tech garage, sensors identify their vehicles and then point them to available parking spots. Throughout the garage, sensor-equipped LED lights brighten and dim as drivers arrive and leave.
And that miraculous coffee app? It doubles as a digital office administrator that can assign daily workspaces that best fit users’ preferences and allows them to control the brightness of the lighting above their work surfaces and adjust the climate of their particular areas. It can direct people throughout the building—reading a meeting location from one’s online calendar, for example, and suggesting a route to get there. Employees can even use the app to track their progress in the on-site gym, where some of the fitness equipment actually feeds generated wattage into the building’s power grid.
Sluiter stresses that personal data generated by sensors and the app cannot be accessed by managers or anyone else. Privacy laws ensure that nobody can track a person’s whereabouts, monitor how many meetings he or she has missed, or see what times he or she is using the garage. “This building offers the technology to do certain things that would make tenants’ lives even easier,” Sluiter says. “But at the same time, it’s extremely important to protect people’s privacy and conform to the law.”
Those minimal barriers aren’t hindering The Edge’s reputation. “Our aim was to make The Edge the best place to work,” says Erik Ubels, director of IT and Workplace Services, Deloitte Netherlands. “Our meeting areas are filling up because every client and employee wants to experience this building. It’s not too small yet, but the economy is growing and the building is getting crowded. It’s possible we made it too popular.”10
Sandy Lobenstein Vice president, connected vehicle technology and product planning, Toyota Motor Sales U.S.A., Inc.
At Toyota, we are all about mobility. I’m not talking just about car ownership. Mobility also includes public transportation, ridesharing, hoverboards, walking—anything that can get people from place A to place B more efficiently and safely. Mobility is truly multi-modal.
Toyota sees the IoT as an enabler of mobility, and we are moving very quickly to embrace its potential. Big data generated by sensors located throughout our cars will help engineers develop automobiles that think for themselves. Likewise, Dr. Gill Pratt, the chief executive officer of the Toyota Research Institute (TRI), and other researchers at TRI, will leverage IoT data to advance the science of intelligent cars as we move into the future mobility of autonomous vehicles. Progress in these areas will likely deliver autonomous connected cars that are reliable, safe, and fun to drive when you want to. The benefits that these innovations may eventually provide to everyday drivers, drivers with special needs, and to seniors could be life-enabling.
Toyota is no stranger to connected vehicle technologies; Lexus began offering connected vehicles in 2001. Today, all Lexus vehicles are connected, which enables services like Destination Assist, which links drivers to live agents who can provide directions for getting from point A to point B. Lexus also offers sensor-driven “car health” reports on current tire pressure, oil levels, and maintenance needs.
These IoT applications are just the beginning. Cars are mechanical products built with mechanical processes. Sensors are so small that we can place them virtually everywhere on cars. And what if you extend the same sensor technologies that monitor tires and brakes to the machines used to build vehicles on the manufacturing floor? These sensors could alert production leaders that there is a problem at a particular station, and that the parts manufactured at this station within a specific time frame will have to be rebuilt.
As for new offerings, it’s sometimes hard for companies to wrap their heads around the value of data. For example, early on, everyone assumed consumers wanted apps in cars. Very quickly, the auto industry realized that what customers actually wanted was for the apps on their phones to work in their cars. Across industries and sectors, strategists, designers, and decision makers typically believe that current approaches and systems are just fine. It takes vision—and a considerable amount of courage—to break with the way things have been done for the last 100 years and embrace some exotic technology that promises to deliver new opportunities.
But in this era of historic technological innovation, all companies must work aggressively to reinvent themselves by embracing new opportunities and compelling visions of the future. This is exactly what Toyota is doing with IoT and mobility.
I’m a car guy. In high school, I loved working under the hood of my car, which was the embodiment of leading-edge technology at that point in my life. For the last 15 years, we amateur mechanics have been distracted by other mechanical wonders—the kind everyone now spends their days staring at and speaking into. That’s about to change. Connectivity and cool new services are going to make cars come alive. All those people who’ve developed relationships with their smartphones are about to fall in love with cars all over again.
The IoT connects critical infrastructure that has been previously unconnected. As organizations begin harnessing these connections to create value, they may also add functionality to IoT networks that will make it possible to take control of devices and infrastructure remotely, and to automate monitoring and decision-making within certain parameters based on sensory data.
Make no mistake: As companies put IoT to work, the smart, connected objects they deploy offer tremendous opportunities for value creation and capture. Those same objects, however, can also introduce risks—many of them entirely new—that demand new strategies for value protection.
For example, every new device introduced in an IoT ecosystem adds a new attack surface or opportunity for malicious attack, thus adding additional threat vectors to a list that already includes protecting devices, data, and users. Likewise, identity spoofing—an unauthorized source gaining access to a device using the correct credentials—may present problems. And even if devices aren’t directly compromised but experience a hardware failure or a bug in the code, they should be able to fail in a safe way that doesn’t create vulnerabilities.
Moreover, the ecosystem structures that organizations often rightfully deploy can give rise to vulnerabilities. For example, IoT applications typically depend on the closely coordinated actions of multiple players, from vendors along the supply chain to clients, transport agencies, the showroom, and end-use customers. Vulnerabilities exist within each node and handoff seam between sensors, devices, or players. It should not be assumed that partners—much less customers—have robust mechanisms in place to maintain data confidentiality and guard against breaches.
In the face of these and other challenges, companies can take several steps to safeguard their ecosystems:11
Work to define standards for interoperability: Internally, define data and service standards to guide consistent rollout within your organization’s boundaries. Also consider getting involved with consortia like the IIC 12 to develop broader standards and ease connectivity and communication.
Internally, define data and service standards to guide consistent rollout within your organization’s boundaries. Also consider getting involved with consortia like the IIC to develop broader standards and ease connectivity and communication. Refactor with care: Retrofitting or extending functionality of old systems may be exactly what your IoT strategy needs. But when doing so, understand that there may be potential security, performance, and reliability implications, especially when pushing legacy assets into scenarios for which they weren’t designed. Whenever possible, use purpose-built components for the refactoring, engineered specifically for the use case.
Retrofitting or extending functionality of old systems may be exactly what your IoT strategy needs. But when doing so, understand that there may be potential security, performance, and reliability implications, especially when pushing legacy assets into scenarios for which they weren’t designed. Whenever possible, use purpose-built components for the refactoring, engineered specifically for the use case. Develop clear responsibilities for the players in your ecosystem: Rather than sharing responsibility across a diffuse ecosystem, players should know where their responsibilities begin and end, and what they are charged with protecting. Assessing potential risks at each point—and making sure stakeholders are aware of those risks—can help make a solution more secure.
Rather than sharing responsibility across a diffuse ecosystem, players should know where their responsibilities begin and end, and what they are charged with protecting. Assessing potential risks at each point—and making sure stakeholders are aware of those risks—can help make a solution more secure. Get to know your data: The quantity and variety of data collected via IoT—and the fact that so much of that data is now held by third parties—can make it difficult for companies to know if their data has been breached. When dealing with tremendous volumes of IoT data, small, virtually unnoticeable thefts can add up over time. Companies can address this threat by developing a deep understanding of the data they possess and combining this knowledge with analytics to measure against a set “normal.” By establishing a baseline of access and usage, IT leaders can more readily and reliably identify possible abnormalities to investigate further.
As IoT gains momentum, many organizations find themselves paralyzed by the sheer volume of vendor promises, the number of novelty examples being imported from the consumer realm, and by an overarching conviction that something real and important—yet frustratingly out of focus—is waiting to be tapped into.
To maximize value, reduce risk, and learn fast, those just beginning their IoT journey should follow three innovation principles: “Think big, start small, scale fast”:
Ideate: Analyze the big ideas and use cases in your industry. Move beyond sensing to doing. Also, explore opportunities for achieving greater consumer and human impact with IoT.
Take stock: Before investing in new equipment, conduct an inventory of all the sensors and connected devices already on your balance sheet. Find your brownfields. How many sit dormant—either deactivated or pumping out potentially valuable information into the existential equivalent of /dev/null?
Before investing in new equipment, conduct an inventory of all the sensors and connected devices already on your balance sheet. Find your brownfields. How many sit dormant—either deactivated or pumping out potentially valuable information into the existential equivalent of /dev/null? Get to know the data you already have: Many organizations have troves of raw data they’ve never leveraged. By working with data scientists to analyze these assets before embarking on IoT initiatives, companies can better understand their data’s current value. Likewise, they may also be able to enhance this value by selectively installing sensors to plug data gaps.
Many organizations have troves of raw data they’ve never leveraged. By working with data scientists to analyze these assets before embarking on IoT initiatives, companies can better understand their data’s current value. Likewise, they may also be able to enhance this value by selectively installing sensors to plug data gaps. Pilot your ecosystem: Pick proven IoT partners to quickly pilot ideas, try new things, and learn quickly from failures. Many aspects of IoT cannot be tested or proven in laboratories but only with real enterprise users and outside customers.
Pick proven IoT partners to quickly pilot ideas, try new things, and learn quickly from failures. Many aspects of IoT cannot be tested or proven in laboratories but only with real enterprise users and outside customers. Get into the weeds: At some point, IoT initiatives require low-level expertise around the underlying sensors, connectivity, embedded components, and ambient services required to drive orchestration, signal detection, and distributed rules. The difference between a provocative “proof of concept” and a fully baked offering lies in a host of nuanced details: understanding the precision and variability of underlying sensing capabilities; MEMS sourcing, pricing, and installation; and wireless or cellular characteristics, among others. To fill knowledge gaps in the short term, some organizations leverage talent and skill sets from other parts of the IT ecosystem.
Adopt an agile approach: Go to market and iterate often. One benefit of all the investment being made in and around IoT is that the underlying technology is constantly improving as existing products evolve and new categories emerge. As you explore possible IoT strategies and use cases, consider using lightweight prototypes and rapid experimentation. This way, you can factor in feasibility concerns, but you won’t be saddled—at least for the time being—with the burden of “enterprise” constraints. As compelling ideas gain momentum, you can then shape your solution, refine the business case for it, and explore it at scale.
Go to market and iterate often. One benefit of all the investment being made in and around IoT is that the underlying technology is constantly improving as existing products evolve and new categories emerge. As you explore possible IoT strategies and use cases, consider using lightweight prototypes and rapid experimentation. This way, you can factor in feasibility concerns, but you won’t be saddled—at least for the time being—with the burden of “enterprise” constraints. As compelling ideas gain momentum, you can then shape your solution, refine the business case for it, and explore it at scale. Enhance your talent model: Just as aircraft manufacturers hire aeronautical engineers to design products and software vendors employ legions of coders with specific skills, so too must companies pursuing IoT strategies hire the right people for the job. Does your IT organization currently include talent with the hardware expertise needed to operate and maintain thousands of connected devices? Most don’t. Before pursuing an IoT strategy, consider enhancing your talent model not only to bring in new skills from the outside, but also to reskill current employees.
Just as aircraft manufacturers hire aeronautical engineers to design products and software vendors employ legions of coders with specific skills, so too must companies pursuing IoT strategies hire the right people for the job. Does your IT organization currently include talent with the hardware expertise needed to operate and maintain thousands of connected devices? Most don’t. Before pursuing an IoT strategy, consider enhancing your talent model not only to bring in new skills from the outside, but also to reskill current employees. Bring it home: Remotely deployed assets and equipment often have starring roles in IoT use cases. But call centers, manufacturing floors, and corporate offices also offer considerable IoT potential. Consider how creating an “intranet of things” might lead to improved workplace conditions and enhanced comfort and safety at individual work stations. Moreover, how might reimagining employee experiences in this way help your company attract new employees and retain existing ones?
The Internet of Things holds profound potential. It is a futuristic fantasy made real—the connected home, connected workplace, and connected government come to life. The sheer scope of IoT carries countless implications for business, both finite and abstract. To sidestep such distractions, focus on solving real business problems by creating bounded business scenarios with deliberate, measurable value. For example, how can you use IoT to get closer to customers or increase efficiency in your manufacturing operations or supply chain? Look for hidden value in your brownfields. Move from strategy to prototyping as quickly as possible. Only real data, actual users, and sensors that respond with actions can demonstrate the remarkable value proposition of IoT.
Deloitte Consulting LLP’s Technology Consulting practice is dedicated to helping our clients build tomorrow by solving today’s complex business problems involving strategy, procurement, design, delivery, and assurance of technology solutions. Our service areas include analytics and information management, delivery, cyber risk services, and technical strategy and architecture, as well as the spectrum of digital strategy, design, and development services offered by Deloitte Digital. Learn more about our Technology Consulting practice on www.deloitte.com.An article by Michelle Canaan, insurance research leader, Deloitte Center for Financial Services, Deloitte Services LP, and Prachi Ashani, insurance senior analyst, Deloitte Center for Financial Services
Global financing of InsurTechs continued to surge with a record $5 billion invested during 2019, which is only five percent shy of the prior two years combined. However, while $19.2 billion has poured into the sector over the past decade, investments have almost exclusively been devoted to the property-casualty side of the business...Continue readingIn the simplest form, IoT technology takes inputs from the physical world, uses digital technologies to derive insights from those inputs, and then makes outputs available for use back in the world. In linking the physical and digital world, the IoT has another impact as well. Traditional physical products create value for customers only by virtue of their performance: A standard lightbulb is valuable based on its brightness, efficiency, and lifespan. With connected objects, information also becomes a key determinant of value: A smart light bulb is valuable not just because it can brighten a room, but because it can enable automation, scheduling, remote controlling, and other abilities.5
Yet, due to possible unfamiliarity with the potential market opportunities, many leaders are taking a wait-and-see attitude toward IoT technology. A recent MIT and Deloitte survey of IT executives revealed that most of their companies intend to leverage IoT-generated data to pursue only small-scope applications aimed at efficiency improvement.6 While it is certainly prudent to start small and scale applications as they succeed, thinking big is also a benefit. And for businesses that need to rationalize initial tech investments, using IoT technology to generate revenue may be the key.
Turning IoT data into money is not necessarily a straightforward process, however: It requires knowledge of customers, and the governance capabilities to take advantage of that knowledge, to be able to offer the right item to the right customer in the right way. To develop these data governance capabilities, IoT players can learn from an industry in which information has long been a primary source of value—software—and explore the monetization drivers that leading firms are leveraging.
Selling technology in the software world has evolved from selling packaged software to selling services, building relationships focused on driving value to customers, and meeting customers’ expectations for flexibility in consumption.7 And from a monetization perspective, this means that new business models are expanding and becoming the norm. For instance, some content management services leverage the “freemium” model: A free service includes a personal account with limited storage and file size, while the premium service allows more storage, bigger file size, more users, enhanced collaboration, etc.8 Other models in the software sector employ pay-per-use (also known as utility) models, monthly subscription plans, and outcome-based models focused on the business value that the product or service delivers.9
All of these techniques can be grouped into three key monetization drivers—usage intelligence, feature-based packaging, and flexible consumption—that form the foundational pillars of top software firms’ monetization strategy (see Figure 1: What drives software monetization?). Executives in other industries can look to these pillars in developing strategies of their own. After all, many companies have little direct experience deriving revenue from customer-generated data, and effectively packaging and pricing products and services can prove challenging.10Sean, a partner at Deloitte & Touche LLP, is the Global Cyber Cloud leader and Cyber IoT leader for the Cyber Risk Services practice of Deloitte Risk & Financial Advisory. He delivers solutions to help organizations address their most pressing and pervasive cyber security challenges for Enterprise, Cloud and IoT environments including Cyber Risk, Cyber threat intelligence, Cyber war gaming, IoT and operational technology (OT) security, identity management, privacy and data protection, and business resilience focused. He has over 35 years of consulting experience and serves some of Deloitte’s largest clients.
Sean is a proven leader with diversified, in-depth experience in consulting and has demonstrated an ability to consistently achieve desired results and provide exceptional value to clients across a variety of business problems, technologies and industries. He specializes in application security; secure systems development; information technology risk management; governance, risk and compliance; and resiliency. His industry experience spans across automotive; consumer products; energy & resources; financial services; health care; life sciences; manufacturing; and media, entertainment & sports.
Sean is passionate about working with the community. He currently serves on the board of directors of YMCA of Orange County and is the chairman of CSUF College of Engineering & Computer Science College Leadership Council.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.August 22, 2018 From ice-cream manufacture to steel making, automated control is a fundamental part of industrial processes. Control technology has been around since the industrial revolution, when centrifugal governors were used to regulate the speed of steam engines. But it was the advent of electrical, electronic, and computerized control technologies over the course of the 20th century that defined the field as we know it today. During that time, three major generations of control technology have evolved. Today, the emergence of an entirely new approach could transform the way companies control their assets.
The first modern, flexible control technology was the programmable logic controller (PLC). Working on the proportional-integral-differential (PID) principle, a basic PLC monitors a single value, say the temperature of a freezer or a furnace, and compare that to a target setting for the machine. Depending on magnitude of the error, its duration and its rate of change, the PID controller output steers the machine, for example by adjusting a valve or changing the power flowing to a heating element or motor.
The earliest PLCs were extraordinarily simple devices by modern standards, but they could do some remarkable things. The PID control principle meant control engineers didn’t need to fully understand the complexities of the process under their care; with just three parameters to adjust, they could often achieve good performance with a little careful tuning. Using more elaborate configurations, such as cascaded control systems in which one PID controller generates the target value for another to meet, these systems could run quite complex processes. They are still widely used today.
The second major generation of control system emerged with the development of personal-computer technology in the 1980s and 1990s. The greater speed and power of these machines allowed engineers to build control systems where numerous inputs and outputs were managed by a single computer, and to connect multiple machines together into networks. These distributed control system (DCS) designs provided a host of benefits for operators, not least the availability of clearer, easier user interfaces and the power to change setpoints from a distance. Under the hood, however, DCS systems ran on the same basic principles as their PLC predecessors.
Toward the end of the 20th century, the availability of more powerful computers led a small number of the most demanding users to take a third step in control technology. These users were typically in industries running operations of huge scale and complexity, such as oil refineries or steel plants. For such applications, even small relative improvements in control-system performance could be worth millions of dollars in additional output, and owners were prepared to make big investments to achieve them.
The approach they adopted replaced the simple principles of PID control with complex and sophisticated mathematical models. By combining theoretical physicochemical models with carefully selected and calibrated sensor data, these advanced process control (APC) systems attempt to determine the current state of the process and decide how it should be adjusted to deliver the desired operating conditions. APC systems work very well, but their high cost means that their use is still limited to a minority of applications, in industries where plants are big enough and similar enough to pay back the enormous development effort required to implement them.
Today, a fourth generation of control systems is emerging, one the promises to exceed the performance of the APC approach at a fraction of its cost and complexity. This new approach uses advanced analytics (AA) or artificial-intelligence technologies (AI), such as so-called machine learning or even deep-learning approaches using artificial neural networks and equivalent methods.
These AA/AI systems work in a fundamentally different way from previous APC technologies. When IBM’s Deep Blue computer chess program beat grand master Gary Kasparov in 1997, it relied on thousands of explicit rules programmed by its designers, much like today’s industrial APC systems. 18 years later, when Google Deep Mind’s Alpha Go program defeated professional go player Lee Sedol, it used no such rules. Instead, the program developed its own strategy by analyzing past matches and playing thousands of simulated games. Alpha Go Zero, a more recent iteration of the company’s program, trained itself to beat its predecessor in three days, purely by playing games against itself.
It is now becoming possible to apply the same approach in industrial control systems, using an AI system that is “trained” using historical process data1. Many facilities have years of detailed records on operating conditions, process settings and the resulting performance. And once they are installed and operating, these systems can on learning, gradually improving their own performance over time.
AA/AI-based control works exceptionally well. Costly APC systems typically provide overall improvements in the order of two or three percent. AI systems can increase the performance of existing APC systems by an additional one or two percent and have boosted non-APC controlled systems by over 30 percent.
AA/AI-based control doesn’t require system designers to model every detail of their process and build complex theoretical models—it learns those intricacies for itself. That means AI can be applied to complex processes with interactions that may not be well-understood. In real-world applications, AI tools have identified issues and improvement opportunities that eluded even experienced control engineers.
AA/AI technology is much cheaper and easier to implement than earlier advanced control solutions. That paves the way for its use by companies with smaller plants or less common processes—especially as the latest generations of technology are user-friendly enough to be placed directly in the hands of the process engineer.
AA/AI control approaches work best alongside people. Capturing the full potential of the approach almost always depends upon a combination of better process steering, technical upgrades to address issues and opportunities identified by the system, and improved performance management. Each of these improvement levers brings roughly one third of the total value at stake, and each requires the input of people with deep process knowledge.
Industrial companies are just beginning to exploit the potential of advanced analytics and artificial intelligence technologies in process control. That won’t be the end-game. Ultimately, the ability of AI to assist the control and optimization of complex systems will unlock entirely new ways to manage not just machines and production processes, but also entire businesses.We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
September 9, 2020 Brian is McKinsey’s partner in charge of global recruiting. He’s been at the firm for 25+ years and started as a consultant before taking leadership roles focused on McKinsey’s people and candidates. He is also one of the firm’s inclusion and diversity leaders and a co-founder of GLAM, McKinsey’s LGBTQ+ network.
Absolutely – very much so! From the beginning of the pandemic, we’ve taken a through cycle approach to recruiting, meaning we continue to hire and have a long term view for our firm, our client service and our ever growing need for top talent.
It is clear our clients need us more than ever right now, so it is important we continue to attract, develop, and retain exceptional people. In terms of roles, we are hiring across the board - from consultant roles for people coming out of school or industry to tech consulting, IT and graphic design.
While many things look different today than they did at this time last year, McKinsey's recruiting process remains generally the same. Our top priority is to ensure candidates have a positive experience as they get to know McKinsey, whether that is in-person or via Zoom.
Long before the pandemic, we conducted some virtual interviewing and events. Starting in March, we had to quickly move all recruiting and our summer intern programs to virtual and we did it. We continued interviewing, hired new people and welcomed incredible groups of interns around the world. My newest proud McKinsey moment is that we honored all offers, including all summer internships and we are now hiring large numbers of new colleagues around the globe.
This summer we worked closely with career service leads at many universities to make sure campus recruiting could continue, even in places where we would not physically be on campus.
When faced with the challenge of COVID-19, we decided to innovate and lean in 100 percent. Instead of looking at this as an unfortunate year with less than ideal circumstances, we are aiming to make this recruiting year better than any other, to look at how we meet new candidates, go to campus, host events and find our new colleagues in totally new ways. We have been calling our efforts Reimagining Recruiting and we’re excited to show candidates how we’re going from best in class in-person events to world class virtual events and interviews. Our experiences this Spring gave us insights and confidence so we invite you to check out our many events and learn more about working at McKinsey.
I am ready for the next step in my professional career and wonder if McKinsey may be for me. What do I do?
To apply for a position, visit our Careers site. We will be hiring thousands of people this year from data engineers to consultants to executive assistants. You may know the kind of role you’re looking for so go ahead and search based on locations, interests, industries or functions.
If you’re not sure what kind of roles we have or which you might be the best fit for, take our quick Find Your Fit quiz.
Once you apply, your CV will be reviewed by a recruiter and you may be invited to play the McKinsey Problem Solving Game. This cutting edge game has been quite popular – hear from a couple recent hires who took it and learn what they liked about it.
In our interviews we look for inclusive leadership, personal impact, entrepreneurial drive and problem solving skills. To learn about how we think of these qualities and how to showcase yours, check out our interview tips and videos.
I recommend thinking about your experiences related to leadership, impact and being entrepreneurial – really bring yourself back to the specific example, and recall details about the challenges, goals and the actions you took. Practice telling your story out loud or with a friend. For interview tips from our colleagues, visit our Careers Blog.
I have hosted many virtual events and done a lot of remote based interviews. Here are my top tips for the best experience:
Eliminate distractions - To ensure you can concentrate, find a quiet room with some privacy. Some people find it helpful to wear headphones to tune out noise.
Gather the necessities and remove the rest - Make sure you have a notepad, pen, and water nearby. Remove resources like a calculator or prepared notes that you would not have if the interview were in person.
Speak up - If you feel stuck, confused or need clarification of what is being asked of you, ask your interviewer to repeat themselves. This is your interview and we want you to be comfortable so you can perform at your best. Though the virtual format has many positive aspects, we can't always read body language or facial expressions well, so we encourage you to speak up, clarify and ask your questions.
The health and safety of our candidates, colleagues and communities is our top concern. Depending on the timeframe and the location, there is a chance we will not meet you in person during your recruiting process. We are, however, monitoring what’s safe and possible in different locations with regard to office openings and safe social connections.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
We use Zoom for our virtual interviews and most of our events. This platform is stable and user friendly, and is used extensively with many clients and internally with our colleagues.
With the click of a link, you will be connected to us. Your interviewer will guide you on any Zoom features you need, and will be there to help in case anything goes wrong.
If you have a disability or require special accommodations, please let us know so we can work together to accommodate your needs.
We know technology can be unpredictable and issues can arise. You will in no way be penalized if something happens during a virtual interview. Our McKinsey colleagues are skilled in using technology and have contingency plans in place. Should you run into issues on Zoom, you can:
We do not expect you to wear a suit or dress formally. We are all in the same situation, and most of us have switched to business casual.
We also understand you may have roommates, pets, or family around – so do we – therefore don’t stress about these matters.
You should have your video on the entire time during interviews. This will help us connect with you, and you with us. Don't worry about your background or setting.
Be yourself! Interviewing helps us learn about you as a person and a potential colleague, and it helps you learn more about McKinsey, our people and what you could do here. We look forward to getting to know you!May 6, 2019 What level of impact can continuous improvement achieve? One of our clients would say ten weeks. Why? That’s how much time they were able to save in their product testing process—cutting the time by more than 80%—through a large amount of small changes to how its engineering and testing teams collaborated.
Continuous improvement is an ongoing effort to improve all elements of an organization—processes, tools, products, services, etc. Sometimes those improvements are big, often they are small. But what’s most important is they’re frequent. Companies that excel at continuous improvement start with the belief that success comes from:
Core to a continuous improvement mindset is the belief that a steady stream of improvements, diligently executed, will have transformational results.
Performance transparency starts with making goals public and cascading those goals (typically a balanced mix of financial and operational metrics) in a way that is tailored to individuals at all levels of the organization. Progress toward goals must be transparently tracked to give the frontline and management clear visibility into what is working and what needs work.
After conducting our Organizational Health Index (OHI) with one of our industrial clients, we saw an opportunity to create greater transparency among different areas of their operations. For instance, the company had capital assets that were poorly utilized, in part because they were shared across multiple teams that lacked the incentive to maximize the assets’ usage.
By instituting an easy-to-understand system to track overall utilization, the teams that used the assets instantly realized that low utilization was a bigger problem than any of them had realized, and it focused their creativity on finding new ways to make the assets more productive—leading to a 20% productivity increase in less than two months.
Knowledge sharing is critical to scale best practices across (and up and down) organizations. One of our clients became adept at deploying small cross-functional teams against any problem to break down the organizational silos that had previously prevented knowledge sharing.
The teams would collocate to promote informal and formal knowledge sharing and were given license to explore every idea and bring in additional expertise as needed. The team had to work together because no single team completely understood most problems “end-to-end.” But by working together in multi-week sprints, they were able to achieve 80%+ cycle time improvements.
Employee involvement is a necessity in continuous improvement organizations. Frontline employees are closest to the work, and thus typically have the richest insights on how their work can be done better. Capturing their perspectives is critical.
When our client struggled with morale among frontline managers, they went straight to the source. Through conversations with frontline management, leaders uncovered issues that needed to be addressed—insufficient onboarding, limited upward mobility and burdensome administrative duties that prevented them from effectively leading their teams.
Working with a coalition of frontline managers, the management team developed a set of focused interventions (many of which were led by managers now empowered to make the changes they sought) to expand opportunities for mobility, leadership development and mentorship, and to reduce waste in their daily workload.
Core to a continuous improvement mindset is the belief that a steady stream of improvements, diligently executed, will have transformational results.
Continuous improvement has helped clients across industries provide greater value to their customers. Are you looking to gain an execution edge for your company? Get in touch with us and check out our upcoming blog posts that will dispel several myths on creating continuous improvement cultures.This blog is part of a blog series around how HR needs to start reimagining their future to thrive in the post COVID-19 world. Click on the button on the right for the full overview of the blog series.
COVID-19 has changed the world, testing organizations’ collective resilience, agility, and adaptability, as it has fundamentally shifted how we work and do business. When there is disruption, there will also be recovery, so how we act in a time of crisis will often determine our long-term impact. It is likely that HR is expected to do the same (or more) with less resources and money. With budget cuts already starting, it is crucial for HR to focus on areas where real business impact can be made. We will most likely never return to “old ways” of doing business, as the pandemic has created an opportunity – or rather an imperative – for HR to focus on value adding activities. Yet, for HR to only focus on added value is easier said than done.
This year’s Human Capital Trends survey (2020) clearly shows that HR organizations are struggling with the prioritization of HR’s work and effort (click here for the full article ‘A memo to HR: the changing role of HR management’). This finding leads to a set of fundamental questions HR will need to answer: Which are the areas where the biggest business impact can be made? Which challenges surfaced during the COVID-19 outbreak and should therefore be addressed today? Where should we focus now that time and resources are limited?At the end of the day, we all want to know who’ll we work with and what makes someone successful at McKinsey. Meet some of our people here.Dr. Dhar is Vice Chairman and US Life Sciences and Health Care (LSHC) Industry Leader for Deloitte LLP leading the overall strategic direction for the life sciences and health care practices, including audit, consulting, tax, and advisory services. He is a respected health futurist and sought-after digital disrupter. Asif helps Governments, Life Sciences and Health Care clients reinvent wellness, solve disease, address pandemics and tackle health inequities. He is also Deloitte’s Lead Partner for the Firm’s US Food and Drug Administration (FDA) relationship and responsible for all work Deloitte performs with and for the Agency. His perspectives on real world evidence, regulatory sciences, digital health, and innovation are sought by clients around the world. Asif’s passion for the LSHC industry is evident in all that he does – as a pioneering thought leader who helped establish a framework for the Future of Health, formed ConvergeHEALTH, an award winning life sciences and health care software solution, and helped frame numerous COVID-19 health-oriented reboot and recovery solutions. He advises some of the world’s most innovative companies and Governmental agencies tackling disease and public health.Developing a successful strategy is essential to simplifying the complexities of transformation. These key areas to consider can empower your transformation strategy and clarify the road ahead for digital controllership.Process. Regulatory complexity is another factor. The growth and complexity of the requirements are continual challenges as businesses aim to meet the needs of external auditors, regulators, management, and others.
Technology. Lack of innovation is an issue as well. Many technologies are coming on the scene that are designed to make compliance processes more efficient and shed new light on the vast amounts of data now available in most organizations. The challenge is tapping into those capabilities, given budget and resource constraints, and beating the ever-ticking clock as companies approach their next compliance deadline.
Talent. As the Dbriefs audience indicated, many companies struggle to find and retain the right resources and skillsets. It’s often a challenge because, many times, SOX compliance programs serve as a feeder to the rest of the organization. That’s great for the overall business, but it makes it difficult to align the right people, with the right skillsets in the most meaningful way.Insert Custom CSS fragment. Do not delete! This box/component contains code needed on this page. This message will not be visible when page is activated.This blog is managed by Deloitte AG, a company registered in Switzerland with registered numbers CHE-101.377.666, with a registered office at General Guisan-Quai 38, 8002 Zurich, Switzerland.
Deloitte is committed to protecting your information by handling it responsibly and safeguarding it using appropriate technical, administrative and physical security measures.
We may collect or obtain information about you that you provide to us, that we obtain from third parties or that is publicly available, or which we infer from the way you interact with us.
For more details on how Deloitte handles and shares your information and for details on your rights and how to contact us, please click here.Michael leads Deloitte Consulting LLP’s Learning Consulting practice in North America. He focuses on working with global clients on building high-performance businesses that drive growth and optimization through talent and learning. Prior to joining Deloitte, Michael led the Learning Strategy business for a Big Four firm and was the head of training for a major online retailer in the UK. He has more than 20 years of experience leading key programs at market-leading clients, including running the learning and change management office for a top-tier merger in the Financial Services industry and driving learning transformation for a global brand in the food and beverage industry. Michael has presented at the Chief Learning Officer annual conference and has won learning program awards with his clients. He also lectures on learning at NYU School of Continuing Education.People are the heart of every business, and when it comes to M&A, tackling the human side of things can make all the difference between continued profits and potentially massive losses. Learn how Deloitte Digital helped Verizon Media successfully integrate two sales teams by putting their people first.Serves clients on a broad array of topics ranging from strategy to organizational design and transformation across industries, including consumer goods, retail, and fashion; leads our organization design work and helps companies through multiyear organizational transformations, focusing on bringing operating models in line with the realities of the markets, strategic shifts, and other success factors
Advises leading global companies in the consumer industry and other sectors on how to optimize organizational design and operating models to improve performance and culture, and boost organizational agility
June 8, 2020 Executives agree: The digital revolution will change the way their organizations operate. According to a McKinsey Digital Quotient survey from April 2019, 93 percent of executives believe that digital is critical to achieving their strategic goals. Even though organizations have been digitizing for decades, the digital revolution is still fairly new. Not only is the speed of technological progress often underestimated, but it is also getting increasingly faster.
Key digital technologies, such as automation, artificial intelligence, advanced analytics, the Internet of Things, and augmented and virtual reality, are constantly evolving. These technologies offer more groundbreaking application areas and will increasingly be implemented throughout the entire value chain. Against this background, corporations need to fundamentally rethink their organizational setup and embed digital in their DNA in order to remain competitive and reap the benefits of emerging technological opportunities.
However, few companies are set up for taking advantage of the new opportunities offered by digitization and for mastering the challenges that come with these. Nine out of 10 CEOs believe their organization is currently not ideally set up. Most companies focus on adjusting and extending their offerings to more digitally enhanced products or services. On the other hand, just as important, organizational implications are often neglected.
Adjusting the organizational setup to embrace digitization drives significant improvements in the financial performance of organizations. As indicated by McKinsey’s Digital Quotient Benchmark, corporations that adopt a digital-ready setup can quadruple their five-year Revenue CAGR and almost triple their five-year Total Return to Shareholders CAGR compared to corporations that do not foster and prepare for such organizational change.
In order to capture the potential of digital opportunities, organizations need to make fundamental design choices along three dimensions:
Structure Does the organization have a dedicated chief digital officer (CDO)? Is there a digital Center of Excellence (CoE) shaping digitalization centrally, or does every business unit have their own digital unit? Do we stay within existing structures or move towards a value-driven agile setup?
People Should the organization build digital skills internally through large-scale re-skilling, build on an external digital ecosystem of talent and partners, or a combination of both? Does the organization go for digital skill density with individual top performers or digital skill breadth across the organization? How do we best leverage our ecosystem of partners to get access to capabilities across the value chain?
Process Do we stick to today’s ways of working, or do we adjust ways of working and the culture coming with these? Should a phased or a big-bang approach be taken to organizational digitization? Are our business processes set up in the right way to meet the expectations of the digital era (e.g., intuitive interfaces, around-the-clock availability, real-time fulfillment, personalized treatment, global consistency and zero errors)?
An example of a European e-commerce player we served epitomizes how well a digital organization can hit the ground running, when structure, processes and people are all adequately addressed by the transformation.
On structure, the company at hand replaced the central digital department with dedicated tech employees staffed to cross-functional teams of buyers and software engineers, operations managers, UX designers, and brand managers throughout the entire organization. This new structural setup ensured that digital was embed in every function.
On the people side, a significant investment was made as the new organizational setup required a new set of skills. Some existing roles became redundant and new roles were created.
With respect to process, the entire process landscape was mapped, stack ranked against digitization impact and embedded into an end-to-end digitization process. In addition, the newly formed teams had to be steered in a completely new way, going from rather rigid, hierarchical processes to agile, output-focused, tech-driven ways of working.
The extent of organizational adjustments needed to meet the requirements of digitization can differ significantly from company to company and will take some time to implement. Nevertheless, in times of the digital revolution, they are of fundamental importance in order to maintain and expand a relevant position in the market.Consulting is the process of helping clients solve their most pressing business problems or issues. Consultants are enablers. We work across a wide range of roles, industries, and geographies to apply our methods of analyzing information, and to identify a new, positive way forward for our clients. Working at a fast (and sometimes unpredictable) pace, no two days or two journeys of a consultant are the same.
A consultant’s day is highly variable depending on the project and role. Your day can vary from building slide decks, designing business processes, or presenting status updates to the leadership team. It keeps us on our toes and allows everyone to stretch their skills and become more adaptable.
Diverse project work is one of the biggest perks in consulting as you get to try out different roles and industries all the while at the same job. With opportunities that range from working with smaller “mom and pop” shops to working with some of the largest multinational companies in the world, consultants get a crash course in dealing with an array of complex business challenges from the perspective of senior leaders and executives. Some of our clients produce cutting-edge technology products, and more than likely, you’ll get an opportunity to experience the products first hand. For example, imagine being coached on how to take a “drelfie”, your very own selfie taken by a drone! No selfie stick required.
As consultants, Excel and PowerPoint are admittedly our go to tools on a day-to-day basis to help synthesize multifaceted ideas to clients in a digestible, actionable manner. However, you do not have to be an Excel whiz or a PowerPoint master in order to work in consulting. Soft skills are highly important to communicate your ideas and manage client expectations, both of which are equally important when working in consulting.
Consulting also allows you to grow your skills amongst some of the best and brightest professionals, all of which are extremely motivated and happy to help at any time. We travel together, work together on client sites and get to know each person’s quirks and coffee orders. We work hard, but have fun while doing it.
All in all, there is no easy answer to the question of what is consulting, just like there is no easy answer to the problems that we are hired to solve. At Deloitte, you are given the skills, support and guidance in order to craft the career you want and truly define what consulting means to you.
Stephanie graduated from the Ivey Business School with an Honors Business Administration. She is currently a Business Analyst at our Vancouver practice.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.Advises leading organizations on how to strengthen their talent-management capabilities and build an HR function that operates as a true strategic partner and value driver for the business
January 23, 2018 The core of HR 3.0 – McKinsey’s vision for the future of employee-related activities – focuses singularly on driving value from talent. But let’s be candid: HR will not have the bandwidth, resources or credibility to achieve this goal unless it delivers smooth and continuous customer service.
To provide such stellar service, HR must employ technologies that are changing how consistent process execution and excellent customer care are delivered.
The biggest workplace disruptor is next-generation automation technologies. The McKinsey Global Institute estimates that nearly half of all work could be automated with current technologies.
For HR, intelligent process automation, which includes artificial intelligence and related new technology advances, can help deliver consistent people processes – something that has eluded many HR operations teams given the dynamic nature of the requests they receive.
Cost savings also materialize through deploying such technologies as robotic process automation, machine learning and cognitive agents. Our analysis suggests that 56 percent of typical “hire-to-retire” tasks could be automated with current technologies and limited process changes.
Robotic process automation is the most mature technology. Its use of software with AI and machine learning capabilities to handle repeatable tasks that humans have traditionally performed is already changing the delivery of HR services. For example, a leading consumer packaged-goods manufacturer deploys bots in its hiring process, starting with onboarding new employees (by, for example, porting application tracking system data over to the HR information system).
With time, opportunities will abound to automate more elements of the hiring process. For example, a bot can draft offer letters, write job descriptions or set up payroll and benefits data. And beyond robotic process automation, cognitive agents can potentially transform the interaction between HR and employees. Always-on chat agents can answer questions instantaneously and be available on employee phones – a better service experience than calling an HR hotline.
Consider the experience of a fast-growing tech company hiring employees rapidly and generating numerous offer letters. Those letters were drafted manually and required many quality checks to ensure compliance and accuracy. The company deployed a bot to automate the entire process, generating an offer letter that pulled information from several systems. Compliance and accuracy checks built into the programmed workflow limited human involvement to the occasional exception and quality control.
The result: Processing time fell 66 percent, compliance improved and four full-time employees moved to more value-added work. Given the generally low cost of bots, the business case for automation is clear – and the service impact is equally apparent. Beyond the measurable impact, faster turnaround time is likely to improve job offer acceptance rates. That would dwarf automation’s potential productivity value.
Still, some important caveats exist. HR has fewer opportunities to carry out more mature automation technologies, such as robotic process automation, than some other support functions, particularly finance.
On their own, only the largest HR organizations would likely possess the transactional base to justify the robotic process automation learning curve. What’s more, many automation technologies require a portion of people’s time, so capturing the opportunity requires real transformation of process and organization.
However, as part of a broader enterprise strategy, HR can and should be a significant deployment opportunity for automation technologies. For example, HR should be part of the charge to automate customer service, particularly at larger organizations with sizable HR call centers.
As technology continues to transform the world, HR clearly must be part of that change, embracing robotic automation and other technologies that promise greater efficiency, superb customer service and significant cost savings.You could spend all day searching for valuable information online. Or you could go directly to the trusted news and analysis you need to stay informed, stay connected, and make smart business decisions. The Deloitte Insights mobile app brings you the best of business insights: Deloitte articles and research, Dow Jones news, and real-time market updates, all side by side and readily available on your smartphone.
Read Deloitte Insights in line at the airport. Browse news waiting for a meeting to start. Check markets any time. Search by industry or topic for a quick, curated collection of news, analysis, and specialized content. The Deloitte Insights mobile app gives you one easy place to get up to speed quickly on what’s happening today and stay smart about what matters most to you and your business.
You can personalize your profile to focus on topics and industries you need to stay on top of and receive notifications about relevant new content based on your interests. View a customized content feed and save content of interest for quick reference under the My Insights tab. Get live updates on equity, currency, and global markets, and create a personalized watchlist of US stocks.We have entered a pivotal point in history that will likely create unprecedented challenges for companies of all sizes and in all sectors. While it will take time and effort, this crisis can become an opportunity to move forward. More than two months have passed since the World Health Organization (WHO) declared COVID-19 a pandemic. Since then, biopharma companies from across the globe have been racing to deliver needed supplies and develop new vaccines and novel therapeutic interventions. We are seeing unprecedented levels of cooperation among many of these companies as they seek first to help patients.
While nearly 135 vaccines are now in the research pipeline, developing, testing, and approving an effective vaccine is expected to take up to 12-18 months (as of mid-May, 2020). However, some drugs and antiviral treatments could be repurposed for treatment of COVID-19 much sooner. More than 215 novel and re-purposed therapies were in the pipeline in mid-May.2 Once effective antivirals have been identified and approved, drug manufacturers will need to rapidly scale up production and distribution capabilities to meet a massive demand.
The pandemic is affecting most parts of the pharmaceutical ecosystem—from supply chain to research and development (R&D) to commercial operations. Although pharmaceutical companies typically have a sufficient reserve of supplies to deal with supply chain disruptions, we are in unprecedented times. While the coronavirus forced some drug factories in China to close, manufacturing disruptions have not yet been substantial, and production has since resumed. For branded drugs and biologics, travel restrictions, quarantines or worker illness, and changes in demand could be disruptive. Branded drug sales, for example, could slow as patients opt to delay new treatment starts or elective medications. Moreover, some next-generation therapies might not be available to patients if hospitals don’t have the resources to prep and treat those patients.
Along with searching for new vaccines and therapies to prevent and treat COVID-19, pharmaceutical companies should also continue day-to-day business operations including R&D. But some pharmaceutical companies have had to slow or stop patient recruitment for clinical trials to reduce the risk to patients who could be exposed to the virus. Some companies are delaying trials and opting not to launch new ones to reduce the burden on health care systems.3
Many commercial field teams are now working from home. Market access and medical teams that are accustomed to meeting customers in clinical settings should be selective and thoughtful about how much to engage critical health care resources.
Once this health emergency passes, we expect biopharmaceutical companies will find themselves on an accelerated path to the future of health that Deloitte envisions. Our response to this global outbreak is already changing business processes for pharmaceutical companies in the following four areas:
1. Greater focus on vaccines and prevention: Biopharma business models could look much different by 2040. Twenty years from now, we expect that biopharma companies will place greater attention on early detection and prevention, which means the onset of some diseases could be delayed or prevented altogether. Biopharma companies are already turning their attention to the development of more vaccines and anti-virals. Lessons learned from this pandemic could lead some biopharma companies to shift R&D investments to prevention of infectious diseases.
2. Increased adoption on artificial intelligence (AI): In response to a request from the White House, five large research organizations released an open research dataset of scholarly literature about COVID-19, SARS-CoV-2, and the coronavirus group.4 Artificial intelligence (AI) could be used to mine the data—which includes nearly 40,000 machine-readable articles about the virus, the disease it causes, and other viruses in the same family—to learn more about COVID-19 and potential treatments. AI could help speed drug discovery by analyzing research data more effectively and screening chemical libraries, de-novo drug design, drug repurposing, and pre-clinical testing, according to a November 2019 report from our colleagues in the United Kingdom. Some biopharma companies that have vaccine and/or infectious disease experience are partnering with AI drug-discovery companies.5
3. Smart automation: Like many industries, pharma is quickly learning how much work can be done remotely, or with fewer onsite employees. Some manufacturing sites have increased the space between workers or are considering more shifts to spread workers out and minimize the risk of spreading infection. While some manufacturing employees always need to be on-site, the pandemic has illustrated how many jobs can be done virtually. Sales teams, for example, can no longer visit hospitals and other clinical settings. In response, some pharmaceutical reps are conducting online meetings with their clients. As more work is done virtually, companies should consider strategies to ensure customer-engagement, productivity, and a sense of team among employees.
4. Digital clinical trials: The need to limit potential exposure to the virus has brought the idea of virtual/digital clinical trials to the forefront. Research facilities tend to be located in metropolitan areas, which might be difficult for some people to reach and could create a risk of exposure to patients who might already be dealing with an illness. The process for recruiting and retaining patients for clinical trials has changed little over the past 30 years, as my colleague Dawn Anderson explained in a recent blog. But many facets of a clinical trial could be done remotely through the use of connected digital devices and the internet. Virtual clinical trials could lead to deeper pools of potential candidates, improve convenience for patients, and lead to more efficient trials. Further, some companies are now exploring new ways of delivering clinical supplies directly to a patient’s home, rather than from the site of the clinical study. We are optimistic that when we recover from this crisis, there will be even faster adoption of the technologies and approaches needed to make digital clinical trials a reality.
5. Regulatory flexibility: FDA, the European Medicines Agency (EMA), and other regulatory bodies have acted to protect both patients and clinical staff involved in clinical trials by relaxing some rules. Both agencies have emphasized the importance of patient safety. FDA recently created a special emergency program, called the Coronavirus Treatment Acceleration Program (CTAP), to approve possible COVID-19 therapies more quickly.6 On March 30, the US Department of Health and Human Services (HHS) announced that its Biomedical Advanced Research and Development Authority (BARDA) is working with a division of Johnson & Johnson to accelerate clinical trials for a COVID-19 vaccine.7 We could see more private-public collaboration in response to the pandemic.
Once the world recovers from this global pandemic, there will be a new normal. We expect the biopharma sector will help lead us through this emergency and will come away with new and more effective business processes that can help prevent future pandemics
1. HHS accepts donations of medicine to Strategic National Stockpile as possible treatments for COVID-19 patient, HHS.gov, March 29, 2020
3. Amid coronavirus, disruptions to clinical trial, drug development, accelerate, STAT, March 23, 2020
4. Call to action to the tech community on new machine-readable COVID-19 data set, White House press release, March 16, 2020
5. Catching up to coronavirus: Top 60 treatments in development, Genetic Engineering & Biotechnology News, March 18, 2020
7. HHS Accelerates Clinical Trials, Prepares for Manufacturing of COVID-19 Vaccines, HHS, March 30, 2020Take a look at those new, ultra-successful companies that have, seemingly, come out of nowhere. They may have started on a shoestring budget, with a skeleton staff, but they have the potential to scale rapidly, and almost infinitely, and to grow exponentially. They do things that older, more traditional companies sometimes can’t. Things that traditional companies wish they could do. They tend to respond to market demands more quickly. Their customer base is growing, while those of traditional companies may be on the decline. In many cases, influencers hawk products from these new companies.
Why? Because they are what many old-guard companies are not: they’re agile. Both traditional and new companies can anticipate changes in markets, but the difference is the newer, more agile companies can change direction quickly and seize opportunities. They often operate with higher margins and shorter lead times at earlier stages in their business lifecycle. Further, they can increase or decrease their tech footprint with growth or contraction and launch platforms and systems in new markets. Finally, they can manage their support systems from a single console anywhere in the world.
So, how do traditional companies deal with competitors they may not even see coming? They become perfectly scalable. And they do it quickly, before their competitors achieve the size and scale to dominate their sector. Here’s what that perfectly scalable enterprise (PSE) looks like. A PSE uses technology to leverage access to excess market capacity, align cost structures with growth, and efficiently use scarce resources to achieve economies of size and scale.
PSEs automate everything they can. They limit the impact of poor decisions and capture growth opportunities. PSEs also focus on avoiding waste and outsource wherever possible. Their financial resources are well-managed, and they target wide-moat competitive advantage plays to drive and sustain success.
PSEs can also launch digital products and services at a global scale with faster time to market. They use data-driven insights to enhance their agility, and minimize upfront capital investments, sunk costs, and technological obsolescence. Simply put: they epitomize enterprise agility.
How do companies become perfectly scalable? First they reimagine their business in a world powered by advanced technology. They redefine competitive barriers, realign partner networks, promote an innovation-based culture, and strive for operational and financial efficiency and flexibility.
For instance, a US-based health insurance startup leveraged the cloud to innovate by scaling its business and guiding customers towards better care by helping them more closely track their health. The company built and deployed its new cloud-based, HIPAA-compliant health insurance platform and analytics solution in less than three months.
They have been able to easily manage enormous usage spikes during open enrollment season, disrupting incumbents, and demonstrating the ability to scale to meet demand—and do it with a lean team to continually deliver value by better meeting business needs and improving the customer experience. The platform also afforded members to realize superior outcomes while reducing the associated cost of health care.
Clearly, the cloud is a key strategic choice that underpins the capabilities of a PSE and can help transform their business, and PSEs know that. PSEs value speed to market as a competitive differentiator, and they know that the cloud is the engine for that. It connects. It improves. It evolves. It integrates—at speed—enabling PSEs to start scaling quickly.
PSEs leverage the cloud to enhance their inorganic growth strategy. With cloud-based technology, they can acquire, integrate, and divest businesses more easily—and they can increase enterprise agility and simplify transformations—all keys to disruption. To that end, PSEs with an eye toward future M&A opportunities use cloud-based solutions to reduce future integration or divestiture costs, increase post-deal transition flexibility, enhance business agility, reduce risks, and facilitate a quicker exit when it’s time.
PSE’s use the cloud to make their technology operations more effective. They automate to drive improved productivity, increase accuracy, minimize waste, and enhance business results. PSEs use cloud-based automation technologies to improve operational spend and time-to-market by employing methods and tools that drive improved business outcomes—things like DevOps, self-service, auto-provisioning, integration platforms as a service, continuous integration and continuous development (CI/CD), microservices, and containerization.
PSEs also understand that deploying cloud solutions provides a quicker route for disruptive innovation, because it allows them to focus resources on finding solutions and delivering value, rather than engaging in capacity planning, procurement, and commoditized infrastructure management.
For example, a US-based financial services startup used the cloud—deployed by a lean team—to create an innovative, massively scalable securities trading app with strong built-in security and compliance features that supported hundreds of thousands of users at launch.
The app has disrupted the industry and is successfully competing with incumbents by offering no-fee securities trading capabilities, supported by a highly-scalable IT footprint. The startup is further exploiting the cloud to grow their online business, deliver and update their mobile trading app, securely store customer information and trading data, and perform advanced business analytics.
The bottom line? The competitive landscape is challenging. New, nimble companies are entering the market faster, with the latest technologies at their disposal—and potentially with little to no technical debt to prevent them from making significant strategic moves domestically and globally. Essentially, they are starting off as perfectly scalable enterprises.
Because they’re perfectly scalable, they have many choices—and limited downside if it doesn’t work out–which sometimes happens. Technology is a great equalizer, and acquiring the technology to become more flexible and scalable is critical to success. Getting smart on the cloud is a sound strategy to get perfectly scalable.Transforms large industrial sites and organizations by implementing the latest performance-based approaches and leveraging the core principles of organizational health to ensure sustainable change.
As a senior expert in culture and change, a facilitator, and a coach, counsels public- and private-sector leaders on building values-driven systems
July 15, 2019 The new CEO of a major multinational organization inherited a crumbling empire. Declining performance. Unsuccessful product launches. Leader infighting. A complete lack of strategic direction.
He could have jumped straight into market analysis or strategic planning to transform the organization. But he took an unconventional approach. The CEO’s first move was to reach out and listen to hundreds of people at all levels of the organization to set a new, organization-wide aspiration addressing both business performance and culture.
Why is it so important for the aspiration to be the priority in a transformation? In short, an aspiration is the foundation and catalyst for everything else that follows. Research from the book “Beyond Performance 2.0” found organizations that align on a clear aspiration across both performance and culture increase the odds of their transformation’s success by 300 percent.
Many books have been written about setting a strategic business performance aspiration, but how do you approach setting a cultural aspiration? Organizations can follow a four-step process. The first two steps are about developing an objective, science-driven perspective on the culture that will make the biggest difference to business performance. The last two steps are about translating data-driven insights into the language of that organization.
Align the organization with a successful cultural recipe. Leaders can select from a set of cultural “recipes”—the combination of complementary behaviors that have an outsized impact on building a performance culture. Our research found that the highest-performing organizations align with one of four recipes: leadership factory, market shaper, execution edge and knowledge core. Senior executives can orchestrate an organization-wide conversation around the recipe that best fits their organization’s industry and organizational strategy. Prioritize critical behaviors. Once aligned on a cultural recipe, leaders should select 6-10 behaviors to emphasize. Our research identified four management “power practices”—personal ownership, role clarity, strategic clarity and competitive insights—that are particularly important because they have a multiplier effect on the culture. Executives should both fix the broken practices and build on the core behavioral strengths of the organization. Agree on the cultural themes. The selected practices can then be grouped into cultural themes that embody the organization’s mission, vision, values and purpose. These themes guide the decision-making process of employees at all levels—from the CEO to the front line. The organizations that do this will often have fewer themes—some as few as three. These themes reflect and signal the management’s core commitments, which will help galvanize the whole workforce to build the organization’s culture. Set behavioral expectations for everyone. The last step is about translating the prioritized behaviors into a language that employees at all levels of the organization can understand and relate to through either a leadership or competency model—usually with no more than 15 behavioral competencies. This leadership model becomes the articulation of cultural aspiration specific to that organization. Leaders can then select a few behaviors—around 3-5—to focus on each year. We will discuss how to change these specific behaviors in subsequent posts.
When organizations follow this process successfully, their cultural aspiration is anchored in the performance objectives, based on data science, and written in a language that excites the entire organization.
For the multinational organization, the initial focus on setting a cultural aspiration has paid off handsomely. Performance improvements have continued steadily for the past five years, and its stock price has tripled. Most importantly, the aspiration has excited and engaged staff across the enterprise, unlocking creativity and innovation.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.Insert Custom CSS fragment. Do not delete! This box/component contains code needed on this page. This message will not be visible when page is activated.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.Insert Custom CSS fragment. Do not delete! This box/component contains code needed on this page. This message will not be visible when page is activated.By Jay Zhu, managing director; Robert Maul, senior manager; and Erich Sachse, senior manager, Deloitte Consulting LLP
Medtech has historically relied on a hands-on, face-to-face sales model where field sales forces communicate value propositions and develop deep relationships with key influencers and decision-makers on-site at hospitals and other health organizations.
The COVID-19 pandemic has turned that model upside down. States have issued stay-at-home orders and hospitals and other health facilities have restricted access. In response, many medtech companies have quickly adopted a work-from-home model to protect their customers and employees, and have turned to digital channels to stay connected to their customers.
Outside of medtech, virtual sales is common across a wide range of industries including financial services and technology. Even within medtech, virtual sales isn’t an entirely new concept. For example, a pioneering genomic sequencing company was able to sell a large capital instrument via its e-commerce channel directly without any face-to-face engagement. Many medtech companies have adopted inside sales and digital marketing over the years to enable multi-channel engagement and to reduce selling costs. These tactics have proven effective for some mature products, hard-to-reach customers, and certain activities along the sales cycle.
Despite some success, virtual sales tends to be a small part of the sales model in medtech. Most companies still rely heavily on in-person promotions and have been reluctant to expand the use of virtual selling. The COVID-19 outbreak abruptly flipped the switch for everyone. Some companies and sales people were not as prepared as others. Different skills and approaches are typically needed to engage customers in virtual settings, especially when it comes to new customer acquisition. Rather than reinventing the virtual sales model, medtech companies should look to other industries and learn what has worked.
Greater reliance on virtual engagement among medtech companies will likely be more than a temporary response to the pandemic. Even after the threat of COVID-19 fades, we expect a meaningful portion of the sales process will remain virtual due to continued limited access and lower revenue expectations. In a post-pandemic world, some customers might prefer engaging with sales reps virtually versus face-to-face. Additionally, many hospitals and health systems will likely be under significant pressure to reduce expenses, which will pose revenue challenges for medtech companies. In response, medtech companies should optimize their selling costs by increasing the use of virtual channels. Medtech companies that strategically incorporate a virtual component into their sales strategy will likely be best positioned to recover faster than their peers and thrive in the new landscape.
Converting face-to-face meetings into virtual meetings—that achieve the same or better effect—might require more than a videoconferencing solution. Sales reps and account managers should fundamentally rethink their interactions, and marketing should be empowered to support this new way of engaging customers. Not only should sales teams adapt quickly, they also should do it well. An ability to embed value into every customer interaction will likely separate the winners from the rest of the pack.
As patients return to medical facilities for the elective surgeries and non-critical procedures they had deferred, medtech companies should shift from responding to the pandemic to recovering from it. There are several key actions they should consider to maximize their virtual sales effectiveness:
Assess what has worked, and what created challenges: The initial response to the pandemic forced many medtech companies to pull together emergency plans and adapt their selling tactics. These early strategies should be assessed based on feedback from sales reps and customers. This could help improve the long-term plan for virtual sales. The lessons learned from the respond phase could lead to more effective sales strategies and tactics during the recovery and thrive phases.
The initial response to the pandemic forced many medtech companies to pull together emergency plans and adapt their selling tactics. These early strategies should be assessed based on feedback from sales reps and customers. This could help improve the long-term plan for virtual sales. The lessons learned from the phase could lead to more effective sales strategies and tactics during the and phases. Listen to the customer: The pandemic might have changed the customer’s near- and long-term needs as well as their preferences for engagement. Each customer is likely to follow a different path toward business recovery. Sales reps should listen to their customers and personalize their sales efforts based on the customer’s preferences and unique situations. This should be seen as an opportunity to build a more strategic relationship.
The pandemic might have changed the customer’s near- and long-term needs as well as their preferences for engagement. Each customer is likely to follow a different path toward business recovery. Sales reps should listen to their customers and personalize their sales efforts based on the customer’s preferences and unique situations. This should be seen as an opportunity to build a more strategic relationship. Reimagine the sales process for the long-run: Medtech companies should not try to just virtualize existing sales processes. Instead, they should evaluate their sales processes and customer-engagement models to determine how to segment and engage customers, leveraging virtual sales as part of an overall sales plan. The process should vary by product category. Larger companies, for example, might need to build multiple models for the future sales process. This is an opportunity to rethink and rebalance the go-to-market model to help enable a more modern customer experience and to optimize SG&A during difficult times.
Medtech companies should not try to just virtualize existing sales processes. Instead, they should evaluate their sales processes and customer-engagement models to determine how to segment and engage customers, leveraging virtual sales as part of an overall sales plan. The process should vary by product category. Larger companies, for example, might need to build multiple models for the future sales process. This is an opportunity to rethink and rebalance the go-to-market model to help enable a more modern customer experience and to optimize SG&A during difficult times. Consider a technology ecosystem to help enable and support virtual sales: Many companies were able to quickly ramp up their virtual sales tools to help ensure reps could continue to engage their customers via teleconference or videoconference. In addition to the basic conferencing tools, companies should also evaluate and enhance other technologies such as content management systems, interactive presentation software, virtual whiteboarding tools, ecommerce platforms, virtual reality tools for customer training, and visual assist tools for remote support. We expect virtual engagement will continue after COVID-19, and companies that can deliver a differentiated virtual experience using digital technologies will likely recover faster and develop stronger long-term relationships with customers.
Many companies were able to quickly ramp up their virtual sales tools to help ensure reps could continue to engage their customers via teleconference or videoconference. In addition to the basic conferencing tools, companies should also evaluate and enhance other technologies such as content management systems, interactive presentation software, virtual whiteboarding tools, ecommerce platforms, virtual reality tools for customer training, and visual assist tools for remote support. We expect virtual engagement will continue after COVID-19, and companies that can deliver a differentiated virtual experience using digital technologies will likely recover faster and develop stronger long-term relationships with customers. Refine and update digital content and sales aids: Sales materials and pitch decks used for face-to-face discussions likely will not work as effectively in virtual settings. Creative virtual approaches, content formats, and agile production models can improve speed to market, create a high level of personalization, and increase engagement. Medtech companies should revisit and adapt their sales materials to make a bigger and more memorable impact on customers.
Sales materials and pitch decks used for face-to-face discussions likely will not work as effectively in virtual settings. Creative virtual approaches, content formats, and agile production models can improve speed to market, create a high level of personalization, and increase engagement. Medtech companies should revisit and adapt their sales materials to make a bigger and more memorable impact on customers. Develop virtual sales training and coaching plans: Training will likely be needed as sales teams make the shift to virtual. They will likely need to improve their general digital fluency and master their company’s virtual technologies. Beyond basic training in virtual sales, companies should develop a longer-term plan to continuously enhance their virtual sales capabilities. A shift to digital also offers new opportunities for coaching. Sales managers can observe and assess virtual sales discussions and offer real-time feedback via virtual coaching tools. This can be a great opportunity for reps to log some product training time and schedule regular account-planning meetings with their teams.
Some hospitals and health systems have already begun to restart elective procedures, which could mean the recover phase of the pandemic response is arriving. Medical facilities may be anxious to get their revenue streams flowing again once concerns about the virus begin to subside. As the pandemic passes, we expect each therapeutic area will recover at a different rate and at a different pace. Additionally, the speed of recovery will likely vary based on geography, local government policies and guidance, and each provider’s strategy. Medtech companies that understand the changing demand curve, and strategically prepare for various scenarios, will likely be best positioned for the near- and long-term future.
The pandemic is likely to change the medtech sales landscape permanently. Companies should re-imagine their future customer engagement strategy and optimize the mix of virtual and in-person channels to accelerate recovery and thrive in the new world.October 7, 2019 Albert Einstein once famously remarked, “Today’s problems cannot be solved with the same level of thinking that created them.”
Consider the example of a Latin American consumer goods manufacturer under pressure to change its performance after not having performed well for several quarters. Due to urgency, the chief transformation officer went off to set more stretched targets and created a weekly governance to review performance initiatives with more rigor.
Yes, people worked hard. Yes, at first some KPIs improved, but all of this drained more energy than the results it was delivering. It soon became clear that the people would not last a marathon at the speed of a sprint; they had started to become disengaged.
Like in this organization, most enterprise transformations focus on changing business metrics and, at best, employee behaviors—and not the thinking what created the need for a transformation in the first place. And, not surprisingly, 70% of them fail. Companies with failed transformation programs identify employee resistance or management behavior as the major barrier (72%) to success.
To avoid that statistic, this manufacturer for the first time shifted the focus on the people. What was driving their behavior? What made their eyes shine? What would truly engage them in a transformation? Looking for these answers, the top team discovered that up until then, people were gaining praise for doing new things even if they were not delivering their promised results. They thought that short-term results were more important than satisfying the consumer. And when the time came to choose, they felt that their individual goals were bigger than the company’s. All this was limiting them from participating wholeheartedly in the transformation underway.
In fact, these mindsets, as we call them, needed to be flipped to make things work. Through a set of targeted initiatives, these mindsets were shaken. The people came to realize that satisfying the consumer is what will bring the short-term results. There is no success for the individual if the company is not doing well. And they started to be recognized for executing with discipline focusing on our full potential to deliver challenging goals. Sharing the story of why the transformation was necessary and addressing these mindsets engaged the employees with a whole new level of energy, and only few months later the organization was able to deliver its first quarter back on track and continue the trend.
Companies that take the time to identify and shift deep-seated mindsets were 4x more likely to rate their change programs as “successful,” according to the McKinsey Quarterly Transformational Change Survey, 2010. In fact, mindset shifts are linked to the highest impact behaviors a person wants to change.
Unless you first identify the mindsets, both limiting and enabling your people, your transformation initiatives may be wasting resources, time and energy. Another company, a telco, found that managers spent the majority of performance reviews explaining the complex rating process vs giving feedback. So, the telco simplified the process and rating system, increased frequency of conversations, and provided training on delivering feedback. However, it’s important to keep in mind that “from” mindsets aren’t necessarily bad; many rational, competent and well-meaning people could and do operate in this way.
In the case of the telco, leaders cancelled reviews and/or spent most time on small talk. Why? Leaders actually avoided difficult conversations and focused the feedback on process because they were afraid that criticism and difficult conversations would damage their relationships. Once this mindset transformed into “honesty (with respect) is the essence of building strong relationships,” leaders started to engage in regular, honest and courageous feedback conversations, and focus their feedback on performance.
Addressing the organization’s mindset has a tangible business impact and is the key that opens the door to successfully transforming an organization. In our next articles, we explore how to uncover those mindsets and how to turn them around.In September, the White House issued a new executive order that it says will reduce prescription drug prices.1 At the same time, many states have enacted, or intend to enact, laws that require pharmaceutical companies to create more transparency around their pricing strategies. The complexity of these laws, which vary by state, has created operational challenges for pharmaceutical companies—particularly those that continue to rely on low-tech reporting processes. More than 40% of small and mid-sized manufacturers, and 35% of large manufacturers, use spreadsheets and manual analyses, according to our recent survey of 235 pharmaceutical companies. Most respondents admit there is room for improvement in their company’s approach to meeting state price-transparency requirements.
Rising out-of-pocket costs for consumers—as well as state Medicaid programs—has been a major driver of drug price transparency initiatives. Along with attempting to drive down drug prices, some states are gathering data from drug manufacturers in an attempt to determine the nature of price changes. Transparency laws are typically triggered when the cost of a drug increases by a certain percentage within a certain period (e.g., one year), or when the annual cost of a therapy exceeds a particular amount (e.g., $10,000). When such rules are triggered, manufacturers need to explain the factors that led to the change in pricing. At least five states have enacted laws this year.
Pharmaceutical companies that fail to comply with state drug-transparency laws could face steep penalties of between $1,000 to $30,000 per day, depending on the state. Typically, the larger the company’s portfolio, the greater chance of triggering a law. While not all states have fines associated with the laws, pharmaceutical companies need to track each law and understand their nuances.
Since the COVID-19 crisis began, we’ve noticed that some state laws are getting more (and sharper) teeth, and enforcement appears to be ticking up in some areas. The California Office of Statewide Health Planning and Development, for example, has levied more than $17 million in fines against companies that failed to comply with its reporting requirements. In Nevada, 21 drug manufacturers have been fined more than $24 million for non-compliance. Reports need to be complete and accurate. Some states are closely scrutinizing information and are coming back to the companies if they believe the information is incomplete.
States are also creating commission boards or drug affordability review boards to set pricing caps for select higher-cost drugs, as well as to limit price increases by drug manufacturers, according to a recent report from the Deloitte Center for Health Solutions. Indiana, Missouri, Nevada, New Hampshire, and New Mexico are examples of states that have created these boards. Maine also worked on a Prescription Drug Affordability Board that sets prescription drug spending targets for public entities based on a 10-year rolling average, considering inflation.
Most of the manufacturers we surveyed said their manual processes are not able to keep up with all of the new state laws and changing requirements. Pharmaceutical companies should consider developing new reporting processes to confirm appropriate information is reported to each state to ensure compliance. Moreover, incorporating state price-reporting requirements into drug-pricing decisions can introduce efficiencies, create a more integrated approach to price management, and lead to more precision in forward-looking financial projections.
Automate and scale analytic processes: Technology and automation can be leveraged for reporting (e.g., having pricing and reporting information in one centralized repository via a system or tool that consolidates laws and regulations) along with business and legal interpretations. This can help companies keep up with a wide range of reporting requirements and determine when reporting requirements are triggered. It can also help generate and populate the reports that need to be submitted. Basic tools and mechanisms can include pricing-scenario models, price trackers, and an electronic inventory of each state’s reporting requirements. Automation can populate reports while analytics can help manufacturers make informed decisions about pricing strategies and understand how changes in one state could trigger broader business impacts.
Technology and automation can be leveraged for reporting (e.g., having pricing and reporting information in one centralized repository via a system or tool that consolidates laws and regulations) along with business and legal interpretations. This can help companies keep up with a wide range of reporting requirements and determine when reporting requirements are triggered. It can also help generate and populate the reports that need to be submitted. Basic tools and mechanisms can include pricing-scenario models, price trackers, and an electronic inventory of each state’s reporting requirements. Automation can populate reports while analytics can help manufacturers make informed decisions about pricing strategies and understand how changes in one state could trigger broader business impacts. Integrate software to generate state-specific reports: The ability to generate price transparency reports is a fundamental capability. Software can be implemented to help companies export data files tailored to each state and then submitted via email or uploaded to a state portal. Such a solution automatically updates any new state requirements. Once a triggering event has occurred and a report is generated, technology could ensure it goes through the proper reviews before being uploaded to a state portal—helping to mitigate compliance risk and avoid costly penalties. The system should also store all product and pricing information and qualitative data required by the state.
The ability to generate price transparency reports is a fundamental capability. Software can be implemented to help companies export data files tailored to each state and then submitted via email or uploaded to a state portal. Such a solution automatically updates any new state requirements. Once a triggering event has occurred and a report is generated, technology could ensure it goes through the proper reviews before being uploaded to a state portal—helping to mitigate compliance risk and avoid costly penalties. The system should also store all product and pricing information and qualitative data required by the state. Identify data ownership: Given the complexity and disparate nature of state regulations, pharmaceutical companies should determine who owns the data. We have found that the information needed to comply with state laws often resides in multiple systems within a variety of groups. This can make it difficult to effectively and consistently aggregate data. Determining who in the company is responsible for each piece of information can make it easier to collect data and ensure the process is repeatable. Smaller companies might not have an employee dedicated to tracking the laws. Instead, it might just be a part of one employee’s duties. Keeping up with new or changing rules could become overwhelming. Many companies that have limited resources worry they might miss something because new rules are being put in place so quickly. It’s dynamic.
Given the complexity and disparate nature of state regulations, pharmaceutical companies should determine who owns the data. We have found that the information needed to comply with state laws often resides in multiple systems within a variety of groups. This can make it difficult to effectively and consistently aggregate data. Determining who in the company is responsible for each piece of information can make it easier to collect data and ensure the process is repeatable. Smaller companies might not have an employee dedicated to tracking the laws. Instead, it might just be a part of one employee’s duties. Keeping up with new or changing rules could become overwhelming. Many companies that have limited resources worry they might miss something because new rules are being put in place so quickly. It’s dynamic. Develop processes to manage the complexity of each regulation: It can be difficult to stay on top of new state laws and changing regulations. Many states provide regular updates or frequently asked questions (FAQs) on their websites. An automatically updated central repository for rules and requirements could include the regulations, key elements (e.g., implementation dates and fines), and legal interpretations. This can ensure that information is organized consistently across the states. This could help serve as an audit trail for the overall process from the determination through the reporting.
Management of drug pricing is becoming more complex and government scrutiny is increasing. Transparency requirements are one more aspect of pricing that requires strong insight from analytics and system interoperability. There are broad implications of wholesale acquisition cost (WAC) price actions on product-lifecycle planning, launch strategies, and contracting. This changing landscape means pharmaceutical companies should build stronger compliance and reporting operations supported by automation and analytics to inform the impacts of state regulations on pricing strategy.
1. Executive order on lowering drug prices by putting America first, The White House, September 13, 2020An article by Michelle Canaan, insurance research leader, Deloitte Center for Financial Services, Deloitte Services LP, and Prachi Ashani, insurance senior analyst, Deloitte Center for Financial Services
Global financing of InsurTechs continued to surge with a record $5 billion invested during 2019, which is only five percent shy of the prior two years combined. However, while $19.2 billion has poured into the sector over the past decade, investments have almost exclusively been devoted to the property-casualty side of the business...Continue readingTo help bolster my resume, I quickly studied and became a Microsoft Certified Professional. I figured I was a shoo-in for this entry-level job. Turned out, the school system was Novell-based. I wasn’t hired.
A couple of weeks later I received a phone call from the person who had interviewed me for the position. He called me first because my last name was alphabetically the first on the list of candidates. One of the people he had hired hadn’t shown up on the first day of work. He offered me the job.
It may sound simple. But throughout my career, I’ve succeeded and moved forward in part because people around me know that I’ll be there, I’ll say yes, and I will do what I promise.
In fact, that’s how I ended up at Deloitte. In the years after I was hired for that first IT job, I grew my skills to encompass a range of capabilities, particularly in Cyber Risk. I moved out of the public school system and into the private sector. One day, a previous manager of mine called. He had taken a job at Deloitte and asked if I could meet him and a Deloitte partner at Starbucks. I showed up. And soon after that meeting I showed up for my first Deloitte client, ready to dive into the world of consulting.
In my work in Cyber Risk at Deloitte Risk and Financial Advisory, I have to show up every day for my clients. After all, they have hackers and other threats showing up at their digital doorsteps every day. It’s my job to help them be secure, vigilant, and resilient. If I don’t show up, problems will.
My colleagues and clients know that they can count on me to show up with the right solutions to new challenges. In 2009, I spearheaded the first implementation of SailPoint solutions for one of our clients. To make sure it went smoothly, I spent day and night learning everything I could to become an expert in the SailPoint products. Today I manage Deloitte’s alliance with that vendor—an alliance that we expect to yield more than $50 million in revenues next year.
Make no mistake. Success in this (and any) profession requires a vision of what you want to achieve and many steps along the way in order to get there. I took the long road to a career at Deloitte.
But as you fix your eyes on where you want to be tomorrow, don’t forget to show up where you need to be today.
Anthony J. Berg joined Deloitte’s Cyber Risk practice in 2009. He is the father of six children and his family lives on a hobby farm in north Georgia where they homeschool their kids, raise a few chickens, and Anthony builds furniture. Read more about his career journey.January 16, 2018 Imagine yourself in a beautiful, serene forest populated by many kinds of wildlife. As you take in the flora and fauna, you learn about an urgent matter demanding your attention: the animals are quickly succumbing to an unknown illness. It’s up to you to figure out what to do—and then act quickly to protect what you can.
In November, 520 recruiting candidates found themselves in just this scenario, on their computer screens. They were at our London testing site immersed in a digital, scenario-based assessment designed to understand and measure how they approach and solve problems—in other words, the type of thinking our own people do every day.
As the needs of McKinsey’s clients evolve, our firm is evolving as well, through both acquisitions and organic growth, and we are broadening the types of talent we recruit, including data scientists, implementation practitioners, IT experts, product and digital designers, and software developers.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com Screenshot from “Build a reef” scenario
McKinsey’s standard recruiting process involves evaluating résumés, administering a multiple-choice test, and then interviewing select candidates. “But the multiple-choice test has limitations,” explains Keith McNulty, McKinsey’s global director of people analytics and measurement. “Recruiting only knows if candidates got the right answer, not how they approached the question. Plus, there’s a large amount of strategy, preparation, and luck involved in multiple-choice tests, and if you use them in the selection process, it reinforces the status quo—at a time when you are looking to widen the scope of candidates you’re hiring.”
Our firm has deep experience using in-person, scenario-based assessments (such as case interviews) in recruiting. Yet we miss more nuanced perspectives on the skills of some candidates and miss out on other candidates completely because we can’t meet everyone in person. McKinsey began investigating this problem in collaboration with a start-up called Imbellus, which has a team of data scientists, engineers, and psychometricians who aspire to replace traditional standardized tests and are committed, above all, to science. We also enlisted the help of UCLA’s National Center for Research on Evaluation, Standards, and Student Testing (CRESST) to help identify and measure the skills we need.
The result of this collaboration is a new scenario-based assessment designed to help our firm attract new and different talent profiles from all parts of the world. It not only evaluates candidates in a lower-stress, more engaging environment than a traditional test does but levels the playing field by minimizing the influence of a candidate’s background.
It also provides a lot more insight into a person’s skills. When people analytics are applied to the test results of hundreds of recruits—a fast-growing data set—it can not only help determine whether a candidate is creative but also provide an understanding of a deeper subset of skills. How does this person absorb information? Is he or she an idea generator? Does he take an unusual approach to situations? Is she methodical in her analysis—or tend to follow intuition? Can he easily manage multiple factors? “When people join our firm, we can be more intelligent about placing them in a position—and on a course—that makes sense,” says Keith. “This approach offers, potentially, hundreds of different readings on a candidate and provides literally an anthology of skills.”
What’s next? The team is expanding the pilot to other geographies to collect additional data points before the assessment becomes a formal part of McKinsey’s recruiting practices. Another goal, in the next few years, is to make the assessment available online so we can understand candidates’ skill profiles without bringing them into the office. “This will especially help recruiting in emerging markets,” says Keith. “As a firm, we’re reinventing ourselves and becoming more diverse to benefit our clients. So if the way we serve clients is constantly evolving, our recruitment processes have to as well.”
Meanwhile, back in the forest, more and more animals are exhibiting symptoms, and time is running out. Our candidate chooses a course of action, and the diagnosis is revealed—and so is a way forward for the candidate at McKinsey.March 11, 2019 A national sales organization approached McKinsey with a talent problem. With record low unemployment and higher rates of attrition among its sales people, the organization was struggling to maintain its desired pace of growth while still making high-quality hires. While many organizations often find it quicker and easier to simply add more assessments to the hiring process, the client here wanted a more objective and data-driven approach—one that begins with a clear definition and measure of job performance.
Encouraging the client to start with the end state in mind (i.e., a clear definition of job performance) before adding more assessments may go against instincts to make quick and decisive talent decisions. However, it is critically important to ensure you think carefully about key performance criteria for different roles in order to avoid costly hiring mistakes at scale. The results from this approach are clear: The client realized a 40 percent increase in the quality of hires and a 12 percent decrease in first year attrition after they became more thoughtful and data-driven about hiring.
The client realized a 40 percent increase in the quality of hires and a 12 percent decrease in first year attrition after they became more thoughtful and data-driven about hiring.
This second part of our three-part series dives deeper into three specific steps organizations should take to be more thoughtful about hiring. In the process, we provide solutions to address two common hiring problems we identified in our previous post: the difficulty of measuring performance and the ill-defined view of what success looks like in different roles.
Job performance seems like a simple concept, but it’s surprisingly hard to define and measure for many roles. To help frame the discussion, it’s helpful to think about the ‘what’s and ‘how’s of performance.
The ‘what’s, more formally described as task performance, capture the core technical aspects of a role. For example, for an HR professional, task performance may encompass resolving employee relations issues, designing and executing new hire orientations, and organizing recruiting activities.
The ‘how’s, or contextual performance, refer to the fashion in which technical work is executed. This may include maintaining a positive attitude, volunteering for non-role tasks, and helping and supporting others. While the ‘what’s are role-specific, the ‘how’s will likely be consistent across the organization and should reflect core values and unique means of “getting things done.”
It’s important to consider a holistic view of performance that accounts for both ‘what’s and ‘how’s that drive distinctive value for the organization. For instance, maybe Joe, a sales manager, has the best sales numbers in the company (‘what’s), but he also fails to mentor new salespeople and actually has pushed people to quit based on his toxic behavior (‘how’s). In getting more concrete about performance, organizations need to think carefully about the ‘what’s and ‘how’s of performance and the trade-offs that may exist between them.
In today’s organizations, the challenge is rarely finding performance data—we have far more data than ever—but rather in identifying the “right data” for a given role that accurately captures an individual’s unique contribution to the achievement of organizational goals. Any single measure of performance is likely to be flawed in some way. For this reason, we recommend trying to acquire and combine several different data sources to prove someone is a high performer.
For example, it is well known that sales revenue numbers are significantly impacted by a salesperson’s assigned region. Overreliance on revenue numbers alone would therefore create a potentially biased, erroneous view of who the best salesperson is. When combined with data also showing that this salesperson makes 10 percent more cold calls to generate leads than colleagues, we solidify our view that this person is indeed a high performer.
The business landscape is constantly changing; what works today will not necessarily work one year from now. For that reason, it’s crucial for organizations to continually track and measure all new hires’ performance alongside their hiring assessment results to ensure that the criteria that predicted performance last year continues to do so. If not, it may be time to start back at step one—but this decision can only be made based on accurate, up-to-date data. In the case of the sales organization, not only were we able to reinvent their hiring approach based on a deeper understanding of high performers, but we also created the data and analytics infrastructure to allow for ongoing monitoring and optimization that will serve them well for years to come.
This second part of our blog series has made the case for being thoughtful about defining performance and capturing what success means for a given role. In the final post of this series, we’ll tackle the practical issue of how to select assessments that drive lasting value.A blog post by William Pollard, partner, Deloitte Risk and Financial Advisory and Samantha Parish, principal, Deloitte Risk and Financial Advisory
At a time when practically every detail, major and minor, is being captured in company data, businesses now can take a new, technology-enabled approach to internal fraud investigations: One that's more consistent, defensible, and efficient. Here's a quick look at five insights from our new report on tech-enabled ways to combat fraud:
Different types of investigations are often necessarily conducted by different departments in an organization with limited, if any, coordination or communication among them. The resulting lack of integration can cause potential fraud risks to be missed, improperly identified, and under analyzed. Cross-functional processes and technologies – like shared case management software and data sensing tools – can help internal investigators identify, communicate, and analyze issues through a broader lens. And this can ultimately lead to a better understanding of the true nature and scope of the fraud.
While the use of technology in investigations isn't new, the rapidly expanding and accelerating role of technology and data in personal and professional lives is. When virtually every action people take is being captured digitally, finding the fraud in ever-increasing data sets and sizes is an inherent challenge. It becomes increasingly important to apply a diverse portfolio of tech-enabled investigative techniques and approaches – from business queries to digital due diligence to data analytics.
The types of behaviors underlying fraudulent activities can be reverse-engineered by investigations, data, and business specialists to develop predictive models. If a company clearly understands what constitutes "bad behavior" among its employees, vendors, and other stakeholders, the results of tech-enabled investigations can be used to design algorithms that can predict, detect, and ultimately help prevent that behavior.
It's not unusual for multinational organizations to conduct tens or even hundreds of simultaneous investigations that, on the surface, have no connection to each other. But what if forensic, data, and business professionals in an organization could connect the dots between investigations? What if data sets could be harnessed to identify patterns or trends across the organization? With new tech-enabled investigation capabilities, organizations can develop a broad-based risk profile supported by a library of risk issues that enables the shift from reactive to proactive – and eventually to predictive fraud risk management.
With tech-enabled investigation capabilities, an organization can bring people, processes, and technologies together to seek out and respond to rare events that can cripple the organization. Organizations with predictive capabilities could find problems before they become systemic. And if a rare event does go undetected, the learning's from the event can be applied to preventive measures for the future.
In the fight against internal fraud and misconduct, it's important to remember that data science on its own won't make you victorious. Effective investigations require more than just the right technology support, they need humans with a strong understanding of data science, business, and criminal behavior.
To learn more about how your organization can harness investigation capabilities for accelerated performance, check out Deloitte's Tech-Enabled Investigations Spark Experience.
And please take a moment to comment below or send me a message. I'd like to hear your insights and experiences on using technology-enabled approaches to combat fraud.Our everyday experiences suggest that with other products—such as online commerce, ride-sharing services, or even person-to-person payments and online lending—account opening is generally smoother and quicker. Based on experiences in other domains, consumers, especially Millennials, want more from banks.
However, it might seem that banks cannot do much to improve the account opening experience given the constraints they face.
But is there an empirical justification for this view? We, at the Deloitte Center for Financial Services, decided to find out, using a detailed survey among 3,000 consumers. Some of the findings are shown below. The most notable insight is that even though many consumers are satisfied with the account opening experience with banks, a fair number of consumers, especially Millennials, think the process can be improved.
You may also see this report for more of the survey findings and on what we believe banks can do meet customer expectations in this area. Hint: speed and follow-up.
Please let us know what you think. Do you think banks can do a better job improving the account opening experience, and, if so, how?Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.November 26, 2018 A healthcare organization going through a massive transformation had to assess and consider more than 2,000 high-potential employees for more than 100 critical positions. By identifying the 45 most critical value-adding roles and defining markers for success supported by people analytics, it was able to build a unique competency model tailored toward its values.
For large enterprises that must match many employees to new roles, properly realigning talent to available and high-value positions proves especially daunting and game-changing. The first step requires gaining strategic clarity on the value agenda.
To compete in today’s competitive, disruptive environment and drive business value requires focusing on talent to ensure that the right employee is matched to the right role that will ultimately create the most value.
While this talent alignment is challenging, when it’s done right, rapidly and at scale by a large organization, the outcome can prove to be a significant performance differentiator. These organizations tend to outperform competitors 2-to-1, based on our research.
Taking a more organized approach to talent matching as part of a major digital transformation triggers several advantages:
Time: Faced with hundreds – and often thousands – of employees and roles, a more organized approach saves time when the information is at your fingertips.
Access: Collecting the data and datapoints for each position, as well as the organization’s leaders, digitally is far easier to peruse vs. poring over binders.
Effectiveness: Tactically, keeping track of the myriad choices you make during a digital transformation is difficult. Having a visual means for keeping track of options vs. choices makes clear the impact being made.
Applying this approach ensures that this process, which must occur no matter what, happens in the most effective way.
Whether a company is entering a new market, identifying ways to cut costs or becoming nimbler, HR business partners (HRBPs) must find more effective ways to deploy talent. When proper and efficient talent-matching practices are missing, filling roles rapidly can become a popularity contest. Positions are filled based on who knows who – which can lead to unconscious bias – rather than on identifying the best candidate.
Redeploying talent in a value-focused manner is essential. It must consider knowledge, skills, intrinsic traits and experiences to match the candidates best for each role. We recommend taking these steps:
Understand your value agenda. Begin by aligning with your organization’s ambition and deconstructing what will drive value across departments.
Identify the most important roles. Without an understanding of the most critical roles based on the value agenda and what matters most in each, it becomes virtually impossible to make informed, strategic decisions. Determine what experiences, skills and traits are needed and back it up with data about your talent pool.
When choosing the best candidate for any given critical role, you will need to understand what is required to succeed in that role.
Get the right talent in the right roles. Assess fit and match talent that reflects each role’s markers for success. It’s important to identify your top talent and ensure this stems directly out of the performance management process, using as much data as possible to understand the fit of the employee.
Solutions such as McKinsey & Company’s Talent Match can prove especially useful for aggregating data and supporting recommendations. The tool helped one client develop a companywide database of high potentials – identifying future leaders, enabling talent mobility and highlighting top candidates for each job.
By taking a methodical, visual and data-supported approach to making human capital decisions at scale, the benefits abound for large organizations. This approach saves time and simplifies the process. It also can help organizations combat unconscious bias, enabling leaders to keep track of the available options versus the actual choices that were made.Businesses need to learn innovating, although implementation of new solutions may be risky, difficult and bring unpredictable effects. In the beginning, performance may be lower than expected, or different, but mistakes are good teachers. Using proven methods, we can mitigate risks and learn faster.
Innovation does not “happen”; it is not the question of money, either. In order to prepare ground for innovation, an organization should focus on changing its own business and make it client-centric, developing creativity-fostering environment for its employees, at the same time giving them enough time and relevant tools.
Innovation stems from actual needs of people, which are defined based on observation, research, brainstorming and on testing of new ideas. The approach reduces the risk related to new solutions and increases the probability of success.To a growing percentage of workers, work is an activity, not a place. The unprecedented nature of COVID-19 has accelerated this trend and forced many companies to adopt a virtual, remote work model to keep business moving. Many organizations are looking to their leadership to build a virtual engagement framework that defines the future of work. But establishing an effective framework may also mean shedding conventions that can hinder success.
A holistic virtual engagement framework can help redefine how work is done, as well as ensure that workers understand their roles and responsibilities and have the support they need. With a virtual engagement framework, it’s possible for workers to be as, or even more, productive than they are with in-office work models.
Employers must nurture talent while improving productivity, so a sound strategy is key to get leadership to agree on the direction and key decisions.
Business drivers : It’s crucial to outline the case for virtual engagement—perhaps operational resilience or improved customer engagement. It’s also key to communicate the benefits—such as increased quality, autonomy, and performance—that talent will realize.
: It’s crucial to outline the case for virtual engagement—perhaps operational resilience or improved customer engagement. It’s also key to communicate the benefits—such as increased quality, autonomy, and performance—that talent will realize. Funding: Securing proper funding is also critical. Standing up virtual engagement may require increased funding in the short term, so any strategy should include that possibility. Funding might be secured more easily if it’s collectively advocated for across talent, technology, and tools. Remember, underfunded efforts often fail, but they can also cost more in the long run since doing it wrong means paying to fix it later.
Securing proper funding is also critical. Standing up virtual engagement may require increased funding in the short term, so any strategy should include that possibility. Funding might be secured more easily if it’s collectively advocated for across talent, technology, and tools. Remember, underfunded efforts often fail, but they can also cost more in the long run since doing it wrong means paying to fix it later. Measuring value: As The Phoenix Project articulates, there are four types of work: business projects, internal projects, operational change, and unplanned work. Unplanned work can stall everything else, which affects the delivery of projects, the deployment of changes, and almost always takes the organization away from meeting goals. Help reduce unplanned work by: visualizing all work to be done (see the section titled, “End-User Computing,” for more), mapping all the actions that should be taken to bring value to the business, eliminating non-value added efforts or work all together, constructing immediate feedback loops, leaving team capacity for the team to solve the problem permanently, and completing tasks rather than increasing the work in progress.
When workers work remotely, working norms change, but those changes can be overlooked. For example, workers need to feel engaged, but that engagement can happen outside the office. So, management must adjust how work is done to accommodate the evolving workforce.
Setting the tone: Leaders in the office typically create the virtual environment that increases productivity as well as worker satisfaction. Work culture should be outcome-driven to empower and hold teams accountable for progress. One caveat: success in a virtual setting doesn’t equate with compulsory oversight; instead, it may require consistent pulse checks, feedback loops, and informal engagement to monitor team effectiveness and personal performance.
Leaders in the office typically create the virtual environment that increases productivity as well as worker satisfaction. Work culture should be outcome-driven to empower and hold teams accountable for progress. One caveat: success in a virtual setting doesn’t equate with compulsory oversight; instead, it may require consistent pulse checks, feedback loops, and informal engagement to monitor team effectiveness and personal performance. Communication: Misalignment on communication is a leading reason virtual engagement models aren’t effective. So, it’s essential to choose the right tools for each scenario to minimize work interruptions and drive productivity. Close collaboration between Business, Technology, Information Security to select tools and deploy effectively is a comprehensive effort from training to ways of working. Once tools are selected, establish which channels to use for different needs (e.g., a 1:1 call to catch up, encrypted email for sensitive information or large status updates, chats for quick questions or decisions, and collaboration tools for working sessions).
Misalignment on communication is a leading reason virtual engagement models aren’t effective. So, it’s essential to choose the right tools for each scenario to minimize work interruptions and drive productivity. Close collaboration between Business, Technology, Information Security to select tools and deploy effectively is a comprehensive effort from training to ways of working. Once tools are selected, establish which channels to use for different needs (e.g., a 1:1 call to catch up, encrypted email for sensitive information or large status updates, chats for quick questions or decisions, and collaboration tools for working sessions). Keeping on track: Moving to remote working capabilities means establishing new routines, as well as understanding workers’ daily rhythms. Small, cross-functional teams with clear objectives and a common purpose can keep everyone on the same strategic course.
Talent is the fulcrum of remote work so it’s vital to fully involve workers in the process of creating a virtual engagement framework. Leadership should welcome ideas and details from across the workforce. For example, there might be specific needs or tools that centralized talent groups may not have considered that could amplify teams’ ability to do their jobs. Some key areas to consider are:
Expectations: Leadership and workers can work together to structure expectations on working remotely, including work schedules (e.g., regular, ad hoc, unscheduled, non-consecutive days), duration of virtual engagement, and which roles are considered essential or mission critical.
Leadership and workers can work together to structure expectations on working remotely, including work schedules (e.g., regular, ad hoc, unscheduled, non-consecutive days), duration of virtual engagement, and which roles are considered essential or mission critical. Eligibility: Many traditional occupations are being disrupted by automation, virtualization, or the gig economy. For example, chatbots are taking on increased volume of customer service questions, software engineers are collaborating albeit dispersed across the country, and consultants are picking up ‘gigs’ to increase exposure to different projects. Leadership and workforce representatives can work together to establish criteria for remote-working eligibility that align with business drivers. Start by breaking down job tasks that can be performed remotely. Then review previous performance experience and define the alternative workspace and equipment. These components serve as a foundation for a modernized model where talent has increased flexibility while being effectively supported.
Many traditional occupations are being disrupted by automation, virtualization, or the gig economy. For example, chatbots are taking on increased volume of customer service questions, software engineers are collaborating albeit dispersed across the country, and consultants are picking up ‘gigs’ to increase exposure to different projects. Leadership and workforce representatives can work together to establish criteria for remote-working eligibility that align with business drivers. Start by breaking down job tasks that can be performed remotely. Then review previous performance experience and define the alternative workspace and equipment. These components serve as a foundation for a modernized model where talent has increased flexibility while being effectively supported. Work time: With virtual engagement, work time can be anytime. Therefore, it’s necessary to redefine core business hours across time zones and service-level agreements, as well as to establish appropriate response times for decisions, deliverables and/or requests for operational roles, so that talent is supported while still effectively meeting customer needs.
With virtual engagement, work time can be anytime. Therefore, it’s necessary to redefine core business hours across time zones and service-level agreements, as well as to establish appropriate response times for decisions, deliverables and/or requests for operational roles, so that talent is supported while still effectively meeting customer needs. Expenses: Virtual engagement can be seen as a mirror of the centralized office, so organizations must determine how expenses are allocated and charged for remote workers—including internet, office space, electricity, and other relevant costs (e.g., travel to alternate worksites).
Virtual engagement can be seen as a mirror of the centralized office, so organizations must determine how expenses are allocated and charged for remote workers—including internet, office space, electricity, and other relevant costs (e.g., travel to alternate worksites). Engagement: Managers should be encouraged to have positive, non-work related interactions with workers. All employees need to feel appreciated and inspired, regardless of their physical location. Leaders set expectations on how and when teams engage with each other, and with leaders. Be mindful about access and availability to encourage productivity and well-being, however. Examples include conducting 15-minute check-ins with team members, encouraging video conferencing for working sessions, or establishing light-hearted themes for informal meetings to keep team members engaged.
Remote work no longer equals simply working from home. Now, work can be anywhere from a coffee shop to an airport. To enable and scale a secure remote working experience, there are three critical components for organizations to consider: software-defined networking in a wide area network (SD-WAN), client certificates, and virtual desktop infrastructure.
Software-defined wide area network (SD-WAN): An SD-WAN architecture can improve network performance as demand patterns change. For example, SD-WAN split tunneling can segment different types of network data traffic. The branching prevents bottlenecks in the data center by deciding what traffic to keep in and what to keep out. Another key to scalability is stress testing the network to plan for volume demand changes and understand the organization’s remote networking capacity.
An SD-WAN architecture can improve network performance as demand patterns change. For example, SD-WAN split tunneling can segment different types of network data traffic. The branching prevents bottlenecks in the data center by deciding what traffic to keep in and what to keep out. Another key to scalability is stress testing the network to plan for volume demand changes and understand the organization’s remote networking capacity. Client certificates: Secure sign-on capability is a fundamental issue in remote work. Single sign-on (SSO) can be insecure, while multi-factor authentication (MFA) can be frustrating to workers. One potential compromise is the use of client certificates—a process in which IT generates a certificate that is unique to that user (client) and installed on their device. Client certificates are defined as multi-factor because they are installed on a password-protected device with a unique certificate. Yet, the authentication is treated as an SSO, because the user takes no action on the client certificate. And, if the user's device is stolen, the certificate can be revoked, and the device can no longer authenticate for remote access.
Secure sign-on capability is a fundamental issue in remote work. Single sign-on (SSO) can be insecure, while multi-factor authentication (MFA) can be frustrating to workers. One potential compromise is the use of client certificates—a process in which IT generates a certificate that is unique to that user (client) and installed on their device. Client certificates are defined as multi-factor because they are installed on a password-protected device with a unique certificate. Yet, the authentication is treated as an SSO, because the user takes no action on the client certificate. And, if the user's device is stolen, the certificate can be revoked, and the device can no longer authenticate for remote access. Virtual desktop infrastructure (VDI): Unlike the decentralized management model of a VPN, VDI manages devices on a central server. It can help rapidly recover desktops and images of devices if a user machine fails. Companies can allow users to access VDI from any device, since data stays in the data center. However, greater flexibility for end-users comes at the cost of design, planning, and preparation to implement. VDI often demands a surge in processing power, storage, and memory to scale with high performance compared to VPN. Further, some applications can require configurations and settings specific to individual companies, customers, and divisions. These use cases pose challenges for IT management. The key is to work across the organization to operate at a consistent level of security and access.
The final component of a virtual engagement framework is end-user computing. More than ever, workers rely on all sorts of technology. Access to multiple tools—especially those used for collaboration—is vital in keeping everyone on track, but it’s important to get the basics right. Providing access to collaboration tools, complemented with training, sets up the workforce for success.
Upskilling: Current skills matter often less than the ability to learn new ones. Workers are responsible for becoming familiar with collaborative platforms. However, organizations also bear responsibility for providing education on tools. To encourage tool use, identify opportunities to utilize tools at your disposal so members can gain experience and discover new features.
Current skills matter often less than the ability to learn new ones. Workers are responsible for becoming familiar with collaborative platforms. However, organizations also bear responsibility for providing education on tools. To encourage tool use, identify opportunities to utilize tools at your disposal so members can gain experience and discover new features. Project or backlog management tools: Making work—including knowledge, culture, workflows, and security—visible to the team creates a platform for continued engagement and collaboration. Team-wide access to management tools should be encouraged so teams can visualize the progression of work, track tasks, and create transparency.
Making work—including knowledge, culture, workflows, and security—visible to the team creates a platform for continued engagement and collaboration. Team-wide access to management tools should be encouraged so teams can visualize the progression of work, track tasks, and create transparency. Collaboration tools: Tools to enable collaboration are also essential. Workers must be able to share files, chat in real-time, and collaborate virtually on projects. It’s also necessary to enable video and conference calls through the collaboration system for a comprehensive collaboration platform. A unified system helps teams keep track of documents, work in progress, conversations without having to technology switch constantly throughout the day.
Tools to enable collaboration are also essential. Workers must be able to share files, chat in real-time, and collaborate virtually on projects. It’s also necessary to enable video and conference calls through the collaboration system for a comprehensive collaboration platform. A unified system helps teams keep track of documents, work in progress, conversations without having to technology switch constantly throughout the day. Video chat and messaging: Periodic face-to-face time is essential to maintain team cohesion. The ability to conduct video conferencing across any device helps teams become acclimated to operating in a virtual environment and helps enable more productive conversations between teams and with clients. However, using these tools requires team-wide coordination and focus to stay on track and topic.
Periodic face-to-face time is essential to maintain team cohesion. The ability to conduct video conferencing across any device helps teams become acclimated to operating in a virtual environment and helps enable more productive conversations between teams and with clients. However, using these tools requires team-wide coordination and focus to stay on track and topic. Calendars: Work can happen anytime as well as anywhere, so it’s key to update enterprise calendars to help workers to reflect true working hours. It’s also a good idea to encourage—and institutionalize respect for—dedicated focus time so that workers can be optimally effective.
As with all change, unifying on the purpose and vision of virtual engagement drives a successful execution. Funding and technology underpin the virtual engagement framework. However, turning leaders across business, talent, security and technology into champions of virtual engagement often requires convincing them that productivity and performance will increase. Organizations that master virtual engagement will help transform the future of work by capturing diverse talent, enhancing productivity, and strategically reducing costs, while creating an organization that employees are more than happy to work for.Combines knowledge of digital with extensive experience in IT strategy and transformation to advise clients on all dimensions of digital, agile, and advanced analytics
Sid is an expert in the Ops practice with extensive experience in helping clients solve problems using digital, analytics, and lean Six Sigma tools.
October 18, 2019 Imagine a future where smart robots assemble products from multiple manufacturing lines by physically reconfiguring themselves on the factory floor. Security drones handle tedious tasks ranging from monitoring for intruders to validating employee parking. Autonomous vehicles transport parts not only between buildings, but also across the country. And factory inspections are performed remotely from a thousand miles away.
Just a few years ago, these were impossible dreams reserved for the realms of science fiction. But with the arrival of 5G connectivity, combined with advances in artificial intelligence (AI) and cloud computing, these dreams are becoming increasingly attainable for today’s manufacturing organizations.
The hype is intense. With data speeds slated to be 25 times faster than today’s 4G networks and lag reduced to virtually zero, 5G appears to promise unending opportunities to strengthen connectivity and digitization—both within factories’ four walls, and beyond them at every step along the entire value chain.
But which potential applications deserve manufacturers’ attention? Five show particularly strong potential for boosting factory productivity:
Cloud control of machines —For decades, factory automation has relied on programmable logic controllers (PLCs) that were physically installed on (or very near) the machines they controlled, and then hard-wired into computer networks to ensure precise, reliable control under extreme conditions. If 5G consistently meets its performance promises, the PLC could be virtualized in the cloud, enabling machines to be controlled wirelessly in real time at a fraction of the current cost.
—For decades, factory automation has relied on programmable logic controllers (PLCs) that were physically installed on (or very near) the machines they controlled, and then hard-wired into computer networks to ensure precise, reliable control under extreme conditions. If 5G consistently meets its performance promises, the PLC could be virtualized in the cloud, enabling machines to be controlled wirelessly in real time at a fraction of the current cost. Augmented reality —Factory workers are no strangers to performing complex maintenance and control tasks, often guided by standard operating procedures (SOPs) in paper manuals, videos, or—in some cases—even augmented reality. But instructions streamed over 4G networks can be unreliable due to bandwidth constraints, and fail to deliver the required levels of quality without stuttering. 5G promises not only the streaming of high-quality instructions on the shop floor, but also stutter-free augmented reality that can guide people, step by step, through each individual motion they need to make. This will allow shop-floor workers to undertake advanced tasks without waiting for specialist engineers or incurring costly machine downtime. The best knowledge and work instructions can therefore be shared with all workers exactly when they need it, building worker skills more quickly, safely, and effectively than ever before.
—Factory workers are no strangers to performing complex maintenance and control tasks, often guided by standard operating procedures (SOPs) in paper manuals, videos, or—in some cases—even augmented reality. But instructions streamed over 4G networks can be unreliable due to bandwidth constraints, and fail to deliver the required levels of quality without stuttering. 5G promises not only the streaming of high-quality instructions on the shop floor, but also stutter-free augmented reality that can guide people, step by step, through each individual motion they need to make. This will allow shop-floor workers to undertake advanced tasks without waiting for specialist engineers or incurring costly machine downtime. The best knowledge and work instructions can therefore be shared with all workers exactly when they need it, building worker skills more quickly, safely, and effectively than ever before. Perceptive AI eyes on the factory floor —Cameras are already common in modern factories to monitor processes and security. However, their use is limited to focused applications and often requires workers to monitor video feeds. 5G will allow the streaming of data in real time to the cloud, and the use of live video analytics. For example, a security camera could see a disturbance, identify if there is an imminent threat or danger, and dispatch a drone or alert a worker to investigate. Alternatively, the same security camera could provide a more efficient mechanism to measure cycle times and monitor process deviations.
—Cameras are already common in modern factories to monitor processes and security. However, their use is limited to focused applications and often requires workers to monitor video feeds. 5G will allow the streaming of data in real time to the cloud, and the use of live video analytics. For example, a security camera could see a disturbance, identify if there is an imminent threat or danger, and dispatch a drone or alert a worker to investigate. Alternatively, the same security camera could provide a more efficient mechanism to measure cycle times and monitor process deviations. High-speed decisioning —The best-run factories rely on vast data pools to make decisions—with inevitable delays as data is collected, cleaned, and analyzed. 5G speeds up the decision-cycle time, allowing massive amounts of data to be ingested, processed, and actioned in near real time. In several heavy industries, for example, manufacturers have been able to sell excess energy back to the grid when machines aren’t running and prices are favorable.
—The best-run factories rely on vast data pools to make decisions—with inevitable delays as data is collected, cleaned, and analyzed. 5G speeds up the decision-cycle time, allowing massive amounts of data to be ingested, processed, and actioned in near real time. In several heavy industries, for example, manufacturers have been able to sell excess energy back to the grid when machines aren’t running and prices are favorable. Shop floor Internet of Things—The addition of sensors to multiple machines means factories are creating more data than ever before. Transmission through wired networks is expensive to scale, and Wi-Fi networks can quickly get congested—as anyone who has tried to connect to public Wi-Fi networks can attest to. 5G has the ability to support high connection density with tens of thousands of endpoints, thereby truly enabling the use of industrial data at scale.
These technologies are all still at an early stage of testing, but the pilots undertaken to date are encouraging. Long-term, one of the most intriguing effects may be on the humans who work alongside 5G. Far from creating a world of lights-out, human-free factories, industrial 5G appears more likely to allow people to move away from tasks that have previously been considered dirty, dull, and dangerous. Instead, people’s focus will shift to capturing the value made possible by the vast data harvests that 5G will enable—and that 4G could not reliably and seamlessly support at scale.We are now on the verge of the fourth industrial revolution, and business leaders have to rethink their strategies from end to end. Christian Greiser explains how BCG is partnering with companies around the world to reimagine how they approach operations in today's complex environment.A blog post by Brad Podraza, managing director, Deloitte Consulting LLP and Alec Kasuya, senior manager, Deloitte Consulting LLP
Advanced digital technologies are—and will continue to be—critical for shared services operations. A strong 90 percent of respondents to Deloitte's biennial 2019 Global Shared Services Survey agree or strongly agree that increasing digital capabilities is fundamental to achieving SSC objectives. Automation and analytics are playing a crucial role in delivering the next wave of value for shared services centers (SSCs), and as we move into the next decade, SSCs are set to evolve in ways we haven't seen before.
Increasingly, SSCs are shifting from being a "provider of what they ask for" to a generator of business value, especially as they play more of a role in strategic and interactive-heavy areas like customer service, sales and marketing support, and procurement. The overall findings fall into four major categories:
Digital adoption : Global business services (GBS) organizations are adopting digital rapidly (cloud, robotics, or single-instance ERP solutions have been implemented by more than 85 percent of respondents). They get it—this is a way to position themselves as catalysts for enterprise-wide digital transformation.
: Global business services (GBS) organizations are adopting digital rapidly (cloud, robotics, or single-instance ERP solutions have been implemented by more than 85 percent of respondents). They get it—this is a way to position themselves as catalysts for enterprise-wide digital transformation. GBS organizational structure : As organizations scale up, GBS organizations and GPO implementations become more prevalent, and the largest organizations overwhelmingly leverage GBS operating models (70 percent for companies with >$25B in revenue)
: As organizations scale up, GBS organizations and GPO implementations become more prevalent, and the largest organizations overwhelmingly leverage GBS operating models (70 percent for companies with >$25B in revenue) Cost efficiency : GBS organizations are increasingly expected to provide higher values at lower cost. Hence, cost-efficient measures like automation are top priority for GBS strategy and investments.
: GBS organizations are increasingly expected to provide higher values at lower cost. Hence, cost-efficient measures like automation are top priority for GBS strategy and investments. Location strategy: The largest global companies surveyed are driving delivery through mature markets—in India, Poland, the Philippines, Malaysia, and Costa Rica—while implementation of on/near-shore models (closer proximity to HQ) are a notable part of companies' location strategy.
In summary, we're seeing companies make big investments in SSCs. More SSCs are putting stock in automation and analytics, and we're seeing organizations use automation to reduce or eliminate transactional work. Ultimately, the data shows the realization of two predictions made in the 2017 Global Shared Services Survey report: knowledge-based processes are the growing function of SSCs and they'll do it with the help of automation and analytics.
In the earlier 2017 report, we concluded that "knowledge-based processes were on the rise." Analytics continue to play a central role in SSC's and GBS organization's business strategies. But how exactly are SSCs using analytics in 2019? Around 61 percent of SCCs we surveyed perform at least three of these six analytics processes:
As expected, global SSCs are more likely to use data analytics to gather and aggregate enterprise data (59 percent) as compared to regional SSCs (35 percent). Scale in data matters.
In 2017, when commenting on where digital technology adoption within shared services centers was heading, we heralded, "Here come the robots." The 2019 report confirms: For most SSCs, robotic process automation (RPA) has moved from being nice-to-have to a must-have. Since 2017, the number of companies that have implemented at least one end-to-end process automation has increased nearly eight-fold, with 63 percent of companies today having automated one or more end-to-end process (for companies with revenue greater than $15B, that rises to 75 percent), compared to only eight percent in 2017.
What's more, 88 percent of respondents say they plan to increase their use of robotics in the next 3-5 years, and most SSCs (53 percent) are planning to increase the use of robotics significantly.
What impact is automation having and expected to have? Around 47 percent of survey respondents reported achieving 10 percent or more in cost savings. In terms of productivity, 47 percent anticipate achieving 20 percent or more productivity increase from future RPA investments. Additionally, nearly two-thirds of respondents expect future investments in RPA to reduce or eliminate business process outsourcing and/or offshore SSCs.
Today, only 16 percent and 11 percent of respondents indicate leveraging artificial intelligence (AI) and cognitive technologies, respectively, within their SSCs. We can expect that SSCs will increasingly harness these technologies to enable them to move even faster with greater precision, to pinpoint truths that improve decision-making, and to create more beneficial customer and stakeholder experiences. All this will help further position shared services as a true driver of enterprise value.
To learn more about the state of Global Shared Services Centers, download the 11th biennial edition of the report.Fundamentally, a bot is software—a unit of capacity, a digital worker. Yet it cannot be managed like just another software application, especially when deployed by the dozens, hundreds, or even thousands. Effective digital workforce management will depend on insights from at least five key areas:
Bot performance. After a bot is deployed and work assigned to it, how will you know if the work has been completed? Is the bot delivering expected results? What happens if it gets stuck mid-task? Visibility into bot performance will be important—visibility over and above technical status that many of the vendor tools provide today.
After a bot is deployed and work assigned to it, how will you know if the work has been completed? Is the bot delivering expected results? What happens if it gets stuck mid-task? Visibility into bot performance will be important—visibility over and above technical status that many of the vendor tools provide today. Automation program performance. Beyond individual bots, how is your automation portfolio performing overall? Many organizations focus simply on the "bot count" without monitoring the efficacy of the investment. Important, high-level metrics across the portfolio should include hard and soft dollar returns on investment, full-time employee (FTE) savings, transaction volumes, automation utilization, and maintenance-related results.
Beyond individual bots, how is your automation portfolio performing overall? Many organizations focus simply on the "bot count" without monitoring the efficacy of the investment. Important, high-level metrics across the portfolio should include hard and soft dollar returns on investment, full-time employee (FTE) savings, transaction volumes, automation utilization, and maintenance-related results. License management. As your bot workforce grows, how will you level the workload across the bot population? Optimizing a digital workforce without necessarily having to scale licenses and structure involves visibility into license utilization rates for the RPA program overall, by functional area, and according to prescribed time periods such as by month or hour.
As your bot workforce grows, how will you level the workload across the bot population? Optimizing a digital workforce without necessarily having to scale licenses and structure involves visibility into license utilization rates for the RPA program overall, by functional area, and according to prescribed time periods such as by month or hour. Bot-human interaction. How will you gather input from human workers to make improvements to automation? Effective bot management should include a feedback loop whereby information about automation initiatives is shared with "the business" and they, in turn, provide insights to help troubleshoot bot issues and elevate bot performance to the next level.
How will you gather input from human workers to make improvements to automation? Effective bot management should include a feedback loop whereby information about automation initiatives is shared with "the business" and they, in turn, provide insights to help troubleshoot bot issues and elevate bot performance to the next level. Service management. For companies that use a centralized automation services model to manage bot deployment and operations, how will service levels be measured and reported on? Can service utilization and performance be tracked to identify improvement opportunities?
Visibility into, and management of, digital workforces is an emerging imperative. Tools are being developed to create visibility and governance over automation portfolios. But the bottom line is that you can't effectively manage a digital workforce as if it was a collection of apps. Bots are more like their human counterparts than software applications, so a leading practice for automation programs will be a digital labor management strategy that includes capturing, analyzing, reporting, and acting on a range of data—digital exhaust—being generated by your bot and human workforces.
Developing such a strategy and properly equipping your automation team to execute on it deserves more attention than it may be getting today.February 8, 2019 It’s something every candidate wonders about: the staffing process. How will I be paired with a team serving clients? How much say will I have in the process and outcome?
It can seem like a daunting, mysterious process until you go through it once or twice. Allow us to open the lid and explain how it really works by answering some of the most common questions we hear from applicants and new hires like you.
At McKinsey, we use an office-driven staffing model, focused on helping you build the skills, find the mentors, and strike the balance you need to succeed. Your preferences, goals, and values, and our clients’ needs will be considered every time.
When you join our firm, you’ll be paired with a professional development manager (PDM) and a formal mentor, called a Development Group Leader (DGL). These two supporters will be based in your home office/practice. They’ll guide you through staffing each time you’re looking for a new opportunity. Before you start at the firm you’ll meet with them to discuss your goals and aspirations. What do you want to learn? What types of colleagues would you like to work with? Where would you like to spend your weeks? You’ll repeat this process each time you get ready to begin a new engagement.
Early in your tenure, your PDM and DGL will encourage you to explore: topics, problem types, engagement durations, team structures, people (with different leadership styles), etc. They’ll pair you with leaders from your office or practice who will help you connect locally and become your foundation. They’ll strive to staff you in your home city at least some of the time to reduce the nights you spend away from home and help you develop the expertise and network you’ll need to serve local clients throughout your career. They’ll absolutely expect you to give input on engagements so together you find opportunities that fit with your development goals and values. They’ll also take clients’ needs into consideration as they build engagement teams.
As you advance at the firm, you’ll take more and more ownership over your staffing, but you’ll never have to go it alone. Your PDM and DGL will always be there as sounding boards, launch pads, and advocates – no matter how your interests, development goals, and lifestyle needs evolve over time.
We hear several concerns from candidates during recruiting. Here are some of the most commonly raised myths, set straight by our colleagues around the world.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Richard, associate, Operations Excellence Program, Chicago: “My experience has been that it’s somewhat difficult to get staffed internationally. To join my current engagement team in Asia Pacific (led by partners from Asia and the US), I had to show I have critical functional expertise that was not available from a local colleague. It took lots of planning, so I had plenty of time to prepare. My PDM and mentors checked my willingness multiple times to make sure this was really what I wanted. The partner leading the work made sure I understood the pros and cons to this undertaking, so I could make an informed decision; then, he spent time helping me develop a travel plan that would work for my family. My wife and daughter accompanied me to Asia during the engagement, so we enjoyed wonderful weekends at the Singapore F1 Grand Prix, Singapore Universal Studio, and Shanghai Disney.”
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Swati, engagement manager, Mumbai: “During my second year as an engagement manager, I needed a break. I enrolled in ’Take Time’ to spend a month pursuing my personal passions and priorities. At the same time, a new engagement was starting at one of my clients. The project team wanted to staff me immediately. I decided to continue with my personal plans, but I worried I was disappointing my clients and colleagues. I was completely wrong. Not only did my mentors understand my need to focus on my family, friends, and health, they created opportunities for me once I was back, rejuvenated and ready to rock and roll.”
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Aniket, associate, Operations Excellence Program, Chicago: “I joined McKinsey in July 2017. In early August, I suffered an acute stomach issue. After losing 30 lbs. in three weeks, and being put on a very restrictive diet, I knew I could not travel for a while. My PDM supported me by helping me find an internal knowledge development effort that allowed me to work from home. She checked in with me weekly to make sure I was recovering and still receiving enough intellectually stimulating work and coaching. Being staffed on this engagement ended up helping me develop a very strong foundation in digital operations and Industry 4.0, which I’m now using to help clients.”
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Diego, business analyst, Lima: “When I joined the firm, I was worried I’d have to staff myself. It’s been completely different. I’ve worked closely with partners, senior consultants and the staffing team to find engagements that would help me develop. One of my goals was to work with a diverse set of colleagues; in my three years at McKinsey, I’ve teamed with people from all continents, with areas of specialization in six industries and in four functions.”
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
YuanYuan, associate, Shanghai: “I came to McKinsey to explore industries beyond my background in consumer goods and marketing. My first engagement, however, was very similar to what I’d done in my previous job. I was a bit worried that I’d be trapped in this area. I shared my concerns with my PDM and DGL who reassured me I wouldn’t be forced to specialize. It turned out that doing something I was familiar with at the beginning was very good for my development since I could hit the ground running and focus on building my consulting tool kit. Afterwards, I got the opportunities I wanted to explore consumer-facing industries, which were way more diverse than I even imagined. I optimized the customer’s experience at a major retail bank and re-designed a non-profit education organization based on consumer insights. If anything came along I didn’t want to do, I was always free to say no and choose other opportunities.”
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Abby, associate, Singapore: “Before I went on maternity leave, I wasn’t sure whether I wanted to come back to consulting and travel leaving my little one at home. However, the transition back to work was much easier than I thought it would be. I started back in a role in the Client Development Hub, a non-client facing function, that allowed me to work from home. This helped me gain exposure to the leaders focused in consumer industries in Singapore, which led to an opportunity to join a local engagement team. With the support of my PDM and team, I was able to serve the same client for 12 months on different topics. I continued to hone my consulting toolkit and never felt like I wasn’t learning or growing. With the help of my PDM and DGL, I’ve achieved the best of both worlds: meaningful, challenging work and time at home with my son every day.”
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Mina, associate, Belgrade: “Before I joined, a lot of people asked me if I was afraid of where I might be staffed. I might have been anxious, but I’ve always had a big say in the opportunities I accept. The range of options McKinsey provides is extremely broad, which means each consultant can find whatever she or he prefers. Chances are, you’ll find several people here who share your passions and style. I sought out client work that would let me explore and found an engagement based in my home office that took me to three continents. That was perfect for me. Other colleagues have stayed closer to home or focused on varying the people with whom they work. There’s no right or wrong way to make your own path in McKinsey.”Intercompany accounting, the recording, and reporting of internal financial activities is a complex system that involves not just accounting functions, but also treasury, tax, and controllership. Recent transformations to the business and financial landscape are introducing cross-function challenges into an already complicated environment—from globalization forming multi-national value chains to more regulatory scrutiny and widespread tax reform.
The tax reform act of 2017 is one of the many significant disrupters transforming the accounting process and challenging financial institutions. When we surveyed attendees during a Deloitte Dbriefs 2016 webcast, only 3.1 percent were specifically concerned with reducing fines, penalties, or unintended taxable events. In just a few years, wide-sweeping tax reform has changed the game. It may not have been top of mind then, but it’s a challenge likely on a lot of minds now.DevOps has also always been about continuous learning. As enterprises big and small matured their processes and became proficient at automating infrastructure and build processes, they started to address the next bottleneck: testing and security. Instead of handing off builds to testers or scheduling security audits that often resulted in rework, they started shifting testing and security left. Many mature enterprises have now implemented automated tests, security scanning, and analysis tools in their build process. Builds are forced to fail if various performance and regression tests fail or if security and coding standards do not receive an acceptable score from the code scanning processes. These advancements can lead to faster development, fewer meetings, higher productivity, and higher morale.
Organizations that have entered years three through five of their DevOps transformation often shift their focus from IT automation to IT transformation. They begin addressing the next level of bottlenecks: Process, compliance, and support. Shifting these bottlenecks left requires strong leadership because this is where significant shocks to organizational structures and culture occur.
At virtually any major DevOps event today, the conversation focuses largely on culture and leadership. Becoming a high performing organization is not a technology project. It is an exercise in leadership, organizational change management, and culture transformation. Any organization can automate infrastructure and IT processes. Very few enterprises seem to have the chops to undertake effective transformation.Sometimes a relatively small investment can lead to the development of a product or process that benefits a company, an industry, or even society as a whole. The three-point seat belt, for example, is a simple strap of nylon webbing that protects drivers and passengers from being injured in an accident. This innovation helped to transform safety standards in the automotive industry and has saved millions of lives.
Similarly, the pharmaceutical industry is focused on ensuring the safety of its customers and the effectiveness of its products. Drug manufacturers use numerous pharmacovigilance (PV) processes and systems to make sure their portfolio complies with government safety standards. PV is the practice of monitoring the effects of a drug after its release to identify previously unreported adverse reactions.
Some manufacturers are taking PV to the next level by making modest investments to automate processes. This can help drug makers draw new insights from safety data to reduce PV costs, improve product efficacy, and discover new combinations and cures that—like the three-point seat belt—could benefit their company, the pharma industry, and society.
Numerous industry and marketplace trends are challenging existing PV systems and processes,2 driving some pharma companies to consider more efficient and cost-effective ways to produce robust safety data and mine it for high-quality information. Deloitte recently surveyed senior executives from mid- and large-cap life sciences companies that have global portfolios of innovative therapies. We wanted to learn more about the industry’s PV practices and find out what they expect for the future. For example, some survey respondents said they are using (or considering) automation to help reduce case-processing costs and improve signaling. Here’s a closer look:
Case processing: Driving cost out of case processing was cited as the primary goal among 90 percent of our survey respondents. Case processing can account for 40 percent to 85 percent of PV budgets. Moreover, case volumes are growing at a rate of 10-15 percent per year. 3 Some manufacturers are outsourcing, taking advantage of scale, and moving aggressively to automate case processing. Survey respondents expect automation could lead to an average annual cost savings of 30 percent per Individual Case Safety Report (ICSR).
Gaining cost control over case processing, while maintaining compliance and enhancing patient safety, depends on a company’s ability to automate more of these activities. Investments into automation can increase the productivity of case-processing teams significantly. At scale, the range can be as much as 300 or 400 annual ICSRs per full-time equivalent, to 1,000 or 2,000 ICSRs per FTE. Among productivity drivers are native automation and “bolt-on” tools that can reduce the effort required to perform duplicate checks, speed up coding activities, and streamline narrative writing. However, there is limited capability to automate away entire stages within case-processing (as opposed to discrete sub-parts within stages). Further, end-to-end case automation, even for relatively simple cases, is even further from a functioning production capability, despite a number of proofs of concept being tested.
Driving cost out of case processing was cited as the primary goal among 90 percent of our survey respondents. Case processing can account for 40 percent to 85 percent of PV budgets. Moreover, case volumes are growing at a rate of 10-15 percent per year. Some manufacturers are outsourcing, taking advantage of scale, and moving aggressively to automate case processing. Survey respondents expect automation could lead to an average annual cost savings of 30 percent per Individual Case Safety Report (ICSR). Gaining cost control over case processing, while maintaining compliance and enhancing patient safety, depends on a company’s ability to automate more of these activities. Investments into automation can increase the productivity of case-processing teams significantly. At scale, the range can be as much as 300 or 400 annual ICSRs per full-time equivalent, to 1,000 or 2,000 ICSRs per FTE. Among productivity drivers are native automation and “bolt-on” tools that can reduce the effort required to perform duplicate checks, speed up coding activities, and streamline narrative writing. However, there is limited capability to automate away entire stages within case-processing (as opposed to discrete sub-parts within stages). Further, end-to-end case automation, even for relatively simple cases, is even further from a functioning production capability, despite a number of proofs of concept being tested. Signaling: Survey respondents see a broad range of opportunities to improve their signal processing and investigation maturity. Half of respondents say they plan to expand these capabilities. As pharma companies drive toward true safety management, short-term signaling investments are likely to focus on visualization and longer-term efforts related to data integration as well as tool and process improvements. Using safety information to tie back into the discovery process remains a gap due to limitations with existing signal detection and management systems. The better the data quality and consistency, the better the signal detection. The ultimate goal is predictive signaling.
Later this summer, Deloitte will release a publication that examines why and how pharma companies are investing in automation and advanced analytics. We will show how they can gain process efficiencies, free-up resources to perform higher-value activities (e.g., benefits-risk evaluation and management, signal investigation, and real-world evidence analysis), improve quality assurance, and maximize return on their PV investment. The paper also will show that even greater gains are possible if companies buckle up and expand their technology and analytics use to create a PV system that focuses on benefit/risk management and proactive surveillance across the entire product lifecycle. Like the three-point seat belt, this approach may benefit pharma companies, the life sciences industry, and society as a whole.
Request a copy of our paper or contact us to learn how Deloitte is helping our clients to achieve their vision of a transformed pharmacovigilance system.
3. According to Deloitte analysis of the survey responses. The 10-15 percent is based on historical case volumes from FDA, available at the FAERS website: https://fis.fda.gov/sense/app/d10be6bb-494e-4cd2-82e4-0135608ddc13/sheet/7a47a261-d58b-4203-a8aa-6d3021737452/state/analysisThis blog is managed by Deloitte AG, a company registered in Switzerland with registered numbers CHE-101.377.666, with a registered office at General Guisan-Quai 38, 8002 Zurich, Switzerland.
Deloitte is committed to protecting your information by handling it responsibly and safeguarding it using appropriate technical, administrative and physical security measures.
We may collect or obtain information about you that you provide to us, that we obtain from third parties or that is publicly available, or which we infer from the way you interact with us.
We may process information about you to email you relevant blog posts, event invitations and content pieces (such as reports) that are related to the Deloitte tax blog.
For more details on how Deloitte handles and shares your information and for details on your rights and how to contact us, please click here.Advises leading organizations on how to strengthen their talent-management capabilities and build an HR function that operates as a true strategic partner and value driver for the business
July 22, 2019 Recruiting top talent, improving performance management and retraining the workforce were top priorities for one tech company.
Leadership, including a new CHRO, realized the answer to their main concerns required moving to a more agile HR model and, consequently, creating levels of excitement and motivation previously absent in the organization.
Top HR talent formed a pool of "internal consultants" to support business priorities, dedicating purpose-built teams to answer the need in a cross-discipline fashion, then disbanding to work on the next priority. Employees seeking to join this pool numbered three times those accepted and one-third were outside the HR department, reflecting broader enthusiasm for the new model—which is now being adopted elsewhere in the company.
In a well-managed agile transformation, results spur employee engagement across the organization and a faster response to emerging priorities. An agile HR model enables the allocation of resources to top business needs, generating these outcomes:
Critical talent initiatives are completed faster with better outcomes and greater visibility of value delivered. In one instance, the time required to deliver a new regional sourcing strategy was 75 percent faster than before.
HR staff can focus on generating clear impact while developing a broad base of skills. Our research indicates a 20 percent boost in employee engagement scores by using an agile model.
A more flexible pool of resources typically drives a smaller overall resource level in HR, more fully utilizing those already in place and increasing productivity through agile project delivery techniques. When a European bank deployed this model, HR realized productivity of nearly 25 percent.
A centrally managed pool of HR professionals permits visibility and control over initiative development and deployment, eliminating the siloed approach typically found in traditional HR organizations.
At a foundational level, an agile organization can scale dedicated resources rapidly to propel progress on key initiatives. This has immediate relevance to HR’s mission: Driving business value through talent.
“Run” activities: HR systematically applies the same processes every time; standard processes run repeatedly by specialists.
HR systematically applies the same processes every time; standard processes run repeatedly by specialists. “Build” activities: HR seeks to improve programs, capabilities and talent initiatives via a new learning program, high-potential development pathway or sourcing strategy—all ripe for agility.
The “standard” HR organization model usually possesses three pillars: Centers of Excellence (COEs), HR business partners (HRBPs) and operations/shared services. “Run” and “build” activities can get mixed up with the first two, so an agile HR model focuses on these areas by answering two questions:
How many HR COEs comprise expertise-driven specialists, and how many concentrate on supporting execution and operations? A handful of people may provide cutting-edge expertise, but an agile staffing model generates stronger execution. Of embedded HRBPs/generalists, how many grasp the value agenda for the area they support, and how many furnish the “arms and legs” to adopt initiatives and respond to generalist questions? An agile HR model delivers more flexible staffing.
The flexible pool typically pulls from both groups: generalists that bring greater focus on how to engage business leaders for maximum impact, and junior COE resources that bring some specialized knowledge of best-practice solutions. Working together, agile HR teams offer a mix of business and HR knowledge, along with domain expertise that drives creative solutions. Simultaneously, key skills for everyone in the pool are more flexible problem-solving and initiative leadership.
Here’s how a European bank employed the agile model: It moved half of its HR resources into the pool of inner consultants working on bank priorities. It kept its COE and HRBP group, and its HR professionals’ pool supported these areas as business priorities emerged.
Exhibit We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Numerous issues must be addressed, when establishing an agile HR model, that require solid planning and change management within and outside HR. This sparks some near-term disruption, but organizations pioneering the model demonstrate that the benefits of transformation cement it as a core component of next-generation HR.A blog post by Katie Glynn, senior manager, Deloitte & Touche LLP and Anastasia Traylor, senior manager, Deloitte & Touche LLP
A manufacturing company faces a federal grand jury investigation involving intercompany cash transfers related to its tax planning.
An insurance company is forced to restate its financial results stemming from its failure to eliminate certain intercompany transactions related to variable-interest entities.
An offshore drilling company is levied fines and penalties due to untimely and incomplete filings of financial statements in a foreign jurisdiction
The costs of a fragmented, manual, and non-standardized intercompany transaction processing and accounting can be significant. It is a process that has typically evolved over time “by default” as opposed to “by design;” but an evolving financial environment and digital transformation have been a catalyst for organizations to rethink, restructure, and redesign the intercompany accounting process. Tax reform, growing regulatory scrutiny in the US and local jurisdictions, and an increased focus on operational efficiency offer a challenge and opportunity for companies to optimize the intercompany accounting process to reduce risk of regulatory and statutory non-compliance, provide for effective tax planning, and achieve a more standardized, sustainable, and cost-effective operating model enabled by technology.
Before we tackle the concepts of redesign and technology-enabled transformation, it is helpful to first highlight the components of the end-to-end intercompany accounting process and the leading practices that may align with a company’s multi-disciplinary intercompany-focused objectives from the perspective of controllership, tax, treasury, and the overall vision across a broader organization.November 11, 2019 As automation and artificial intelligence dramatically change the nature of work, employees must fine tune the social and emotional abilities machines cannot master. To encourage this behavior, employers must adjust the ways they assess, educate, train and reward their workforce on soft skills such as collaboration, communication and critical thinking.
Our previous post demonstrated the value of developing and rewarding soft skills, considering the impact of automation and AI on the workplace of the future. But what exactly are soft skills, and how can organizations meet these needs?
Soft skills, which are commonly defined as non-technical skills that enable someone to interact effectively and harmoniously with others, are vital to organizations and can impact culture, mindsets, leadership, attitudes and behaviors. These skills fall into the following categories:
Advanced communication and negotiation skills Interpersonal skills and empathy Leadership and management skills Entrepreneurship and initiative-taking Adaptability and continuous learning skills Teaching and training skills
A key difference among today’s large-scale skill shift and those in the past—including the transformative transition from agriculture to manufacturing—is the urgency for workers who exhibit these capabilities.
Reskilling at scale is a concern and priority for 80 percent of C-suite executives worldwide, according to a McKinsey survey. Reskilling significant portions of the workforce within the next 5-10 years will be required—tens of millions of mid-career, middle-age workers, particularly in advanced economies—with the development of soft skills a key element.
Developing required soft skills and ensuring employees, and in turn organizations, are set up for success isn’t as simple as popping in a training video. Instead, companies must change their employees’ processes and behaviors—a much harder task.
Assessment is an important first step. Sizing the soft skill gap proves particularly challenging, since they typically lack systematic evaluation and certification mechanisms. HR departments must be equipped with a framework that codifies soft skills and defines their respective evaluation criteria.
For example, several European firms are employing “stepping stone” initiatives to build a digital platform to help workers evaluate their soft skills, know their strengths and development needs, gain access to specific trainings, and get certified.
Effective reskilling requires blended learning journeys that mix traditional learning, including training, digital courses and job aids, with nontraditional methods, such as peer coaching. One retail giant has distributed over 17,000 virtual reality headsets that immerse employees in unfamiliar situations, such as their first Black Friday sales day, and is training them in new tech, soft skills and compliance.
People naturally operate based on incentives—they do what is rewarded. To encourage people to not only begin their soft skill learning journey but to continue with it, rewards and incentives are critical. One large advisory firm has recently implemented a series of digital badges to reward people who complete certain training sessions. Much like the progression of belts provided to martial artists, these badges serve as public recognition for others that the trainee is becoming an expert in a certain topic, thereby encouraging employees to further invest in key skills.
Given the critical need for soft skills now and in the future, training current employees is not enough. It is also crucial to ensure that new talent coming in the door is ready with the most critical skills on day one. Recruiting for soft skills can be tricky, but it generally involves structured interviews which elicit responses that include details about one’s past work and life experiences that contribute to who they are today, or situational judgment tests whereby the interviewer puts the candidate in a specific hypothetical scenario and asks how he or she would deal with it.
Employers providing soft skills training report positive impacts on their workforce, including higher productivity and improved results. As today’s skill shift accelerates, it is essential that organizations enhance and expand development initiatives for business longevity.August 17, 2020 The helix organization model, which we explored in part one and part two of this blog series, separates people-leadership tasks from day-to-day business leadership, helping organizations strike a better balance by reducing complexity and increasing flexibility, encouraging faster decision-making, and empowering employees to act.
In order to make this model a success, changes beyond the structure need to be made. The following recommendations help ensure that an organization is set up for success:
Make resource planning transparent, flexible, and focused on value The biggest advantage of the helix organization is the flexibility, which people can be shifted between value-creating areas where the organization sees the highest return on its investment. To enable this, best-in-class organizations attach this process to a quarterly priority setting process (e.g. as we see it in many agile organizations a quarterly business review “QBR”). When quarterly priorities across the value creation areas are defined, implications on resource shifts can be derived. By that value-creation leaders give capability leaders ample time to match supply to demand for skills and roles. A leading consumer goods company which struggled to compete in the market owing to slower decision making as compared to its peers achieved significant reduction in time to market by implementing the helix organization model. This organization dedicated resource allocation as one of its core priorities in the QBR at the highest level to improve its focus on value.
Create a talent marketplace Whenever shifts of resources are decided on in the resource allocation process, a transparent talent marketplace is required to staff the right people at the right time to the right topic. This requires that leaders have a detailed understanding of available human resources. Companies who do that well, have a digital marketplace, where supply and demand are listed, with a transparency on people’s profile. In larger organizations we also find new HR profiles called “Staffer,” that support the matching of supply and demand and deal with potential conflicts between value creation areas. A consumer company defined the role of a “Staffer” who staffed from skill groups to squads by matching necessary skill sets and was aligned either to a tribe or a non-tribe skill group.
Support leaders shifting their mindsets and organization’s culture Both kinds of leaders need to adapt a “we over me” mindset; value-creation leaders need to accept that management of the day to day business can work without a traditional “formal” solid people line, and need to learn how to operate in this model using other methods to align people behind the joint goal. The model also requires a stronger culture of collaboration, to align resources and business requirements in the best way, a culture of trust and partnership. Exhibit We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com An automotive company decided to take out capability managers (e.g., Head of R&D, Head of Marketing) from stage gate meetings. As a result of this, the project team members felt much more empowered to make real decisions on the process and the meetings became much faster and focused.I am currently still staffed on the first engagement I was assigned, which is a large Navy project. We now build and maintain an enterprise-level web-application used all over the world. When I first started, I was purely a functional tester, but as soon as I could, I picked up ETL testing. Now I am currently transitioning into a .NET developer role.
I was extremely nervous! When we had our project onboarding meeting, we went over a very high-level the scope of the work we do and the services we provide. Some of the technologies I had never even heard of—I felt completely out of my depth.
1. Learn as much as possible. When you get on a new project, there will be no shortage of things to learn, whether it's how the project operates, new domain knowledge, or new procedures. For example, when I first started, I spent a lot of time learning about our testing tools and methodologies, but I also had to learn the extensive change management process that was specific to our project.
2. Ask questions. It can be tough to get up to speed on a new project, but it's part of the process. No one expects everyone to know all the answers, least of all a newcomer. Asking questions of people who have been in your shoes is one of the best ways to learn what you need to know—and most of them expect it.
3. Meet people. This one does not just apply to a new project, but to Deloitte in general. Growing your network and meeting people with various skillsets can be crucial to your success at Deloitte. As you build your network, you can create available resources for any new or unknown challenges you may face.
I would say, being prepared. This might be overlooked in the day-to-day of a busy work week, but it should be the easiest to remedy. Simple things like staying on top of your calendar and setting aside time to prepare for meetings go a long way toward being professional. I dedicate time before every meeting to prepare, whether that means thinking about what I'm going to say or even reading any information provided beforehand.
Read about Manan Shah's and Courtney Newcombe's first client engagements, and check back soon for more stories!A blog post by David Linthicum, managing director, chief cloud strategy officer, Deloitte Consulting LLP
Über-mergers will be the focus of enterprises over the next three to five years. The Global 2000 wants to leverage their stock value as a currency to make key acquisitions that will take them to the next level.
Unfortunately, many of these acquisitions may not work out as planned. It’s difficult to bring together the IT systems of both companies, and synergy can take years, not months to achieve. Both the customers and investors can become underwhelmed by the progress, and the company often pays the price by falling short of expectations.
Enter the use of cloud computing and its ability to more easily merge IT systems. Cloud-based resources can be allocated as needed, and public cloud-based systems can easily work and play well with each other.
The amount of time it takes to merge and integrate systems to support an acquisition varies, depending upon the type of companies pushed together. However, the core capabilities of leveraging the cloud include:
The ability to exchange data intra-cloud. It’s faster and easier because cloud providers leverage the same cloud-native databases, middleware, and database ops solutions. Traditional approaches to inter-datacenter integration are much more problematic, and often takes more time and money when compared to the cloud computing-based alternative.
The ability to merge security systems together using a common platform. When the cloud-native security system exists on the same public cloud provider, it’s just a matter of integrating directory services, and thus identity and access management solutions. Security can be synced within weeks. Traditional legacy security integration can take as much as a year, not including planning.
The ability to deal with common data semantics. With the same notions of a customer, inventory, product, etc., there is no misunderstanding of what data is the single source of truth between the merged companies. This requires some understanding of the metadata, and perhaps some common MDM solutions. The public cloud again provides an effective common platform for all of these integration efforts.
There are many more benefits to M&A in the cloud than can be listed here. You’ll find that it’s a matter of understanding where your enterprise is at, where the company you want to acquire is at, and the potential use of the public cloud platform as a point of integration between both IT systems.Will 2019 be different from 2018? For many investment managers, yes! Those firms breaking ground on new developments will likely see contrast afforded by a new perspective. No doubt, most investment management firms still face challenges such as margin compression, regulatory change, rapid technological change, and shifting investor preferences. Just as necessity is the mother of invention, these pressures are driving firms to find avenues for growth, improve operational efficiency, and develop elegant customer experiences.
In order to achieve growth, capabilities have to improve, because the competition is stiffer in both emerging and traditional markets. New technologies, such as artificial intelligence, are being increasingly deployed in search of a competitive edge.
Many firms will choose to grow their current products and markets, but this is not to be confused with business as usual. They still have to refine, if not revamp their investment operations. While some firms might pursue incremental improvement strategies, others are expending considerable effort to improve their core investment capabilities. Since the markets are always pricing in more information—never less—active investment management firms should consider looking for ways to build deeper insights into the investment process, just to keep up.
Keeping up is important. For mutual fund managers in particular, many of the large advice-driven distributors are trimming funds from their shelves. More than 4,900 funds have been dropped from the shelves of leading distributors over the past two years.1 This shelf-space dynamic demonstrates that competition for distribution is stiffening. Differentiation and innovation help investment management firms from being left out.
To get ahead, many firms are considering expansion into China, and joint ventures and acquisitions are often part of that strategic decision. At its current double-digit growth rate, China will become the world's second largest market for investment in the next decade.2December 27, 2017 Nobody likes annual performance reviews. Even high performing employees can be demoralized by rigid or arbitrary goals. But what if you could find a way to flip it – turning the annual performance review process into a positive moment where employees feel empowered to learn and grow?
While goals have long been used as a quantitative measure for employee performance, many organizations find that the goal-setting process takes a huge amount of time and is, frankly, not very effective. However, when done correctly, goal-setting can help improve employee engagement in a way which elevates performance and benefits organizations overall, according to recent McKinsey research.
Setting goals can be as challenging as meeting them. Here are three things to keep in mind when establishing effective employee goals:
Involve employees from start-to-finish The purpose of goals is to help employees improve – naturally, it makes sense to include them in the entire process. Securing employee buy-in allows you to help develop their short- and long-term goals, and increases the likelihood that they will be achieved. Managers should jointly develop goals that are SMART (specific, measurable, actionable, results oriented and time bound). Doing so inspires commitment and allows individuals a sense of ownership in achieving their goals. Encouraging employees to set stretch goals also helps push performance and serves as a motivator for ongoing development.
Link individual goals to business objectives Of companies who have effective performance management systems, 91% say that employees' goals are linked to business priorities. The explanation is simple: employees will be more effective if they can see how their individual goals fit into the big picture. In recent years, there has been an uptick in the number of companies linking organizational business goals to functional business objectives, and converting those into team-performance goals. This encourages accountability and better performance as individuals grasp the direct impact of their performance.In March 2018 the European Commission published an Action Plan on Financial Sustainable Growth (the “Action Plan”) to help investors identify, compare and classify sustainable investments and integrate ESG criteria into their investment processes. More recently, the European Commission began the process of amending MIFID II to ensure that in future, investment managers will be required to take into account consumers’ Environmental, Social and Governance (ESG) preferences as part of the overall suitability process. The market is already seeing growing client demand for ESG products; Morningstar data shows sustainable funds domiciled in Europe showed resilience during the recent market sell-off. Driven by continued investor interest in ESG issues, the European sustainable fund universe grew by EUR 30 billion in the first quarter of 2020 compared with an outflow of EUR 148 billion for the overall European fund universe. Advisors and Investment Managers should therefore not only be on the front foot from a regulatory perspective, but also from a commercial and strategic perspective, ensuring they are able to serve their clients’ best interests.
The expected implementation date for the updated rules on suitability is March 2022. This might seem far away, however, given the expected challenges and all-encompassing nature of ESG, firms should be thinking ahead as to how they will address these key regulations into their existing process and control frameworks.
In this blog, we explore in more detail the operational and compliance challenges ESG will create for Advisors; specifically the risks and challenges in capturing ESG preferences of clients during the suitability assessment process.
The existing MiFID II suitability rules require those providing investment advice and portfolio management to obtain information on clients’ financial objectives, risk profiles, capacity for loss, as well as knowledge and experience in relation to the specific type of financial instruments being advised on. The proposed updates to MiFID II will add clients’ ESG preferences to this list.
The purpose of this regulation is to create demand for ESG products; to move to a more sustainable economy. Whilst clients’ aren’t obligated to provide any ESG preference, and factors like investment objectives must be assessed before a clients’ ESG preferences, if some clients provide a strong opinion on ESG and the firm does not have a suitable product available, consideration must be given as to whether the firm can still make a suitable recommendation for that client.
Advisors will need to review the proposed changes to regulation the surrounding provision of advice and portfolio management to ensure ‘sustainability preferences’ are captured within their suitability process. To this regard, they will need to consider the wide range of ESG factors that their clients may have a preference on which will form part of their overall recommendation.
Defining ESG issues can at first appear daunting, given for many it is unchartered territory. Fortunately, the starting point can be aided by a number of existing frameworks and principles
ESG needs to be grounded in materiality. For example, what is considered a material set of environmental issues for oil and gas companies is not directly comparable to textiles or consumer products. Identifying the material ESG issues facing underlying assets should be the first consideration for Advisors. The Sustainability Accounting Standards Board (SASB) outlines where they consider relevant ESG issues as material to different industries, including example metrics that can be used for monitoring performance. SASB is used by many as a guide for determining material ESG issues – recently a prominent institutional investor announced it would use selected SASB KPIs as a method for engagement and stewardship.
Advisors should also consider the UN Sustainable Development Goals, and their associated targets for 2030, as part of understanding definitions of ESG or sustainable. Climate change action is one of seventeen key focus areas globally agreed to achieve sustainable development. The World Economic Forum, appreciate this ‘new age of materiality’ for ESG has been working toward standardising ESG metrics used by companies, that will support investors decision making based on ESG performance.
Finally, firms should consider the key activities outlined within the EU Sustainable Finance Taxonomy to determine a variety of ESG preferences. To this end, incorporating ESG will provide a new set of product governance challenges when firms decide on the range of investments that they can advise on. Collecting appropriate data on ESG products and monitoring this on an ongoing basis in itself will be another key challenge for firms.
One of the main challenges for firms will be effectively embedding ESG considerations within their suitability process. Many may argue that suitability requirements are already overly burdensome for clients, and adding further requirements on ESG preferences risk making the process overly lengthy and complex, ultimately jeopardising customer engagement. It is therefore important that firms consider the customer journey in its entirety, and, as we will explore in this blog, it is not as straightforward as one might perceive.
Let us consider the key steps within the suitability process by taking an Advisor focused view. We will explore the key considerations and challenges that may arise as ESG is incorporated into the process, and call out some key impacts that firms and their Advisors should start to consider.
Before asking a client what their ESG preferences are, Advisors will first need to ensure clients understand what is meant by ESG in clear and simple language. This may include describing the difference between the ‘E’, the ‘S’ and the ‘G’ and what sort of factors are considered under each heading.
Firms should consider whether they would need to verify or otherwise test client responses with regards to ESG. In the same way Advisors have to assess clients’ knowledge, experience and understanding of investment risks associated with the advised products, firms may wish to consider whether they should do the same for ESG. For example, a client who misinterprets ESG might limit what products the advisor considers for them. In future years, if the Advisors recommendation has not achieved the desired outcome for the client, it could give rise to a suitability related complaint.
Client responses could fall across a spectrum of attitudes and preferences for ESG for Advisors to consider. This could range from clients having no ESG preference to clients having very specific preferences towards achieving an impact that aligns with a particular Sustainable Development Goal (SDG), otherwise known as Impact Investing. This is illustrated below:
Advisors also need to be aware that people’s attitudes to ESG factors may change over time. Client preferences in response to world events and topical issues at the time of assessment will likely influence their responses. Striking the right level of granularity in the questions asked will therefore be key, too niche or too detailed could limit investment choice or lead to portfolio rebalances over time; too high level and firms risk not capturing a client’s actual ESG preferences.
When making a recommendation, Advisors need to be clear how they have considered the client’s ESG preferences for each financial instrument recommended. In particular, suitability letters should contain an explanation on whether, or how, clients’ objectives have been achieved by taking into account their expressed ESG preferences. To do this, Advisors need to have clear consistency between the internal categorisation of ESG products and external marketing information for ESG products. Embedding the suitability process with product governance oversight will be key to successful implementation.
One other key concern is around fee transparency and the potential conflicts of interest that could exist between firms and clients. Many ESG products are, by nature, more costly than their non-ESG equivalents and this could create conflicts where funds or strategies are labelled as ESG in order to charge higher fees. To this end, ESMA set out in its technical advice that firms should have in place appropriate arrangements to ensure that the inclusion of ESG considerations in the advisory process does not lead to mis-selling practices or misrepresentations and do not damage the interest of the client. Or, as ESMA describe it, “an excuse [for a firm] to sell its own-products or more costly ones, or to generate unnecessary churning of clients’ portfolios, or by firms misrepresenting products or strategies as fulfilling ESG preferences where they do not”.
Firms will need to consider any limitations of how particular ESG preferences may affect uptake of model portfolios and investment strategies, and, ultimately whether the clients’ objectives can be met where the client has expressed strong ESG preferences.
The current process for periodic reviews of suitability requires firms to provide an assessment of suitability of any recommendations they provide to the client, where they hold an ongoing relationship. For many, periodic reviews will include ESG as a consideration for the first time, reaching a population of existing investors who might have never expressed their ESG preference.
This may present a number of challenges for Advisors, including how they obtain client engagement on a new topic when clients have had long standing relationships; or how the process would account for any portfolio transitions to more ESG friendly assets without impacting the risk exposure and objectives for the client.
The impact of ESG will be wide ranging and require careful planning in the run up to implementation. Suitability is just one aspect of the ESG requirements however, other impacts to additional areas such as product governance and conflicts of interest that deserve equal attention. Firms will look to their ESG change programmes and impact assessments to highlight these areas in further detail, however in the meantime, we have set out below some high level questions for Advisors and firms to take away and consider when implementing ESG into their suitability process.
Deloitte has supported the mainstreaming of sustainability within the investment system by leading and actively participating in every critical framework, taskforce and committee that is used and relied on by investors. We regularly publish thought pieces on how sustainable finance has grown and is still evolving.
Every day we work with investment management clients, around the world, supporting their approach to sustainable finance through six key areas:Though major crises may inflict significant economic damage, they can also inspire innovation. From digital connectivity to diversity, this issue of Deloitte Review explores innovations that organizations can put to use both now and in the future.Coleads our Organization Practice in Asia, developing the talent and leadership that organizations need to thrive; leads our work across China on infrastructure, sustainability, and public-sector issues; and works extensively with cities and major developers to plan and deliver integrated, sustainable urban developments
Coleads the Organization Practice globally and is head of McKinsey’s OrgSolutions group, helping clients organize in an integrated way by applying analytics methodologies and tools to improve culture, talent, change management, agility, and leadership
April 22, 2019 Leadership development interventions often lack strategic rigor, and the results show—only 10 percent of CEOs strongly believe their leadership development initiatives have a clear business impact.
For organizations to develop successful strategies requires leaders who are trained to think critically about where to compete and how to break down big-picture strategies into the smallest, most granular components. To break through requires real rigor and data-driven analysis to identify pockets of opportunities invisible at an aggregate level.
Leadership development programs, however, are rarely as rigorous. Too many organizations focus on broad, generic leadership competency models that apply a one-size-fits-all approach. One organization we know held a workshop to help leaders foster a “more global mindset”—with little discussion on why a global mindset was valuable for the company strategy in the first place or what participants should do differently in their daily work.
When leadership development links to specific context and strategy, however, outcomes improve significantly. Organizations that are successful at this are 8.1 times more likely to focus on the most critical leadership behaviors linked to their performance objectives, compared to those that are not successful.
Too many organizations focus on broad, generic leadership competency models that apply a one-size-fits-all approach
How, then, can you identify the most critical leadership behaviors to propel performance? There are four key steps:
1. Identify the context of the organization and the leadership behaviors that matter. Every organization resides in a unique context, and the specific leadership behaviors that enhance performance objectives must be identified with rigor. Multiple lenses apply here, including industry, ownership structure, strategic objectives, geography and organizational culture.
For example, an oil and gas company might emphasize operational discipline and safety while a Private Equity-owned company might emphasize quick decision-making and a bias for action. One lens we always apply is that of organization health and recipe, which can be measured quantitatively and has a clear link to performance. Organizational health measures the ability of an organization to align around a common vision, execute effectively against that vision and renew itself through creative thinking. Our research shows that organizations at different stages of health require different leadership behaviors to be effective and transition to higher levels of health and performance.
2. Crystalize leadership aspirations in a tailored leadership model. This model—sometimes called leadership competencies or values—typically includes 3-6 overarching themes, each comprised of several specific underlying skills and/or behaviors.
For example, a conglomerate embarking on a new strategic direction was focused on customer centricity, addressing disjointed cultures across its operating companies, and constructing a leadership pipeline. As a result, the organization developed a tailored leadership model with six themes, all of which supported the strategic aspirations. The explicit focus on a handful of specific and tailored leadership behaviors ensured that participants saw the program’s immediate value in their daily jobs, with an average program rating of 9.3/10. At an organizational level, the leadership program contributed to a 13-percentage point increase in leadership effectiveness and a 14-percentage point increase in overall organizational health.
3. Pinpoint the 3-5 behaviors that matter most. We consistently find that leadership development initiatives hit obstacles when they try to change too many things at once. Organizations cannot address the whole leadership model at once and must prioritize. In practice, it is individuals who must begin doing things differently on the job and developing sustainable behavioral change can prove challenging.
4. Identify the difference between the leadership the organization requires and where it stands today. This is the concrete gap across the 3-5 priority behaviors that the leadership development program should fill. Sometimes called “from-to” shifts, they serve as an objective measuring stick for program success. It is critical the behaviors are defined in detail, as they will ultimately drive the design of the program.
Few successful organizations operate with a vague notion of strategy. Similarly, it pays for organizations to pinpoint specific leadership behaviors required based on their context and to ensure that leadership development efforts are laser focused on addressing them.
Defining the critical leadership shifts that matter to performance is the first of four core principles we outline in McKinsey’s new book, Leadership at Scale. Our next blog post in this series will explain why organizations need to engage a critical mass of pivotal influencers during leadership development programs to ensure the change effort sticks.This blog is managed by Deloitte AG, a company registered in Switzerland with registered numbers CHE-101.377.666, with a registered office at General Guisan-Quai 38, 8002 Zurich, Switzerland.
Deloitte is committed to protecting your information by handling it responsibly and safeguarding it using appropriate technical, administrative and physical security measures.
We may collect or obtain information about you that you provide to us, that we obtain from third parties or that is publicly available, or which we infer from the way you interact with us.
We may process information about you to email you relevant blog posts, event invitations and content pieces (such as reports) that are related to the Deloitte banking blog.
For more details on how Deloitte handles and shares your information and for details on your rights and how to contact us, please click here.Walking into an office as a new hire [after new hire orientation and training] was so much different than coming in as an intern. It was intimidating, but mostly it was so exciting because I came in with a completely blank slate and a yearning to prove myself. I remember coming in at 8:00 AM and wondering if I was too early or too late. Luckily, I was joined by fellow new hires and experienced professionals eager to answer questions about what to expect from Deloitte. After completing about three hours of training and filling the day with networking activities, I remember walking out feeling energized, hopeful, and eager to learn over the next few months.What was your first client engagement?
I was working on an enterprise resource planning (ERP) system integration. The scope of our work involved the configuration and testing of an external tax engine to successfully process and calculate tax amounts on transactions in dozens of new countries. The scope was global, and I was able to learn firsthand the complexity and data wrangling capacity required by tax.
As a staff level on this engagement, I was heavily involved in the efforts of configuration in the tax engine, the subsequent testing of these configurations, as well as the documentation. Working across systems also allowed me to be heavily involved in the creation of report specifications for blueprinting the data that flowed between systems.
Absolutely! It is difficult to know how to feel when you are not quite sure what to expect on your first project. This project required me to travel every single week—something that put me outside of my comfort zone. Despite this, however, I was lucky enough to have a team that was supportive and made me feel at ease. This is something that I have found to be a pattern at Deloitte—even though the work is challenging, the people are talented and very willing to mentor.
Something that would have helped me is knowing the importance of taking initiative. By this, I mean seeking out ways where you can be useful, and not just waiting for a senior team member to give you a task. Members of a project team are extremely busy, and it is not always easy to find tasks for inexperienced staff. If I knew how much of a difference it would have made, I know, I could have been more helpful on my first engagement and could have learned how to excel technically and professionally.Problem solvers and creative thinkers. Engineers and new business builders. Put your talents to use where opportunities are limitless and every day makes a difference.
Whether you’re an experienced professional or a recent graduate, working with McKinsey could be a challenging and rewarding next step in your career.Has a passion for capability building with deep expertise in lean and green operations and the use of advanced analytics in operations; experienced in successful large-scale operations-transformation programs
April 15, 2019 To improve, organizations must consistently seek out and solve their problems—an insight that underpins lean management’s emphasis on root-cause problem solving (RCPS). Indeed, companies that have used RCPS to build a problem-solving culture that lasts are able to avoid continuous firefighting by effectively preventing fires from starting.
But RCPS takes discipline and patience, which some leaders resist: a manager may be reluctant to use this model if she’s convinced that she has already identified an “operational solution.” Nevertheless, persuading her to join her team on a problem-solving journey can help uncover a more effective and sustainable set of solutions—most importantly by including the people who know the problem best: shop-floor employees. Their perspective often shows that the initial idea would not have addressed the problem’s real causes, and would have met with a lot of resistance from the people charged with implementation.
Ops 4.0 technologies are making it easier to overcome that resistance and invigorate root-cause problem solving performance. What follows is a non-exhaustive overview of how different technologies (italicized) could be applied in each of the five RCPS elements (exhibit).
Exhibit We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
The rise of advanced analytics and business-intelligence applications allows companies can detect many more problems than in the past, and in a more effective way—so long as they have sufficient internal support to interpret the output. Examples include fraud detection in banking and insurance, as well as deviations from normal operating conditions of equipment in manufacturing plants. For the latter, the increased availability of high-frequency, high-precision sensors, together with the rise of the Internet of Things provides companies with larger data sets from which to identify problems.
Once the problem is defined, root causes are often identified via the five-why methodology. Instead of using the traditional colored sticky notes to facilitate this exercise, companies can now use interactive whiteboards incorporating speech-to-text or handwriting-to-text algorithms, together with high-quality touch commands. Moreover, the whiteboards can link to data warehouses, thereby enabling self-service analytics or even machine-learning algorithms for performing the analyses required in confirming or rejecting potential root causes.
Augmented- and virtual-reality applications can help designers’ creation process become even more productive. Faster iterations between the drawing board and a more real-life representation shorten lead times toward final design. Rapid prototyping and 3D printing can accelerate this process even further by bringing intermediate versions of the solution to life.
Once a solution has been designed, it is crucial to test its efficiency and effectiveness. The increase in computing power enables companies to perform extensive computational simulations. Using digital twins helps organizations create virtual mirrors of their operations, allowing them to test ideas more realistically before implementation.
The digital communication and collaboration platforms that are now in widespread use can often be linked with interactive tools such as digital whiteboards, minimizing the time teams spend on documentation so they can instead focus on the creative parts of problem solving. Having past records of problem-solving sheets available at only one touch avoids solving the same problem all over again.
The above list shows how the ancient art of root-cause problem solving can take shape in today’s environment. The question for most organizations is how to start, especially with technologies that can sound like science fiction. A learning center designed to replicate an actual, digitally enabled working environment can provide the first step, helping people experience the impact these technologies can achieve in a practical and realistic setting.Two months ago, I was on a panel at the SCOPE Summit in Orlando where we discussed the role digital technology could play in improving clinical-trial recruitment and retention. During the session, my group predicted that pharmaceutical companies would eventually incorporate more telemedicine visits into clinical trials and rely on internet-connected medical devices to conduct tests and gather digital data. At the time, I anticipated the transition to remote/virtual clinical trials was still a few years off. I was wrong. The COVID-19 pandemic is likely to push this timeline from years to months.
Last month, the US Food and Drug Administration (FDA) issued guidance that would temporarily allow researchers to use virtual visits, telephone interviews, and remote monitoring to collect data for clinical trials where possible.1
Clinical trials often require patients to make regular visits to a clinical site, which tend to be located in large medical institutions or hospitals and involve face-to-face meetings with clinical staff. Safety risks tied to the COVID-19 pandemic—combined with stay-at-home orders in most states—are preventing patients from traveling to investigational sites. Moreover, some patients and clinical staff have been quarantined after becoming infected by, or exposed to, the virus.
A March 23 article in STAT noted that biotech and pharma companies with market values of more than $300 million are running more than 120 Phase 3 clinical trials. Topline data readouts were expected before the end of the year. However, many trials are now struggling to recruit and retain patients, and most ongoing trials have been delayed. Some hospitals that had been hosting clinical trials are now busy responding to COVID-19 patients. As a result, many biopharma companies now have to consider incomplete patient data due to missed or delayed clinic visits.
Some trials for therapies that treat life-threatening conditions such as cancer are more likely to move forward, as are potential treatments for COVID-19. As of the end of March, more than 300 clinical trials related to the virus were either recruiting patients or preparing to recruit.2 Many of these trials are taking place in China, Korea, and some European countries hard hit by the disease.
Here are five things pharmaceutical companies should consider when evaluating existing or future clinical trials:
Conduct a risk-based portfolio analysis: Pharmaceutical companies should evaluate their portfolio of studies, conduct a risk-based assessment for dealing with the impact of COVID-19, and document a contingency plan. Many of our pharma clients have made the difficult decision to delay any new trials that aren’t deemed life-threatening or where an effective therapy already exists. They have also paused ongoing trials due to missed visits or incomplete data. For critical studies, they are working with their institutional review boards and regulators to determine which tests or processes can be conducted virtually, including telephone calls with patients or video visits via the internet. They should also determine if Bluetooth-enabled devices could be used to remotely gather patient data without requiring the patient to travel to the clinical site. Determine if trials can be relocated: Clinical trials that were taking place in hot spots might need to be relocated to other regions that haven’t been hit as hard. Rather than requiring a patient to travel to a large hospital, alternate sites (local clinics, laboratories, imaging centers) near the patient’s home could be an alternative. Home health agencies might also be used to help keep patients at home. Home health aides can travel to a patient’s site, draw blood, listen to lungs, and perform tests that the patient can’t do alone. Evaluate the potential of virtual visits and digital tools: Health concerns and travel restrictions related to the virus are likely to keep patients from volunteering for clinical trials or staying in existing clinical trials. They might be more willing to participate in trials if some visits can be done remotely. Companies should evaluate their protocols to determine what can be done virtually and what must occur in a clinical setting. Many of our clients are evaluating various technologies for telemedicine visits. They are also trying to determine how to leverage connected medical devices to capture patient data. During this assessment, it is critical to consider data privacy and security concerns as well as global regulations and the cultural impacts of remote visits. Consider partnerships: The outbreak has created additional logistical challenges in getting supplies delivered to investigational sites or directly to patients. Trial sponsors are trying to figure out how a patient would get their drugs if they can’t travel to the trial site and how to furnish tests that require specialized medical equipment (e.g., x-rays or CT scans) if the patients can’t go to the hospital. Several pharmaceutical companies are looking at forming new types of partnerships. For example, they might work with a retail pharmacy chain that can make investigational drugs available to clinical-trial patients locally. Another option is to train and enable local imaging centers to conduct tests that would typically be done at a hospital. Determine how to manage missing data and deviations: It is inevitable that patients will miss visits, have events occur outside visit windows, or withdraw from clinical studies. This can result in protocol deviations and missing data. Trial sponsors should develop processes and plans to manage those issues and decide what to do with incomplete data sets. Data collected remotely will likely need to be assessed in new ways. Sponsors should update their contingency plans with these process changes and update their data-analysis plans accordingly.
It feels like a year has passed since the SCOPE conference in February. In that short amount of time, the world has changed. Pharmaceutical companies that had expected to digitize clinical trials over the next few years are looking at weeks or months instead. At this point, the technology and infrastructure needed to push clinical trials into the virtual world might not be fully ready. For example, there are privacy concerns that should be worked out before patients and clinicians can conduct visits over the internet. During the months ahead, I suspect regulators will evaluate experiences, determine what works, and update the guidance. Once the industry, regulators, and patients see the benefits of remote clinical trials, I believe it will be difficult to go back to the way things were.
1. Coronavirus (COVID-19) Update: FDA Issues Guidance for Conducting Clinical Trials, FDA, March 18, 2020
2. Global coalition to accelerate COVID-19 clinical research in resource-limited settings, The Lancet, April 2, 2020It is well known that COVID-19 pandemic rapidly sent millions of people to work from home (WFH), which created an immediate challenge for many organizations – providing secure system access to employees. However, the less visible and more challenging transformation that also occurred was the sudden requirement to digitize processes, including previously paper-based transactions, in-person meetings, business travel, and other “normal” day-to-day operations.
Rapid digital transformation has enabled organizations to respond and thrive during the pandemic. A May 2020 blog post by the World Economic Forum stated “the transition to a new model for supply chains will be underpinned by a rapid and wholesale digitization of the paperwork that accompanies global trade.” However, this transformation has also introduced new risk into business operations – and it is important for organizations to understand and mitigate those risk as we enter into the “Next Normal.”
Some organizations had already begun the digitization journey before the pandemic hit, providing them with a head start. For example, companies that were already focused on collaboration technologies before COVID-19 were in the strongest position to maintain steady business operations when social separation and work-from-home (WFH) became new realities. Likewise, those with robust security mechanisms in place, such as sufficient VPN licenses and multifactor authentication, were better positioned to transition to virtual working while protecting sensitive information. And organizations that increased their internet and network capacity before the pandemic found it easier to connect to remote employees, customers, suppliers, partners and other stakeholders.
As one might expect, companies with bandwidth constraints prior to the coronavirus pandemic had a difficult time in the WFH environment, as did those with inflexible legacy systems and processes that could not keep up with user demand. For example, old government systems running COBOL had severe capacity problems as millions of citizens filed claims for social assistance. These older systems can’t be migrated to the cloud quickly, so IT departments were stressed finding “workarounds” to the problem. Other problems arose in cases where there was no pre-existing mobile strategy. For example, most call centers operate out of a central location with employees using desktop computers. Due to a shortage of available laptops, some call centers had no choice but to send desktop computers home with employees so they could work remotely, which led to implementation delays and interrupted operations.
Technology Preparedness - This includes the adoption of virtualization and cloud technology. Whether it’s servers, networks or desktops, virtualization enables organizations to dynamically scale their IT resources up or down as needed, while also providing centralized management and control. Virtualization can also enable more efficient use of existing IT resources, which generates greater return on investment.
While this has been an IT trend for several years, the increasingly widespread adoption of cloud continues to generate strong results. Migrating data to the cloud gives companies the scale, flexibility and redundancy to keep IT systems running effectively, even during massively disruptive events like a pandemic. It helps reduce the costs of hardware, power, firmware upgrades and on-site support, because these become the responsibility of the cloud provider. Software-as-a-Service (SaaS) is a great example of how moving applications to the cloud gives simplified, scalable and more reliable access.
Improved Cyber Security including Identity and Access Management (IAM) – WFH has obliterated many remnants of the traditional network perimeter, and with it the concept of perimeter security, where virtual “fences” keep the bad guys out. Identity has become the new paradigm of enterprise security – if you can ensure that only the right resources are accessed by the right people doing the right things, then you have a more secure environment. Modern IAM systems provide flexible authentication that enables people to work from home or anywhere else. And, with many companies announcing they plan to maintain expanded WFH policies beyond the pandemic, IAM has become the foundation in the modern secure working environment.
COVID-19 can be thought of as a harbinger indicating where organizations need to focus in order to thrive in the future with far more agile and resilient business processes.
Technologists alone cannot make digitization initiatives successful. Organizations can take a holistic view and consider many aspects of digitization, including:
Re-envisioning controls and testing – As more processes become digitized, it is logical to concurrently consider how control processes can also be digitized and automated. Building in more automated control processes at the beginning will allow companies to more efficiently and effectively monitor digitization risk while potentially reducing costs and time associated with compliance activities.
– As more processes become digitized, it is logical to concurrently consider how control processes can also be digitized and automated. Building in more automated control processes at the beginning will allow companies to more efficiently and effectively monitor digitization risk while potentially reducing costs and time associated with compliance activities. The ability to re-engineer processes – Before digitizing a process, it is important to evaluate that process to determine if it can be reorganized and re-engineered to deliver a better business result. Otherwise organizations risk digitizing flawed processes. This requires much broader thinking than simply ramping up bandwidth or installing new software.
– Before digitizing a process, it is important to evaluate that process to determine if it can be reorganized and re-engineered to deliver a better business result. Otherwise organizations risk digitizing flawed processes. This requires much broader thinking than simply ramping up bandwidth or installing new software. Proper funding – While investment is needed to get digitization projects underway, investments will be under scrutiny during the current uncertain business climate. Executives will likely need to show the projected value of a digitization initiative when stating their case for more funding, pointing out both short-term and long-term benefits.
– While investment is needed to get digitization projects underway, investments will be under scrutiny during the current uncertain business climate. Executives will likely need to show the projected value of a digitization initiative when stating their case for more funding, pointing out both short-term and long-term benefits. The right talent – Effective digital transformation requires expertise that spans both technology and business. These qualified professionals should be able to understand the functionality that was valuable in old processes, the benefits of creating new processes, and how technology can make it happen.
– Effective digital transformation requires expertise that spans both technology and business. These qualified professionals should be able to understand the functionality that was valuable in old processes, the benefits of creating new processes, and how technology can make it happen. Flexibility – Certain digital controls may have been relaxed during COVID-19 in order to speed up implementations and get WFH employees online quickly. This can open up new risks, so these controls may need to be re-applied over time to their proper levels. However, any process controls should be flexible enough to accommodate unforeseen requirements in the Next Normal, to avoid the fire drills caused by the coronavirus pandemic.
Finally, to thrive in the Next Normal, organizations should consider conducting risk assessments of digitized processes and take appropriate actions to remediate any identified security gaps. These assessments should also be a foundational element of future digital transformation initiatives, so the proper controls can be implemented from the beginning.
COVID-19 has turned digitization from a “nice to have” to a “must have” for many organizations, forcing them to adapt and modernize quickly in order to keep their operations running. While digitization may seem like a daunting task for some organizations, the pandemic has made it clear that sound business strategy demands identifying digital transformation opportunities and getting those initiatives underway quickly.
However, speed of transformation cannot come at the expense of risk, or the entire initiative can cause more harm than good. It is critical that cybersecurity and other risk factors be considered in the design stage of digital transformation initiatives, so the new digitized process does not weaken the overall risk profile of the organization. The good news is, all of this is readily achievable, and when done properly, it will make organizations much better positioned to thrive as they emerge from the pandemic into the Next Normal.​An organization’s biggest potential talent source may be its own people. But why do so many organizations find internal talent so hard to access?
Organizations have historically focused on external recruiting to find people for new roles, but with growing skill shortages and low unemployment rates, they are now finding that acquisition alone isn’t enough to access the capabilities they need. To fuel growth, organizations need to more effectively tap their current workforce to identify and deploy people with the required skills, capabilities, motivation, and knowledge of the organization, its infrastructure, and its culture. Creating better programs to facilitate internal mobility can pay off in multiple areas: growth, employee engagement, and business performance.
As talent markets get tighter and the world becomes more connected, a major new trend has emerged from our research: the need to improve internal talent mobility to more effectively move people among jobs, projects, and geographies. This year, internal talent mobility has become a C-suite-level topic, with 76 percent of our survey respondents rating it important and 20 percent rating it one of their organization’s three most urgent issues.
It’s not hard to understand why. For many organizations, their biggest potential source of talent is to access the enterprise’s own workforce and internal talent market. Surprisingly, however, that market is often undervalued and even overlooked, and many organizations find it amazingly difficult to access. The sad and maddening reality is that employees generally find it easier to find new—and more attractive—opportunities in another organization than to explore and move to new roles at their current employers.1 In this year’s Global Human Capital Trends survey, more than 50 percent of respondents told us that it was easier for employees to find a job outside their organization than inside (figure 1), a situation that leaders would do well to address.
Organizations have many reasons for starting to explore internal mobility in earnest. Hiring people with critical skills is highly competitive; workers who want to reinvent themselves don’t necessarily want to leave their current employer; internal mobility can be a way to embed collaboration and agility into an organization’s culture, which is one of the key attributes of becoming a true social enterprise; and agile organizations and career models dramatically improve employee engagement and commitment. Ingersoll Rand, for example, developed a robust internal career program to help employees reskill themselves for new positions within the organization, and invested in an interactive, analytics-based technology solution that allows them to explore and access alternative roles and career paths across the company. The result: a nearly 30 percent increase in employee engagement.2
Another major driver for internal mobility is the need for many organizations to globalize their operations as they expand into the fast-growing economies of Asia, the Middle East, and Africa. Schneider Electric, one of the largest French manufacturers of electrical systems and components, changed its structure from being a Paris-based, centralized operation to having four global headquarters: one in France, one in the United States, one in China, and one in India. The company now develops and markets products in each of these geographies, requiring the organization to create a culture of mobility, diversity, and inclusion. By creating four headquarters, the company can now offer roles in all four places that were available in only one location before, which increases both the need and the opportunity for employees to develop and grow into new roles. Schneider is now investing in new technology solutions to create more mobility options for its expanded organizational talent markets around the world.3
The shift toward flatter organization models also creates a greater need for internal mobility. As organizations start to operate in teams and networks, managers are realizing that open access to the diverse skill sets, backgrounds, and experiences held by the organizations’ own people is essential for success. To staff projects and programs as they grow, team leaders have to find expertise throughout the network, which is difficult if the organization lacks an active and open internal mobility process.
Although internal mobility is a high priority, it’s not easy to do well. Only 6 percent of respondents told us they believe they are excellent at moving people from role to role; 59 percent rate themselves fair or inadequate (figure 2).
One reason internal mobility is difficult is that most organizations are modeled around hierarchical structures: systems that people enter at the bottom and spend years working their way up to increase their influence, impact, and rewards. But while organizations have spent decades building career and promotion models to help people move up the pyramid, that’s not the same thing as having a vibrant, easy-to-navigate internal mobility market and culture across the entire organization. Only 32 percent of this year’s survey respondents believed that their organization’s employees have opportunities to move between operating divisions. Forty-nine percent of respondents, the largest proportion, identified the lack of processes to identify and move employees as a top-three barrier to internal talent mobility (figure 3). Siloed organizational models make it hard for managers to look for talent outside their own fiefdom, and block employees’ views into opportunities elsewhere in the enterprise.
What’s more, incentives are rarely set up to encourage hiring from within. Unless hiring managers are actively encouraged and rewarded for hiring internal candidates, they may pass over existing employees looking for development. Equally problematic, an internal candidate’s current manager may resist other departments’ or managers’ efforts to recruit the person unless incentives are in place to encourage managers to develop subordinates’ skills and support their growth. Indeed, 46 percent of this year’s survey respondents told us that managers resist internal mobility. Team leaders who are rewarded for producing results but not for promoting internal mobility have no reason to welcome the prospect of losing a high-performing team member—creating an obstacle to mobility, no matter how hard HR promotes mobility programs.
Culture is also a barrier in many organizations. Seventy percent of respondents told us that talent mobility expectations, the culture around talent-sharing, and decision-making around mobility were inadequate or only fair at their organization. Technology and systems around internal mobility, too, are often lacking. Forty-nine percent of respondents told us that they have few, if any, tools to identify and move people into new internal roles. Forty-five percent said their employees lacked visibility into internal positions. And in our conversations with clients, many HR leaders tell us that employees find it easier to quit and be rehired than to change positions within the organization because of the lack of systems to enable and promote internal moves.
Are the problems worth overcoming? Our respondents think so. Beyond looking at internal mobility to fill open positions, our respondents cited several other strategic business reasons for urgently focusing on this issue. Thirty-eight percent are looking at internal mobility to build better leaders, 31 percent cite the need to expand the business, and 32 percent believe mobility is required to increase employee engagement.
At one global engine manufacturing leader, encouraging internal talent movement stems from a firm belief that learning through experience is extremely powerful. One employee we spoke with said that this emphasis makes the company a “playground for learning” and praised “the number of cross-functional moves that take place and how open leaders are to considering high performers for any number of assignments regardless of their technical background.” Not surprisingly, enabling these experiences not only provides learning opportunities, but also raises employee engagement.4
Other organizations that have made substantial investments in internal mobility are also seeing these investments pay off. To take a well-known example, AT&T has spent hundreds of millions of dollars since 2013 on upskilling its employees, both by providing direct education and professional development programs and through tuition assistance. The program’s goal is to fill existing openings with people already at the company, and by that measure, it is succeeding: From January to May 2016, upskilled employees filled half of all tech management jobs and received almost half of the available promotions.5
A global bank offers another illustration of the types of talent market and mobility initiatives organizations are exploring and launching. The bank is building a new function for internal mobility that integrates talent acquisition with career mobility and takes an enterprisewide view and scope. Not only are internal mobility initiatives moving beyond new programs and processes, but leaders’ mindsets are changing to view the company’s entire workforce as a talent market that allows for multidirectional careers. This, in turn, is influencing how leaders think about operating models and organizational structures as internal boundaries become less important and enterprise teams and internal capability markets increase in importance and impact.
Companies like these have caught on to what is becoming more and more self-evident: Internal mobility is a driver of growth in today’s digitally powered, highly competitive global economy. The numbers tell the story: When we looked at the fastest-growing organizations (those growing at 10 percent or more compared to the prior year) in our survey, they were twice as likely to have excellent talent mobility programs than organizations that were not growing at all, and more than three times more likely than organizations whose revenues were shrinking.
As organizations reexamine how they approach internal mobility, they need to address a fundamental issue: Internal mobility today is governed by a set of (often unwritten) norms that are outdated and need to be fundamentally recoded for the future needs of today’s workers and organizations (figure 4). It is only through this reinvention that organizations may be able to unlock the potential hidden within its existing workforce.
Not surprisingly, the earliest adopters of this shift have come from the technology industry. Spotify and Facebook are leading examples. At Spotify, internal mobility has become such a core cultural element that employees take on a new role, on average, every two years.6 And at Facebook, employees and managers have conversations about career progression with internal mobility understood as an accepted element.7
Internal mobility, in short, can be a major source of critical talent and competitive advantage. To do it well requires investment and a focus on culture, infrastructure, and incentives—but it’s an investment well worth considering for leaders looking for ways to bridge the talent gap. In an economy where outside talent is becoming more and more difficult to find and attract, looking within can make the crucial difference between struggling and succeeding.Every organization already has some form of vulnerability management. But often it is not immediately related to DevSecOps. This is understandable as traditionally the use of security tools and monitoring of the IT landscape is often positioned with the security team. DevSecOps brings the security tools and monitoring to the development teams themselves. This means that the traditional vulnerability management needs to be extended or copied into the development teams. But since there is a different way of working, it calls for a different approach.
Our DevSecOps model shows various tools that can be leveraged in a DevSecOps pipeline. All these tools provide output; information that is new for the developers that work with those tools. All this information needs to be interpreted and adequate actions need to be taken. But how to interpret it? When is something bad, really bad, or not bad at all? And does action mean drop all your work and fix it, fix it next week, or just put it on the backlog for later?
The security team, developers and product owner need to work together and think about this. Depending on the nature and purpose of your application some vulnerabilities might be acceptable or not. And mitigating actions can be simple of complex. All these things need to be considered and balanced out with the costs and business priorities. For this there should be a clear and flexible vulnerability management process, to bring together the tools and people, as well as the developers and the security team.At the beginning HR has played a crucial role in managing the COVID-19 response at an organizational level. HR has been the driving force in keeping the workforce and organization engaged, productive and resilient. This situation has illustrated the true value of HR and has proven the importance of investing in flexible and robust HR processes and structures. As shocking as the COVID-19 crisis is, it also introduces a rare opportunity for HR to rebuild and take the lead in driving organizational stability and strength. Now that we are past the respond phase, HR needs to materialize on this opportunity: the time has come for HR to reimagine not only its own future, but also the future of the business/enterprise (see here for the full story around the Future of work: Redefining work, workforces, and workplaces).Massive scope: During this phase, there is a lot of excitement about the world of possibilities with RPA. Processes are selected based on how easy is it for humans to execute the process. 80% of the work is deemed suitable for automation just because it is rules-based. There is little comparison of what constitutes rules based decision-ing for humans versus RPA (e.g. Jon versus Jonathan may be ok for humans to action but typically not ok for Robots).
Huge savings: Industry “benchmarks” are used to estimate the size of the prize, with anecdotal evidence from single data points and article headlines used to justify the initial cost-benefit estimates. Savings of 50-60% and program return on investment in the first 6 months are not unusual.
Easy to implement: There is a strong belief that RPA programs are really easy to implement. This is partly driven by advances in user interfaces on the RPA tools and desktop recorder like functionality used in most demonstrations and Proofs of Concept. The roles in the RPA program are mainly business focussed – typically Business Analysts, with some doubling up as RPA configurators/RPA developers and project/program manager(s).
Missed roles in the operating model: As the first few project are nearing go-live, multiple roles emerge with team members asking the question “who’s responsible for that”? Typical examples are – who would oversee actual running of these Robots updating schedules and resource allocation based on changes in demand? Who would tweak/fix/modify them when business processes change “slightly”, IT applications have an unplanned change e.g. batch jobs are cancelled for a week requiring different interpretation of the data presented on the user interface?
Underestimating IT environment complexity: Using the assumption that Robots are simply rules based humans, initial RPA projects typically overlook the complexity and idiosyncrasies of interacting with various target applications. Some of IT application require only one log on and log off during the day, others are the opposite. Some are built for browsers that the RPA tool doesn’t support natively leading to longer build times and requiring a more robust design. Finally, there are implications on upstream and downstream systems that underpin the target applications which need to be considered in the Automation build.
Using RPA to cover for process gaps: RPA is sometimes incorrectly used to address operations pain points related to broken processes e.g. lack of standard operating procedures, low levels of documentation rather than challenges around scale, operational risk, seasonality, speed for mature, well documented processes. This leads to longer design times, “discovery” of new business scenarios during testing/pilot, reduction in scope of what can be automated using RPA and rework of Automation build – leaving the stakeholders frustrated, increased costs and lower benefits
Phase 3: Eyes wide open – “RPA requires structured, cross functional effort with specific focus on foundations”
Industrialised RPA framework: Development of a Robotics Operating Model (ROM) is critical to scale process automations. The ROM needs to clearly define new roles, accountabilities and controls specific to development and use of RPA. The RPA build requires a new Robotics Delivery Lifecycle and a new Robotics Support Lifecycle. Both of these are similar in some aspects but quite different in others from the typical software delivery and support lifecycles.
Robust Robotics platform: The RPA platform is only as strong as the underpinning platforms it relies upon. These include but are not limited to the virtualisation platforms, the networks and hardware infrastructure that host the Virtual Desktops that the Robots use to interact with the target applications. Any gaps here will result in slow robots resulting in missed OLAs/SLAs, typically mitigated by increasing resource requirements or adding more bots but this results in higher run costs. An inadequate platform also causes robots refer more business transactions to human workers which in turns reduces benefits from Automation.
Cultural change readiness: Implementing RPA at scale requires a change in the organisational culture at many levels. First and foremost, the business needs to prepare for the workforce implications both in terms of roles that are no longer needed as well as the new ones that are going to be needed. Secondly, RPA needs to be seen as a lever in Operations Excellence which means fundamentals such as waste elimination, process standardisation and simplification cannot be ignored. Finally, for RPA to scale it may be business led but it also needs to be technology (IT) driven – after all Automations are a hybrid of process and technology.
RPA programs can be a huge success and scaled RPA capability is not a pipe dream. However, organisations need to realise that their human workforce is a lot more adaptable and forgiving than their robotic counterparts. Building out a Robotic work force requires a lot more operational discipline, a technology platform to match, and much greater collaboration between the operations and technology teams.
In the next post, we will share our battle-tested tactics to advance quickly and with less pain to Phase 3.June 17, 2019 You might think that advanced industry—a sector characterized by research and development and use of artificial intelligence and other breakthrough technologies—also optimizes the way its R&D organizations work. But continual business and technology trends in advanced industries (AI) have triggered fundamental challenges that require advanced industry innovate in its approach to R&D.
Just consider the three major R&D hurdles automakers confront in designing autonomous cars: more complexity and functional interfaces across projects, especially involving interlinks between software and hardware; amplified change and ambiguity in customer demands; and tighter interaction with an increasingly diverse ecosystem. As a result, decisions take too long, milestones are missed and standard operating procedures are delayed, siloed and fragmented. R&D staff stay in task force mode, and collaboration and job satisfaction diminish.
Early agile models in advanced industry R&D departments are delivering significant impact. We’ve seen a doubling of the time spent on value-add work, speedier decision-making, a 30 percent rise in productivity, increased engineer motivation and enhanced responsiveness to customer demands.
Sidebar Designing flying taxis: Is agile the key to innovative R&D? Many research and development (R&D) teams find themselves held back by a traditionally siloed structure in a rapidly changing environment, particularly in heavy industries. We connected with James Arnold, head of design systems and head of process excellence at Lilium—a European company developing the world’s first electric vertical take-off and landing jet—for a first-person perspective on what an agile R&D department looks like when starting greenfield in a highly innovative industry. Arnold and his team recently completed a successful first field test of its all-electric five-seat aircraft and hopes to launch a fully operational flying taxi service in select cities by 2025. Question: You are a small start-up exploring a very futuristic technology. How are you approaching innovation, and how has experimentation played a part in the process? Arnold: The history of the development of our aircraft is one of experimentation and iteration. From the very start, our founders worked with physical prototypes to test and demonstrate ideas, and as the company has grown, we have developed many prototypes in increasing levels of complexity. This kind of experimentation—and working towards something that can be tested and learned from—is essential for innovation. Q: Can you talk about the positive social and environmental impact of this unique mode of transportation? Arnold: We like to think about the “radius of life.” When you can travel five times faster than you can by typical ground transport, your horizon for commuting also increases by five times. Five times the radius gives 25 times the area and 25 times the possibilities. Or you can gain that time back for yourself and your family and create a big increase in wellbeing. Congestion and ground-level pollution will drop dramatically; cities will become cleaner, greener, quieter and safer. Q: What characteristics were critical in putting together your R&D team? Arnold: Research shows the impact of diversity, in terms of outcomes and the positive effect on team interactions. We have people with 30 years of experience working alongside undergraduate interns. We have people from different industries and cultural backgrounds. To benefit from this, we also need people who are open and ready to learn and try new ideas. Q: How do you manage collaborations to incorporate cross-functional teams for effectiveness? Arnold: We build our main cross-functional teams around the product breakdown structure; each major aircraft system has a dedicated team. Each team is established from the start of the program and is co-located, with a single day-to-day leader from the systems engineering team. We believe there's a huge increase in effectiveness and efficiency when sitting together vs. trying to collaborate virtually. Q: How are you looking at scaling the R&D unit? Arnold: Our goal is to make the foundations, processes, systems, mindsets and skills scalable. This means continuously challenging and improving things like our onboarding process for engineers, day-to-day collaboration and data management. It’s also important to expect and embrace the changes that scaling brings. Different structures and approaches are better for different sizes of teams, and it’s OK to change! Q: How is agile part of the equation for your team? What principles have been key? Arnold: One of the original principles of the Manifesto for Agile Software Development—the progenitor of the “agile” concept—is simplicity. Our whole architecture is designed to be extremely simple, and we drive this down into the detailed design of every part. We also work in short, iterative cycles that come to some sort of end product that can be evaluated. The objective is to learn quickly and efficiently, with a short lead time. Q: The hallmark of agile is to continually evolve. How do you ensure ongoing changes happen while still protecting the agile culture? Arnold: Due to our extremely fast team growth, we have a slightly different problem. Change is happening and will continue at a breakneck pace for several years. We work to protect and build on our engineering culture but also allow evolution and new people to bring new ideas. To take advantage of this, it’s important to have and reinforce core principles that give a framework but are not too rigid. Sometimes you can embed these principles into processes, but that’s not enough—there needs to be a huge and continuous effort to reinforce the right mindsets.
So, what comprises a more effective agile organization that sparks cross-functional collaboration, quick decisions, fresh ideas from anyone, flexible shifts of priorities and resources, and a place that attracts talent drawn to rewarding and fun work?
We can look to other industries such as banking, energy and telecom because they have faced similar issues. For instance, when one banking institution moved to a model where small teams follow a joint purpose and enjoy full end-to-end responsibility, they significantly improved cross-functional collaboration, time to market and customer satisfaction while moving to No. 1 employer of choice from No. 12 two years prior.
From these other industry pacesetters, advanced industry can take agile mindsets, principles and values while tailoring practices and tools to their own R&D realities. If an R&D organization truly wants to change how it operates, it needs to:
Derive promising learnings from pilots for organizing agile teams and make necessary changes to its “backbone” system, such as budgeting and work allocation processes and alignment of plans and priorities.
We do see some winning practices in selected “frontrunner” R&D departments in advanced industry as they pertain to structure, process/technology and people dimensions.
Structure: Create small, stable e2e teams that are accountable and possess a shared purpose instead of organizing by competencies. When priorities change, shift the task, not the people. People should work and sit together in teams but retain a home base within their discipline (e.g., electronics). They assume responsibility for managing common components and setting software and other architectures.
Processes/technology: Work on end products in rapid iterations and quick learning cycles, applying new testing technologies in standardized, not religious, processes. Enlist customers early. Favor more frequent and smaller decision meetings—in a way disaggregate today’s big meetings—that focus on decision-making versus status approvals.
People: Leaders change their style, e.g. visionary, focusing on coaching and problem solving and embedding ownership in their teams. That means asking them to develop their own plans and solutions and focusing on providing a clear framework, including clear interfaces and responsibilities. This requires ensuring a culture with stronger collaboration, more ownership from lower-level team members and risk assumption. Development teams also must step up. As one manager explained, “If your engineers behave as fenced-in sheep and you remove the fence, they will just continue grazing in the same place and nothing changes.”
Most advanced industry players have begun experimenting to determine where and how to apply agile, but they must scale it up for the full impact. Pilot projects prove important to learn whether a concept works, and they can boost enthusiasm. Technology trends will continue and as organizations meet these challenges, a full agile operating model will be required.A blog post by Dennis Ortiz, managing director, Deloitte Consulting LLP and Howie Stein, senior manager, Deloitte Consulting LLP.
Imagine you have a question about your subscription to a streaming service. As you search the company's website for a customer service number, a message box pops up to ask if you need assistance. You soon find that resolving your question can be done as easily as texting a friend—but the customer experience hadn't always been so fluid. The media company behind the service had grown through acquisition, building a vast product catalog with complex service processes. To simplify support, the firm deployed an intelligent chatbot—powered by artificial intelligence (AI)—to enable customers like you to self-serve through voice or text interactions with a computer.
This is just one example of how companies across technology, media, and telecommunications (or TMT) are leveraging conversational user interfaces (UIs) to meet their unique service delivery challenges. More and more, TMT customers expect the same leading customer experience from their support interactions as is delivered by the products themselves. These buyers are increasingly digital-native, with growing expectations for service and support to be integrated or adjacent to the services themselves. For example, wireless subscribers expect support options within the carrier's app, and software customers expect service on the same platform they are using from the provider. Moreover, TMT customers expect sophisticated personalization across channels, including chatbots. If their need cannot be resolved by the UI, customers expect to be transferred to a human with context on the issues and which products the customer uses.
The chatbot has evolved. Today's top chatbot platforms offer a powerful bundle of advanced cognitive technologies, including native machine learning and natural language processing and generation. Such technology can handle large datasets1 to process, evaluate, and respond to inputs, mimicking human conversation. This enables numerous customer engagement applications, including common uses such as billing support, customer authentication, and FAQ responses, and more sophisticated applications, such as technical support.
Chatbots can integrate with back-end systems to aggregate what a company knows about a customer (e.g., products, usage, and error messages) and proactively diagnose problems. For example, a wireless company can detect excessive dropped calls and proactively suggest there may be a problem in the customer's neighborhood, and a hardware manufacturer may take action based on error codes received from its hardware. Further, a chatbot can consume volumes of service records to guide a customer in troubleshooting a product.
TMT leaders leverage chatbot technology to address costly challenges that hurt customer satisfaction: Ineffective customer hand-offs, manual processes driving handle times, procedural confusion or inconsistency, etc. Others are hindered by traditional data silos that exist in TMT companies, especially relating to customer data. These firms must design cognitive programs that break silos to uncover data and insights outside their traditional IT systems, enabling them to service customers in new ways.
Chatbots are a strategic avenue for companies to begin integrating AI into their business, and the benefits can be significant. To learn more about how conversational UI and other AI-enabled technologies can help improve your customer engagement strategy, read our full article or get in touch.Dr. Suz is a social-personality psychologist and a leading practitioner of Deloitte’s Business Chemistry, which she uses to guide clients as they explore how their work is shaped by the mix of individuals who make up a team. Previously serving in Deloitte’s Talent organization, since 2014 she’s been coaching leaders and teams in creating cultures that enable each member to thrive and make their best contribution. Along with her Deloitte Greenhouse colleague Kim Christfort, Suzanne co-authored the book Business Chemistry: Practical Magic for Crafting Powerful Work Relationships as well as a Harvard Business Review cover feature on the same topic. She also leads the Deloitte Greenhouse research program focused on Business Chemistry and is the primary author of the Business Chemistry blog. An “unapologetic introvert” and Business Chemistry Guardian-Dreamer, you will never-the-less often find her in front of a room, a camera, or a podcast microphone speaking about Business Chemistry. Suzanne is a University of Wisconsin-Madison graduate with an MBA from New York University’s Stern School of Business and a doctorate in Social-Personality Psychology from the Graduate Center at the City University of New York. She has lectured at Rutgers Business School and several colleges in the CUNY system, and before joining Deloitte in 2009, she gained experience in the health care and consulting fields. A mom of two teenagers, she maintains her native Minnesota roots and currently resides in New Jersey, where she volunteers for several local organizations with a focus on hunger relief.Job search and application: The job search/application is the first touchpoint that a candidate has with an organization. Sometimes, job postings can be too tailored to organizations, leading to confusion among candidates, while deciding roles that match their experiences and skills. While providing a negative candidate’s experience, this can also reduce the quality of applicants. Alongside this, overly lengthy application processes can also deteriorate the candidate’s experience.
According to a survey, 60 percent of candidates have quit an application process because it took too long. (Erin Engstrom, n.d.). Various talent acquisition vendors have identified this as an opportunity to enhance/simplify and provide a high-touch candidate’s experience. If we look from the perspective of the candidate, an ideal scenario would be where they would be able to apply for a job, as easily as they can click ‘buy now’ when shopping online—providing only must-needed information upfront! However, sometimes this information would not be sufficient for the recruiters to weed out applicants. The balancing act is to create an application that is not front-loaded—gathering only relevant information upfront, while also being interactive for the candidate. Outlined below are two ways where technology has been utilized to generate a unique candidate’s experience during the job search and application experiences.
Job seekers are often unaware of the various roles in an organization that they may be a good fit for based on their skills and experiences. Artificial intelligence and cognitive talent management solutions can be utilized to personalize the experience and guide applicants to jobs they may potentially be best suited for within the organization. When an applicant is visiting the website, Artificial intelligence can also engage with the job seeker in personalized discussions and recommend potential job opportunities to the candidate within the organization. By providing this unique experience for the candidate, organizations are able to make a strong connection with potential employees at the very beginning of the process.
The rise of voice technologies has changed the way individuals have been completing tasks and interacting with their devices. A leading fast-food chain (McDonald's) has utilized voice recognition to provide a quicker and more interactive way for them to apply for jobs.² A job prospect can now utilize voice recognition software to answer a couple of quick questions and apply for a front-end job. Followed by which they receive an SMS link on their phone to complete their application and apply for a job. The company is envisioning this as a way to provide young people an opportunity to start entry-level careers at one of its restaurants through artificial intelligence-powered digital voice assistants. In a time, where convenience is a key market differentiator, this organization has definitely utilized it to generate a positive hiring experience!
Interviews: LinkedIn has found that 83 percent of talent say a negative interview experience can change their mind about a role or company they once liked. Strategic implementation of tools and technologies can help organizations significantly enhance the screening and interview experience of candidates. A clear and transparent interview process is a paramount priority for job seekers today. Outlined below are two ways in which an organization can drastically improve its candidate’s experience while interview scheduling and conducting the interview.
An organization can successfully differentiate its candidate’s experience during interview scheduling by reducing the amount of time spent back and forth between emails trying to identify timings that work best for interviews. Technology can be utilized to manage schedules and availabilities, book rooms, provide clear communication, etc., providing recruiters with the opportunity to focus on more strategic work. Self-scheduling interview technology can be utilized to significantly reduce interview coordination time for candidates. Once the candidate elects their chosen interview time, some leading systems can even generate notifications to the interviewers providing them with all the relevant information required to conduct the interview. Providing candidates with the opportunity to schedule interviews per their own convenience, while reducing the back and forth between themselves and the recruiter, helps generate a positive experience for the candidate.
The advent of new digital technologies and methods of collaboration has changed our ways of working. Considering our new reality and rapid increase in virtualization, video interviewing technology has been rapidly incorporated amongst many leading organizations instead of face-to-face interviews. Talent lives all over and is not restricted to the headquarters of your organization. Considering that many candidates (like talent acquisition specialists and managers) have busy schedules, in-person interviews can sometimes be difficult to conduct, while also being more expensive. This brings in the need for video interviewing software. Video interviewing software can be utilized in the form of live in-person interviews as well as prerecorded interviews. Prerecorded interviews serve as an optimal method to prescreen candidates, prior to bringing in top talent for in-person interviews. Utilization of video interview technologies as a part of the screening process provides candidates the flexibility to move through the talent acquisition process at their convenience.
Providing a positive candidate’s experience has enormous benefits to an organization not only in terms of developing a stellar brand but also in terms of measurable business outcomes. Sixty-four percent of surveyed job seekers say that a poor candidate’s experience would make them less likely to purchase goods and services from that employer.³ Therefore, a poor candidate’s experience can not only drives top talent away but also helps increase the number of unhappy customers. So, a focus on a candidate’s experience is imperative for an organization’s success.
Technology can play an important role in improving the candidate’s experience during their talent acquisition journey. Treating candidates well helps enable the organization to find the top talent and stellar candidates, including those who weren’t right for one role, but were the best fit for another or will reapply again in the future.
Bhawna Bist is a senior manager in the Workforce Transformation practice of Deloitte Consulting LLP, specializing in the Future of Work and talent acquisition transformation. She has more than 18 years of cross-industry and consulting experience advising global organizations and leading strategic transformation programs.
Aarushi Gandhi is a consultant in the HR Transformation Advisory practice of Deloitte Consulting LLP based out of Canada with experience across talent acquisition transformations, HR roadmap and org design, and workforce experience and process design.
¹ https://www.forbes.com/sites/zackfriedman/2019/05/22/millennials-disillusioned-future/#21317b03353e
² https://www.theverge.com/2019/9/25/20883007/mcdonalds-apply-thru-amazon-alexa-google-assistant-job-applications-ai-automationYou don’t need a business background to succeed at McKinsey. More than one-third of McKinsey consultants don’t have business degrees, and about half don’t have MBAs. Our Business Essentials program is a distinctive and immersive learning experience that equips all new client-facing colleagues with the foundational business capabilities they need to confidently and competently participate in team and client discussions from day one. It is individualized to your background and experience, and will introduce you to a set of curated core business principles and their application within the McKinsey context and frameworks through a blend of on-line modules, virtual classroom sessions and an in-person capstone event. Beyond the formal training programs, you will learn quickly by working with other McKinsey consultants on client engagements, and you will find that McKinsey has a supportive environment, with both formal and informal mentoring to promote development.
McKinsey allows you to use your legal training to make an immediate and dramatic impact. Consultants need the very skills that lead to success in law school, including strong leadership and communication skills and the ability to address multiple conflicting points of view to solve complex problems. At McKinsey, you also have the opportunity to advance more rapidly than you might in the legal profession. Whereas it can take years for new associates at a law firm to advance to a position of responsibility, new McKinsey consultants frequently find themselves directly advising CEOs and other leaders within months of joining the firm. McKinsey has a long-standing interest in attracting and retaining lawyers. In fact, Marvin Bower, the father of the modern McKinsey organization, was a lawyer, and he built McKinsey based on the professional principles he learned from his experience in law. Today, more than 250 consultants at McKinsey have law degrees. They joined McKinsey at various points in their careers—some immediately after law school and some after practicing law for years.
Consultants with master’s degrees represent a broad spectrum of experience. Your role upon beginning your career at McKinsey depends on your academic and professional background.
Generally, if you are pursuing a master’s degree and you earned an undergraduate degree fewer than 4 years ago, you will be considered for a business analyst position. If you hold a bachelor’s degree and have at least 4 years of work experience, or you completed or expect to complete your master’s program 4 years from the time you received your bachelor’s degree, you will join as an associate.
We understand that the additional training you received and the expertise you developed by attaining a master’s degree add value to your work as a McKinsey consultant. McKinsey was the first consulting firm to systematically hire consultants with advanced professional degrees outside of business; currently, more than 3,000 of our consultants worldwide hold master’s degrees in fields other than business. Often, because of their professional experience, business analysts with master’s degrees show promise immediately, putting them on a fast track for promotion to associate.
At McKinsey, consultants advance based on performance—not background or tenure—so if you perform well, you’ll be considered for early promotion. Here are some example scenarios for possible entry points to a career at McKinsey. If you are interested in the German office and hold a bachelor’s degree and completed a 1-year master’s program, you will join as a fellow. If you are interested in joining the UK and Ireland office with a master’s degree, you will typically join as a business analyst. If you are interested in a North American office and hold a bachelor’s degree and have at least 4 years of work experience, or you completed or expect to complete your master’s program 4 years from the time you received your bachelor’s degree, you will join as an associate.
Nearly 200 McKinsey consultants around the world have medical degrees. Some joined the firm right out of medical school, others after years of leading clinical departments at major medical centers. McKinsey has found that the consulting world needs many of the same attributes and skills that contribute to MDs’ success in medicine, including being intellectually curious, creative, and analytically talented. MDs bring their teams not only relevant skills but also a valuable clinical perspective that allows them to approach healthcare problems distinctively. On healthcare projects, MDs understand the context deeply from day one and can speak the language of medicine with clients and external experts.
McKinsey typically hires MDs as generalist consultants into an associate role, the same roles as their colleagues with MBAs. While most McKinsey MDs focus on healthcare over time, all McKinsey consultants, regardless of background, are encouraged to pursue a range of interests across a wide array of industries and countries. On McKinsey teams, MDs find many opportunities to contribute their medical knowledge, but the strong problem-solving and people skills developed during their medical careers are often their most important assets.
Practicing medicine can be fulfilling, emotional work. As a physician, you establish relationships with individuals and often see your influence immediately. Performing a difficult surgery, diagnosing a disease accurately, or giving hope to patients and their families can bring tremendous satisfaction. McKinsey offers a different kind of satisfaction. Rather than influencing one patient at a time, you can help shape the systems and strategies that have much broader impact. We help our clients tackle some of their toughest problems. As a consultant, you have the potential to help shape the way healthcare decisions are made—decisions that influence the care of thousands or even millions of patients. Additionally, McKinsey MDs enjoy the opportunity for learning and personal development. Through the combination of diverse and challenging client work, high-quality training programs, and one-on-one apprenticeship, McKinsey creates an unparalleled learning environment that most McKinsey MDs value greatly. Finally, McKinsey MDs greatly enjoy their colleagues; McKinsey is a diverse, talented, and engaging group of people who do their best work as part of a team.
Currently, there are more than 1,400 consultants with PhDs at McKinsey globally, and most say they came to McKinsey to broaden their horizons beyond the academic setting. As consultants, they find they can apply their problem-solving skills in new ways, work in fun and stimulating team settings, and make a measurable impact more quickly and more often. Many came from careers in basic research, where they often worked in isolation and where it can take years to achieve tangible results. As McKinsey consultants, they work through their clients’ problems in months or even weeks rather than years. To solve those problems, they work side by side with other consultants and with their clients. As in academia, the environment at McKinsey is intellectually stimulating and competitive, but it’s also ever changing and supportive. PhDs who come to McKinsey appreciate the chance to tackle a new challenge with each engagement, and they develop personally and professionally as they go, with mentoring support, on-the-job training, and more formal learning opportunities such as our Business Essentials program and leadership courses. For someone who has spent years conducting research within the same field, coming to McKinsey offers the chance to branch out—to explore new industries and new ways of thinking. Many consultants with PhDs in fields such as pharmaceuticals or high-tech go on to work in those areas, but some choose to enter industries they might never have been exposed to before joining McKinsey, including media, private equity, consumer goods, and banking.
Every McKinsey engagement demands the same qualities you need to succeed in academia: strong problem-solving skills, intellectual curiosity, and the drive to achieve results. The difference is, at McKinsey you’ll be working with and presenting your findings to business, government, or social-sector leaders. McKinsey consultants learn to solve problems quickly and make fast decisions, even when they don’t have all the information about a particular subject. Consultants with PhDs say one of the biggest challenges—and most attractive aspects—of a career with McKinsey is this shift in thinking. In the academic setting, they grew accustomed to diving deep into a subject, often spending years gathering and analyzing data. At McKinsey, consultants learn to work with the most important information, whittle a problem down to its core, and offer a solution that helps a client make better decisions, often when it’s not a clear-cut, easy answer.
Joining McKinsey would be a major career change for me. How can I ensure my success in the long term?
Consultants with advanced professional degrees outside of business are elected to partner at McKinsey just as often as consultants with MBAs. We want you to succeed, and we’ll support your growth with formal training and development programs to continually strengthen your business and leadership skills. Our apprenticeship model ensures you’ll always have experienced consultants to turn to for advice or insight. Expectations are high—McKinsey consultants handle some of the most sensitive, critical issues faced by the world’s top organizations—but they’re also clear. You’ll know your responsibilities before beginning each client engagement, and when you need help, you can turn to one of your fellow consultants or one of our 30,000 plus alumni worldwide. You’ll grow with each engagement, but you’ll be the one directing that growth. We understand that not everyone wants to become a partner. If you find another opportunity that interests you, we’ll support you as you pursue it. You’ll take the skills and knowledge you built at McKinsey with you into your chosen field, and you’ll stay connected as part of the global McKinsey alumni network.
McKinsey can enable you to build skills in new industries and functional areas as well as use and build on the skills and experience you have already gained. After building on your core consulting skills, you can choose to craft a program that leverages your background, experience, and knowledge by serving clients on topics close to your background area, or you can choose to focus your program on completely new client topics. In either case, you should be prepared to increase your knowledge base of new industries and functional topics.Whenever your organization uses a third party as a processor, there must be a data processing agreement in place. This contract, which can be integrated in the general contract with the third party, is important to ensure that both parties understand their responsibilities and liabilities regarding the processing of personal data. A clear contract negotiation and onboarding process sets the basis for a structured and successful relationship with a third party. This process should involve all the requirements, controls and procedures that are relevant to your business with regards to data protection, data use and privacy compliance. A clear contracting and onboarding process will make sure that your future contracts with third parties contain adequate privacy measures. To make sure also existing contracts with third parties contain adequate privacy measures, those could be addressed through a risk-based approach and adjusted where needed.If you have read any of my articles over the years you will know that I subscribe to the definitions of DevOps that focus on outcomes and business value, not the definitions that focus on tools and engineers. Having said that, I have frequently written that DevOps is about continuous learning and improvement and removing bottlenecks from the software development lifecycle (SDLC).
As I look back over the last 10+ years since the term DevOps was coined, I have witnessed a pattern of removing bottlenecks from the SDLC in the following order (usually):
In the early days, DevOps was mostly focused on solving the bottleneck of inconsistent builds and environments. Practitioners focused heavily on tooling and automation around the build process and infrastructure. This is the primary reason why many people think DevOps equals CI/CD, but as you will see in the rest of this article, it has moved way beyond that. CI/CD is a commodity now and an area that many organizations have solved yet are still continuously improving over time.
As practitioners beefed up their skills in perfecting the build process, they looked to solve the next bottleneck which was throwing the code over the wall to be tested. A lot of time was being wasted in the back and forth processes required to shake out the critical defects. Automated testing became a standard for the CI process from this point forward.
Most companies who have been on their DevOps journey for a few years, have a solid track record with CI/CD and automated tests in the build process and are now focusing on one or more of the next bottlenecks.
Yes, the dreaded DevSecOps term. Practitioners who removed many of the bottlenecks caused by inconsistent builds, unrepeatable deployments, and lack of test automation now look to remove the next big bottleneck which is usually security. A lot of work is happening in enterprises to involve security teams and security architects in the SDLC from the start. Security code scans are now part of many CI/CD pipelines. Security policies are being baked into cloud platforms and continuous security monitoring and alerting is becoming the new norm.
Traditional Ops is being totally rethought. We see a lot of movement around SRE (site reliability engineering), observability, platform engineering, chaos or resiliency engineering and many other modern approaches to running apps and platforms in the cloud.
Nothing says bottleneck more than governance and compliance. Many mature DevOps shops are focusing heavily on culture change in this area. Some companies are creating governance and compliance teams that focus solely on the cloud and act as a liaison back into their respected COEs (Center of Excellence) in corporate IT as a way to speed up approvals and decision making.
Another major bottleneck is problem resolution and MTTR (mean time to repair). Many companies are shifting support left, closer to the people with the proper context of the application so that problems are solved faster. This usually requires a culture shift to product centric mindset as opposed to project centric mindset and t-shaped management structures where the same manager who is responsible for building the software also owns supporting it.
While I have watched this unfold over the last 10+ years, I often ask “why aren’t we talking about architecture?” All the automation, op model changes and process improvements in the world do not solve for bad or overly complex architectures. At the DevOps Enterprise Summit in 2019, I watched a great presentation by architect Scott Havens that nearly brought tears to my eyes. Finally, someone was talking about architecture as a bottleneck and prescribing a way to address it. He discussed functional programming methods and ways to avoid or simplify complexity in systems. If you are technical and have 30 minutes, I recommend watching this video (he starts around the 7-minute mark).
I wish more architects would be more pragmatic like Scott. I have seen too many instances where architects run to microservices as an end-all be-all solution to solve all of their problems only to create a complex mess of unmanageable chaos. Microservices are only as good as the architecture they are deployed in. The same can be said for any of today’s hot new technologies such as Kubernetes. I run out of fingers and toes to count how many times I have seen teams run off and go dark on the business as they spend precious dollars and hours building Kubernetes clusters for the sake of Kubernetes, not for the sake of the business.
Microservices, Kubernetes, Cloud, AI, ML and all other hot technologies are all force multipliers and can be powerful business enablers, but all of them are only as good as the architects and the architecture for which they are designed and deployed in. Take a page from Scott’s talk and design a well thought out architecture to avoid complexity and solve real business problems.
DevOps is all about working together to build more reliable software with more agility while delivering business value. As we mature along our DevOps journey, we must focus on continuous learning and improvement while we change the way we think about systems, the way we work and the way our culture embraces change.
While we focus on our people, process, and technology bottlenecks, let’s not forget that our success can be severely limited by the complexities caused by both or legacy and new architectures. As we run to new tools and technologies to achieve our technology nirvana, let us not forget that a pragmatic architecture that limits complexity, anticipates and recovers from failure at all layers and focuses on delivering business value can be one of the best ways to remove bottlenecks from your entire SDLC.
Great architectures minimize technical debt thus freeing up staff to contribute to even more business value. Refrain from using tech for the sake of tech and start creating real business value with a focus on architecture, not tools.As the future of work unfolds, adaptable learning organizations will likely stay ahead of their competition, attract the best and the brightest prospects, and manage market movements with their customer base with more agility. Learning leaders are well positioned to lead the charge to develop an adept workforce that can not only respond to rapid shifts in markets, but also thrive in them as well.
HR professionals use virtual reality to facilitate employee training and increase retention. Sports reporters use natural language generators to automatically recap games and to highlight interesting statistics. Actuaries use cognitive computing to automatically evaluate data, compute results, and predict new patterns. Professionals across many industries engage employers in alternative work arrangements through the gig economy. This future of work is rapidly becoming reality as technology develops exponentially. Exponential professionals are those who capitalize on the shifting workplace by embracing new technology, leave behind traditional automatable tasks, and apply their uniquely human skill set to more high-value, strategic roles.
AI. Automation. Machine Learning. Natural Language Processing & Generation. New technology is rapidly disrupting and transforming the nature of work and the identity of professions by enabling humans and machines to work together, side by side. A new breed of professional is rising to navigate this shifting landscape by embracing technology, leaving behind traditional tasks, and applying a uniquely human skill set to focus on higher-value, strategic roles. Enter the exponential professional.
Is capitalism broken? Rising inequality, high profile corporate failures and the potential for technology to displace millions of workers has prompted many to ask this question. It will be part of the discussion at Davos this week, where world leaders will debate what’s holding back inclusive economic growth. They’ll also question how ready we are for the Fourth Industrial Revolution – the blurring of technology into all aspects of our daily lives – and whether businesses are doing enough to manage the impact of automation on the workforce.
Mornings are easier than ever for me. True, I need to be careful shaving around the RFID chip in my chin. That’s a small price to pay for not having to look around the house for my wallet and keys, which I no longer need because that tiny chip and biometrics lock my front door and start my car, which now drives itself. And if something goes wrong on the road and I arrive at the hospital unconscious, my RFID chip will present my medical history to emergency room doctors.
The rise of robots in organizations has resulted in two schools of thought—those who believe robots will replace humans and those who believe robots will help humans perform better.
Industry has used robots for decades. They were once confined to safety cages in manufacturing facilities, programmed to perform one task perfectly, over and over again.
The future workplace is going to require a change in organizational culture, and this needs to come from the boardroom.
Today’s interview is with Erica Volini, who is the US Human Capital leader for Deloitte Consulting. Erica joins me today to talk about the Future Of Work, the implications for organizations, organizational transformation, Digital DNA and how the employee experience fits into all of this.
Mix smart machines, businesses as platforms, and diverse teams solving complex problems, add a whole lot of uncertainty, and you have a recipe for the future of work. Jeff Schwartz ’87, a principal at Deloitte, discusses how leaders can navigate fast-approaching opportunities and challenges.
By 2025, cognitive technologies — that’s robots, AI, machine learning and automation — will replace 7% of jobs in the U.S. By 2033, economists predict AI could convert 30 percent of full-time jobs today into augmented services completed through a collaboration of human and automated labor.
Your organization, like most of those we see, is probably already incorporating contingent workers in your talent mix, and likely seeing year-over-year increases in the number of contingent workers in your workforce.
We recently sat down with Josh Bersin, the Founder of Bersin, to discuss where he believes the future of work is heading towards, and what the most important aspects to consider within that would be.
The head of one of Australia’s biggest professional services firms believes public negativity and misconceptions are preventing Australia from fully embracing automation. Deloitte chief executive Cindy Hook, who also heads a Business Council of Australia committee looking at the workplace, says business and government “need to change the narrative” that automation, robotics and digitisation will eliminate jobs, “because that’s not the case”.
As organizations navigate technological and societal shifts, corporate boards will have a critical role to play. Diversity of thought—and of people—will be more vital than ever to ensure that boards are considering different perspectives and exploring challenges from every angle.
What skills are essentially human? It’s a question that many HR professionals never thought they’d need to answer. But with the advent of AI, robotics, sensors, and cognitive computing, that’s what every HR professional should be asking—because the future of work is here.
On Tuesday, I participated in a panel discussion hosted by the Organisation for Economic Co-operation and Development (OECD) on the rapidly evolving workforce and the role business can play in navigating these changes.
We are living in an age of disruption. More than 50 years after the formulation of Moore’s law – which holds that computing power doubles on capability every 18 to 24 months – technologies such as artificial intelligence (AI), mobile platforms, sensors, robotics, and social collaboration systems are becoming more pervasive before revolutionizing the way we live, work, and communicate.
As I prepared for my time in Davos, I spent some time thinking about what the biggest takeaways will be. Clearly, based on the recent buzz over the past year, the future of work and how to navigate it is on many people’s mind. The fact is that we are already living this future and to be successful in the next three to five years we will all have to embrace constant change.
The world of work is rapidly changing as we deal with new technologies, AI, generational changes, and a more interconnected organization. What are HR’s mandates in this new world? Moreover, how can HR add value in organization design, driving new models of leadership, driving engagement, and improving organizational culture?
The phrase “Future of Work,” has become a buzz word. (I found 48 million Google hits on the phrase.) There are are suddenly hundreds of conferences, books, and articles on the topic, covering everything from artificial intelligence to robotics to income inequality and contingent labor.Digitization in companies is advancing more and more. Even though processes are increasingly being carried out electronically, logistics service providers often receive their orders outside the transport systems - often still via analog channels. This increases the effort required on the part of logistics service providers to record shipment data.
In order to optimize the yard planning, staff utilization and operational processes, an increasing number of clients is asking their logistics providers to book dedicated time windows to pick-up and deliver goods. The booking of the time windows usually needs to take place 24h before pick-up/delivery. The booking itself causes additional effort for the logistics providers and reduces efficiency. In addition to that, the flexibility to plan the pick-up/delivery tour is reduced which can negatively affect the utilization of the available loading capacity.
Customers are increasingly demanding reliable transparency on the status of shipments from their service providers. This requirement presents logistics companies with an enormous challenge. On the one hand, the recording of the conventional barcode by warehouse personnel is time-consuming and therefore inefficient. On the other hand, additional information, such as temperature or vibrations, must be transmitted to the customer more frequently. Current transport systems are often not suited to provide this type of information.
In the event that companies do not transmit their shipment data electronically, the data must be recorded by the service provider. This entails the risk of incorrect information being recorded, which is even increased by the existing shortage of skilled workers and outsourcing. In addition, shipments cannot be reloaded as long as the shipment data has not been recorded. In reality, this repeatedly leads to delays in operational processes.A blog post by David Cutbill, partner, Deloitte & Touche LLP and Beth Kaplan, managing director, Deloitte & Touche LLP.
Many US publicly-traded companies that operate on calendar fiscal years are now expected to include leases on their balance sheets as of January 1, 2019. As public companies implement the new lease accounting standard and private companies continue to prepare for the January 2020 effective date, Deloitte pulled together a group of industry executives to take part in a special Dbriefs to answer questions and discuss their lease accounting compliance efforts.
Guest panelists, Anne Bernath of American Airlines Inc., Tiffany Moseley of Valero Energy Corporation, and Todd Sears of Walmart Inc., shared their thoughts on the new lease accounting standard, including lessons learned during implementation and some of the near- and long-term actions companies are taking to prepare for reporting and improve overall operational efficiency.
Take a look at our summary of highlights and insights from this special edition Dbriefs and listen to our Green Room podcast for a deeper dive discussion with additional insights from our guest panelists.SAPinsider says that a little more than half of SAP customers planning SAP S/4HANA investments are opting for either new implementation or system conversion.2
Those choosing a new implementation typically want to eliminate custom programs, shed ineffective practices, and drive more standardization around best practices. Organizations that implemented SAP when they had simpler business models, different competitors, and a less demanding customer base find this approach allows for remodeling to support productivity and growth. It also lets them start afresh and keep their ERP clean.
Those choosing system conversion usually want to preserve some of their custom environments and have business models that have not evolved. They see this as a lower-cost path, one that could require less change management. This approach is often used by companies that completed SAP implementation within the last five to seven years. These companies don’t need to transform, but they want to take advantage of the SAP S/4HANA digital platform.
For many SAP customers, a new implementation or system conversion can be combined with a third implementation option: leveraging SAP Central Finance.
SAP Central Finance allows companies to deploy a single instance of SAP S/4HANA Finance and then integrate some or all their financial and operational processes back through that instance. A company’s current SAP or non-SAP financial systems don’t need to be converted and can remain in their existing environments.Leads our agile work in Central Europe and our Enterprise Agility Center in Budapest and helps institutions across industries to shape growth strategy and transform themselves in the digital age
October 5, 2020 In previous research, our colleagues have outlined the importance for agile organizations to create both stable and dynamic practices. A periodic business review, prioritization of different activities, and alignment across organizational units (frequently called tribes) are often together referred to as Quarterly Business Reviews (QBRs). QBRs can be the cornerstone of an effective agile organization, linking overall strategic direction to agile organizational units and team-level backlogs.
When done well, QBRs can bring immense value to an organization by creating vertical and horizontal alignment. However, inefficiencies often occur due to limitations in the ecosystem around the QBR—even if the narrowly defined process is done well. There are five reasons behind these suboptimal operations:
QBR ownership: The QBR and the broader ecosystem surrounding it are at the heart of an agile organization and must have a proper owner. This role spans three main activities: managing the QBR process, ensuring proper content quality, and continuously improving the QBR. A dedicated squad is required during QBR cycles, combining agile, IT, finance/budgeting and strategy expertise, and a strong and respected leader. Broad dependency alignment: During the QBR process, these units set Objectives and Key Results (OKRs) and plan what they will deliver to achieve them. Ideally, a substantial portion of the unit backlog can be delivered autonomously by the owner of the group, while a smaller fraction requires broader alignment. The QBR should serve as a forum to understand those dependencies and resolve them while not making the process highly technical and administrative. For instance, one LATAM company organizes a quarterly fair where each unit leader presents its initiatives and all other leaders are responsible to challenge them and understand potential dependencies. Traditional budgeting: Agility brings a paradigm shift in the logic of budgeting. Instead of projects, agile organizations use cross-functional teams as budgeting units. Agile organizational unit leads must assume resources are relatively fixed, and their job is maximizing impact, generated via prioritization. This is important, because if agile organizational units are subject to traditional project and business case-based budgeting logic, then QBRs cannot function properly. If fully agile budgeting is not realistic in the short term, companies can opt for a hybrid approach. For example, a leading bank uses QBRs to review budget status against delivered business results—and potentially make adjustments in a transparent and fast way during the QBR meeting, if circumstances require. KPI and OKR misalignment: OKRs are among the most fundamental elements of QBR logic, used by many organizations to set aspirational targets with motivating narratives to rally people behind a common vision. In the QBR, these units must define OKRs from strategic company aspirations. Yet, organizations often struggle to draw a connector line between the newly introduced OKR concept and end-of-year key performance indicators (KPIs). A Western European bank defined the value driver KPIs for each agile organizational unit and derived OKRs that helped to achieve these relatively fixed end-of-year KPIs. Disconnect from IT processes: In an ideal agile environment, agile organizational units can release standards and an IT architecture vision. This is rarely the case in large corporations due to legacy architectures and monolithic systems. Given that planning for major monolith IT systems often requires 12+ months, QBRs often need to co-exist with IT release planning. One European telco solved this by synchronizing the timing of IT release planning with QBRs, and then used them as a complementor forum—refining and breaking down the upcoming portion of the high-level IT roadmap.
Building proper QBR practices and enabling the ecosystem takes time and effort. However, once these pain points are addressed, the QBR can truly act as the nerve center of the organization, transmitting key impulses and strategic signals.Global process owners (GPOs) are individuals who own an end-to-end process across functional silos, geographic and business unit boundaries. The role has become increasingly common, in line with the development of global operating models and the concurrent evolution of the process model.
While GPOs have arguably been successful in bringing about gains in process efficiency and effectiveness, there may be opportunity for GPOs to add enterprise-wide value. Companies are pushing to manage global business services as a single organization and are leaning towards a service delivery model that has fewer global locations rather than more regional ones.
In coming years, GPOs will have the opportunity to play an important role in enhancing how global business services organizations partner with the overall business. With the right level of management support, GPOs can greatly help in aligning the organization better, changing detrimental behavior, and reinforcing the overall culture and brand in the organization.Intercompany transaction processing at global financial institutions has historically been passed over in favor of other finance initiatives. These decisions were generally founded on:
Global financial institutions are experiencing escalating pressure from downstream challenges caused by legacy complex and manual intercompany processes. These challenges include increased regulatory scrutiny due to apparent data quality issues and reporting inconsistencies, as well as bottom-line tax impacts from the meaningful changes brought on by tax reform. These challenges stem from increasingly granular regulatory data required to satisfy reporting requirements for regulated entities and the challenge of satisfying these requirements with numerous disparate systems and siloed intercompany processes. Additionally, tax reform, while complex, also provides opportunities for companies to analyze their tax footprint in alignment with broader business objectives. These factors are causing financial institutions to revisit their intercompany transaction processes, seeking opportunities for automation, optimization, and enhanced governance.
We previously discussed a new framework with leading practices for the intercompany accounting process and optimization that offers a road map to reimagining the end-to-end process informed by our proprietary intercompany maturity model. To implement a strategy that can align with a company's focused objectives, it is necessary first to address the unique challenges facing the intercompany accounting transaction life cycle at financial institutions.August 21, 2019 From the early 1970s to the mid-2000s, demand for electric power and natural gas in North America outpaced the growth in invested capital. Regulated gas and electric utilities were therefore stable and profitable. They earned reliable returns and were also able to keep customer rates down, satisfying both customers and regulators. These positive conditions, however, also meant that utilities didn’t need to be as efficient with their capital as other capital-intensive industries, such as metals, mining or oil and gas.
Now things are different. Since 2008, there has been no electric load growth in North America. Thirty-three states and several Canadian provinces have actually registered declines, thanks largely to greater efficiency and lower industrial demand. For gas utilities, higher efficiency in home heating and insulation has contributed to stagnating demand. Nevertheless, utilities still need capital, to upgrade aging infrastructure and to make investments in flexibility, resiliency, and functionality. According to Global Market Intelligence, capital expenditures for major North American electric and gas utilities have risen 7 percent a year over the past five years, with transmission and distribution (T&D) accounting for about 60 percent of the total.
At the same time, regulators are pushing back against rate increases. In 2018, they approved only 38 percent of such requests, compared with 52 percent over the previous nine years. Regulators in North Carolina, Virginia, Kentucky, and Massachusetts, for example, rejected requests for rate increases to fund utility grid modernization. There is a growing gap, then, between the amount of money needed to maintain and upgrade North American grids, and what regulators are allowing utilities to charge to raise that investment.
Given these constraints, utilities need to use their capital more productively. They do have options. Among them: aligning capital plans to strategic priorities; focusing on the minimum technical solution; applying lean-construction techniques; and using advanced analytics to make asset-management decisions.
In this article, we discuss each of these options, and suggest questions leaders can ask themselves to determine whether they are using their capital as productively as possible.
Aligning capital plans to strategic priorities: Utilities need a rigorous capital planning and risk-assessment process. This starts with developing a common understanding and quantification of the most important risks. In practice, different asset classes and planning groups often have different views of what matters most; as a result, utilities’ capital plans often miss the mark. Done right—that is, by focusing on the biggest risks and rethinking where dollars are spent—we estimate that utilities can deploy their capital as much as 20 percent more efficiently.
One gas utility achieved this level of impact after doing a thorough evaluation of the roughly $3 billion in capital projects planned for the next three years. The utility created a consistent record of the rationale and scope for each project; this understanding enabled it to figure out which projects mattered most and to spend accordingly.
The types of investments utilities need to make are changing. For example, as more investments are made in supervisory control and data acquisition, automation, analytics, and grid modernization, information technology (IT) needs to support these efforts. Under typical capital-planning approaches, however, IT investments are often left to the end, and then get squeezed for funding. Implementing a planning process that shows regulators the trade-offs between core power systems and supporting infrastructure is an important first step to establish which projects utilities should pursue, in what order.
How has spending evolved over the last five years in different asset classes, such as poles, transformers, IT, and analytics?
Focusing on the minimum technical solution: It is relatively easy to re-think the business case, design, and scope of a project in the early stages. One way is the “scrub.” This is a process in which a cross-functional group of experts ask structured questions and scrutinize the project’s scope and design to identify ways to develop it more cost effectively.
Project scrubs are common in unregulated, capital-intensive businesses that are seeking the “minimum technical solution”—meaning the lowest-cost design that meets current and likely future objectives. The context is somewhat different for utilities, because they have a wider set of stakeholders, including regional transmission organizations, regulators, customers, and municipalities, with varying priorities. Finding the minimum technical solution provides a way to assess whether project add-ons, such as upgrading substation breaker designs or replacing equipment not yet at end of life, are worthwhile. At one utility, a series of project scrubs before design and construction identified 15 percent savings on $400 million of annual spending on large, complex projects in the transmission organization. The effort also identified more than $50 million in large projects that were no longer needed.
Applying lean-construction techniques to capital projects can deliver planned work for less, and additional work within the same budget. Lean-construction techniques have a proven track record in other industries, as well as in utility operations and maintenance (O&M), but they have not been widely deployed in utility capital projects. One reason is that once regulators approve a project budget, the utility has little incentive to cut costs. Another is that utilities make greater use of outside contractors, rather than in-house crews. Lean techniques for field execution, such as daily huddles (Exhibit 1), and tracking and monitoring unit productivity, should be standard practices, but are not.
Exhibit 1 Exhibit 1: Huddle boards can be a useful aid for daily structured conversations. We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Lean techniques should also be applied earlier in the project planning process. “Pull planning” is one example (Exhibit 2). In this process, a cross-functional team starts with the commissioning date of a project and identifies the critical dependencies, such as permitting, rights of way, and design. Then it establishes milestones against each critical component, with clear accountability. In one transmission organization, the pull-planning team found in its first week of work that 40 percent of projects were either not on track or the utility didn’t know if they were. By week four, that was down to less than 10 percent.
Exhibit 2 Exhibit 2: Display boards show job progress and readiness We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Ideally, lean-construction techniques should be incorporated in parallel with the capital-planning process. By using a combination of lean techniques, we estimate that utilities can cut costs 10 percent to 15 percent.
Using advanced analytics to make asset-management decisions: Making sound maintenance, renewal, and replacement decisions conserves capital and lowers the total cost of ownership. Better decisions start with the collection and analysis of data, and this is easier than ever, through the use of monitoring software, automated sensors, drones, satellites, and the improved analytical capabilities available in the market.
One utility improved the use of its data to inform asset-management decisions, leading to almost 10 percent savings in O&M and capital spending. For example, the utility analyzed the maintenance records of the breakers that were scheduled to be replaced in the following year. It found that 40 percent had never needed any attention; for these, preventive maintenance was the right choice. On the other hand, three percent of the breakers had incurred significant maintenance costs; for these, quick replacement was the better option. Though the decisions were different, in both cases, the utility optimized its spending. In general, we estimate better asset management decisions can save about 10 percent—and more if digital tools and data analytics are fully incorporated.
How has asset management decision-making evolved over the last two years, taking into account developments in technology and data?
Improving capital productivity can seem daunting, particularly since many utilities have not had to make this a priority. However, many of these options can be implemented independently and even small changes can yield significant improvements. With affordability pressures increasing and the need for investment growing, utilities have to accept that using their capital better is a matter of urgency.
Adam Barth is a partner in McKinsey’s Houston office. Sarah Brody is a consultant in Washington, DC. Zak Cutler is a partner in Toronto. Corey Hopper is an engagement manager in New York City.Since early March 2020, finance professionals have been forced to shift to a remote working environment, challenging many organizations to manage a quarter-end close with a distributed and sometimes distracted workforce. Financial services have faced challenges and are continually making adjustments to the ways they navigate these complex business challenges.
We wanted to know how it’s working, so Deloitte surveyed more than 25 C-suite professionals in banking, insurance, investment management, and real estate firms on the overall impact of remote work on the execution of the 2020 remote close. In reviewing the results, it is clear that many organizations could have a better understanding of the overall impact the remote working environment has had on the industry and how they compared to their peers in the past quarter.Someone posted an article on LinkedIn the other day claiming “Agile is Dead”. The comments that followed were more interesting than the actual article. Many people were bashing agile frameworks. It is no secret that organizations have spend a lot of money on doing agile and many times never really achieved being agile. Right now, SAFe (Scaled Agile Framework) is trending and many of my clients are implementing it. But methodologies and frameworks are nothing more than a set of guiding principles for delivering software. At the end of the day, doing agile comes down to the three things:
A framework is only as good as the people, processes, and organizational structures that use it. Silos with competing goals always trump frameworks. Each silo creates an unnecessary handoff and increases wait time. Too often, additional processes get added to deal with the interaction between silos.
Then there is the people part. I am old enough to remember when all projects managers had to be PMBOK certified which trained project managers how to follow a set of processes and procedures (framework) to navigate the waterfall methodology. When we moved to agile, all these people were retrained and became certified scrum masters. Unfortunately, they still had the old command and control, sequential mindset and most agile efforts became “Wagile” — waterfall with daily standups.
The point here is it takes much more than a few training classes or certifications to change the mindset. This is a transformation and requires an investment in organizational change management to get the value out of the new frameworks.
All the process in the world can’t fix a bad architecture. To do agile, one must have an architecture that supports being agile. Characteristics of an agile architecture include:
Service-oriented — opposite of Monoliths, the system is made up of small parts that can be deployed separately
Testable — system supports testing hypothesis with methods such as A/B testing, feature flags, chaos engineering, etc.
The more a system supports the characteristics above, the more agility can be achieved. Not all systems need to implement all of those characteristics, but each characteristic can reduce manual intervention, allow for more frequent deployments and quicker MTTR, reduce widespread system outages, and provide for better availability. It can also reduce the amount of unexpected work which is probably the biggest single issue all agile frameworks struggle to deal with.
Even if you have an agile architecture and your agile framework is being executed flawlessly, if your operations people and processes are not in alignment, the whole house of cards will come tumbling down.
There is a lot disruption in operations these days. DevOps has played a huge roll in getting developers and operators collaborating better. Operations is now being thought of earlier in the lifecycle and teams are designing for ops. Companies are reevaluating their operating models and investigating newer practices such as Site Reliability Engineering (SRE), accepting that testing in production is a good thing (if done right), moving from reactive to proactive operations, embracing observability, and much more. As we move to more agile architectures, it’s common sense that we need to embrace more agile methods of operations.
The list goes on and on. I have yet to see a framework that even mentions most of these characteristics. The frameworks focus mostly on how to manage backlogs which is important, but if the software and the operations of that software does not promote agility, the framework is not going save you.
Organizations should focus more on being agile rather than doing agile. Being agile requires more than a framework. It is a mindset and it should be applied everywhere, not just in Dev and Ops. The Security and Governance teams need to be agile. Procurement can’t take six months to procure a software product. Decisionmakers need to come to conclusions in a timely manner. Processes that take forever should be redesigned. Approvals should not take forever. You get the point.
Being agile is a cultural issue and should be treated as one. If you want to make your organization agile, adopting a framework is only one piece of the puzzle. In fact, many teams that I have seen that are truly agile use no framework at all. They do a good job of managing a backlog and they do a great job of collaborating, writing good software, automating everything they can, and recovering from issues quickly. At the end of the day, agility can be measured by customer satisfaction. If the customer is getting their demands met, the system is reliable, and issues are resolved quickly, it really doesn’t matter what framework you use.December 16, 2019 For most organizations, the clear boundaries of who is “in” and who is not are becoming blurred, and what seemed like bright line differences are now becoming like concentric circles, where the types of people and organizations working together to create value vary widely, and system participants exist along a spectrum.
Consider some vendors in a value chain ecosystem who - in every other way but being on a company’s payroll - act like employees. Are they part of the organization or external? In today’s world, perhaps the answer is not such a simple either/or. It might be more helpful to see some participants as neither at the inner core, nor fully external.
Defining the “who” matters because it can radically expand or contract your focus when evaluating whether your operating model will deliver on your strategy. We believe companies should increasingly have strategies for how they deal with “quasi-employees” and other participants in their system who are neither traditional “inner core” employees, nor fully external.
Leaders have an opportunity to take control of their ecosystems and shift from passive subjects to deliberate architects of a much broader range of participants in the organizational system. Taking a holistic, systemic approach to operating model design and including the broader ecosystem as part of the solution space can deliver real opportunities for value creation. To ensure organizations can deliver on their strategic value agenda in an increasingly complex world of opportunities, we believe leaders must incorporate ecosystem design into the operating model design process and pressure-test old boundaries, become more expansive in the scope and aspirations of the redesign, and explicitly create more flexible organizational perimeters that effectively utilize the concentric circles of people and organizations within an ecosystem.
An insightful example of this is the ubiquitous credit card company Visa ™. When the credit card business exploded onto the banking scene in 1966, the initial impact was chaotic. The systems for managing sales drafts, data entry and clearing of sales were primitive; each merchant-signing bank accepted all transactions regardless of the issuing bank, and reimbursed itself by drawing a draft on each issuing bank through the Federal Reserve system. The clearing draft was then posted to a suspense ledger while waiting for the merchant bank to send them through the U.S. mail. And that is only half of the utterly complex, siloed process that effectively led to hundreds of millions of unprocessed transactions and, ultimately, provided opportunities for criminal activity.
Dee Hock, a bank official, was involved in organizing regional committees to help address these major issues. Hock would eventually go on to found Visa™ by shifting from a passive subject to a deliberate architect of the banking ecosystem in which the credit card idea was born. While there is nothing simple about the processes and structures that had to be developed to deliver on the ultimate goal, Hock understood early on that no one bank or financial institution could own the credit card (or resolve the myriad problems it produced) and developed an idea of a self-organizing, networked organization that could evolve, organize and invent itself. Rather than design the organization, Hock came up with some basic principles of organizing that would facilitate the complex self-organization of the committees that had already been created.
When leaders let go of old paradigms and adopt new ones, it unlocks opportunities in our increasingly connected world— one where the sources of value are constantly changing. Because these shifts are constant, successful leaders will need to take an open systems view over a mechanistic view or organizations. Not only will leaders begin to better understand the current landscape, they will be empowered to make choices on what to do about it and expand value creation opportunities.
This blog post is part of a series on Organizing for the Future, which explores a set of new principles such as anti-fragility and experimentation that are becoming increasingly critical for today’s organizations as they build more creative, adaptable, and human systems.Leaders throughout industries have ambitious visions of how digitization will transform their core businesses. In service industries, the vision typically includes completely new consumer journeys enabled by comprehensive self-service, integrated omnichannel offers, and full utilization of all available data. As a result, data flows digitally in a highly automated manner, costs are lowered, efficiency and quality improve, and flexibility increases.
This vision may come true at some point. In the near term, however, it is highly unlikely that payers will be able to adopt fully paperless processes, despite the myriad problems manual document processing entails. Although many payers have taken steps to move away from paper, they have found that eliminating it is more difficult than they anticipated. Both internal and external factors have made the transition to fully paperless processes nearly impossible as of yet.
We expect that a large share of all paper-based interactions at most payers today could remain paper-based for at least the next several years. Given this, finding ways to process paper-based documents in the most efficient way possible—and to smoothly merge data from paper and digital sources—is becoming an imperative for all businesses that must process a high volume of documents from consumers, providers, and vendors. In this article, we describe an approach that payers can use to achieve these goals.
In every industry in which paper plays a significant role, manual document processing causes problems. Manual processing is slow and tedious. It requires employees to perform repetitive, monotonous tasks while adding little value, which can reduce their job satisfaction. Manual processing is also error-prone and not transparent, and thus often causes operational inefficiencies and confusion among teams. As payers expand their use of omnichannel strategies, the lack of process transparency also impairs consumer satisfaction. In addition, paper data can hinder growth, since it makes it more difficult for companies to gain insights from advanced analytics.
Given these problems, it is not surprising that pundits have predicted the demise of paper for more than 30 years. Nevertheless, fully paperless processes have yet to materialize in many businesses (Exhibit 1). Progress has been especially slow in service industries. One large German payer, for example, still uses about 100 tons of paper each year for its claims operations alone. A medium-sized European payer purchases five truckloads of paper each year just to support customer service. Yet both companies have striven to eliminate as many paper processes as possible. Why have these and other payers found it so hard to stop using paper?
Exhibit 1 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
The progress toward fully digital document processing has been hindered by a variety of factors. Internal roadblocks include general organizational rigidity, risk-averse decision making, and employees’ fear of job losses. Moreover, designing and building new IT solutions, then integrating them into existing organizational technology, is inherently complex and usually requires changes in both behavior and processes, as well as significant company investment.
Given the economic benefits of fully digital document processing, many companies are starting to find ways to overcome these obstacles. However, they have found it much harder to get around external obstacles. Payers operate within ecosystems that include partners, vendors, providers, government agencies, and consumers. Getting all these stakeholders to agree to adopt fully digital communications requires a comprehensive transformation, which for many of them entails significant switching costs. For example, providers in countries with multipayer health systems may need to adapt their claims submissions processes to account for the requirements of different payers. Many consumers may be reluctant to switch to digital self-service because health insurance is often a low-involvement product—touch points are infrequent, which gives consumers little incentive to memorize login credentials and keep their contact information up to date.
Moreover, regulations may hinder the move away from paper in many countries. Payers and other companies that deal with health data are usually subject to strict data protection laws. Security and privacy standards are not only stringent but also often tailored to the use of paper-based communication. In some cases, regulations may require a member’s signature on a form. Even if the regulations do permit two-factor digital authorization as an alternative, it is often difficult for payers to establish sufficiently secure transactions.
In short, paper-based processes endure because they are well-established in payer organizations, avoid high switching costs for outside parties, and do not require members to interact with digital platforms they may use infrequently. Because this situation is unlikely to change rapidly, payers that want to gain a competitive advantage must find better ways to handle paper while moving toward the longer-term vision of fully digital processes
Payers can generate significant value during the transition to a fully digital future by optimizing the way in which they process paper documents and other data. The consequences of suboptimal document processing are significant. Effective handling of paper is crucial because data is at the core of the payer service offer, and paper continues to be a main source of data from day-to-day operations. Furthermore, data analytics is increasingly important to support strategic decision making. Leading businesses use analytics to discover valuable consumer and operational insights; the lack of access to data in digital form makes it much harder for a payer to do this.
Fortunately, new technologies have emerged that enable more efficient processing than has been possible before, including quicker and more accurate information retrieval from paper documents. (This retrieval process is called document ingestion.) Ranging from intelligent character and pattern recognition to machine learning, the technologies have made impressive progress in recent years.
The benefits offered by these new technologies go far beyond efficiency improvements (as important as those improvements may be). Accurate, structured data is a prerequisite for many other digitization efforts, from omnichannel to analytics transformations. Automation efforts rest on good data and cannot be successful when information is buried in large piles of paper.
Digital document processing has three main phases. The first phase, document ingestion—our main focus in this paper—is the route through which incoming information on paper documents is “consumed” and then made available in a structured, digital fashion (Exhibit 2).
Exhibit 2 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
In the second phase, digital data is processed internally using automated workflows. By optimizing these workflows, data usage can also be optimized, which often avoids the need for redundant stakeholder communications (for e.g., asking consumers for the same data multiple times). By combining the data derived from paper documents with the wealth of digital data already available, a comprehensive data landscape can be established, significantly enhancing data evaluation and analytics possibilities.
In the third phase, documents are delivered to stakeholders more efficiently. Many types of outgoing communications are shifted to digital channels, and the processes required for paper-based communications are streamlined. Keeping coherent records is a crucial efficiency lever because it ensures that information is sent to the appropriate point of contact (for e.g., when billing confirmations are sent to providers).
To get digital document processing (including document ingestion) right, payers must understand and master all three phases. As part of this effort, they need to consider the full range of documents that will have to be processed. Incoming mail and other physical documents are an important source of data, but not the only one—many documents that arrive digitally can pose significant challenges if not handled correctly. Emails, for example, may require significant effort to become structured, digital data that can be processed automatically.
To incorporate the full range of documents that need to be processed, a digital document ingestion workflow typically has six steps (Exhibit 3):
, to turn paper documents—physical mail, for example—into digital images Optical character recognition (OCR) , to detect characters in the digital images and convert the output of a scanner or fax machine into digitally stored text
, to detect characters in the digital images and convert the output of a scanner or fax machine into digitally stored text Data extraction , to pull out relevant pieces of information from the OCR output and other digital sources (for e.g., email or online chats)
, to pull out relevant pieces of information from the OCR output and other digital sources (for e.g., email or online chats) Interpretation , to take effective, logical steps to transfer the information to relevant IT systems
, to take effective, logical steps to transfer the information to relevant IT systems Exception handling , to recognize errors and uncommon scenarios and provide alternative routes for their proper handling
, to recognize errors and uncommon scenarios and provide alternative routes for their proper handling Data utilization, to ensure awareness of newly available information, trigger relevant workflows, integrate data into consolidated views of consumers and providers, automate processing, and ensure data security
Exhibit 3 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Effective document ingestion cannot be established without a proper foundation. To build the best possible processes, payers need to put these critical components in place: technology, organization, and capabilities/sourcing.
Technology. Document ingestion requires effective new tools. However, it also has significant implications for the supporting IT architecture.
Introducing new technology is a pivotal element in establishing document ingestion. Although basic OCR solutions to digitize information are typically easy to implement, subsequent steps in the workflow are much more challenging. In particular, turning a large range of semistructured, or even unstructured, information into meaningful data often requires highly advanced OCR solutions such as intelligent character recognition (ICR) software, which has much higher recognition accuracy than traditional OCR software.
Once the information is made available in a structured digital format, the data usually requires further refinement before it can be processed automatically; it is because of this requirement that document ingestion goes far beyond the mere reading of information. For example, the data must be embedded into comprehensive records stored in a consistent format and find its place in comprehensive data models describing consumers and providers from a payer point of view. An event bus (a software mechanism that allows different components in an IT system to communicate with each other) must pass the information on and ensure that all relevant IT systems are made aware of the new data. Automating this part of the process often requires a wide range of application programming interfaces or robotics solutions.
Organization. Improving document-handling processes takes significant cross-functional effort, strong organizational commitment, and careful change management.
Document ingestion has important implications for a payer’s organization. At a minimum, the organization needs to establish corresponding roles and responsibilities to ensure that all steps in the ingestion process run properly. More importantly, altering the way paper is handled requires a significant change effort. Many organizations could benefit from establishing a dedicated team to act as a “digital factory” that uses a process-by-process approach to achieve organizational change in all business units and departments. Such a team is usually staffed with full-time members who operate in an agile environment with substantial management support. The digital factory builds new IT tools and processes, but also reshapes the ways different organizational units work on a day-to-day basis. The addition of cross-functional project teams with rotating personnel inside of the digital factory enables the spread of new knowledge throughout the organization.
Capabilities and sourcing. Implementing the correct technologies and processes and ensuring that the necessary changes are embraced typically require the use of both internal and external expertise.
To successfully implement document ingestion, companies need the right capabilities—they need to be able to redesign existing processes, build required technologies, run the new systems, and manage change. These capabilities can be built in-house or acquired by partnering with vendors or other organizations. In many cases, both internal and external resources are necessary.
Currently, the document ingestion industry is shaped predominantly by OCR vendors. Their solutions are a central pillar of the overall technology blueprint, but some organizations have found their products difficult to install and run. Furthermore, know-how is usually lacking outside of these specialized firms. As a result, companies often find themselves locked in with individual vendors. Strong vendor management capabilities are therefore especially important.
Sidebar Case study: digital document ingestion A large German payer enabled a large-scale digital transformation by optimizing digital document ingestion. Several factors had led this payer to believe that paper would remain a major channel for several years or more. For example, many of the providers and government agencies it dealt with were behind the curve in digital adoption and regulatory issues (including data privacy concerns) were making it difficult for the payer to move consumers to digital channels. The payer therefore decided to incorporate paper-based communication into its overall omnichannel strategy but also created a road map to help it move toward omitting paper from its internal processes. The payer started by optimizing its methods for scanning and OCR of all paper documents and then entering the digital files into a document management system. In this way, the payer was able to avoid storing additional documents in physical archives and reduced the time that many work items were in transit. These changes made it easier for employees to work from home by providing digital access to all documents and improved the company’s performance management capabilities. The payer’s second step was to create a shared-services center that would be responsible for data transfer from paper documents into the company’s core IT systems; the business units would take over once the data was in the core systems. As a result, the business units increased their efficiency through labor arbitrage and more straight-through processing. Because of the momentum generated on the business side, the payer then established a central output management system for printing and letter finalization, which allowed the business units to achieve higher quality and even greater efficiency. No letters had to be handled manually by an employee. Finally, automated data extraction was introduced to manage the transfer of data from documents into the core systems. As a result, the shared-services center gained efficiency, which freed up valuable time so that employees could focus on more consumer-centric processes, such as personalized communication.
Companies that successfully implement digital document processing—including document ingestion—often use a similar approach, which is frequently embedded in a larger digital transformation.
First, these companies identify the right technology vendors to build and run the necessary components along the full document processing value chain. In addition, they typically assess the potential of process redesign and identify the behavioral changes that will be needed throughout the organization.
Second, the companies often use a dedicated project team to put the essential IT infrastructure in place relatively quickly. Typically, they undertake an initial technical proof of concept and then start building the IT infrastructure while transforming the first end-to-end processes (for e.g., invoice processing for a group of chosen pilot providers).
Third, they scale up the effort by setting up a digital factory (as described above) and start to rotate people in and out of the effort. In addition, they begin transforming payer processes one by one (perhaps by starting with claims, then moving on to invoicing). In this way, the new technology and organizational structure of all paper-based processes at the companies are transformed.
Fourth, the companies not only use a digital factory but also undertake a dedicated change management effort to implement the digital document processing system. Employees who are used to paper-based processes and often have considerable control over process decisions typically need help in adapting to the new digital processes. The change management effort is crucial to ensure the transformation is carried out to the end because the last 20 percent of paper-based processes are usually the hardest to eliminate. Attention to change management helps give employees at all levels of the organization the ambition to fully eliminate paper.
Payers, like many other companies, are finding it difficult to realize their vision of fully digital processes. However, they can gain immediate benefits by improving their approach to digital document processing—especially digital document ingestion. This approach acknowledges that paper documents will remain a reality for some years to come but enables payers to move along the path to a fully digital future.
To be effective, digital document processes must consider the full range of inputs (both paper and digital) and cover the end-to-end workflow. To make this possible, a payer typically needs to build or acquire the required technologies and establish the necessary organizational foundation.
Payers that cannot get digital document processing right will put their other digitization efforts—and their ambitious digital goals—at risk.
In all industries, digital document processing in general, and digital document ingestion in particular, are important for core back-office functions. However, their relevance for corporate functions varies across industries (Exhibit 4). Similarly, the typical level of digital document processing maturity also varies across (and within) industries and regions. Payers and most of the stakeholders they work with lag behind most other industries in their level of maturity and thus face high switching costs if they want to move to fully digital processes.
Exhibit 4 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
New digital journeys for consumers can succeed only if they can be seamlessly integrated with paper-based processes and all required information (including claims status) is available.
Analytical modeling (e.g., for fraud detection and automated claims handling) needs to be built on comprehensive data sets.
IT architecture transformations require a comprehensive view of all digital processes and are unlikely to succeed if manual work-arounds based on poorly handled paper-based processes are present.
Unnecessarily heavy reliance on paper is expensive. Reducing the use of paper should be an integral part of any cost-cutting initiative.
Consumer service improvements are of limited use if communication based on physical mail is not handled properly.
Omnichannel implementation requires a 360-degree view of all consumer interactions, including the role played by paper-based communications.
Do not assume that all communications can be rapidly moved to digital channels, making paper superfluous. This will take time. Build IT architecture that can cope with all aspects of document processing. Digitizing the last 20 percent of documents is particularly challenging. Involve the business units as early as possible and pursue a clear minimum-viable-product logic to achieve some early successes. Establish consistent key performance indicators to monitor success and steer toward maximum value. Refrain from overinvesting in the wrong areas. Be cautious about building custom solutions. Available commercial solutions are highly advanced. Do not underestimate the effort that redesigning internal IT workflows requires. Do not overlook basic analytics capabilities—they are often more valuable than artificial intelligence (AI) approaches. However, digital document processing can create a great playing field for building AI knowledge and skills.Sweeping global forces are reshaping the workplace, the workforce, and work itself. Organizations are now rethinking their talent strategies at all stages of the employee lifecycle, vying for top talent in a highly transparent job market and becoming laser-focused on their external employment brand.
Powered by Deloitte’s Human Capital practice, Capital H blog is a forum for sharing insights on all things HR. Timely, relevant, and relatable, the blog features discussions on the HR topics and challenges facing businesses today. Check out the blog by browsing previous topics, subscribing to receive updates when new content is posted, and sharing your opinions on these top-of-mind subjects.Here is a preflight checklist of specific components to think about as you prepare for and continue down the path of ASC 842 implementation.
Make sure that your teams have performed end-to-end testing across the lease ecosystem—including data entry processes, calculations, modifications, transition, reporting, and integrations to upstream and downstream systems.
Organizations should consider the quality and approval processes to determine whether data is complete and accurate. In our experience, an efficient operating model to maintain and align both lease accounting and operational data is imperative for implementation and beyond.
There are a large number of data elements for a lease that are required to be captured, some of which exist in the lease and some that come from sources outside the lease agreement itself. Data is absolutely critical to getting this right from an accounting perspective.
Are internal controls designed and implemented, including such areas as transition accounting; interim solutions, if applicable; ongoing data maintenance; and any other new system-related internal control risks?
Making sure that the appropriate resources are available and trained can ease the transition. In addition, clearly established roles and responsibilities can help to increase the efficiency of talent. Organizational resources, such as a help desk, center of excellence, and on-site support, can also help amplify the performance and effectiveness of talent resources.
Policies around ASC 842 should be ironed out and communicated to stakeholders. Particular consideration should be given to maintenance of accounting policies to keep current with ongoing developments and interpretations.
The new lease accounting standard is a substantial change for many companies. Regular updates and communications to stakeholders are important to help investors and lenders understand the impact of the new standard.
Adoption of the new lease accounting standard will likely present immediate and ongoing challenges to the operating model, talent resources, accounting policies, new systems, and communications. While many organizations and professionals should be wheels up and ready to go, a final preparations checklist can assist organizations through the transitioning months ahead and into the first reporting deadline.
For further discussions and insights to consider as the new standard takes effect, watch the full Dbriefs webcast, Public company lease accounting: Time for the final sprint.
Following the Dbriefs, listen to the Green Room Podcast episode on the new lease accounting standard for public companies, to gain additional perspective and hear in-depth answers to ongoing questions about the implementation process, experiences with software solutions, new borrowing rates, and more.April 19, 2018 You can tell an organization has problems making decisions when you hear these complaints: The organization is “too complex,” possesses a “meeting culture,” or has “too much consensus.” “Too complex” can simply be code for “it’s too hard to get things done.” And while people often finger too many “cooks” as the culprit, we’ve seen matrix structures where, despite many people being involved, roles are clear, how things work is straightforward, and decision-making is fast and effective.
For agile organizations, getting decision-making right is critical since their foundation rests on an action-oriented decision architecture. The result: Organizations with high decision-making velocity and quality generate 2.5 times higher growth, 2 times higher profit and 30 percent higher return on invested capital, our research shows.
Still, decision-making is hard. An unclear or poorly defined process can trigger decision “churn,” where previous judgments are revisited; a “fog of accountability,” where no one is truly answerable; “death by PowerPoint,” where decision-making gets lost from too much information sharing; and bureaucratic governance.
Good decisions are often made quickly. Usually, it reflects a decision-making system designed to maximize engagement of the right stakeholders but minimize the number of decision makers, accelerate the entire process through decision execution, provide ruthless role clarity, orchestrate key points of collaboration, and streamline governance to keep meetings and approvals to a minimum.
While these can help, in many cases they don’t. In fact, more technology and more data can lead to information overload and analysis paralysis. Also, beware of big data and analytics creating a belief that decision-making can be entirely rational, thus taking emotion out of it. Emotion can be very helpful in determining what is good and desirable and what isn’t.
In fact, most “best” practices are conditional. They are good in some situations and not others. Different types of decisions require varying approaches, and advice helpful for some decisions can be terrible for others.
What’s the key to unlocking great decision-making? As we advise in “Untangling your organization's decision making,” any organization can improve the speed and quality of its decisions by paying more attention to what it’s deciding. We recommend segmenting decisions into four basic types and applying a different set of best practices for each:
Big bet: Infrequent high-stakes decisions that affect the organization broadly (e.g., mergers, acquisitions, big investments). In these instances, healthy debate among top team members is more important than data. Cross-cutting: Frequent decisions that affect multiple areas in the organization (e.g., budget allocations across products/regions, sales and operations planning, new product development). Clarity of process is more important than who gets the decision right. Ad hoc: Day-to-day decisions by individuals as part of their job (e.g., interactions with customers). An open and trusting culture with personal ownership and role and strategic clarity are more important than formal accountabilities. Delegated decisions: Day-to-day operational decisions made by a team or individual closest to the information vital to making the decision (e.g., deciding on regional or site level promotions, adjustment to local manufacturing operations). Here, clarifying delegation of authority is only half the battle; leaders need to learn how to empower and let go.
Recognizing these impediments to decision-making and targeting action against them helps improve the choices organizations make. In three forthcoming blogs, we will focus on different decision types and share tested approaches for ensuring the best results.October 1, 2019 Following the annual three-day gathering of approximately 7,000 insurance industry leaders last week at InsureTech Connect in Las Vegas, we reflect on what we heard. Five themes were clearly top of mind for most attendees.
1. Leveraging digital and analytics to reduce costs and streamline current operations. Freeing up capital to invest in growth, customer and agent experience, and other priorities gives carriers the flexibility to strengthen their long-term relevance. As a result, many carriers are prioritizing productivity and using the digital disruption in the industry to accelerate bottom-line impact.
Digital and analytics solutions have helped many carriers identify and harness opportunities to improve productivity across the value-chain, including overhauling general expenses and overhead, optimizing IT service contracts, and reducing claims losses. As innovation continues, incumbents face the difficult task of integrating these technological advances into their legacy operations and navigating an industry culture that often resists digital adoption and change.
2. Using data to enhance customer experience. Developing a leading customer experience begins with knowing your customer. In an industry hugely influenced by intermediaries, sometimes the target customer—be it advisors, end consumers, or another group—is not obvious. Once that target customer is defined, data can support determining how to most effectively understand and support them.
Data is the backbone of much of the disruption and technological advancement occurring in the industry. As a result, a focused data-architecture strategy is critical for supporting both core and digital priorities. This data strategy is also a foundational capability that many insurers overlook as they move to implement more advanced digital approaches such as artificial intelligence or robotic process automation (RPA). But maintaining and organizing data, analyzing data, and making decisions using data are the best ways to enhance and customize customer experience. When transforming customer experience, data is at the center of comprehensive, journey-based approaches to streamline processes and interactions that customers have with insurers.
With more carrier options and more commoditization across products, a leading customer experience has never been as important as it is today. Data is an integral competitive advantage to forming insights that gain customers' trust and approval, and establishing a value proposition that is tied to customer needs.
3. Insuring and managing risk. Insurers must now address an unprecedented amount of new age risk, including that from cyber, cloud computing, and autonomous vehicles, among many others. With the rapid pace of technological advancements, the scope of risks that carriers must protect themselves against (both business risk prevention and mitigation, especially regarding data protection) and insure others against (underwrite) will only continue to grow. To keep up, insurers must understand how to apply new solutions—including AI, predictive analytics, telematics, robotic process automation (RPA) or chatbots, text ingestion, and content-management systems—to analyze and evaluate their risks. Further, in the face of a significant increase in demand, they must use these new tools to determine which risks they are best suited to underwrite based on their appetite and underlying portfolio.
4. Finding growth outside the core. With a largely saturated market across life and P&C, insurers are now searching for their next growth horizon and taking a three-to-five-year view of developing new businesses. Insurtechs are expanding their influence across ecosystems, and carriers are exploring how to best use their core competencies to enter adjacent growth markets. Many carriers have created venture funds to test new growth opportunities while others have installed innovation hubs within their core operating businesses. As lines continue to blur across health, wellness, personal finance, insurance, and other industries, the ability to develop flexible capabilities and integrate with third-party platforms or application programming interfaces (APIs) is becoming essential to enabling successful growth in the near term. Over longer-term horizons, insurers are investing in internal innovation capabilities that link to continuous improvement, pursuing digital upskilling, and adopting a venture capital–style approach to evaluating opportunities.
5. Securing top-tier digital talent. With an aging agent population—our research shows the average insurance agent age is 59—and higher demand for digital and analytics talent, carriers are facing pressures to upskill and refresh their talent pools. The issue of an aging population extends beyond just insurance, with the proportion of the world's population over 60 years-old expected to nearly double from 12% to 22% between 2015 and 2050, according to the World Health Organization. While some carriers are pessimistic about finding new talent and believe that millennials and recent graduates have limited interest in insurance, others are cautiously optimistic that the creativity emerging from insurtechs, new ventures, and disruptors will attract top talent to the industry. With the evolving demands that technology is placing on the industry’s workforce, digital skills should now be considered when evaluating most roles whether they be producers, underwriters, technologists, managers, or service representatives.
It is clear that there will be winners and losers in the war for talent. Finding innovative ways to excite and retain top talent in both competitive urban markets and more fragmented rural locations will be an important differentiator over the next decade.
These topics are top of mind for most carriers as they face extraordinary innovation and disruption across the insurance industry. If the vendor pit at the InsureTech Connect expo was any indication of the future, the pace of this innovation will only accelerate. Establishing a strategic approach to productivity, data, customer experience, risk management, growth, and talent is becoming table stakes to remain competitive in an ever-changing space.May 11, 2020 Jo joined McKinsey as an associate in the Houston office in January 2020. She came through our recruitment process in the fall of 2019 while pursuing her PhD in applied physics from Rice University. We wanted to know what it was like for this former research scientist, model, actress, avid traveler and active volunteer.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
I first learned about the work McKinsey is doing in digital and analytics through a connection of mine who works out of the Houston office. I’m very interested in that type of work as well as sustainability and energy, which are also growing areas of focus for McKinsey. The nature of the work I could do at the firm and the level of impact I could achieve in these areas really drew me to apply.
I was so excited to receive the invitation to interview – this was my chance! Then my nerves started to fire. I didn’t know much about the process or style of interviews. I’m a researcher at heart, so naturally I started exploring the McKinsey Careers website for information, resources, and guidance. It’s super informative and contains great video overviews of what to expect, practice cases, etc. My recruiters, Allison and Jackie, did an amazing job of explaining what to expect. They communicated with me often, which I really appreciated.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
All McKinsey interviews contain at least two parts – a conversation about your personal experience and a case study. I took the personal experience portion as a great opportunity to reflect on my studies, career experience, most memorable achievements, and biggest challenges. I practiced sharing my stories with a couple of friends who were not very familiar with them, which helped me learn how to communicate my experiences, convey my excitement, and share my thought process about these moments with another person.
For the case portion, I did a few of the samples on the McKinsey careers website and went through a couple of practice sessions with my McKinsey Mentor and a friend from school. It really isn’t about memorizing answers or frameworks and I didn’t want to start sounding overly rehearsed in my answers, so I didn’t do too many. Instead, I focused on learning how to break down the problems and show my work and thinking.
During the time of application and interviews, I made sure to take breaks and stay active, workout regularly, and go for hikes. It was very helpful when dealing with the stress from graduation, writing my dissertation and preparing for interviews at the same time.
Of course, I felt nervous, but also very excited to learn more about the McKinsey and the Houston office and to meet interesting and inspiring people along the way. I felt more comfortable going into final rounds because I was more familiar with the process and I received very helpful, specific, and actionable feedback after round one, which I practiced incorporating into my responses.
Yes, a few things did. First, I thought there would be multiple interview type questions, and I was pleasantly surprised when my discussions felt very conversational. I was thrilled to discuss not only on my professional experience, but also my aspirations and goals.
Second, the feedback I received from practice sessions and round one interviews was very encouraging. One of my assessors called me after round one to tell me I was advancing to the next round. He started with very positive feedback and emphasized all the things I should keep doing in my next round of conversations.
Finally, I want to reassure everyone who is getting ready for interviews or considering applying that it is a standardized process and there aren’t tricky questions or curve balls. All the aspects the interview are listed clearly and comprehensively on the interview website. Interviewers are trained well and are empathetic and not critical. Multiple interviewers sympathized that it’s a long day , it’s natural to be tired by the end, it’s ok to take breaks, etc.
I received a lot of support from my recruiters and built connections with many McKinsey people during the process. I had an interview coach from the Dallas office named Hannah who helped me think through the feedback I received. She shared her McKinsey interview experience and encouraged me to, “try not to be stressed out about having the perfect interview. I made a couple of mistakes during mine. It’s really not the end of the world.” This advice significantly lowered my stress level. And lastly, I received an incredible amount of support from Southern office Women’s network. The members of this group regularly reached out to me to help address my questions and share their personal experiences. I was so impressed by the McKinsey Mentor program, I became a Mentor after I joined. Now, I am super excited to coach candidates through interviews.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
The people and the connections I built during the interview process. I really appreciated how efficient and supportive everyone was. I could see myself as part of the big McKinsey team . I was still very excited about the client opportunities , and knowing I’d work with interesting people made it all even more appealing. McKinsey’s values played a part in my decision as I felt they aligned well with my personal mores.
Jo started her career as a research scientist at Baker Hughes Oil Services. She has also been a medical products research fellow, model, and actress. When she is not working, Jo enjoys traveling, music and sports, especially hiking, playing the cello, swimming and weightlifting. She’s a PADI certified scuba diver. She spends a lot of time volunteering, especially in education by teaching for the Junior Achievement Program and mentoring through Girls in Science.Connected cars have become one of the most prominent implementations of the internet-of-things. In fact, cars themselves have become internet-of-things environments, usually with between 70 and 100 Electronic Control Units (ECUs) embedded in each vehicle. These ECUs work with sensors and other hardware units, and are connected internally by busses (a small in-car network) as well as to the outside world using mobile sim-cards. As with computers and smartphones, software has become increasingly prominent in managing vehicle functionality and has replaced many formerly hard-wired functions in classic ECUs. In fact, the growing dominance of software has helped modern vehicles become known as “computers on wheels.”
Unfortunately, software also makes vehicles vulnerable to potential cyber-attacks. According to the United Nations Economic Commission for Europe (UNECE), new vehicles include approximately 100 million lines of software code, and that number is expected to triple by 2030. In response to this trend, the UNECE World Forum for Harmonization of Vehicle Regulations adopted two new cybersecurity regulations in June 2020 – one for ECU cybersecurity and one for software updating – and they require automobile manufacturers to implement control processes across four domains:
Securing vehicles “by design,” to decrease the likelihood of risks being introduced by the technical architecture or through supply chain partners
These new regulations present a major challenge to automobile Original Equipment Manufacturers (OEMs) due to the complex and decentralized technical architecture in modern vehicles, as well as the necessary reliance on supply chain partners for software (classic OEMs have just a 10-30 percent share of self-developed software in their cars). Additionally, the cybersecurity talent shortage makes it difficult to recruit employees with the specialized skills required to assess cyber risks, implement controls and perform other mitigating activities. Also, different manufacturers are at varying stages of maturity with vehicle cybersecurity, and many will be building the capabilities required to comply with the WP.29 regulations almost from scratch.
While enforcement dates for WP.29 cybersecurity compliance may seem relatively far off – in the EU, for example, manufacturers must be able to show cybersecurity compliance for all vehicles, both new and legacy models, as of July 2024, to receive vehicle type approval (the deadline is two years earlier for newly developed car series). This is a significant challenge given the development cycle of new models, which is typically around three to four years. In other words, engineers developing new models for 2022 or 2024, when the regulations are in force, are already into their development projects and must now retrofit cybersecurity into their designs.
There are several key challenges automobile manufacturers are facing today as they work to move their manufacturing, supply and aftermarket processes to WP.29 compliance:
The most fundamental question automobile manufacturers are dealing with right now is: “Who owns these new WP.29 requirements?” Typically, engineering owns the automobile design and manufacturing process, but the IT department (more specifically, the CISO) owns cybersecurity. IT and engineering have been crossing paths for some time in the automobile industry – with the convergence of operations and information technology networks, and with an increasing number of ECUs and digital capabilities in vehicle designs.
To reconcile ownership of the new regulations, most manufacturers are either making the CISO the point person for WP.29 cybersecurity compliance, or creating a new role in the engineering department (Chief Product Security Officer being a commonly used title). Either way, establishing clear ownership is an important first step to addressing the new WP.29 cybersecurity and software update requirements. However, this is just crossing the first organizational hurdle as departments that typically work in their own silos urgently need to cooperate to assure cyber secure vehicles. These departments include R&D, cybersecurity, IT, quality, procurement, aftermarket, and more.
Cybersecurity is different from other vehicle quality processes, because software components must be tested much earlier and more often than other vehicle hardware components. (You can test a hardware system by driving millions of miles with pre-series/pre-production cars – this will never be a successful approach with software because by the time those cars are available, it’s already too late.)
To achieve sound cybersecurity practices, the automotive supply chain needs to be differentiated between hardware and software. The software part needs to work like a professional technology company for software development. Software is currently developed through a combination of internal development organizations and tier-1 suppliers. To incorporate cybersecurity processes that enable WP.29 compliance, OEMs will need to develop new processes that not only change how software is developed, but also evolve relationships with those tier-1 suppliers.
When the vehicle goes away – responsibility stays. Under the new regulations, manufacturers are responsible for cybersecurity measures across the entire vehicle lifecycle. As a result, the aftermarket duties of OEMs to sustain cybersecurity for their fleets represent a cost and profitability risk. And, they need skilled people to manage the fleet’s compliance in the aftermarket. As might be expected, current aftersales organizations are not prepared for this brand-new challenge. These factors require the creation of new teams to manage these processes, and staffing these teams will be difficult amid a cybersecurity talent shortage.
Acquiring the right expertise may also require enlisting the help of external assistance. At the strategic level, consulting organizations with a strong focus on the automobile industry can provide expertise in WP.29 regulations to help manufacturers build their compliance programs. At the tactical level, specialists in penetration testing, cyber secure software design, software update management, fleet monitoring and other cybersecurity disciplines may be required for software security assurance.
As mentioned above, automobile manufacturers typically outsource software and ECU system development to supply chain partners. This introduces significant complexity into WP.29 compliance, because those partners now must adhere to secure coding and testing practices that ensure the software installed in vehicles is cyber secure.
These challenges will require a realignment of the relationship between manufacturers and their computer technology supply chain partners. Manufacturers will need access to source code, and will also need to implement rules around which tools and technologies are used to develop the software. Ideally OEMs and their software suppliers work with one source code (including free and open source software, or FOSS) repository, which contains just cyber- and quality-approved source code modules. All of these new rules and requirements will need to be detailed in revised contracts, which today only define software/hardware functionality requirements, not WP.29-specific cybersecurity requirements.
Manufacturers will also rely on their software suppliers to deliver updates for the life of the car, which creates ramifications for the business model around selling cars. They will need to develop ways to finance the update process, so they do not defray profit margins over the life of the car.
Deloitte is currently engaged in WP.29 cybersecurity projects with more than 10 international automobile manufacturers. Based on this experience, the following initial steps can help automobile manufacturers move in the right direction toward WP.29 cybersecurity compliance:
Conduct a readiness assessment. By assessing the current status of their organizations against the requirements of the WP.29 cybersecurity framework, manufacturers can identify the staff, capabilities and procedures they will need to put in place to achieve compliance.
By assessing the current status of their organizations against the requirements of the WP.29 cybersecurity framework, manufacturers can identify the staff, capabilities and procedures they will need to put in place to achieve compliance. Set up an internal UNECE cyber readiness program. The readiness assessment should provide the information required to design an effective readiness program. When implemented, this program will enforce the controls, procedures and reporting required for WP.29 cybersecurity compliance
The readiness assessment should provide the information required to design an effective readiness program. When implemented, this program will enforce the controls, procedures and reporting required for WP.29 cybersecurity compliance Do a deep dive into ongoing vehicle projects. The ultimate nightmare for manufacturers is to build a car they can’t sell. To avoid this, conducting a comprehensive review of vehicles in the development pipeline will identify any potential WP.29 issues before production begins.
The new WP.29 cybersecurity regulations will have a fundamental impact not only on the automobile supply chain and manufacturing process, but also on automobile manufacturers’ after-market support requirements and the business model for selling cars. Complying with these requirements may seem daunting – but it is achievable if manufacturers take a methodical approach that starts now. And, as automobiles become increasingly reliant on software for everything from entertainment to safety and suspension options, it is likely less costly to implement more secure software development and update processes now, than it would be to respond to and remediate a serious cybersecurity incident later.The client sought help from McKinsey in coordinating the relationship of its middle-market line of business with its risk management group. This association was characterized by ineffective and inappropriate commercial-credit decisions, portfolio- tracking methods, and metrics. Loan charge-offs exceeded normal expectations, and our client made little or no economic profit on significant portions of its middle-market credit portfolio after full-loading all costs.
McKinsey began by examining the client's loan portfolio to determine sources and concentrations of risk. This required analyzing the pipeline to gauge the credit outlook and determining the organization's appetite for risk along each dimension. McKinsey then detailed the end-to-end process across sites including time, cost and quality. To accomplish this, the team identified sources of variation, modeled the end-to-end economics, established appropriate trade-offs, and mapped roles and responsibilities.
The next step was to benchmark the client's competitive position and customer requirements by assessing current performance and the performance of likely market entrants. McKinsey synthesized its results and developed recommendations that identified opportunities to reduce risk and/or costs and enhance customer satisfaction. McKinsey also clarified roles and responsibilities between the middle-market line of business and the risk group.
McKinsey's plan established a risk strategy and management framework that was integrated with the client's overall strategic business objectives. McKinsey helped the client streamline the credit process, resulting in an expected loss reduction of $15 million in the first year. The client's improved focus on origination quality and reduced charge-offs was expected to boost return on capital by 3 percent over 3 years.I entered the pharmaceutical sector 32 years ago as a clinical research associate. In all that time, there has been surprisingly little change to the way biopharmaceutical companies and contract research organizations conduct clinical trials. While digital technology is widely available to the general population, it generally has not made its way into clinical trials. Most trials continue to use paper-based processes, which can make the process slow and inefficient.
Drug manufacturers might spend $2.6 billion to bring a new drug to market, according to a recent estimate from the Tufts Center for the Study of Drug Development. Every day that a new drug isn’t on the market could translate to $1 million dollars or more in lost revenue.1
During a recent keynote presentation, I outlined some of the challenges and potential rewards involved in moving to virtual clinical trials. Most of the attendees—who were from the largest biopharmaceutical companies—were interested in learning about the complexities of conducting virtual clinical trials and wanted to hear how their peers are approaching the process. While there was an overall feeling that virtual clinical trials represent the industry’s future, even the largest and most technically advanced organizations are just beginning to dip their toes into the digital waters.
Some pharmaceutical companies have been somewhat reluctant to move to digital clinical trials because they assume regulators will not support it—even though companies running pilots with digital technology have found that regulatory agencies are open to novel solutions. Some large technology companies, which have limited experience in life sciences and generally aren’t held back by perceived regulatory barriers, are leading the charge toward virtual clinical trials. While some pharma companies are concerned about the role these new entrants might play, others appear to be anxious to work with them. Along with offering innovative technologies, tech companies might also bring new perspectives to clinical trials.
One of the primary benefits of virtual clinical trials—for pharmaceutical and medical device companies—is the potential to improve recruitment. Our research and client experience suggest that digital transformation can be a complex and resource-intensive undertaking, but the rewards can be significant. By making the recruitment process more efficient, clinical trials could get patients enrolled more quickly, which can reduce the time it takes to bring a new product to market. While patients should be at the center of our universe, we really don’t make it easy on them when it comes to clinical trials.
Consider this: A typical patient travels an average of two hours each way to participate in a clinical trial. After parking, the patient typically has to sit down and complete a variety of forms, undergo tests, and wait for the doctor to become available. Given this enormous time commitment (and possibly time away from work), it’s not surprising that only about four percent of eligible cancer patients participate in clinical trials—that percentage is even lower outside of the US.2 As a result, recruiting patients for clinical trials tends to be highly competitive, and the tiny pool of potential participants can make it impossible to recruit a representative sample. To make matters worse, an estimated 40 percent of people who sign up for a clinical trial wind up dropping out before it concludes.3 This can waste time and money for pharmaceutical companies, researchers, and patients.
Patients might be more willing to accept the burden of a clinical trial if they don’t have to commit as much time. By digitizing processes, patients can fill out forms and complete some medical tests at home or at a more convenient location. Further, some of the monitoring could happen remotely. For example, a diabetes patient might use a digital blood glucometer at home that the doctor can read virtually.
Improving clinical trials could improve the return from R&D for pharma, medical technology firms, and the contract research organizations (CROs) that conduct research studies. A wide range of digital tools could transform traditional clinical trials. These include:
Cognitive computing and machine learning: Information clustering and deep learning can make it possible to solve previously intractable problems.
Information clustering and deep learning can make it possible to solve previously intractable problems. Predictive-Interactive analytics: Aggregated real-time data views can be constructed on agile data lakes, with algorithms, thresholds, workflows and alerts.
Aggregated real-time data views can be constructed on agile data lakes, with algorithms, thresholds, workflows and alerts. Internet of Things (IoT) and mobile health: Wearable medical devices, always-on sensors, and consistent IoT connections can make it possible for a continual flow of data between patients, doctors, and researchers.
The availability of wearable devices makes it possible to gather vast amounts of patient data in real-time and allow patients to participate at home or at the point of care. A patient connected to a digital device might generate one million data points in a single day.4 Ten years ago, by contrast, an entire clinical trial might have generated one million data points. Moreover, data are coming from sources including clinical and patient-reported outcomes, mobile apps, social media, electronic health records, and wearable devices. As a result, physicians and researchers now use a wealth of data to understand how their patients are living with an illness and what might be done to improve their care. These richer data sets can also provide better insight into the effectiveness of a drug or device.
Regulators recognize the value of virtual clinical trials in improving safety. For example, instead of receiving one reading once a month, digital devices can generate a continuous flow of readings, which could provide a much clearer picture of a drug’s safety and perhaps effectiveness. From a safety perspective, the US Food and Drug Administration has acknowledged that data collected digitally can be analyzed more quickly, which can improve the safety profile of a new product. During a presentation early this year, former US Food and Drug Administration (FDA) Commissioner Scott Gottlieb called digital technologies among “the most promising tools we have for making health care more efficient and more patient-focused.” He noted that real-world data gathered from wearable devices, electronic health records (EHRs), and even social media can “expand the sources of evidence that we can use to make more reliable treatment decisions.”5
Though virtual clinical trials have clear benefits, they also face challenges. If the patient population is elderly, participants might not have much experience with digital devices and could be reluctant to participate. Some patients might not be comfortable with collecting and transmitting personal health information electronically. Companies need to incur upfront costs to move to a digital platform.
Clinical trials exist so that we can ensure the safety of new therapies and medical devices for patients. However, there seems to be a growing sense of excitement among pharmaceutical companies that want to become a part of the digital world.
PS: If you happen to be attending this year’s DIA conference, please stop by booth #1855 in the exhibit hall—we will be featuring a virtual clinical trial demo.
1. A Tough Road: Cost To Develop One New Drug Is $2.6 Billion, Policy and Medicine, March 21, 2019 (https://www.policymed.com/2014/12/a-tough-road-cost-to-develop-one-new-drug-is-26-billion-approval-rate-for-drugs-entering-clinical-de.html)
2. Despite pressing need, survey finds most Americans unlikely to enroll in clinical trials, Memorial Sloan Kettering Cancer Center/ScienceDaily, May 2016. (www.sciencedaily.com/releases/2016/05/160523105038.html)
3. https://www.advisory.com/research/oncology-roundtable/oncology-rounds/2016/10/why-patients-dont-enroll-in-clinical-trials
4. Surmounting eClinical Data Volume and Diversity, Applied Clinical Trials, March 1, 2018 (http://www.appliedclinicaltrialsonline.com/surmounting-eclinical-data-volume-and-diversity)
5. Speech by Scott Gottlieb, former commissioner of the US Food and Drug Administration, January 28, 2019 (https://www.fda.gov/news-events/speeches-fda-officials/breaking-down-barriers-between-clinical-trials-and-clinical-care-incorporating-real-world-evidence)Automation has underpinned growth of industry for hundreds of years. From automation of physical tasks in manufacturing to automation of digital processes in recent decades.
Historically, automation was more prevalent in operational areas, that is, in performing tasks that didn’t interact directly with the customer (e.g. robots that make stuff). As technology became more accessible to consumers over time, so did the ability of customer facing processes to be automated (e.g. ATMs).
With digital technology and machine learning, more customer interactions are being automated and we are now seeing rapid increase in algorithmic decisions on customer experience. Every day we interact with algorithms – from ordering pizza to booking a flight, from settling a dispute during online shopping to travelling on elevators with no buttons – each has a profound impact on our experience as consumers and our day to day life.
These innovations have allowed new industries to emerge and allow society to benefit from new products and services. Most of the industry dialogue, however, on the topic of automation has been one sided – either focusing on cost reduction or opportunity expansion. We rarely see an examination of the harmful side of automation, and what are appropriate levels of automation.
Algorithmic processes and automation can have both positive and negative impacts on customer experience as well as on society generally. We categorise impact of automation on customer experience in three broad categories:
In this category of automation, customers benefit from faster service, flexibility of when they can access the services, receive relevant and engaging communication from service provider. In other words, things improve for the consumer. Examples include convenience of online shopping or ordering a taxi.
The supplier of service also benefits from efficiencies through automation and improvements in customer engagement.
In this category, customers face increased complexity in interactions with the supplier and slower overall process due to time spent on finding the right information or reaching an officer for assistance resulting in an overall frustrating experience, or both.
Typically, this is a result of an algorithm being designed for “normal” customer scenarios, that is, an algorithm designed for when things run well. But when a customer’s need falls outside the “normal” range e.g. when there is a problem, such an algorithm can result in an overall poorer experience.
Think of calling a utility company when there is a problem. In this “exceptional” scenario, trying to navigate through an automated system can be frustrating and having a manual process and/or a real person to interact with can vastly improve the customer experience.
In this category of automation, the supplier of service faces risk of customer disengagement and complaints.
In some industries, consumers have formed negative perceptions of customer experience to the extent that some companies are using their customer service call centre capability as a means of differentiating themselves from the competition (e.g. an insurance company advertising “a real person will pick up the phone when you have an accident”).
In this category, customers face harmful impacts of automation through privacy intrusions, unfair discrimination in automated decisions or other actions that may fall below community standards.
This may be unintended e.g. when the automation behaves in unexpected ways. For example, an algorithm based recruitment may result in unintentional discrimination against certain groups during the recruitment process.
In this scenario, the supplier or service provider faces compensation liability, regulatory actions and damage to brand. For example, banks have faced regulatory intervention on algorithm-based lending to borrowers who could not afford to pay back the loans.
Since this category of automation has the greatest harmful impact on consumers and society, it has resulted in public scrutiny in recent years and increasingly we are seeing legislation introduced internationally on holding companies and their officers accountable for decisions made by algorithms and automated systems. Examples include GDPR Right to object and automated individual decision-making, Principles of Accountability raised by ASIC and a recent discussion paper on Australia’s AI Ethics Framework.
How to build algorithms that enhance customer experience and comply with corporate and social objectives?
1. An algorithm should be designed and implemented in a way that meets objectives of the supplier as well as customers and society. Is there clarity of purpose of the automation project from corporate, customer and social perspectives?
2. There should be a clear understanding of value created through automation. For example, while some things are suited to automation others are inherently best served by a human (e.g. the barista that makes fabulous coffee).
3. There should be a tangible improvement in user experience, and not relying on improvements at face value from vendors’ marketing material. Improvements should be verified through field and lab experiments.
4. Algorithm should be designed to handle both “normal” and “exceptional” user scenarios and should have the ability to prompt human intervention when needed.
5. There should clear human ownership of an algorithm. Accountable persons should be empowered with full understanding of an algorithmic process and have control over its actions.
6. Regular testing and maintenance should be performed on the algorithm to check whether it is behaving within expectations as well as whether the system continues to be fit for purpose over time.
Deloitte Business Algorithms has developed a process for designing, implementing and monitoring algorithms that enables human ownership of algorithmic outcomes – “Human in the Loop” (HITL) – which requires human cognisance, ownership and sign-off that algorithmic output is consistent with corporate and social objectives. We help organisations articulate corporate and social objectives, design human-centered customer experiences, use quantitative and qualitative tools to develop intelligible algorithms, apply behavioural science expertise to encourage desirable behaviours and provide certification of algorithms.Digital transformation can be, well, transformative, but I’m hearing rumblings from some people I talk with that their digital transformation initiatives aren’t living up to their promise. They talk to me about budget overruns, unmet expectations, and technology integration problems. There’s an old saying that goes, “If you don’t know where you’re going, any road will get you there.” It applies perfectly to digital transformation.
Back in the day, technological transformation at a company happened maybe once, twice in a decade. It took months—sometimes years—to implement a change. Think process moving to client-server from the mainframe and shudder. Today, though, change comes at you fast—almost daily—and as the pace of change will only accelerate, it’s time to step back and realize that transformation can no longer be managed in silos. Instead, it’s critical to deal with transformation strategically and holistically, and embed transformation into the strategy of the organization.
Silos have been a thorn in the side of IT forever. IT processes and projects are often implemented on a one-off basis that satisfies the needs of the sponsoring department or business function and not the entire system or enterprise as a whole. Even with the rise of DevOps, it’s still too easy to be narrowly focused, because there’s still a lot of, “Well, we’ve always done it this way.”
It’s also just sheer lack of insight. Many people don’t understand the effects of siloed work to begin with, and these effects are magnified when the work is part of an enterprise digital transformation. Transformation is ongoing; it never stops. At any given time, there may be one group transforming for cloud, another for machine learning, another for IoT, etc. The work one group does will almost certainly impact the work of others. When the transformation is managed in silos, the changes become just as fragmented and ineffectual as the original processes that spawned them.
There’s a better way. As I said in the opening, it’s essential to look at transformation holistically, to embed it in the strategy. That means making it a strategy itself. To do that, you need to acknowledge that one-offs don’t work. They’re usually just plasters that cover a sore spot. Instead, it’s critical to understand that the pace of business is transformation. Every day, all the time.
To meet those 24/7 demands for change, it’s essential to put a structure around the transformation process, to make it repeatable and sustainable, sure, but more importantly, to make it the air your organization breathes—to embed it in the very fabric of the organization.
That’s a mouthful, but here’s what it looks like: it’s people, it’s process, and it’s technology—integrated to build a transformative whole that works with change, but more importantly, welcomes it and thrives on it. Each technology project should have transformation user stories being worked on each sprint so that the pace of organizational and process change moves at the same pace as the pace of technology adoption.
So how do you get there? The journey will be different for every company, but there are a few key steps you can take. First, look at your people. What people do you have? Where are they? What skills do they have? What skills do they need to achieve your transformation goals? Answer these questions and put the right people in the right place along with a training, recruiting, and retention plan.
Next develop a plan to assess and manage change—at the top level of your organization. This is the holistic, strategic part I talked about earlier. The plan should be based on the precept that change is constant and pervasive, and that, almost without exception, a digital transformation in one business function or department will ripple like a rock in a pond.
That ripple effect is why step three is crucial. For transformation-as-strategy to work, the idea and thrill of transformation must be embedded into the culture of the company. Everyone has to be on board, to understand that change is a fact of life that should be embraced, not feared. They should live for change. The cultural ethos of the organization should reflect the fact that transformation is continual, and processes and technologies should be implemented with how they affect the organization as a whole in mind.
Individually, people, process, or technology will never solve all your business problems. It is the three combined moving at the same speed toward shared goals that will have the greatest impact on success as we move into the digital age. If you make transformation a core strategy, embed it in your organizational culture, and include it in your project budgets, you just might be able to wrangle those people, processes, and technologies to get more out of it.Deloitte Asia Pacific FS Technology Lead Partner Clifford Foster outlines the trade-offs needed between how technology-driven innovations raise customer expectations, offer new sources of revenue, and transform the competitive landscape, and how enterprises’ extensive IT infrastructures and systems enable them to run their existing businesses, with a wide range of products and channels to support.
When moving into the future, these existing assets can be an advantage or disadvantage. To determine next steps the questions to ask include:
Organisations have to figure out how to harness these existing IT assets and capabilities to meet their current needs, while positioning their businesses for the future. They need a clear, executable, strategy on how to leverage and integrate emerging market services into their offerings quickly and smoothly; while continuing to meet regulatory and broader stakeholder requirements.
The organisation will need to implement technology and practises that isolates the core systems in the IT environment. These core systems can be wrapped as interoperable nodes that interact with other business system nodes, to deliver functions that are vital to the operation of the business.
Although this may not seem to be too different to the IT environment that it has today, it has created untapped potential waiting to be exploited to the benefit of the organisation and its stakeholders.
There is value in the nodes. But even more value in the network that connects these nodes within the organisation. A core network provides a clean and secure gateway for connecting nodes within the organisations and external nodes or services external to the organisation. This allows internal teams, as well as chosen third parties, to innovate and implement new ways of working.
As with Metcalfe’s Law, the more nodes isolated within the IT environment, the greater the potential value to the organisation. This facilitates the flow of data, rather than restricting it to islands of information at the edges. For example, by generating new business insights from data in flight through the network, with data-at-rest in the core nodes you can provide, monitor, and action events at the heart of your business.
Exploiting the potential of the core and core network requires a new set of skills, management and governance. Combinations and intersections become more important than single data points.
The enterprise should clearly consider its technology and information management operating model by considering what capability is needed to:
The organisation’s that are best able to exploit the digital core will position themselves for a future whereby the value and assets within the enterprise can be rapidly combined with new market services to deliver unprecedented value to shareholders.Anna joined our Warsaw office as an experienced hire after working in finance for several years. While completing her bachelor’s and master’s degrees—both in finance—from Wrocław University of Economics in Poland, she also completed her CFA program, paving the way for her to work almost exclusively within our financial institutions group. She speaks four languages, which is useful given her love of international travel. Outside of work, you’ll find her skiing, sailing, or attending the theater.
Hi everyone! I've spent the last 6 months working on a pretty intense, yet truly rewarding project. Our client has set ambitious goals that required a team with wide range of newest competencies. From day one, I've been working hand in hand with a very large, international and very diverse group of colleagues specializing in digital solutions, advanced analytics, UX and UI design, implementation etc.
Team dynamics has been great, we spent a lot of time working closely with the client, travelling and meeting in person. Three weeks ago, the situation changed due to the COVID-19 outbreak, and like all other teams in the firm - we had to reorganize the way we work. As the manager on the project, I immediately thought: multiple client meetings planned, all our equipment left in the team room, fifty people on the team suddenly need to work remotely... How will we manage that?
Thankfully, the firm already had multiple solutions in place, the technology and tools were all there - we just had to make good use of them. Our team works Agile, and there are many applications enabling virtual work. I connected with our Agile teams in China who shared advice on what worked for them. One of the firm's strengths is undoubtedly the global knowledge sharing and our Chinese colleagues helped a lot.
We now use an online Kanban board, stay in touch using Teams, and continue our scrum ceremonies virtually. Our clients have also switched to remote work, so overall I am happy to see that despite challenges we can maintain delivering to our client at the same level as always.
My initial fear was that given lack of in person interaction, maintaining strong team bonds will become challenging. We are staying as connected as possible, though. We are trying to have individual 1:1 calls and also find time to connect informally. We recently arranged an online team dinner with charades, which was a lot of fun!This blog post has been adapted, based off a talk given at the 2018 Lean Agile Systems Thinking Conference and shared at a couple of Melbourne based meetups through the year.
Over the past 12 months there have been a number of bold, public and notable announcements and changes (ANZ, Bankwest, Telstra to name a few) to Australian organisations looking to think, work and organise themselves differently.
However transformation or change, of any kind, is hard. Especially when this change is so fundamental to the core of how organisations, and the people within them, operate.
Yet only 11% of organisations feel confident in their ability to get it right. Source: Deloitte Global Human Capital Trends Survey 2017
94% of business leaders think that ‘agility and collaboration’ is critical to their organisation’s success. Whether that be in an attempt to be more purpose driven, more focussed on customer needs, creating greater alignment and transparency around priorities, or reinvigorating and creating a great workplace for their employees.
Companies will have either seen the benefits of agility and collaboration in their own organisation and want to replicate this at scale, or have observed what their competitors are (or are not) doing and deciding to act.
A need to change will stem from either an ambition to constantly change and innovate – however, this is often culturally deeply embedded as a part of the organisational fabric. Organisations like Zappos, Netflix, Amazon do this naturally.
Or from a more traditional burning platform, where the result of not changing may result in more dire consequences for the organisation. This is particularly prevalent in industries or organisations adversely impacted by disruption or changing external environmental and market forces. This is evident with the digital impact on telecommunications, the royal commission into banking, and the rising cost pressures on utilities providers.
In an effort to become more agile and adaptable, are these organisations focussing on what really matters?
The goal should not be ‘to do or become agile’. It should be about delivering a better outcome for their customers.
Here are five suggestions to think about, before considering adoption or launching any kind of transformative agile change.
Most organisations recognise the need to be more customer-obsessed, however few understand what is required to become customer-obsessed.
It was now almost fifty years ago that Peter Drucker said “There is only one valid definition of business purpose: to create a customer. The customer is the foundation of a business and keeps it in existence.”
However most internal practices within an organisation do not have line of sight to an end customer and often service internal needs.
If you are able to create alignment within a team about who the customer is, what matters to them and why you are trying to serve them – that is a good start.
While the commercial drivers that support running any business (revenue, cost, compliance, etc.) are important, setting short to medium term goals focussed on changing customer behaviours as a leading indicator is critical.
Set goals that promote introducing small changes directly to customers, to validate if you are doing the right thing. This naturally favours a more hypothesis-driven approach to validating customer needs.
Being able to quickly shift or respond to customer behaviour, will support longer-term decision making about where and how to invest time, effort and money.
The role of a leader in an adaptive organisation often represents a shift in how they would have lead organisations to-date. There is a noticeable change from the Leader as the expert, to the Leader as a servant.
Without proper support and coaching, they may struggle to adapt to the changing nature of what their teams need from them. To best support these leaders, be specific and measured about what they do and do not need to do.
There is no cookie-cutter playbook or method for successful agile adoption. The context in which each organisation plays in will also vary (the same as every individual team).
Enter into this change with an understanding of the current parameters, constraints or deliberate choices about what matters to the organisation and what can or cannot be shifted.
Openly discussing and assessing on a sliding scale where your organisation currently sits and where they would like to be, across a range of dimensions (example below), will help shape what your adoption or change might look like.
Having agreement on what dimensions can be impacted and to what benefit is incredibly powerful in order to gain alignment to the common goal and purpose, and useful to manage perceptions and communications of the direction the organisation is heading.June 17, 2019 You might think that advanced industry—a sector characterized by research and development and use of artificial intelligence and other breakthrough technologies—also optimizes the way its R&D organizations work. But continual business and technology trends in advanced industries (AI) have triggered fundamental challenges that require advanced industry innovate in its approach to R&D.
Just consider the three major R&D hurdles automakers confront in designing autonomous cars: more complexity and functional interfaces across projects, especially involving interlinks between software and hardware; amplified change and ambiguity in customer demands; and tighter interaction with an increasingly diverse ecosystem. As a result, decisions take too long, milestones are missed and standard operating procedures are delayed, siloed and fragmented. R&D staff stay in task force mode, and collaboration and job satisfaction diminish.
Early agile models in advanced industry R&D departments are delivering significant impact. We’ve seen a doubling of the time spent on value-add work, speedier decision-making, a 30 percent rise in productivity, increased engineer motivation and enhanced responsiveness to customer demands.
Sidebar Designing flying taxis: Is agile the key to innovative R&D? Many research and development (R&D) teams find themselves held back by a traditionally siloed structure in a rapidly changing environment, particularly in heavy industries. We connected with James Arnold, head of design systems and head of process excellence at Lilium—a European company developing the world’s first electric vertical take-off and landing jet—for a first-person perspective on what an agile R&D department looks like when starting greenfield in a highly innovative industry. Arnold and his team recently completed a successful first field test of its all-electric five-seat aircraft and hopes to launch a fully operational flying taxi service in select cities by 2025. Question: You are a small start-up exploring a very futuristic technology. How are you approaching innovation, and how has experimentation played a part in the process? Arnold: The history of the development of our aircraft is one of experimentation and iteration. From the very start, our founders worked with physical prototypes to test and demonstrate ideas, and as the company has grown, we have developed many prototypes in increasing levels of complexity. This kind of experimentation—and working towards something that can be tested and learned from—is essential for innovation. Q: Can you talk about the positive social and environmental impact of this unique mode of transportation? Arnold: We like to think about the “radius of life.” When you can travel five times faster than you can by typical ground transport, your horizon for commuting also increases by five times. Five times the radius gives 25 times the area and 25 times the possibilities. Or you can gain that time back for yourself and your family and create a big increase in wellbeing. Congestion and ground-level pollution will drop dramatically; cities will become cleaner, greener, quieter and safer. Q: What characteristics were critical in putting together your R&D team? Arnold: Research shows the impact of diversity, in terms of outcomes and the positive effect on team interactions. We have people with 30 years of experience working alongside undergraduate interns. We have people from different industries and cultural backgrounds. To benefit from this, we also need people who are open and ready to learn and try new ideas. Q: How do you manage collaborations to incorporate cross-functional teams for effectiveness? Arnold: We build our main cross-functional teams around the product breakdown structure; each major aircraft system has a dedicated team. Each team is established from the start of the program and is co-located, with a single day-to-day leader from the systems engineering team. We believe there's a huge increase in effectiveness and efficiency when sitting together vs. trying to collaborate virtually. Q: How are you looking at scaling the R&D unit? Arnold: Our goal is to make the foundations, processes, systems, mindsets and skills scalable. This means continuously challenging and improving things like our onboarding process for engineers, day-to-day collaboration and data management. It’s also important to expect and embrace the changes that scaling brings. Different structures and approaches are better for different sizes of teams, and it’s OK to change! Q: How is agile part of the equation for your team? What principles have been key? Arnold: One of the original principles of the Manifesto for Agile Software Development—the progenitor of the “agile” concept—is simplicity. Our whole architecture is designed to be extremely simple, and we drive this down into the detailed design of every part. We also work in short, iterative cycles that come to some sort of end product that can be evaluated. The objective is to learn quickly and efficiently, with a short lead time. Q: The hallmark of agile is to continually evolve. How do you ensure ongoing changes happen while still protecting the agile culture? Arnold: Due to our extremely fast team growth, we have a slightly different problem. Change is happening and will continue at a breakneck pace for several years. We work to protect and build on our engineering culture but also allow evolution and new people to bring new ideas. To take advantage of this, it’s important to have and reinforce core principles that give a framework but are not too rigid. Sometimes you can embed these principles into processes, but that’s not enough—there needs to be a huge and continuous effort to reinforce the right mindsets.
So, what comprises a more effective agile organization that sparks cross-functional collaboration, quick decisions, fresh ideas from anyone, flexible shifts of priorities and resources, and a place that attracts talent drawn to rewarding and fun work?
We can look to other industries such as banking, energy and telecom because they have faced similar issues. For instance, when one banking institution moved to a model where small teams follow a joint purpose and enjoy full end-to-end responsibility, they significantly improved cross-functional collaboration, time to market and customer satisfaction while moving to No. 1 employer of choice from No. 12 two years prior.
From these other industry pacesetters, advanced industry can take agile mindsets, principles and values while tailoring practices and tools to their own R&D realities. If an R&D organization truly wants to change how it operates, it needs to:
Derive promising learnings from pilots for organizing agile teams and make necessary changes to its “backbone” system, such as budgeting and work allocation processes and alignment of plans and priorities.
We do see some winning practices in selected “frontrunner” R&D departments in advanced industry as they pertain to structure, process/technology and people dimensions.
Structure: Create small, stable e2e teams that are accountable and possess a shared purpose instead of organizing by competencies. When priorities change, shift the task, not the people. People should work and sit together in teams but retain a home base within their discipline (e.g., electronics). They assume responsibility for managing common components and setting software and other architectures.
Processes/technology: Work on end products in rapid iterations and quick learning cycles, applying new testing technologies in standardized, not religious, processes. Enlist customers early. Favor more frequent and smaller decision meetings—in a way disaggregate today’s big meetings—that focus on decision-making versus status approvals.
People: Leaders change their style, e.g. visionary, focusing on coaching and problem solving and embedding ownership in their teams. That means asking them to develop their own plans and solutions and focusing on providing a clear framework, including clear interfaces and responsibilities. This requires ensuring a culture with stronger collaboration, more ownership from lower-level team members and risk assumption. Development teams also must step up. As one manager explained, “If your engineers behave as fenced-in sheep and you remove the fence, they will just continue grazing in the same place and nothing changes.”
Most advanced industry players have begun experimenting to determine where and how to apply agile, but they must scale it up for the full impact. Pilot projects prove important to learn whether a concept works, and they can boost enthusiasm. Technology trends will continue and as organizations meet these challenges, a full agile operating model will be required.Many years have passed since Agile has become a household name globally in IT. Large organisations which previously worked in very traditional ways have now been on the journey to achieve Agility for many years. This journey has typically commenced at the grass roots in software development teams, and then has scaled up to multiple teams using agile to run large programs.
Agile has now widely been recognised as a way-of-working that enables you to define, plan, and execute against outcomes. This wider recognition has resulted in the demand for the application of these ways-of-working outside IT in business functions, such as Marketing, Sales, and Legal. With the repeated success of agile achieving faster, smarter, and cheaper customer outcomes, large enterprises have realised the need to adopt these ways-of-working across the full organisation which we call Enterprise Agility.
In this blog post, we explain why Enterprise Agility is needed to remain competitive and what Agility means at the Enterprise level.
A volatile market with innovative competitors focusing on the customer and leveraging new technologies has created pressure on existing players
The need for Enterprise Agility is driven by the current VUCA (volatile, uncertain, complex and ambiguous) market dynamics. Competitive pressures against large organisations across industries are increasing. Contributing to these pressures and the change in these market dynamics is disruption from global innovators, particularly through start-up organisations which are able to compete in new ways. They are achieving this by pinpointing lucrative / niche segments and combining these with a customer first focus and new technologies. This is lowering the barrier to entry allowing start-ups to compete at scale with traditional large corporates.
Traditional ways of the past will not stack-up against the new goal of the customer for 21st century organisations
Not only is the competitor and technology landscape changing, so are customer demands for a better, more personalised service.
With the rise of digitisation and the global economy, this has changed the information customers now have access to. This means the goal for organisations now also needs to change. No longer can an organisation prioritise their shareholders needs over their customers. They can no longer offer an average service or customer experience and see no broader impact outside that single customer. They can also no longer take months or years to provide customers with the products and experiences they want. The customer needs to be at the heart of everything they do. As the below slide presented by Steve Denning at the inaugural business agility conference in New York 2017 shows:Agile and Design Thinking are complementary. Design Thinking is a human-centred approach to defining and solving problems, which encourages innovation and creativity in the problem solving process. Design Thinking is particularly well-suited to situations where the problem itself is not clear, advocating a strong focus on problem definition, problem shaping, and requirements clarification. Likewise, Agile methods embrace uncertainty and are appropriate for projects where the requirements are subject to change.
While Design Thinking is a solution-centric approach, it also places great emphasis on having a clear articulation of the problem. For Agile projects, the backlog is where the functional requirements of the system under development are captured, and the quality of those requirements is a significant factor determining the success of the project.
A pairing of Design Thinking with an Agile mindset and method can occur across the lifecycle of a project, from Initiate to Release. We will explore three examples of how to elevate your Agile with Design Thinking:Project Management processes are maturing with more and more projects being delivered successfully. According to the Project Management Institute[1], a lack of project sponsorship continues to be the number one reason why projects fail. Scope creep continues to be an issue coming in at number two, with number three being a lack of capability in value delivery.
Organisations embark on large complex transformation journeys to achieve breakthrough performance, support acquisitions or comply with regulatory obligations to name a few. These journeys are time-boxed, budget dependent and face ever-changing risks, including regulatory, competition and resource capability. Ways to increase the likelihood of project success and value delivery include project governance, management and use of better practice delivery frameworks such as PRINCE, PMBoK, Waterfall and Agile.
Agile continues to be a topic of growing importance in project management, with 71 percent of organizations now reporting they use agile approaches to their projects sometimes or more frequently than in the past[2]. Two out of every five projects use an agile, hybrid or blended agile approach[3] and some of the agile methodologies now in use are Scrum, Lean and Kanban.
No single delivery framework fits every project and agile methodologies need to be adapted to suit project needs.
Kanban is a popular framework used for software implementation. This point of view captures the use of Kanban to deliver large and complex projects.
"Kanban" is the Japanese word for "visual signal" and was developed as a scheduling system by an industrial engineer at Toyota to improve manufacturing efficiency and just-in-time manufacturing.
It requires real-time communication of capacity and full transparency of work. Work items or tasks are represented visually on a Kanban board that helps to keep everyone on the same page. This can be tracked on a physical wall or digitally. The simplest Kanban boards are physical boards divided into vertical columns where teams mark up a whiteboard or wall space and place sticky notes/cards on. These move through the workflow of Do, Doing or Done phases and demonstrate progress. Digital boards allow teams that do not share a physical office space to use Kanban boards remotely through tools such as Jira, Slack and Trello.
In 2018, a leading organisation was de-merging from its parent division to create an independent top 30 ASX-listed company, representing Australia’s largest ever-corporate transaction. Part of the scope included the setup of a new Treasury operating function including operating model, bank accounts, payments, interest rate risk management, hedging, and accounting, recruitment of its key resources and rapid implementation of a new and critical Treasury Management System.
A market leading Software as a Service solution was chosen with 19 weeks for implementation. From a system perspective, this would encompass and support capabilities such as integration with four banks and existing technology platforms, third party financial and market data systems and a supplier finance facility to start with.
Given the 19-week delivery timeline, principles such as transparency, collaboration, leadership, understanding, and agreement were required between the business and IT teams to achieve successful delivery of the new treasury system. Aside from the development of standard project management components, it was necessary to establish a methodology for effective collaboration, transparency of information and communication of change across the multiple stakeholder groups involved.
The Kanban methodology was chosen for this purpose and physical wall was setup in a dedicated project room with co-location of business, IT resources to deliver the system under the aggressive timeline (see Figure 1 below).
To commit to these timelines, activities and tasks from the integrated project schedule were developed in to a backlog and then prepared based on delivery priority into columns on the wall moving from left to right in the form of sticky notes highlighting a 3-week view and tracked daily. These sticky notes (see Figure 2 below) were assigned to team members with an end-date and then moved from ‘do-doing-done’ during the plan, design, build, test and deploy phases.
Daily stand-up and iteration reviews were performed to support the body of work underpinning the Kanban methodology and highlight updates to tasks, risks/issues and dependencies making every team member from the project, business or IT co-own the wall. This level of engagement, collaboration and transparency helped to maintain clear channels of communication and continue the delivery momentum. This also assisted in feeding information to the Program Management Office and provided and appropriate layer of first line governance and controls for the project.
The visualization of the work that Kanban established underpinned the interpretation of the to-be world, provided focus on continuous delivery, reduced re-work, quickly resolved risks, issues and dependencies and drove the successful delivery of a Minimum Viable Product in an aggressive timeframe.Organisations are experiencing disruption at an unprecedented pace. Enterprises hesitant to embrace ambiguity in the past, now want and need to be agile enough to meet evolving customer, technology, and market dynamics.
However large, traditional organisations are struggling to keep pace. They have typically built-up significant internal complexity over a number of decades, which is slowing or preventing them from change. Examples of this complexity are:
Different operating cadences across core business functions causing misalignment and slow go to market
Multiple layers of command and control style hierarchy creating bureaucracy and an inability to deliver change quickly.
To keep up with the constant change required, it’s a challenging juggling act to quickly reconfigure strategy, up-skill or hire new people, update process, protect existing business, and create new propositions, all on an ongoing basis.
There are some local, recent examples of traditional organisations, such as ANZ 1 and Bankwest 2, looking for new ways to design their internal ecosystem. These organisations have used Spotify as a source of inspiration.
We believe that having a tailored operating model, with a foundation built on empowering network based, sticky, multi-disciplinary teams is paramount.
Also ensuring that these teams have the right skills and capabilities with the required supporting infrastructure to enable creativity and productivity to be unleashed is essential for success.
Our previous blogs have looked at our definition of Enterprise Agility 3 and why it is a business imperative, as well as, how you can start your journey 4. In our third edition of our Enterprise Agility series, we will discuss our key agile operating model design principles.
Conway’s law states that “organisations which design systems … are constrained to produce designs which are copies of the communication structures of these organisations.” 5
The replication of complex and matrixed structures, based on internal process compliance doesn’t deliver what customers ultimately want or need.
Projects are too often launched without actually addressing the true customer need. Moving human centred design closer to the problem, rather than the solution is a great way to challenge the norm.
Having teams focused on the customer journey and experience ensures that, rather than mimicking complex internal structures, teams are organised around delivering value to the customer.
For example, ING had squads within their Mortgage Services tribe that focused on the search engine and another on the mortgage application. Both aligned with the overarching customer outcomes which the tribe was responsible for delivering. 6
The greater the alignment to a customer strategy, and the more autonomously these teams can deliver outcomes against that strategy, the better.
When multiple lines of business or functional areas follow different timelines, release windows or cadences – the ability to coordinate at scale becomes challenging.
This is most commonly the case across areas that may have constrained resourcing (e.g. legal, change, finance), or where there may be added complexity or longer lead times (e.g. technology, operations, security).
Organisations need to develop an operating model which can support delivering change multiple times per day, planning every fortnight, and changing direction at least every quarter, if appropriate.
Our guiding principle is to adopt a common cadence across all involved parties to make it easier for teams to plan or pivot based on shifts in strategic direction.
As the role of leaders changes from being less about operational decision making, to servant-leading and empowering teams – the need for complex matrixed structures diminishes.
Employees closest to the work need to be allowed to make real decisions, and be accountable for them. Management need to either get out of the way, or step-in and proactively remove the blockers which prevent teams from going faster.
Focusing less on antiquated and lengthy governance processes and adopting a build, measure, learn philosophy enabling rapid experimentation and lean start-up techniques is a fast way to ensure you’re working on the right things.
When change is enacted with greater frequency and in smaller packages, it naturally minimises the scale of what could go wrong.
Our guidance is to allow employees to experiment and test solutions; but do so by time-boxing the design and experimentation process in order to quickly make a decision whether to pursue, pivot or perish an idea.
Your enterprise agility journey doesn’t necessarily need to begin with a re-designed operating model or new organisation structure.
However three design principles that you need to consider in your operating model are shifting the focus of teams towards the customer, aligning to an organisational cadence, and removing layers of bureaucracy and focusing on operating lean.
Without these, large organisations will continue to face challenges in keeping up with the pace of change and leap frogging their competitors.Data from an OECD study reports that 15% of Australian graduates are overqualified for their jobs[1], working in fields which do not require a degree. Meanwhile, the World Economic Forum is advocating that traditional learning is leaving graduates without the skills they need to contribute in the workplace.[2]
Increasing HECs debt and a workforce skills gap presents complex problems for many stakeholders. Co-Founder of LinkedIn, Allen Blue states that “many members of the global workforce can’t keep up with the shift in skills required for jobs”[3]. Given the heavy focus on traditional knowledge such as literacy, numeracy and recall skills in assessments, it is no surprise that students are lacking the 21st Century skills they need to succeed.
21st Century skills are traits that are universally applicable and in-demand in the modern era. As relevant and important as technical skills are, adapting to new ways of working by leveraging the characteristics and behaviours which make us uniquely human will give us an edge over AI.
Skills frequently rated by the World Economic Forum as important for 21st century workers include[2]:
Firstly, whose responsibility is it to ensure students graduate with the necessary skills for today’s workforce? More broadly, how do employees continually maintain relevant skills despite a rapidly changing workforce?
The answer to both may be found through a thoughtful balance of traditional technical skills and newer, more human-centric ways of working. Many of these 21st century skills are uniquely human, and learning to solve the problems of others through transdisciplinary group work is one way to develop these skills. The practice of human-centred innovation could also offer a safeguard for the future as it requires advanced communication skills, and demonstration of empathy, creativity, and adaptability.
These previously under-prioritised skills will become ever more crucial with the rise of robotics and AI. Predictions by the Committee for Economic Development of Australia indicate that almost five million jobs are likely to be replaced by artificial intelligence in the next twenty years[4]. Others, such as the founder of China’s Sinovation Ventures, Dr. Kai Fu Lee, suggest that jobs which utilise the characteristics of creativity, complexity, dexterity, empathy and compassion will not be replaced by AI[5]. Regardless of the resulting conclusion, it is undisputable that the future of work will be very different, and it’s difficult to clearly determine how.
The best we can do for future generations is to equip them with the versatility and resilience they need to adapt to the rapidly evolving work environment – a monumental challenge which poses more questions than answers. Perhaps AI will become a self-inventing, self-constructing, self-improving and empathetic force, replacing the societal structures we know today. One can only speculate. Until then, we can do some self-evaluation and self-improvement of our own by asking, ‘how can we each ensure that we’re prepared to navigate the challenges ahead?’
[1] https://www.telegraph.co.uk/education/2018/09/11/almost-one-three-graduates-overqualified-job-major-report-finds/
[4] https://www.ceda.com.au/News-and-analysis/Media-releases/More-than-five-million-Aussie-jobs-gone-in-10-to-15-years
[5] https://www.forbes.com/sites/forbesbusinessdevelopmentcouncil/2018/08/13/three-trends-on-the-future-of-work/#10540c1b60a4Before joining McKinsey, Aaron worked at several other consultancies, as an independent consultant, and served as a research associate at the Institute for Behavior Resources. He has a PhD in social and organizational psychology from Columbia University, where he specialized in organizational dynamics, culture, human-resource management, leadership effectiveness, and strategic change.
Aaron, who writes frequently about organizational topics, has published many articles in McKinsey Quarterly and elsewhere. He is a member of the master faculty of the Change Leaders Forum and of the Organizational Agility Forum , which he helped establish. He has also led McKinsey’s thinking on organizational health and was on the teams that developed the Organizational Health Index (OHI), OrgLab , and Influencer.
Much of Aaron’s work focuses on helping large distributed organizations to achieve growth, innovation, productivity, and organizational agility. He serves clients across several industries, including agriculture, biotechnology, chemicals, energy, financial services, and healthcare.
Aaron counsels leadership teams as they transform their organizations to improve performance, organizational health, speed, and agility. He is also an expert on organizational design, corporate culture, leadership development, team effectiveness, capability building, and transformational change.
“Decision making in your organization: Cutting through the clutter,” McKinsey Quarterly, January 2018
“Reimagining how life sciences work will be done in the next normal,” McKinsey & Company, October 2020
“Reskilling in the age of COVID: There’s no better time than the present,” blog entry, McKinsey & Company, October 2020
“Unleashing sustainable speed in a post-COVID world: Reshape talent,” blog entry, McKinsey & Company, September 2020
“What 800 executives envision for the postpandemic workforce,” McKinsey Global Institute, September 2020
“Unleashing sustainable speed in a post-COVID world: Rethink ways of working,” blog entry, McKinsey & Company, September 2020
“The need for speed in the post-COVID-19 era—and how to achieve it,” McKinsey & Company, September 2020
“Four considerations for helix success beyond structure (part three),” blog entry, McKinsey & Company, August 2020
“What does a helix reorganization look like? (part two),” blog entry, McKinsey & Company, August 2020
“Become flexible and speed up with a helix model (part one),” blog entry, McKinsey & Company, July 2020
“Ready, set, go: Reinventing the organization for speed in the post-COVID-19 era,” McKinsey & Company, June 2020
“To emerge stronger from the COVID-19 crisis, companies should start reskilling their workforces now,” McKinsey & Company, May 2020
“Leadership in a crisis: Responding to the coronavirus outbreak and future challenges,” McKinsey & Company, March 2020
“Busting a management myth: empowering employees doesn't mean leaving them alone,” blog entry, McKinsey & Company, February 2020
“What it really means to lead more effectively through empowerment,” blog entry, McKinsey & Company, February 2020
“Improve your leadership team's effectiveness through key behaviors,” blog entry, McKinsey & Company, January 2020
“How companies can help midlevel managers navigate agile transformations,” McKinsey & Company, April 2019
“Leading agile transformation: The new capabilities leaders need to build 21st-century organizations,” McKinsey & Company, October 2018
“Houston Astros: winning the World Series with advanced analytics,” blog entry, McKinsey & Company, September 2018
“Building the critical foundation of an agile organization,” blog entry, McKinsey & Company, February 2018A couple of years ago, larger organizations focused solely on implementing agile projects in which they tried to leverage benefits from agile methodologies to deliver better results, with higher quality and a faster time-to-market. These days, the discussion has moved on: More and more organizations are thinking about transforming the entire enterprise into a product-centric organization to bring business and IT closer together and deliver more value directly to the customer.
Several organizations have already started on their journey or are planning to do so. Before deciding to embark on such an endeavor, it is important to evaluate whether agile is the right solution to achieve the organization’s goals. Otherwise, the risk of being stuck in a long-term transformation without direct benefits is likely to be high. Having agreed on the urgency of an agile transformation, we usually find ourselves discussing with our clients all the diverse dimensions that need to be considered for such a journey.One of the reasons that doing agile transformations is difficult is that there is no one formula for how to do it. The starting point and context for each organization’s journey toward agility is different.
Our cross-functional agile tribe recently brought together executives of more than 50 organizations from across financial services, healthcare, software, retail, chemicals, industrials, advertising, manufacturing, and advanced industries for our inaugural Agile Day in New York. The event included multiple speakers who shared their companies’ experiences, a panel discussion on the pitfalls of agile, and breakout how-to sessions aimed at helping companies drive agile at scale. What we heard is that although every organization’s story is different, five common factors seem to underpin all successful agile journeys:
Bold vision and clear commitment communicated from the top. This may sound obvious, but it’s critical to success. In almost every journey we heard about, leaders said they invested most of the first months of their programs in helping the organization’s biggest influencers understand the vision. Everyone has to see that there is no going back to the old way of working. “People need to know what’s in it for them, and they need their questions answered,” said the CEO of a British financial-services firm. That’s when you can also point out the downside of the status quo. Building trust this way is key. “You can’t hide behind slides—you have to be real with people,” he said. Use agile to implement agile. Healthy agile teams continuously learn and challenge themselves to be more mature. “Don’t be afraid to fail, don’t punish failure, and don’t even think of it as failure,” advised the CIO of a US insurance company. Teams should not expect to get to the end in one step. Rather they should celebrate their experimentation, and that includes celebrating the bumps in the road. Go beyond technology. Successful agile transformations address every aspect of the organization. As the chief digital officer of a Latin American bank described it, “You can’t do just one thing.” You can start with technology, if that’s preferable, but eventually an agile transformation has to touch all parts of an organization, including HR and marketing and finance. End-to-end, the entire organization has to embrace agility. Engage your leaders. You need them to champion the cause of agile transformation, Agile Day speakers said. Part of doing that is for leaders to move away from giving directions and instead ask, “What do you think?” As the CIO of a multinational bank put it, “You have to arrive at answers by asking questions.” It’s a collaborative method of problem-solving that has to be reinforced with role modeling and the right performance assessments. Agility is about empowering and trusting in a self-leading team to figure it out, speakers at Agile Day said. This means top leadership needs to look for opportunities to strengthen teams, remove roadblocks facing them, and improve their performance. People first. This also may seem obvious, but getting the best talent is truly a delicate balancing act. You have to move quickly or you’ll lose the right candidates to other employers. At the same time you need to be especially sure that any person you hire is truly the right fit for your culture. “You may have to adapt policies,” said the chief product officer at an HR solutions company that allowed its agile team to make offers in less than 24 hours, rather than the company’s usual six weeks.
It’s not easy, but agile transformation is worth it, as we heard from the success stories recounted at our Agile Day. It can lead to all sorts of improvements: faster time to market, significant cost reductions, customer-centricity across all functions, reduced waste, and a generally healthier and more successful culture.
The author would like to acknowledge Somesh Khanna, Marcus Sieberer, Aaron De Smet and Krish Krishnakanthan for their contributions to Agile Day and this post.Jak skutecznie skalować pracę zespołów zwinnych w dużych organizacjach? O tym, między innymi, rozmawialiśmy pod koniec października z naszymi kolegami z niemieckiego Deloitte, którzy podzielili się praktyczną wiedzą i doświadczeniami ze swojej pracy z wykorzystaniem metodyki Scaled Agile Framework (SAFe). Przy okazji poprosiliśmy o krótki wywiad specjalnie dla czytelników naszego bloga „Zwinne organizacje”.Traditionally, leaders have been encouraged to dynamically reallocate capital to the most pressing and attractive opportunities. This focus remains today, but many companies face a challenge: human capital is now the scarcer of the two main capitals. Companies that manage talent with the same rigor they do financial capital, treating it like the precious resource it is, typically see better results. They reallocate talent to high-value areas and push talent management to the top of their growth ...April 9, 2020 I’m an agile coach in McKinsey’s Gurugram office. I joined McKinsey in 2012 as an operations engineer, providing support for Oracle, MySQL and other relational database management system (RDBMS) technologies. From there I expanded to the reliability engineering group, where I was responsible for product management, change management, problem management and onboarding new applications.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com Agile coaching session (before COVID-19)
McKinsey has given me great access to tech learnings both internally and externally. In my operations engineering technology role, I learned additional RDBMS technologies, including MySQL and DB2 and NoSQL systems like Apache Cassandra and the Neo4j graph platform. I also worked on automation projects using Ansible, Python & Shell Scripting.
In 2017, with the support of my managers, I decided to try my hand at becoming an agile coach and scrum master. I’m now a certified scrum professional, scrum master and product owner, certified agile leader and Kanban system designer. I’ve led more than 10 agile squads in development operations, product and client services as a scrum master. Now, I’m a leader in McKinsey’s agile group.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
We have a saying here, which I find rings true: Make your own McKinsey. It means that within the firm you can explore opportunities and build your own path based on the work that excites you. We have the opportunity here to learn and experiment with disruptive tech languages, platforms and methodologies.
In my current role, I serve as an agile coach to squads around the world, leading them to follow data-driven visualization approaches to problems, past patterns and new opportunities. I also mentor and coach scrum masters through designing and executing virtual and in-person workshops and training programs.
I don’t limit my methods to scrum. I am inspired by Liberating Structures techniques, lean processes and design thinking. I also love using Kanban’s practices like visualizing and managing workflow to establish predictability.
The leadership at McKinsey has been very supportive. I have had mentors who helped me in my journey, and I’ve mentored others in turn. I enjoy the people at McKinsey, the culture and the inclusive environment that the company fosters. Every day, I work with colleagues at all levels within McKinsey, with different technologies and in many geographies and time zones.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com Bhangra performance (before COVID-19), a Punjabi folk dance form with my McKinsey group “Bhangra Jammers”
I am happy to have found groups of like-minded people within McKinsey. I perform Bhangra, a Punjabi folk dance form with my McKinsey group “Bhangra Jammers” at McKinsey events like Values Day. I’m involved in the corporate social responsibility team, I serve as the Go Green Team board member and I’m part of McKinsey Toastmaster’s club, which promotes communication, public speaking and leadership.
Based in Gurugram, India, Gurbrinder is an agile coach with our internal Technology & Digital team. Prior to joining McKinsey, he was a Java developer focused on insurance and telecom projects. Gurbrinder earned his bachelor’s in technology from Guru Gobind Singh Indraprastha University in New Delhi. Outside of work, he volunteers with charity groups for causes including women’s issues, children with special needs, pollution and blood donation.1. Transparency: As one of the basic three pillars of scrum, raising constant visibility and tangibility is vital. It sets the foundation for good decision-making. A collective view of the strategic progress that factors in all interdependencies will make organizations more aware of emerging events, risks and issues but also potential synergies between existing initiatives. This can be achieved by commonly using Kanban boards, strategic backlogs and sprint plans as basic tools. Further, monitoring activities and feedback loops supplement the understanding whether the organization’s initiatives are aligned with the strategic vision.
2. Continuity: Since Agile Strategy is using an incremental approach, strategic initiatives are divided into various, manageable sizes fitting into one iteration. In doing that, each part builds on the previous one leveraging new attained insights and learnings. For instance, an initiative that usually takes one year can be divided into four to five pieces (each for one sprint). This helps organizations to build strategies from different angles using these new insights and increases momentum on a frequent pace. The same applies to the overall governance of agile strategy management: in a retrospective at the end of each iteration, conclusions for identified improvements are evaluated. Consequently, this promotes a relentless optimization of strategy planning and execution. This stands in contrast to traditional plan-build-run approaches, where the delivered outcome, such as organizational changes, can only be verified at the very end.
3. Consistency: This feature goes hand-in-hand with the previous one: after each sprint, the outcomes can be verified and measurements for the next steps investigated. By releasing a steady stream of strategic artifacts (initial and ongoing outcomes of initiatives), organizations can build and maintain sustainability as well as predictability. This has two benefits. Firstly, short-term and long-term needs can be addressed more effectively. Secondly, strategic plans are not treated like single artifacts anymore but as growing strategies that are continued and optimized. Closely interlinking (re)design, execution, monitoring and adaption can help achieve this as part of the strategy development and execution process.
4. Flexibility: The main motivation behind adopting an Agile Strategy framework is the ambition to adjust and adapt more quickly towards the strategic impact of changing environments. After each iteration, it is either to pivot or to preserve: by conducting regular reviews at the start of each iteration, the value contribution of an achieved strategic artifact is evaluated against the present situation. Practitioners can either continue to work on it or they can stop and tackle more critical matters that have emerged in the meantime. The same applies to any new risks or issues that need to be solved beforehand. Previous initiatives hereby will be set back to a strategy backlog until the next iteration. Not only does this iterative proceeding defy the rigidity and flaws of traditional strategic management. It centers the view on business value and increases the focus on managing strategic initiatives in a predefined time.
5. Feasibility: Unlike tremendous planning activities, dynamic decision-making methods such as hypothesis-driven and scenario-based planning help to explore and test complex and uncertain environments. They lead to repetitively new assumptions or selective options until a fitting solution has been narrowed down. One level beyond, experimentation-based ‘trial and error’-activities, piloting and data-driven automation procedures lead to alternative conclusions that can change a previously anticipated status quo immediately. In any case, organizations need to familiarize themselves with an insight-driven ‘Fail and Learn fast‘ mentality in order to increase the success rate of strategic realization.
6. Engagement: Organizations are advised to empower self-organized, interdisciplinary strategy teams dedicated to put these strategies into practice. They should consist of senior managers representing all affected organizational areas – business as well as IT – who are committed to shape and contribute to strategic discussions. In doing that, they maintain a mutual exchange of information between Top Management and the engaged staff. Latter provide their subject-matter expertise and consult the strategy team on the feasibility of planned initiatives. The Top Management oversees that the strategic team adheres the strategic direction while promoting the team in its autonomy. In the end, this encourages a higher dedication by all involved parties including a broad knowledge base for decision-making and an increased buy-in from all relevant stakeholders.Wouter is a life coach, with certification from the MMS Worldwide Institute, and has coached more than 20 senior executives and board members on making the personal changes needed to lead their companies’ transformations. He writes frequently on organizational topics and is a leader of McKinsey's Organizational Agility Forum .
Wouter is a leader of McKinsey’s agile organization work. He has deep experience in serving global high-tech companies and technology functions in other industries as well as cross-industry experience in agile operating-model design and transformation.
Wouter has led several large-scale transformation programs for clients, helping them achieve sustained improvement in both performance and organizational agility. These programs focused on strengthening mind-sets and capabilities from the leadership team to the front line while delivering improved performance. He believes strongly in integrating hard measures to boost operational and financial performance with soft skills, such as self-awareness and effective teamwork.
“Rethinking the boundaries of your organizational (eco)system,” blog entry, McKinsey & Company, December 2019
“How to select and develop individuals for successful agile teams: A practical guide,” McKinsey & Company, December 2018February 5, 2018 Across industries and regions, the concept of organizational agility is catching fire as companies scurry to deal with rapid change and complexity. Yet, achieving the ability to reshape themselves quickly is proving elusive for most.
The findings of McKinsey’s first global research study of agile organizations underscores the difficulties in achieving their desired nimbleness. But it also illuminates that getting agile right delivers substantial rewards ranging from efficiency improvements and improved customer satisfaction, to faster time to market.
We cast a broad net in our research, and it delivered some major surprises in identifying key success factors for becoming agile. Among them:
1. An organization must excel at all the 18 identified key practices to achieve agility. Our research finds that doing a few of the key practices well is not enough, all 18 must be embraced. The 18 include some basic elements – such as standardizing ways of working and sharing access to unfiltered data – and several more advanced techniques, such as having an open talent marketplace where people move regularly between roles and teams. You must address the holistic set of levers to scale organizational agility across most or all of an institution.
2. Speed is central to becoming agile, but so is stability. Organizational agility requires a core set of organizational elements that don’t change a lot, such as a platform to build and launch fast, dynamic capabilities. Even if your company is stable, you need to determine how it is stable. Most global enterprises possess the wrong type of constancy; instead of a launching pad for dynamism, most big companies today have stable elements that are bureaucratic “speed killers,” such as rigid organizational structures centered on hierarchy and control.
The research identified six stable, foundational practices among the 18 key elements upon which to build and scale agility, such as a shared vision and purpose that establishes a North Star for the entire organization.
3. An organization must deal head-on with the No. 1 agility challenge: culture and leadership mindsets. They surpass insufficient resources, lack of leadership commitment and system limitations as the biggest barriers to becoming nimbler. To solve them requires abandoning many basic assumptions about how organizations can and should work, including that senior leaders must maintain control. Letting go of control is vital to becoming agile.
Amazon’s CEO Jeff Bezos gets it. In a 2016 letter to shareholders, he maintained that the company must treat every day like it’s Day 1. “Day 2 is stasis. Followed by irrelevance. Followed by excruciating, painful decline. Followed by death. And that is why it is always Day 1,” he wrote. To keep that Day 1 energy, he says, requires being extra fast on making decisions, even if they must later be reversed or are made without having full information. And, he said, senior leaders must feel free to disagree with a decision, although they must fully commit to it if they’re outvoted.
Understanding these three insights from our research into how to become agile will especially benefit organizations starting or still in the early stages of their journey to agility. In subsequent blog posts, we will explore other essential ingredients for achieving an agile organization, including a deeper examination of the 18 practices considered essential to adopt.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
March 16, 2020 Throughout my career, I’ve experienced how agile methods improve workstreams and deliver tangible results firsthand. I spent time as a scrum master, digital product owner, agile trainer and a tech strategy consultant at Accenture.
One day, a new job alert popped up on my LinkedIn: Agile Coach at McKinsey’s Warsaw office. My father worked at McKinsey 20 years ago, so I read McKinsey’s posts and blogs about agility to learn more about their work in the space. During the entire recruitment process, I had great support from McKinsey recruiters, who coached me and helped me land the job.
McKinsey approaches agility differently. We go right into the boardroom and make agility a priority for the client’s entire organization, not just one department. Agile isn’t an experiment here, it’s a long-term business practice.
Day to day, I help large organizations shift to agile workstreams to create lasting change. Some of the organizations I work with use agile in segmented departments, and we help take that company-wide. The most rewarding part is working alongside people across the company who are experts in their fields, building a strong team, and making this change a success.
Agile work at McKinsey explores a variety of methods and frameworks. We use practices from agile approaches like SAFe, LeSS, scrum and Kanban and tailor our methods to each situation. For higher-level steering, we bring OKRs into the mix and institute quality planning structures like those many Silicon Valley tech companies use.
I’m working on a very cool project right now for a large apparel company. We’re using agile methodologies to connect the company’s planning and logistical operations to improve the company’s processes. As a loyal brand customer, it’s a dream come true to work alongside these clients and bring agility to their business.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Working at McKinsey is amazing because of the people. I have the chance to work with remarkable, smart and kind people from different backgrounds from all over the world. Even when I’m the only person in a t-shirt in a room full of suits, I feel welcome and appreciated for the expertise I bring to the table.
I enjoy McKinsey’s focus on people and communities within our offices, within our 4.5K+ global tech community and within our practice of 100+ agile coaches. Through the agile community, I can connect with colleagues worldwide when I need support during a project. We have in-person meetups, where we get to know each other on a more personal level, share our experiences and discuss the future of our role in the firm. I always look forward to these meetups and we always have great fun.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Tomasz is an agile coach based in Warsaw, Poland. Prior to joining McKinsey, he was an accredited agile trainer and a senior tech strategy consultant at Accenture. Tomasz earned his bachelor’s in finance and accounting at Kozminski Academy in Warsaw and his master’s in international management at Warsaw School of Economics. He is certified Scrum Master, Product Owner, DSDM practitioner and Kanban Management Professional. In his free time, Tomasz enjoys spending time with his wife and kids and keeping up with the latest blockbuster action movies.As the business impact of the COVID-19 crisis mounts, leaders in every industry are moving urgently to protect employees and build resilience. Governments are mobilizing to safeguard citizens and manage the economic fallout. Immediate action is critical, but leaders must also embrace a new agenda—one aimed squarely at what comes next.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.Enterprise agility was desirable and is now becoming essential. Agility across a whole enterprise combines speed and stability; helps role clarity, innovation, and operational discipline ; and can produce positive outcomes for organizational health and performance. Although the beneficial outcomes of agility are widely recognized by executives, those considering an enterprise-wide agile transformation are questioning both the potential of such an undertaking and the outcomes they should seek.
What should executives focus on, and what might they expect to change? Some data are emerging to help with answers. We analyzed the impact of enterprise-wide agile transformations as part of our worldwide agile-research effort. We analyzed 22 organizations in six sectors, and our preliminary results identified three main outcomes of agile transformations: improved customer satisfaction, employee engagement, and operational performance. These make up what we call the “agile impact engine.” The benefits are mutually reinforcing and produce a fourth outcome: improved financial performance (Exhibit 1). Exhibit 1 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
The agile impact engine forms a framework for assessing potential gains by examining in more depth those organizations that have successfully completed agile transformations (see sidebar “A word on our research methodology”).
Sidebar A word on our research methodology To create the ‘agile impact engine,’ we collected outcome data on 22 companies across six sectors that completed agile transformations at the business-unit or enterprise level (excluding organizations that implemented agility solely at the team or squad level or within just one function). We measured the level of agile maturity (the extent to which a company operates in an agile manner) before and after the transformation. This allowed us to check if the transformation had successfully increased the level of agility and to weight the improvements observed in the outcome metrics. To measure agile maturity, participants rated a set of statements capturing agile behaviors across five dimensions—strategy, structure, processes, people, and technology—on a scale from one to five. We compared the change in agility maturity as a result of the transformation with the change in outcome metrics to understand how agile maturity might drive company outcomes. When conducting our research, we encountered three main challenges that influenced our sample size and the outcome metrics considered: the limited number of enterprise-wide cases that are currently sufficiently mature, given the pioneering nature of such full-scale transformations
the lack of a single measure of impact—impact depends on industry, and measurements need to be taken across a combination of metrics, given the complexity of impact
the difficulty in tracing the impact of marginal output (for example, additional product features resulting from more agile development) on financial results
Although these results seem highly desirable, there are three caveats. First, the extent of the gains depends on the starting level of enterprise agility, since, naturally, those starting with lower baselines experience more change. Second, significant gains are found only where agility is implemented successfully, holistically, and with high ambitions for performance improvement. Finally, the 20 to 30 percent improvement in financial performance may not register as profit and loss, as organizations make strategic decisions about removing cost and reinvesting in growth and capabilities.
Before we look closer at the potential impact of agile transformation, it’s important to build a shared understanding of how we define and understand the topic.
Agile organizations can quickly redirect their people and priorities toward value-creating opportunities. A common misconception is that stability and scale must be sacrificed for speed and flexibility. Truly agile organizations combine both: a strong backbone or center provides the stability for developing and scaling dynamic capabilities.
This backbone binds structural stability (standard operating procedures) to cultural stability (shared purpose, direction, and values); it also supports dynamic capabilities (for instance, fluid changes to strategy and team setup) in order to respond quickly to fast-changing conditions.
Sidebar How agile are you? Understanding your company’s agile maturity today is an essential step in shaping your journey to enterprise agility. Curious to find out your company’s agile maturity? Take our 20-question survey in the paper’s appendix.
To balance flexibility and stability, organizations can implement choices in five dimensions of the agile operating model (Exhibit 2). The extent to which an organization has implemented these agile elements represents their level of agile maturity (see sidebar “How agile are you?”). To reap the fullest benefits of agility, companies should implement any operating-model changes across all five dimensions.
Exhibit 2 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Few organizations have completed a full transformation across all dimensions of the operating model at the enterprise or business-unit level; most still work at team-level agility. However, we see a growing interest in scaling agility from pilot projects at the team level to implementation across larger parts of the organization. With this in mind, our research included only those agile transformations at the enterprise or business-unit level.
Although the five dimensions seen in Exhibit 2 provide a clear path to implementation and how to assess the level of enterprise agility, they offer no guidance on how to measure the impact of enterprise agility. The danger here is using the table to measure the ruler rather than the other way around.
We tracked a broad set of outcome metrics during agile transformations and saw that organizations use a unique set of metrics depending on their sector, customer type (for example, B2B or B2C), and transformation objectives (Exhibit 3). However, we can broadly synthesize the key outcome metrics into the four categories that compose the structure of the agile impact engine shown earlier:
Exhibit 3 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Clearly, different organizations undergoing agile transformations will tend to emphasize apposite outcome categories. For example, those in our sample who needed to recruit talent focused more on employee engagement, whereas those in financial distress concentrated on financial gains and those facing competitive pressure valued customer satisfaction.
Section 2 How much do your customers love you? Agility has the potential to improve the customer experience by up to 30 percent
Using enterprise agility to meet rapidly changing customer needs can result, unsurprisingly, in a better customer journey. In the cases we examined, agile transformations resulted in an uplift in customer satisfaction and engagement of between ten and 30 points.
An obvious driver of this impact on customer experience is the shift toward an obsession with the customer; this is key for all agility. During an agile transformation, customers move to the heart of the organization, and the “North Star” (a shared purpose and vision across the organization) invariably centers around customer needs.
In fact, the North Star is essential to an agile transformation, since it informs all decisions and missions and provides a language shared across the organization. For example, Amazon’s North Star is, “We seek to be Earth’s most customer-centric company.” Amazon’s four guiding principles, of which one is “customer obsession rather than competitor focus,” further emphasize this purpose.
During an agile transformation, customers move to the heart of the organization, and the “North Star” invariably centers around customer needs.
Another element that enhances customer satisfaction is a flexible network of teams (one of the five trademarks of an agile company). In a successful agile transformation, the teams need to operate with high standards of alignment, accountability, expertise, transparency, and collaboration, all in service of the customer.
The impact of these standards on customer satisfaction becomes clear when we consider the complicated pathway that new product ideas took at an Asia–Pacific telco in its preagile state. As Exhibit 4 shows, new ideas to meet customer needs went through countless handovers between departments with different customer value propositions and incentives. This resulted in frequent delays and, consequently, low customer satisfaction. During the company’s agile transformation, it moved to a cross-functional setup of its digital-consumer business, with 18 squads taking end-to-end accountability for different outcomes within the new digital hub. As a result, customer satisfaction increased by 35 points.
Exhibit 4 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Section 3 Do your employees really care? Agility leads to a potential 20 to 30 percent improvement in employee engagement
A second area in which the impact of agility is clearly visible is in employee engagement. The organizations in our sample experience a 20- to 30-point improvement in engagement in an agile environment, compared with a nonagile environment. This change was seen whether engagement was measured by employee willingness to recommend their workplaces or by internal employee-satisfaction surveys.
Several factors could explain the impact of agility on employee engagement. Most fundamentally, in the nonhierarchical organization of cross-functional teams, employees have the opportunity to develop a strong sense of autonomy, mastery, and purpose. These have a positive influence on employee satisfaction and engagement, as evidenced in previous McKinsey publications and extensive research, including that compiled in Daniel H. Pink’s Drive: The Surprising Truth About What Motivates Us (Riverhead Books, 2009).
An agile transformation encourages these three motivating factors, as illustrated by a telecom operator from Asia–Pacific. The company launched an enterprise-wide agile transformation, with improved employee engagement as a leading goal, alongside increased customer centricity and faster time to market. Throughout the transformation, the company’s operating model went through an overhaul. They transformed its hierarchical and multilayered organization structure into a simple, three-layered approach consisting of a leadership squad, 18 tribes, and approximately 200 autonomous squads.
Autonomy was embedded by creating small, cross-functional teams with full end-to-end accountability for specific missions and products. Mastery grew from its need for people who could apply knowledge across a broad range of situations while having deep knowledge in one area. The new setup recognized individuals for their technical skills and allowed growth in expertise, not just a move into management with a multidimensional contribution model.
Sidebar What is the difference between a key performance indicator and an objectives-and-key-results metric? A key performance indicator (KPI) is a metric used to measure the performance and track the health of a business, and it usually refers to an ongoing activity. A mature organization will track many KPIs but conceptualizes them as levels to maintain, not necessarily targets for change during the period of measurement. Setting objectives and key results (OKR), however, allows companies to focus on aligning its objectives for change and monitoring progress toward those objectives during the period of measurement. The objectives, based on the overall company road map and strategy, get revisited regularly as the team or organization evolves. There may be an overlap between a KPI and the OKR framework if a KPI aligns with an objective that a change in the KPI could accurately measure, but this is not necessarily the case.
Finally, purpose was created through an inspiring North Star translated in clear goals and missions for each squad in the organization. Concrete tools such as objectives and key results (OKRs) allowed the North Star to act as a common language between distributed and autonomous teams (see sidebar “What is the difference between a key performance indicator and an objectives-and-key-results metric?”).
As a result, employee engagement scores in most of the agile tribes now significantly exceed levels seen even in many of the iconic digital natives, allowing the organization to attract top talent in the market and strongly outperforms its peers in this area.
It makes sense to want happy, motivated, and engaged employees. There is a strong connection between employee engagement and efficiency metrics (such as speed of issue resolution), as well as between employee engagement and customer satisfaction. And the contribution of such employees is widespread. Moreover, it should come as no surprise that high employee engagement scores attract better applicants and support organizations in the war for talent.
Sidebar Mini case study: Purpose in the public sector An example of the impact of a purpose orientation comes from a European public-sector defense organization. One senior leader commented, “In order to overcome organizational inertia, we focused on crafting a ‘North Star’ vision and redesigned our previous hierarchical structure into purpose-based teams. We really wanted our staff to feel part of this transformation, so [we] focused from the start on cocreation and listening.” This enabled the organization to set priorities for each team, make “health checks” to identify pain points and strengths, and facilitate early employee buy-in. Overall, the organization became more responsive to change, and its employee engagement increased by 20 points.
When measuring the impact on employee engagement of agile transformations, it is important to track changes over time. Any transformation can initially provoke excitement across both agile and nonagile parts of the organization. Equally, parts of an organization may experience a subsequent decline in engagement when they encounter obstacles in nontransformed parts of the organization.
The HR director of such a fully agile organization expands on the powerful impact purpose and autonomy had on the large improvements in employee engagement :
[Without purpose and autonomy], you’re in a world where people come in to work, they do their little bit, they go home, but they may have no idea where that fits into the big scheme of things. Agile puts direct ownership and real-time accountability with the squad so that they have absolute clarity about where it all fits now. That’s where the engagement comes from—employee engagement goes off the chart because people have richer jobs, they’ve got a broader perspective, and they’re focused on solving problems. They don’t feel like hamsters—they feel like they’re part of a squad that’s on a mission.
Operational-performance metrics vary by sector. Common examples in our sample include time to market, planning time, issue-resolution speed, predictability, and raw product output, among others. These can fit broadly into three categories: speed, target-achievement rates (TARs), and other industry-specific metrics. Our research shows that implementing an agile transformation can unlock an improvement of 30 to 50 percent in these metrics.
Two specific factors—enhanced visibility and understanding of objectives and improved team dedication—are dominant here:
Agile units have more visible expectations of their tasks (by having strategy expressed in OKRs, team-level milestones, and deliverables). They are also clear about their current performance (by using real-time key-performance-indicator dashboards). Adjustments can occur quickly. Tasking dedicated teams with particular outcomes reduces the need for handovers (for example, sending a customer from department to department or handing off an unfinished product to another team) and the waiting time, thereby increasing efficiency.
Using agility, organizations can increase the speed of decisions and product development, as well as shorten the time between the conception and release of a product (known as time to market). They dream of a setup that allows them to stop trailing their competitors and to move to the forefront of product development.
Implementing an agile transformation can improve operational-performance metrics by 30 to 50 percent; enhanced visibility and understanding of objectives, as well as improved team dedication, make a difference.
This happened to a telecom player in our sample. As a result of the company’s new, agile setup, it could respond to its competitors’ new-product releases within one week, as opposed to several months: it cut time to market by as much as 70 percent. Overall, our research indicates that agile transformation can reduce time to market by at least 40 percent.
This is also relevant for B2B companies, or parts of B2B companies, in which speed can have a large impact on capital expenditure. An oil and gas company, for example, wanted to reduce the time it took to plan and design a new oil well. The health and safety implications of drilling rely on a variety of technical skills and require large capital and time expenditure. By creating one co-located team of engineers from the completion, drilling, geoscience, and petroleum teams, as well as supply-chain and commercial specialists, the company halved the time required to plan and design its wells and increased quality by reducing handovers.
Finally, in service operations, speed can drive significant gains in productivity and customer satisfaction, as we have seen in many instances of agile transformations of customer-service and back-office activities.
Another operational metric that shows significant improvement after agile transformations is the TAR. Capture 70,000 customers of a goal 100,000 new customers, and the TAR is 70 percent. Whereas most traditional companies struggle to meet their targets (falling below the 100 percent rate), all agile companies in our sample, bar one, surpassed their targets: rates ranged from 90 percent to 140 percent. The 140 percent TAR was at a European bank that outperformed its objectives despite deteriorating market conditions. That said, outperforming targets is not always desirable. Predictability of performance is crucial in accurate forecasting for strategy and resources. Agility allows organizations to adjust their forecasts and targets up and down in a timely manner.
There are many industry-specific operational metrics that illustrate the benefit of agility. For one Australian liquefied natural gas producer, increasing the amount of gas produced per employee was a key operational metric. By applying agile methodologies, such as shifting technical middle managers to “doers” and creating semiautonomous operating assets, the producer was able to raise overall gas production by 5 to 10 percent. However, with a significant reduction in full-time-equivalent hours by means of these methodologies (and by reducing its organizational layers to four), the overall increase in the volume of gas production per employee went up by 70 to 80 percent.
Although successful agile transformations lead to impressive operational improvements in the long run, a dip in operational performance is common during the initial phases of the transformation. This is the result of employees and the organization adjusting to new ways of working. For example, at an Asian telco, senior leaders mentioned that performance—measured by time to market and achievement of performance targets—initially dipped after implementing new initiatives (sprint-based operating rhythms and newly cross-functional squads). But after three months, performance surpassed the company’s preagile level.
Can improvements in customer satisfaction, employee engagement, and operational metrics (such as speed) as a result of agile transformation translate into financial uplifts? Whereas almost all the organizations in our sample tracked productivity gains and cost savings, few systematically looked at revenue or margin uplift, citing difficulties in baselining the pretransformation state. This led to the data overemphasizing cost savings; nonetheless, we have qualitative evidence of revenue-based improvement as a result of agile transformation.
Although cost savings is seldom the primary objective of an agile transformation, it is a natural consequence of the improved operational performance and ability to provide the same outcomes with fewer people. The internal and external costs savings identified in our sample ranged from 20 to 30 percent. Importantly, in several cases, companies reinvested part of the savings to capture new business opportunities—meaning these savings did not register as part of profit and loss.
For example, a Latin American bank decided to go agile in one of its discrete business units. By applying a “no middle managers” rule; reducing the number of layers to three, from seven; dedicating squad members 100 percent to the transformation; and removing the silos between the business and IT functions, it saved 30 percent of its internal full-time-equivalent employees. The bank identified all these employees as new capacity and redeployed them to new roles within the agile company.
Our research so far shows that the prize for agility at the enterprise level is a significant boost in multiple organizational outcomes; we have summarized the maximum potential in our agile impact engine. The findings hold true for successful agile-transformation implementations across sectors and geographies. As the pressures mount to find innovative ways to remain competitive in today’s rapidly changing environments, agility is no longer just desirable but becoming essential.
To continue building our fact base, in coming months, we will extend our research on agile maturity and key performance indicators (including financial results) across industries and over time.Where are you today? Given the growing popularity of agile over the past number of years, especially within IT and recently emerging for business areas like Marketing, Sales, etc., there are likely to be pockets of agile within your organisation. These learnings are important to capture and will feed into your understanding of the current state enterprise agility spectrum. The current state view will provide a rough indication of how much change will be required.
Where do you want to get to? To determine where your organisation would like to get to starts to define the choices and decisions that will be required. Based on the examples across culture, people, leadership, governance, strategy, structure, policy, ecosystems and technology in the spectrum, there is a clear contrast between how a classic/traditional organisation works vs. a high performing agile organisation.
As an executive leadership team, clear decisions need to be made on the set of guiding principles that will define the ways-of-working for the organisation across these core themes. These principles should be universal. However, the application of these principles will vary as a one-size fits all execution approach will not work consistently across all areas of the business (e.g. core customer/product business units vs. shared functions like HR, Finance, Risk, Procurement).
Lastly, the accumulation of the previous 3 steps will set you up to create a clear, simple and purpose-driven story that will drive your change narrative. It is essential that all individuals in the organisation, including the executives at the top, new graduates / recruits, and individuals who have been with the organisation for years, are able to articulate with conviction, strength and a sense of urgency the case for change.
The case for change needs to be balanced with the benefits of the change (enabler of your strategy through embracing the art of the possible and solver of current challenges) and the investment required to get there in people, process and technology. There needs to be a recognition that you will ‘slow down before you speed up’, and clarity on how success will be measured iteratively on the way.
All 4 steps are important to work through, yet the most fundamental for your success is to ensure that there is leadership sponsorship, alignment and prioritised focus. An evolution towards Enterprise Agility, regardless if it commences from within IT or from the Business, will result in a complicated mess, with both leaders and team members feeling frustrated, and likely end in failure, if there is minimal or no visible, active, or aligned leadership.
Moving beyond the phase of Ideation, an Enterprise Agility journey continues in an iterative and incremental way – in the true agile spirit. Committing and delivering on small actions as an organisation, team, and individuals, at all levels, is fundamental to the approach. Measuring outcomes along the way will be your guiding light. Remember, there will be feelings of resistance, fear and discomfort at the start, and during ‘the emotional journey to creating anything great.’ It will not be easy to change. But, if your organisation doesn’t change, how else will you respond to the ‘change is the new norm’ world that we live in today?April 9, 2020 I’m an agile coach in McKinsey’s Gurugram office. I joined McKinsey in 2012 as an operations engineer, providing support for Oracle, MySQL and other relational database management system (RDBMS) technologies. From there I expanded to the reliability engineering group, where I was responsible for product management, change management, problem management and onboarding new applications.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com Agile coaching session (before COVID-19)
McKinsey has given me great access to tech learnings both internally and externally. In my operations engineering technology role, I learned additional RDBMS technologies, including MySQL and DB2 and NoSQL systems like Apache Cassandra and the Neo4j graph platform. I also worked on automation projects using Ansible, Python & Shell Scripting.
In 2017, with the support of my managers, I decided to try my hand at becoming an agile coach and scrum master. I’m now a certified scrum professional, scrum master and product owner, certified agile leader and Kanban system designer. I’ve led more than 10 agile squads in development operations, product and client services as a scrum master. Now, I’m a leader in McKinsey’s agile group.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
We have a saying here, which I find rings true: Make your own McKinsey. It means that within the firm you can explore opportunities and build your own path based on the work that excites you. We have the opportunity here to learn and experiment with disruptive tech languages, platforms and methodologies.
In my current role, I serve as an agile coach to squads around the world, leading them to follow data-driven visualization approaches to problems, past patterns and new opportunities. I also mentor and coach scrum masters through designing and executing virtual and in-person workshops and training programs.
I don’t limit my methods to scrum. I am inspired by Liberating Structures techniques, lean processes and design thinking. I also love using Kanban’s practices like visualizing and managing workflow to establish predictability.
The leadership at McKinsey has been very supportive. I have had mentors who helped me in my journey, and I’ve mentored others in turn. I enjoy the people at McKinsey, the culture and the inclusive environment that the company fosters. Every day, I work with colleagues at all levels within McKinsey, with different technologies and in many geographies and time zones.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com Bhangra performance (before COVID-19), a Punjabi folk dance form with my McKinsey group “Bhangra Jammers”
I am happy to have found groups of like-minded people within McKinsey. I perform Bhangra, a Punjabi folk dance form with my McKinsey group “Bhangra Jammers” at McKinsey events like Values Day. I’m involved in the corporate social responsibility team, I serve as the Go Green Team board member and I’m part of McKinsey Toastmaster’s club, which promotes communication, public speaking and leadership.
Based in Gurugram, India, Gurbrinder is an agile coach with our internal Technology & Digital team. Prior to joining McKinsey, he was a Java developer focused on insurance and telecom projects. Gurbrinder earned his bachelor’s in technology from Guru Gobind Singh Indraprastha University in New Delhi. Outside of work, he volunteers with charity groups for causes including women’s issues, children with special needs, pollution and blood donation.It was a Saturday morning. I was standing in line at a coffee shop, thinking about flow, as I often find myself doing when waiting in line. I reached for my phone to pass the time (while stuck behind a constraint in the cafe’s system of work) and sent the tweet above*. This tweet went, relatively-speaking for me, viral, breaking in to triple digits of likes and retweets. It seems to have struck a chord.
If you want to do an Agile Transformation, don’t. Focus on Better, Value, Sooner, Safer and Happier and you will end up transforming to have agility.
This is the first of a series of posts, where I’m going to share a number of anti-patterns and corresponding patterns. It is worth noting that everything is context dependent. An anti-pattern for one scenario might be a pattern in another context. That said, I believe that the anti-patterns to be presented are applicable in the majority of contexts.
This is based on lessons learnt through doing including learning from failing. Along with many talented people, we’ve been servant leaders on better ways of working (the application of agile, lean , DevOps, design thinking, systems thinking and so on) across a large (80,000 people), old (300+ years old), global, not-born-agile, highly regulated enterprise, with personal experience of delivering change with an agile mindset, principles and practices since the early 1990’s, about a decade prior to the Agile Manifesto, when the term ‘lightweight processes’ was used. The anti-patterns and patterns are also based on learnings from the community, from other horses (rather than unicorns) on similar journeys, as we are all at a turning point in the Age of Digital.
A capital ‘A’, capital ‘T’ Agile Transformation, from the perspective of an employee, infers involuntary, mandatory change being done to you, whether you like it or not.
The capital ‘T’ denotes that you have to change and the capital ‘A’ denotes how you are going to change. Both of these words carry baggage.
Not surprisingly, this triggers fear and resistance for many reasons, including loss of control, uncertainty, changing habits, fear of failure, fear of incompetence, more work, change fatigue and ‘better the devil you know’.
From an evolutionary perspective, depending on the messaging of the why and depending on how the change is approached, and in particular for those with a fixed mindset, change drives a fear of survival, which leads to resistance and less rational thought as the primitive brain takes over.
Looking at autonomy, purpose and mastery, as per Daniel Pink’s Drive and that human motivation is primarily intrinsic for knowledge work, two of the top three motivators have been taken away. There is a lack of autonomy (you have to do this thing) and a lack of mastery (you’re a beginner again, possibly after a long career). If the why is articulated as cost reduction or profitability, meaningful purpose is also removed, taking away all three categories of human motivation.
“The problem with the amygdala and its fight-or-flight response today is that it sets off alarm bells whenever we want to make a departure from our usual, safe routines. The brain is designed so that any new challenge or opportunity or desire triggers some degree of fear. Whether the challenge is a new job or just meeting a new person, the amygdala alerts parts of the body to prepare for action — and our access to the cortex, the thinking part of the brain, is restricted, and sometimes shut down.” (One Small Step Can Change Your Life. The Kaizen Way, Dr Robert Maurer, 2014)
This evolutionary fear of change is also seen in loss aversion, which is people’s tendency to prefer avoiding losses to acquiring equivalent gains. This evolutionary tendency to loss aversion further cements people’s desire to maintain the status quo.
“Humans may be hardwired to be loss averse due to asymmetric evolutionary pressure on losses and gains: for an organism operating close to the edge of survival, the loss of a day’s food could cause death, whereas the gain of an extra day’s food would not necessarily cause an extra day of life.” (Loss aversion, Wikipedia)
Agile should not have a capital A unless it is at the start of a new sentence. Agile is not a noun. It is not a trademark. You can’t buy Agile In A Box (really, you can’t). By the very fact that agility is optimal in complex contexts, where the What and the How is inherently unknowable in advance, where acting in the space changes the space, there cannot be a one size fits all solution. It is about exhibiting agility, being agile not doing Agile. It is first and foremost a mindset that informs every single deliberate decision and automatic reaction.
The capital ‘A’ Agile mindset leads to the Agile Industrial Complex. It leads to a number of anti-patterns, such as the imposition of practices on people and to certification schemes with questionable value. We don’t want agile for agile’s sake or DevOps for DevOps sake. This can lead to local optimisations where the expected business benefits, end to end, do not materialise.
There is a need to focus on Why are we doing this and what the desired business outcomes are. Then agile, lean, DevOps, Design Thinking and so on are bodies of knowledge, they are tools in the toolbox, to achieve those outcomes, applying what works in your unique context and continually improving through experimentation.
First, as well articulated by Simon Sinek, start with why. There should be a clear and well communicated Why for the organisation of the need to change ways of working, why constant improvement is needed, with nuanced context-sensitive and relevant definitions of why for the any sub-organisations within the parent organisation which may have their own cultural norms, history, folklore and legacy ways of working.
The ‘why’ should be more than profitability, shareholder returns or stock price. As per the article ‘The Irrational Side of Change Management’
Research shows that when employees are asked what motivates them the most in their work they are equally split across five forms of impact: (1) society (2) customer (3) company (4) team (5) the individual.
“What the leader cares about (and typically bases at least 80 percent of his or her message to others on) does not tap into roughly 80 percent of the workforce’s primary motivators for putting extra energy into the change program.”
Teal organisations, the most evolved, are driven by a higher level purpose. This is echoed in ‘Drive’ by Dan Pink, where people are motivated by a transcendent purpose. Ensure that the definition of why has a higher level purpose and covers society, customers, company, team and the individual.
From there, identify high level, thematic desired outcomes. Start with what does awesome look like, what is the current reality and what are the obstacles. Next, derive, prioritise and theme outcomes which get you to your state of awesomeness.
For us, our desired outcomes are described as Better Value Sooner Safer Happier, each of which is measurable.
Value => context specific unique measures per quarterly Business Outcome (e.g. customer Net Promoter Score increased 10 points, reduced carbon usage by 10%, increased gender diversity by 15%, increased lending to small and medium firms by £100m, reduced Risk Weighted Assets held on balance sheet by 20%, etc.)
Sooner => Flow => Lead Time, Release Cadence, Flow Efficiency. Be wary of becoming a feature factory. Reduce Lead Time and spend more time with the end users, refactoring and innovating.
Safer => GRC Control Compliance (e.g. InfoSec, Know-Your-Client, Data Privacy, GDPR type mandatory requirements). Speed & Control. Agile not fragile.
Ultimately, it is all about Flow. This needs balancing measures, as anything can be done badly, so that it is not Flow at the expense of quality, happiness, safety or value.
On a regular cadence, a one pager is sent to senior leaders with measures for the above, including vector measures, the rate of improvement. Everyone can see everyone else’s data. In addition, a real time dashboard with drill down is available.
The scope is the whole organisation, to enable business agility. It is Incremental and Disruptive, Exploit and Explore. It is equally aiming to delight customers in existing markets and to delight new customers in new markets.
Then, for the reasons above, rather than doing a capital ‘A’, capital ‘T’, Agile Transformation for the sake of agile and framing it as such, and commence the rollout of a set of prescriptive practices or a prescriptive framework, frame the change around the Why and around the improvement in the identified Outcomes.
This appeals to intrinsic motivation, it is asking people to bring their brain to work, to understand and internalise the mission, and in an empowered manner to take personal ownership for working out how to achieve the desired outcomes. Agile principles and practices, Lean, DevOps, Systems Thinking, Design Thinking and so on are tools in the toolbox, and are supported with training, coaching and psychological safety in a context sensitive, not one-size-fits-all, pull-based not push-based manner.
*this has been slightly adapted from the original tweet to represent the current Business Agility narrativeAs organizations adapt to the ongoing COVID-19 crisis, their agile teams can be a real source of competitive advantage. Such teams are typically well suited to periods of disruption, given their ability to adapt to fast-changing business priorities, disruptive technology, and digitization.
But the abrupt shift to remote working in response to the coronavirus has challenged the typical approach to managing agile teams. Traditionally, such teams thrive when team members are co-located, with close-knit groups all working in the same place. Co-location allows frequent in-person contact, quickly builds trust, simplifies problem solving, encourages instant communication, and enables fast-paced decision making. And while we know from experience that agile teams that have worked remotely from the start can be as effective, the sudden transition of co-located teams to a fully remote approach can reduce cohesion and increase inefficiency (Exhibit 1).
Exhibit 1 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
The good news is that while it takes real work, much of what leads agile teams to lose productivity when they go remote can be addressed. In fact, if the necessary technology is in place, a talented remote team can deliver just as much value as co-located teams. Assuming a firm’s IT function will handle the organization’s technology, we’ll focus here on the kinds of targeted actions agile leaders can take to sustain their people and culture and recalibrate their processes.
Remote work for agile teams requires a considerable shift in work culture. Without the seamless access to colleagues afforded by frequent, in-person team events, meals, and coffee chats, it can be harder to sustain the kind of camaraderie, community, and trust that comes more easily to co-located teams. It also takes more purposeful effort to create a unified one-team experience, encourage bonding among existing team members, or onboard new ones, or even to track and develop the very spontaneous ideas and innovation that makes agile so powerful to begin with. And these challenges are complicated by the unique circumstances of the current health crisis. Teams working from their living rooms or their dining-room tables are often sharing that space with children or other family members also working remotely.
Teams already operating remotely before the crisis are less likely to struggle, given their ability to handle ambiguity without losing focus and to concentrate on outcomes over processes. But many teams that just switched to a remote way of working are facing new challenges, which may require revisiting team norms, cultivating morale, and adapting a team’s approach to coaching.
Virtual whiteboards, instant chat, and videoconferencing tools can be a boon to collaborative exercises and usually promote participation. But they can also require teams to reconsider existing norms and agreed-upon ground rules.
Some challenges may require team members to adjust to the tools themselves: team members should be generous with one another in offering practical support on navigating virtual tools—such as help formatting or recording presentations or informing the host about any technology issues. Teams need to get up to speed quickly on visual management and virtual whiteboarding and tailor established ceremonies into standard virtual routines. New ground rules for communication may be needed to keep people who are interacting virtually from talking over one another. For example, something as simple as asking each speaker to “pass the ball” by calling out the next presenter by name can help.
Other team norms may also need to be revisited—and revised. On an agile team, everyone needs to take responsibility for capturing spontaneous ideas and putting up blockers to avoid losing them. When using virtual whiteboards, for example, teams need to make extra effort to capture the collective view, especially in larger remote teams. That will help avoid ambiguity and confusion in individual priorities. Similarly, when brainstorming in person, it’s easy to organize and reorganize sticky notes in columns on a whiteboard. That’s not always something that’s easy to replicate using virtual-collaboration tools.
And while teams should put a premium on personal productivity and allow time for it, they may also need to make a conscious point of allowing themselves and others to have more personal interactions. For example, some teams will leave a video feed turned on for longer periods of time; this conveys visual cues that aid in coaching and collaboration and helps team members maintain a face-to-face relationship.
Importantly, teams need to be respectful of personal choices. Working from home blurs the lines between professional and personal lives. Team members may feel added stress about the impression they create on video, whether because of the appearance of their home workspace, interruptions from young children, or even family members sharing the same workspace. Teams should accept these limitations and interruptions graciously—and team members should feel free to set their own boundaries around scheduling and use of video.
Many of the kinds of activities that nurture morale for co-located agile teams—such as casual lunches, impromptu coffee breaks, or after-work social activities—are not possible in a virtual environment. Team members should encourage one another to introduce their pets and family members and to show any meaningful items in their working space. Working remotely, teams need to make a more conscious effort to be social, polite, precise, and tactful—to ensure everyone feels just as safe contributing remotely as they did in person.
For many teams working remotely, some approaches to cohesion and comradery have grown quickly familiar. At one bank in the United States, for example, one agile team established virtual happy hours. Squad members join a videoconference call for a half-hour every week, sharing the beverage of their choice and talking about whatever comes up—other than work. Another team uses a website that generates quick and easy surveys. A designated team member (usually one appointed by the scrum master) sets up each poll with trivia questions to test team members’ knowledge of one another. The whole activity takes under ten minutes, is easy to do, and winners get bragging rights. These activities might sound silly, but they’re also fun—and a useful way of supporting morale and shaping a shared experience virtually.
Agile teams working remotely may also require a more deliberative focus on empathy, openness, respect, and courage. For example, team members may need to remind themselves to create and receive communications with a collaborative mindset and always to assume the best possible motivation from their colleagues. This practice is important to agile teams in general but to remote agile teams in particular, given how easily electronic communications can be misunderstood. For example, an agile team at one retail company has an explicit agreement that team members will always assume that the contributions of others are made with positive intent. Especially in written interactions and brief chat messages, the agreement observes that a comment that may seem appropriate to one team might not seem so to another. Assuming positive intent can create a safe space for team members to play a role as custodians of the culture, flagging such comments and negotiating new rules for collaborating. The person who flags an inappropriate comment can bring it up with the person who made it directly or with the scrum master to resolve it. Or if needed, a small group could stay on the line after a stand-up meeting to discuss. To ensure that team members feel psychologically safe to voice their concerns, one US insurance company conducts an anonymous biweekly survey to solicit input. Tribe leaders and scrum masters use the survey to take the team’s pulse—for example, on whether they’re feeling overworked, how motivated they are, how many things they are being pulled into each day, whether and how processes are working, and what professional-development concerns they might have. The scrum masters and tribe leaders then agree on a benchmark goal and identify a list of two or three tangible actions to take over the coming weeks to improve—which might include visible teamwide actions or more personal one-on-one conversations. All of these are good practices even in a co-located setting, but they become even more critical in a remote setting.
With coaching, agile teams should aspire to model remotely everything they would have done in person—but more frequently, given the abruptness of the switch to remote format. If you would do one-on-one coaching over coffee, try doing it remotely—while actually having coffee over video. Encourage all team members to turn on their video and actively monitor body language during group meetings, especially those in the role of coach.
At one US insurance company, for example, coaches observed meetings while scrum masters led them. Then the two got together afterward to compare notes, and the scrum master followed up with team members individually. Coaches also increased the frequency of feedback—with a regular cadence that included a short meeting every day or every other day. Some even kept a chat window open during ceremonies, to give people they were coaching real-time feedback. Coaches would also host open meetings, so that team members had an informal forum to seek impromptu support on an as-needed basis.
The challenge for remote agile teams is that they’ll be tempted to try to replicate exactly whatever has worked for them in a co-located setting. But what worked in the office setting won’t always work remotely—or isn’t always necessary. The trick is to work backward—start with the outcomes you were getting in the office and modify your scrum ceremonies as appropriate (Exhibit 2). It’s all about adapting to the situation rather than sticking to a guide.
Exhibit 2 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Consider breakouts, for example. Group meetings that use certain video-chat forums can allow large groups to break up into smaller ones for discussion, just as they’d do in person. At one US insurance firm, agile team members joining the virtual group late sometimes found themselves in an empty chat room because everyone else was in a breakout. Their teams were taking more time than they took during in-person meetings to cover the same ground. And they would often return to the general group without having assigned a spokesperson. In person, they’d have had a host or group of hosts going back and forth to different breakouts to check progress, direct latecomers to the right room, and then call everyone back to the main room. They soon realized that in a virtual meeting, they’d need someone performing those same logistical functions. Teams may need to adapt their norms to let individual team members jump in as support, which isn’t possible in a live setting.
Remote work may also require new ceremonies. For example, keeping teams aligned with organizational objectives can be even more challenging. This is easier for teams working together in person, where they can lean more heavily on organic interactions. But working remotely requires more purposeful and structured communication. To navigate that, agile teams at one company adopted biweekly division-wide meetings to identify and agree on objectives for the following weeks.
As performance stabilizes and teams grow more comfortable with working remotely, they may eventually be able to trim down the ceremonies and make them more organic. When an agile team at one insurance company first transitioned to remote working, team members found it necessary to double down on backlog-refinement sessions and documentation because the output of conversations was getting lost. Over time, they’re seeing more organic conversations and collaboration and are beginning to refine ceremonies so that they’re more lightweight.
Agile team processes are fairly informal when working in person, and there’s little need for capturing notes and documenting agreements. Conversations are organic and in real time. Take morning stand-up meetings, for example. This is the daily huddle that keeps teams informed, connected, and aligned—and in person it usually takes 15 minutes of discussion. Teams make decisions with everyone in the room, so there’s little need to record them.
Working remotely, teams may need to consider a different approach to documenting team discussion—producing a so-called single source of truth to memorialize agreements. This can then be kept in a single shared workspace. A remote stand-up can be more involved than an in-person one, depending on a team’s cohesiveness and its maturity. If team members don’t all participate in the event—or if there’s a risk that they’ll be distracted during the call—then it’s important to calibrate the process to the context. The right approach is likely to be team specific, depending on team maturity and existing norms. Others might find it sufficient to simply submit their notes to a shared online workspace, with a bot to collect and compile everything for the records.
Similarly, most agile teams find that the importance of keeping their backlog clean, up to date, and well documented increases when working remotely. A user story inadvertently left active would be a minor matter for a team working in the same room, because a team member could quickly confirm its status verbally. But working in a remote setting, team members might work on a story for hours before getting an alert that it should have been closed.
Asynchronous communication, such as messaging boards and chat, can be effective means to coordinate agile teams working remotely. In fact, we have already seen some teams replacing certain traditional ceremonies with asynchronous communication. For example, a team in a services institution has replaced some of the daily huddles by a dedicated messaging channel to which team members submit their updates and identify impediments to further work. This has the benefit of allowing team members to raise red flags at any point during the day, and it serves as the registry of concerns that have been raised and addressed.
Note that asynchronous communication needs to be used carefully. Teams that grow overly reliant on asynchronous channels may see team members feeling isolated, and the trust among them may suffer.
A remote-working arrangement creates new challenges to keeping agile teams motivated and avoiding burnout. Working in isolation is hard for any person, but particularly for agile teams accustomed to face-to-face communication and frequent interpersonal engagement. Multitasking and home-based distractions also take a toll, depending on how things are set up.
But approaches to keep team members engaged aren’t unique to agile teams, even if the imperative may be more acutely felt. At one US financial institution, for example, a scrum master realized that staring at a video screen for more than a couple of hours was draining without the dynamic interaction of an in-person workshop. Her solution? For longer meetings, she began to schedule in a ten- to 15-minute exercise break every 90 minutes—with a shared videoconference tool to recommend different exercises.
The core mission of leadership stays the same, whether co-located or remote. But leaders need to be more deliberate when engaging with customers and teams, especially when you have limited in-person interaction. Leaders in this context can be anyone on the team, whether product owners, scrum masters, or even a developer demonstrating leadership. Working in the same location, agile team leaders often empower teams to push work forward. Working remotely, they need to be closer to—and more proactive at—guiding their own team members.
They also need to be purposeful at engaging external customers and stakeholders. They must be transparent and reassuring in their communication about team performance and objectives. The tools and approaches can vary (Exhibit 3). But the individuals and interactions should be the main consideration. Leaders need to show, in their tone and approach, that everyone is in this together.
Exhibit 3 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
At one insurance company, for example, the product owner does five-minute individual check-ins with her team members throughout the week, asking if there’s anything she can assist with or any problems she can help trouble shoot. She’s also scheduled sessions with customers and stakeholders every week, in addition to the usual sprint ceremonies, to see if there’s anything more the team should be doing to get their feedback. Too much communication can overwhelm people working remotely with emails and instant messages. So it’s worth putting extra emphasis on making sure they feel heard without overwhelming them further.
The abrupt shift to a remote-working environment was a dramatic change that particularly affected agile teams. The hope is that these changes won’t be permanent. But for now, teams can reinforce productivity by taking a purposeful approach to sustaining an agile culture and by recalibrating processes to support agile objectives while working remotely.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.It is an exciting time to be part of HR. Right before our eyes, HR is transforming into ways of working never seen before. The 1990s are well behind us and it’s fair to say that at most enterprises HR now has a strategic role in leading the business. This is a blessing, a challenge, and the biggest opportunity to create value that HR has ever experienced. As HR has moved into the boardroom and solidified its role in the C-suite, visibility to business imperatives is much clearer for HR and the opportunity to shape those imperatives from a workforce angle is greater than ever. In return, leaders are expecting that workforce programs evolve more rapidly and drive greater, measurable value.
These new expectations drive HR leaders to look outside organizational walls, learn from other functions, and import leading practices that will enable HR to travel at the speed of business, make data-driven decisions, and deploy workforce programs that enable the business to win over the workforce and customers.
The seemingly never-ending quest continues: How do HR organizations, which are aspiring to enable their businesses and people to excel, operate? And, how do the latest insights about becoming exponential HR connect with, complement, or replace the array of practices that have come before in the forms of Lean, design thinking, strategic planning, and agile? These new expectations drive HR leaders to look outside organizational walls, learn from other functions, and import leading practices that will enable HR to travel at the speed of business, make data-driven decisions, and deploy workforce programs that enable the business to win over the workforce and customers.
Irrespective of methodologies, HR must accelerate its pace to effectively deliver on the workforce priorities at the speed of business today. This demands laser-sharp attention to delivering work outcomes that impact business imperatives. HR should architect solutions that elevate the human experience and apply advanced, digital technologies to generate insights and partner machines with humans to help generate value.1
HR leaders are drawing from the methods of lean, design thinking, strategic planning, and agile to break away from traditional operating models and achieve work outcomes in an integrated way that enable HR teams to unlock previously unrealized value when applying each method independently.
We observe HR organizations integrating methods as they work toward evolution—perhaps even revolution—of how HR operates. Although integrating methods may not be the result of an intentional effort and, instead, the blending of practices learned and borrowed over the years, the result may be to fuel an HR organization that consistently focuses on outcomes to achieve sustained results. Four key, interdependent components are coming together, as shown in the visual below:Michael leads Deloitte Consulting LLP’s Learning Consulting practice in North America. He focuses on working with global clients on building high-performance businesses that drive growth and optimization through talent and learning. Prior to joining Deloitte, Michael led the Learning Strategy business for a Big Four firm and was the head of training for a major online retailer in the UK. He has more than 20 years of experience leading key programs at market-leading clients, including running the learning and change management office for a top-tier merger in the Financial Services industry and driving learning transformation for a global brand in the food and beverage industry. Michael has presented at the Chief Learning Officer annual conference and has won learning program awards with his clients. He also lectures on learning at NYU School of Continuing Education.Few IT organizations—or enterprises—can make the leap to agile in one fell swoop. Here's how to make the journey step by step, realizing benefits at every stage.
More customer value, faster development times, greater responsiveness to market changes, better employee motivation, higher user satisfaction, and lower costs. The lure of benefits like these often motivates IT organizations to investigate agile methodologies, widely believed to be able to deliver such positive outcomes. However, transforming a traditional IT shop to an agile one is rarely easy or quick, and it can be even harder to extend the agile philosophy to functions outside IT to become a truly “agile enterprise.” Our experience shows that many agile initiatives get stuck in implementation, failing to deliver the hoped-for benefits. Why?
One big reason is often the approach to agile transformation. Many leaders adopt a mindset that envisions an orderly transition from one stable state to another, seeking to move the entire IT organization to agile in one fell swoop. However, such an approach rarely yields the desired results. Instead, we have often observed that more-successful agile initiatives break with traditional ways of thinking to begin the journey with selected parts of the IT organization. This alternative mindset accepts a certain degree of instability and uncertainty during the transition to agile, and allows ample time for the IT organization as a whole to adapt (in essence, applying agile principles to the agile transformation process itself). Once agile practices are well-established in portions of IT, they can be expanded to other teams, and eventually to other functions within the broader organization, so that the entire enterprise supports the IT organization’s efforts to operate in an agile manner.
There is no way around the observed fact that a wholesale agile transformation usually takes time. Indeed, it can take up to 10 years to go from a traditional IT organization just getting started with agile to an entire enterprise where agile ways of working are part of the culture. But that is no reason not to start. We envision a four-stage transformation process in which every step along the way can deliver benefits—and where each step can be accelerated by taking certain specific actions (figure 1). Below is our guide to cultivating agility in an organization, from small beginnings in the IT department to its adoption across the entire enterprise.
At the first stage, the traditional IT level, the predominant operating model follows a “plan-build-run” approach. This model calls for each team within IT to focus on a certain activity that it and it alone performs. The planning team defines the strategy, processes, and governance mechanisms; the build team is responsible for all change initiatives, which are conducted with waterfall methods; and the run team focuses on IT operations. Process frameworks such as ITIL are often used, defining stage gates at which the most promising initiatives are selected and given resources and budget to continue.
To introduce agile methodologies into an environment like this, leaders can identify one or more projects or groups to manage separately from the prevailing plan-build-run model. This may mean implementing agile approaches for a specific project, or it may mean identifying a relatively self-contained group within the IT organization that can adopt agile approaches without extensive detrimental impact on the rest of the organization. The idea is to seed agile within the broader IT organization, creating a nucleus of experience and know-how in agile methodologies that can later be extended to other parts of IT.
Paradoxically, one step toward preparing an IT organization for the journey toward agile can be to establish a structured operating model for a plan-build-run approach. This step can be important for IT organizations where development occurs in an unstructured, ad hoc manner, as it allows IT personnel to become accustomed to following a defined process instead of approaching each project in an idiosyncratic way.
Another important action leaders can take to help accelerate progress out of the traditional IT level is to outsource a number of projects and encourage those vendors to use agile methodologies. The organization can hand over all IT services and initiatives related to the project in an unstructured state. The outside vendor then takes over, structuring the activities and providing services by applying standardized processes, while monitoring agreed metrics and intervening if the metrics fall outside the agreed-upon ranges. By observing the vendor’s actions, the client’s staff can learn how an agile project is managed, sharpening their ability to steer the outsourcing vendor over time.
The experience of a multinational banking corporation shows how a traditional IT organization can begin moving toward agile. Under pressure from new marketplace entrants (such as fintechs) that were often more flexible, had shorter times to market, and offered more comprehensive product suites, the company decided to experiment with agile methodologies to shorten its product development cycle. It had already outsourced most of its IT projects to vendors that followed agile methods, and the positive results from these efforts supported the business case for establishing an agile delivery model in-house.
The company decided to start the transformation in its offshore center in India to keep costs down, targeting IT executives in a specific organizational unit. Cultural differences between workers from the company's headquarters in Germany and those in India presented an initial difficulty, but after both sides reached a common understanding, the change of mindset toward agile principles—as well as the motivation to act differently—took hold. The teams in India learned agile methodologies from the overseas professionals and developed effective ways to manage multicultural teams in an agile context. Currently, the company is expanding agile practices throughout its Indian IT organization with the goal of eventually applying agile methods around the world. As a first step, the organization has refined its project approval and budgeting process so that agile endeavors are being evaluated on the same basis as classical projects.
An IT department at the bimodal IT level operates in two worlds. At this stage, IT organizations frequently have several initiatives or “digital labs” that use a broad range of agile methodologies and thinking approaches such as Kanban, lean startup, design thinking, and scrum. These digital labs operate as self-contained entities aiming to develop prototypes and minimum viable products outside of the traditional IT environment. Their goal is to deliver innovative solutions that are easy to understand by customers in the business. Meanwhile, the rest of the IT organization continues to operate along plan-build-run lines.
Tension between the digital labs and the remainder of the IT organization is not uncommon at this stage. For one thing, projects started in digital labs are difficult to complete by the classical IT organization, as the timelines for planning and implementation often differ significantly. For another, the classical IT organization tends to be skeptical of the digital labs’ agile project managers, perceiving them as lacking clarity on how to reach the final goal since the agile teams’ minimum viable products are developed in increments. The funding process also differs fundamentally between the digital labs and the rest of IT. While classical projects need up-front funding for the entire project duration, agile digital labs typically compete with each other for budget, with only the most promising developments receiving funding at each project checkpoint.
One way for a bimodal IT department to progress to the next stage more quickly is to require—not just encourage—vendors to apply agile methodologies to outsourced projects. This can deliver benefits on two fronts. First, technology companies frequently have agile resources and know-how on hand, so many vendors are able to start projects very quickly. And second, the client’s IT staff can learn about the procedures and tools of an agile way of working by observing how the vendor acts.
As an example of how digital labs can help an IT organization gain comfort with agile, consider the story of a global insurance company that had created a digital lab to gain experience with agile methodologies. The digital lab had evolved to the point where it was using agile methods to develop standardized insurance products without being technologically or culturally constrained by direction from corporate headquarters. In fact, by having experts from the insurance business work with the software developers, using journey maps to gain a customer-centric perspective, and continuously reprioritizing projects based on the end product’s envisioned value to the customer, the digital labs were able to develop more-relevant products—and get them to market more quickly—than the product development initiatives driven by headquarters.
Some time after the digital lab’s establishment, leaders decided to centralize the provision of IT services for all of the company’s products, hoping to take advantage of synergies with current and previously developed software products to reduce asset development costs. Encouraged by its positive experience with the digital lab, IT embarked on an ambitious agile transformation, establishing multiple cross-functional scrum teams in multiple delivery locations. A strong change management program enabled the scrum teams to spool up on a steady and gradual basis regardless of location.
The company intended to use the scrum teams to not only develop standardized products, but to apply agile methodologies to quickly consider and implement local requirements (for instance, to comply with specific countries’ regulations) into those products. The effort was successful. To date, the scrum teams have been able to produce more than 12 digital assets, which are live in eight countries.
The third stage, agile IT, is characterized by increased collaboration among groups and a prevailing mindset that focuses on outcomes over predefined outputs and deliverables. Typically, this stage is catalyzed by leaders who have seen the benefits of the digital labs’ agile operations in the bimodal IT phase and now want to extend those benefits to the entire IT organization. Although the biggest shift in this transition is cultural, there is also an organizational impact: Whereas a traditional IT organization organizes by process—putting together teams from multiple groups focused on completing specific tasks—an agile IT organization organizes around the product, integrating all team members into a single group striving to achieve the same outcome. The product they are working on, in essence, becomes the organizational entity to which these workers belong.
Operating as a product organization can enable the formation of stable, self-organizing, cross-functional teams across the IT organization that can be up to 400 percent more efficient than traditional IT project teams.1 Such product teams adopt an agile mindset and culture, and are thereby able to take over further development of any minimum viable products that a digital lab may produce.
Another common strength of a product-focused organization is that, as it becomes more mature, it is increasingly able to use a variety of different frameworks, such as SAFe and DevOps, that focus on different aspects of agility while still maintaining a common agile culture. The impetus for variety typically comes from the realization that a single framework cannot fit all situations equally well, and that teams could be more effective if allowed to pursue their method of choice as long as they commit to following agile values and principles. Hence, teams can use different methods, including scrum, Kanban, or even waterfall, without sacrificing the adaptability and focus on outcomes that are hallmarks of agile. (See figure 2 for a guide to deciding what kind of approach may be preferable in different situations.)
To accelerate progress to the next stage, organizations can deploy transformation teams organized in communities of practice to share knowledge and lessons learned among the IT organization’s various development teams. The use of a minimum viable design approach, in which the most basic changes are implemented first, can help to reduce the transformation teams’ need to reinvent the wheel for each new group they work with. At the same time, the transformation team should be allowed the freedom to calibrate the speed of agility adoption to each group’s needs. We recommend taking a “minimum viable change” approach in which change progresses by making small, frequent adjustments rather than all at once. This can help the transformation team quickly test its approach with each new group with which it works, and speeds up the delivery of value for the larger organization due to the small but frequent increments of change.
One multinational telecommunications company that had historically relied on classical development approaches for its core systems wished to adopt agile approaches—both within the IT organization and across the broader business—to become more responsive to the marketplace. Since the company’s mission revolves around the technology-enabled dissemination of information, it had the advantages of both an advanced technical infrastructure and a culture that was supportive of innovative business solutions. At this company, the IT organization had reached the point where it was organized around products—but the business was still split into the familiar departmental silos of finance, procurement, marketing, and so on. The company sought to extend the adoption of agile principles across these silos by promoting collaboration between business and IT. Customer journey maps—which depict a customer’s interactions with the organization, along with the related internal processes and information systems, from the customer’s own perspective—and value streams—which show the multiple customer journeys that can lead to a given outcome—were extensively used to drive collaboration. These journey maps allowed personnel in different functions to understand, for the first time, how customers interacted with the organization’s technology at various points in their experience, which helped engage functional representatives in proposing and testing improvements.
Other changes also supported the business’s shift to agile ways of working. From a financial perspective, the company went from project-based funding to an incremental approach that allowed it to provide seed funding for developing minimum viable products. In terms of leadership, executives were coached to accept failure as an option, while remaining cognizant of the need to halt unsuccessful efforts. Finally, from a technology architecture standpoint, the company was able to allow classical methodologies (primarily waterfall) to seamlessly coexist with agile methodologies by eliminating “technical debt” and ensuring that the organization’s long-term vision was reflected in the data model.
The fourth and final stage in the progression to agile is the agile enterprise stage. At this level, all stakeholders work closely with each other to increase the alignment between technology products and customer requirements. To increase collaboration, organizations create end-to-end teams that cut across functions. Further, the concept of the customer has evolved. All parties orient themselves toward serving the end customer—those who buy the company’s products or services—instead of considering the customer to be the internal business units or functions that use IT products.2 Endeavors are funded incrementally in stages rather than contractually via a fixed project budget. (In an environment with stage-based funding, a project team must continuously apply for the next round of funding, with approval contingent on delivering the desired results.3 In this way, funding is directed to the most promising intermediate products rather than to a predetermined but possibly suboptimal final deliverable.) From an HR perspective, performance management also reflects an agile way of working, with workers’ performance being measured on multiple agile endeavors rather than against the outcome of a single project.4
It can be helpful, to ease the non-IT functions’ transition to agile ways of working, to develop templates or blueprints that give examples of how they can support agile approaches. For example, the finance department can be given an off-the-shelf model for incremental funding. In this way, the functions can more quickly and easily implement the changes they need to adopt to support IT’s use of agile methodologies.
That it may take years to move through one stage to the next should not necessarily be a cause for concern. Every stage in the journey to an agile enterprise can yield benefits, although the advantages (and limitations) can differ from stage to stage (figure 3).
An important point, too, is that many different methodologies can coexist in an agile enterprise—as long as all teams commit to a joint culture based on the agile values and principles defined in the agile manifesto:5
Becoming agile on an enterprise level is a long journey that, for many organizations, is most feasible to accomplish in a stepwise fashion. Starting the journey toward agility often requires leaders to accept that the IT organization will likely experience some instability and conflict during the first two stages, when pockets of agile activity are still surrounded by traditional development culture and processes. Although each of the steps toward enterprise agility has certain limitations, each also delivers worthwhile benefits. The ultimate payoff: the potential for gaining a competitive edge through agile methods that allow companies to be more responsive to and aligned with customer demands.Belkis is one of the pioneers of agile thinking at McKinsey. With over 18 years of experience in delivering robust solutions and coaching teams, she is wholly focused on agile transformation.
An expert in agile transformation, Belkis partners with leaders in banking, healthcare, and other sectors to engender productivity and launch innovative products. Her primary mission—which has her across North America and to Europe, India, Latin America, and South Africa —entails helping large companies innovate with the agility of small start-ups.
Belkis is an experienced agile coach and practitioner with deep knowledge in building truly agile organizations across an assortment of sectors. She is an active leader in the external agile community, as well as a board member and leader of the Agile New York City meet-up, which convenes a group of 100 agile leaders in the city every month. Using the agile methodology as a starting point, she expands its impact dramatically, guiding at-scale transformations, pursuing digital strategy development, and leading end-to-end digitization initiatives. In this, she is passionate about guiding teams out of their comfort zones so they can make a transformative leap.
During her 16 years with McKinsey, Belkis has coached executives while leading major change programs. For global banks, she has worked to minimize technological risk and increase productivity through improved engineering practices—her efforts accelerated product launch time by 60 percent for a leading bank in Brazil. She has also designed centers of excellence focused on agile product management; one program for a healthcare company improved efficiency by aligning the organization around product lines.
Belkis speaks internationally at workshops and on panels, sharing insights on such concepts as talent recruitment for agile professionals, digital industry trends, and the guidance of high-performance teams.
Before joining McKinsey, Belkis led the upgrade of mission-critical enterprise systems at the New York Stock Exchange and held leadership roles with the New York City Law Department and Brooks Brothers.Our recommendation is for any large organisation in this situation, or for organisations scaling their approach beyond the team to the portfolio/program or enterprise, that the ‘right’ balance of both agile mindset and agile frameworks is best to enable success. Large organisations typically need to consider how do they evolve and do this while not putting their existing ways of working, such as legal, compliance and shareholder commitments at risk.
In this blog post, we will cover off how you can leverage both the agile mindset and principles to enable the ‘heart’ of agile, which supports the underlying culture change required to drive different behaviours, as well as, leveraging the agile frameworks to enable and support that change with ‘hard’ structure to provide a ‘freedom within a frame.’
The quest and driver to achieve enterprise agility may commence in many ways across different organisations and teams. For example, the driver may be to improve delivery speed and efficiency to deliver faster to catch up or out-pace competitors. Or the driver may be to better understand customers to meet their needs and to ensure a customer-centric focus. Or it may be a combination of both. Either way, an agile evolution and journey has begun and questions on ‘where do we start?,’ ‘what choices do we need to make – now and later?,’ and ‘how do we actually do this’ begin. The agile manifesto provides a set of values and core principles, which many of us would not disagree with and would accept as common sense. But how do you convert those values and principles into action?
At regular intervals, the team reflects on how to become more effective, then tunes and adjusts its behaviour accordingly.
There are techniques and practises provided within Agile frameworks that can be leveraged. Examples include retrospectives and prioritisation methods, which are a good starting point to enable adopting these principles. The key is to understand what others have done before to not only save time (maximise the amount of work not done) and so we can improve, do better, and apply to our context (tune and adjust).
As an organisation undertakes the journey to agility, it makes sense to take advantage of what has already been learnt by other organisations and broader industry expertise. Agile frameworks are evolving and being tuned based on the practical execution experience from a wide base of organisations.
Further examples of challenges faced by organisations which can be solved by taking guidance and leveraging some of the many agile frameworks are:Much has been written over the years about parallels between the military and large corporations. But what insights are most relevant for senior executives today in an age of agile organizations? With his long experience in the Army and then in business, Justin Maciejewski is unusually well placed to reflect on the lessons for business, as a former commander of the British Army’s 800-strong 2nd Battalion, The Rifles, during its vital peacekeeping mission in Basra, Iraq, from 2007 to 2008.
Sidebar Justin Maciejewski biography Justin Maciejewski has been the director of the National Army Museum, in London, since 2018. He spent 27 years with the British Army, including serving as commander of the 2nd Battalion, The Rifles, during its vital peacekeeping mission in Basra, Iraq. He subsequently brought his leadership experience to the commercial sector as a management consultant with McKinsey.
Maciejewski’s career in the army spanned more than a quarter of a century, taking in the years after the Falklands War, in 1982, to recent operations alongside coalition forces in Afghanistan, the Balkans, and the Middle East. It was a time that coincided with the development of a new type of leadership based on empowerment, designed to make the British Army more tactically agile and able to overcome larger adversaries through maneuvers, rapid planning, and decision making that disrupt and break down the enemy’s cohesion. This has transformed the British Army’s approach, which for generations had been based on centrally controlled, set piece battles focused on overwhelming firepower and attrition. Awarded the Distinguished Service Order for his role in Iraq, Maciejewski joined McKinsey in 2013 and was appointed director general of the National Army Museum in London in 2018.
In this conversation with McKinsey’s Rob Theunissen, Maciejewski talks about the modern army’s agile model, the balance between command and control, the importance of (good) process, and the notion of learning without blaming.
Justin Maciejewski: In the Second World War, the British Army achieved success by focusing a huge amount of resources on a smaller enemy force, then wearing them down through attrition. Battles were often very static, relying on numerical superiority. The battles were designed top down; everyone knew their place. Montgomery, the great British commander of the Second World War, called this “a tidy battlefield,” and he referred to it as the orchestra of war: one conductor conducting, with all the different instruments doing exactly what they are told to do.
As the British Army got smaller in the 1960s and ’70s, it found itself at a numerical disadvantage relative to the forces it was facing in the Cold War. Nevertheless, this culture of top-down direction continued. And in the Falklands, the British Army found that soldiers were waiting to be told exactly what to do in circumstances where casualties might have been avoided had they been more proactive. At the end of that war, people asked themselves, “Why did intelligent people sit there, waiting to be told what to do? Why didn’t they just get on and do it?”
In the late 1980s, the British Army radically redesigned the way decisions were made and how officers were empowered. A new system was introduced: Mission Command, which would now be called agile, was all about giving people the tools to make rapid decisions in order to disrupt the enemy.
In reflecting on our performance in the Falklands War, in the late 1980s, the British Army radically redesigned the way decisions were made and how officers were empowered. A new system was introduced: Mission Command, which would now be called agile, was all about giving people the tools to make rapid decisions in order to disrupt the enemy. The idea was that you could defeat a larger enemy by getting inside their decision cycle, moving so quickly that their cohesion is disrupted and they begin to fall apart.
Justin Maciejewski: In Montgomery’s army, the functions—artillery, engineers, logistics, medical, intelligence, signals, et cetera—were very powerful. In the 1980s, led by General Nigel Bagnall, the notion of integrating the functions at every level took hold. Every group was tailored for the operation that it was required to do, and functions were integrated in the volumes that were needed for that operation.
That sounds easy, but it’s difficult to do. And in order for that to happen, the army had to be much more standardized about the way it planned, the way it gave direction, and the way it cascaded intent. If you’re going to be very modular and agile about the way you allocate resources, people need to be speaking the same language.
Mission planning lies at the heart of military operations, and the army came up with seven questions, which everyone now uses across the entire organization. Once you standardize like that, you create organizations in which people feel confident to make decisions and where trust grows because people know what other people are going to do even before they come up with an idea.
The Quarterly: Standardization can feel rigid and bureaucratic—it almost sounds paradoxical alongside agility. Was that not limiting?
Justin Maciejewski: The trick is to work out what process is good and fundamental to the stable functioning of an organization—and to its consistency—and what process is bureaucratic and superfluous. Don’t throw out the good stuff when you get rid of the bad stuff; organizations that have been fossilized by bad processes sometimes try to get rid of it all.
What the army managed to do in the 1990s was to get rid of a lot of bad processes but design these very solid core processes, which everyone was able to rally around. I never saw them as constraining; I rather saw them like a trellis where a plant grows up an open frame. The effort to root out bad processes was considerable and involved significantly reducing the number of operating procedures to encompass only those activities that genuinely needed to be standardized.
For me, a good process is a process that helps someone see how to think, how to find a solution, but it doesn’t tell them what to do. It doesn’t tell them the exact answer. In other words, it’s not a tick box. It’s a framework that lets people bring themselves to the problem in a way that they know they’re not going to miss anything. It’s a support—but a support that gives them the chance to be creative.
The Quarterly: Could you describe in more detail how structure, process, and creativity work together?
Justin Maciejewski: In the old world, leaders wrote down what they wanted people to do in quite a precise way. People were given tasks that fit within an overall operation or mission. A mission today is not a set of tasks, because, in a dynamic situation, people should revert to the purpose rather than the task. Situations change; the enemy’s done something. That’s my purpose—that’s what I’m going to go after—rather than in the old system, where people would literally do their task and wait to be told what to do next.
For example, in the old world, you could say to someone, “Take and hold the bridge by midnight tonight.” In the new world, you would say, “Our intention is to cross that river. To do that, I see you securing that bridge by midnight tonight. And the reason we want you to do that is because we want to put 20,000 soldiers on the far side of that river by the close of day tomorrow.”
If you imagine that philosophy being replicated across an organization of 80,000 people at every level, it dramatically changes the performance. Everyone at every level is thinking, “What if it changes? How do I respond?”
In a business environment, people often express annual targets as percentages of growth or the amount of cost they have to take out without any real articulation of how that feeds into the overall success of the business. [What they should be saying is,] “We need you to take out this much cost because we want to put that into the R&D program for the next model that’s going to win us a new market.” It’s very disempowering to have targets without any real context of how that target fits into the bigger picture.
Justin Maciejewski: I grew up during this transformation, but I think it was a lot tougher for some of the people who’d grown up in the old army. One thing you have to be prepared to do as a leader is to give people space to fail, to let people spread their wings as leaders, and to trust them. Occasionally, they’ll get it wrong. And, when they get it wrong, you mustn’t crucify them. Because if you do, they won’t do it again, and then you have to micromanage them because there’s no other option. Watching people grow as leaders, by tripping over the first time and then getting up and dusting themselves down, is most fulfilling. As new leaders gain more experience, you can supervise less.
Leaders also need to understand that there is a tension between command and control. A commander may want to do something, but it may be impossible, and that’s where command has to be constrained by control. And there are other times when the commander knows something can be done and has to be done, and sometimes the machine needs to work a little bit harder to make it happen, and that’s where command pushes control. They are both critical to success, and that distinction between command and control is something I really came to value.
Justin Maciejewski: Once the army moved to Mission Command, much more of leaders’ time was spent up front in the creative process: “What am I trying to achieve? How do I visualize this happening? What is my mission? What am I being asked to do?” It’s about making sure everyone is clear around what’s expected of them. This gives commanders much more time away from their laptops and more time with the people they are commanding. I like to think we were all frontline people.
When we first got to Basra, we had an operations room—a control tower—that had all the screens with satellites and aircraft photography coming down and data flowing in from people on the ground on their radios. It was a huge hub of information. What I actually found was, I may have had all the data, but what I didn’t have was the fingertip feel of what was actually happening on the ground.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com Justin Maciejewski (right) sitting with a fellow soldier in the back of Maciejewski’s command vehicle in Basra, Iraq, in 2007.
Over time, I came to realize that the data was not the most important thing for me to see on any given day. I would get a much better feel for the operation by seeing the “customers”—the people on the streets—and the soldiers themselves who were doing the job. I would spend two-thirds, maybe three-quarters, of my time with soldiers at the front line, either talking to them or listening to them after an operation. I spent a quarter of my time planning.
That’s where the chief of staff in the army really kicks in. In business, the chief of staff is someone who organizes the CEO’s diary. The chief of staff in the army is an incredibly powerful figure and is literally the chief of the machine. My chief of staff bought me the time to be with the soldiers, talk to my Iraqi colleagues, or meet local leaders in Basra. The chief of staff also was able to triage the data and feed to me what I needed: “Be aware that this is happening.” A key thing [in the army] is that the system selects the chief of staff to work with the commander. When I look back now, I really appreciate how much effort went in to selecting the right chiefs of staff to work with the right commanders.
How you allocate your time, though, is only part of it. The army also invests a lot of time in training leaders to manage the mental and emotional states of the troops.
Justin Maciejewski: When a leader shows up in the army, the soldiers immediately worry that they’re under scrutiny, that they’re being evaluated. That imposes an additional burden. So when I started in Basra, my assumption was to let the guys lead. They’ve got the enemy to worry about, and they’ve got the local population to worry about, but if you show up, they’ve got their leader to worry about as well. When a leader shows up in the right way, it’s a source of encouragement; it shows you also have skin in the game on any particular day. When the bullets are flying around, it makes the point that we’re all in this together.
One day, we had a mortar attack, and a lot of guys were badly injured on the other side of the city. The day before, someone had been killed by an improvised explosive device, and someone had lost one of their legs. So we got into our vehicles, and we drove across the city to spend the afternoon with this company and see how they—a company of about a hundred people—were getting on. I just went up there, had a cup of tea, put my arm around a few people.
One thing you have to be prepared to do as a leader is to give people space to fail, to let people spread their wings as leaders, and to trust them. Occasionally, they’ll get it wrong. And, when they get it wrong, you mustn’t crucify them. Because if you do, they won’t do it again, and then you have to micromanage them because there’s no other option.
The fact that we made the effort to get up there after this attack, in the same sort of vehicles that they’d been attacked in, meant a huge amount to the guys. I came to realize that showing vulnerability and presence as a leader becomes a very important way of galvanizing everyone around a particular mission. I wouldn’t go on a mission with a leader because I was worried about that leader, but because I wanted to show that leader that I was right next to him. And that mind-set change was the most profound for me personally as a leader: seeing yourself not as an evaluator but as a supporter of the people who work for you.
Justin Maciejewski: For a meeting somewhere with, say, a tribal leader or local power broker, I would turn up with my entire panoply of drivers, communicators, and bodyguards—we call it the “commander’s tac,” maybe as many as 15 people—and there might be a jet in the air over the area. That’s saying you’re the biggest tribal chief in the area.
The vulnerable bit is when you go to a group of soldiers who are being led by somebody and say, “I would like to come out with you tomorrow.” And you don’t try and command it; you just try and be with them, to walk in their shoes. The night shift, for me, was the place where you got the best conversations, turning up in a guard tower at two in the morning and saying to a young soldier, “How are you feeling?” And they’d be honest. They’d say, “I’m scared.” One could then talk about things that we were all concerned about and how we were going to tackle them.
I’m always struck by Henry V in Shakespeare, when he goes out and walks around. That is a very profound insight of good leadership. It’s in the night, when it’s quiet or when people have got their thoughts, that you can gently get alongside them.
I think the king is but a man, as I am [. . .]. When he sees reason of fears, as we do, his fears, out of doubt, be of the same relish as ours are: yet, in reason, no man should possess him with any appearance of fear, lest he, by showing it, should dishearten his army.
Justin Maciejewski: My team was built by my predecessors: years of investment in developing the right talent and pushing it forward. So my regimental sergeant major had spent 20 years in the army, but he’d been recognized 15 or 16 years previously and had been pushed through the system to be ready when I needed him. I didn’t find him through advertising a job.
When I looked at this group of 800 people, I could see the sort of institutional investment in talent over at least 20 years—but, in reality, over generations. And it made me realize just how good the army is at getting and developing the right people. I had to remove a few people when I was there, but not many—a handful in an organization of 800—while everyone else stepped up and did what was required of them.
Talent selection is crucial, and being rigorous about it is important. I haven’t come across many organizations [in business] where talent selection is really rigorous. Often, it’s based on a good year’s performance, then you leap forward into the next job rather than really understanding what potential looks like versus performance. It could be that someone’s doing something they’re not actually ideally suited for, but, by God, they’ll be good for the next level. I think business is too quick to bring in talent rather than develop it internally. Endlessly looking outside creates a very transactional approach to people.
Justin Maciejewski: People have got to complement each other. So if you have an extrovert leader who may not be very good on detail, you need to make sure they’ve got a second in command who’s bloody good at it. You mustn’t let people pick their own teams, because what you then create is an inner circle. I’ve seen this in other armies, where commanders were allowed to move with their inner circle. And when you have an inner circle around the boss, you just create a sense of disempowerment for everyone who’s not in the magic circle of power. That creates a very fractious—and, ultimately, toxic—organization. In business, I often saw an outer circle of people who were feeling very scared and vulnerable, and I don’t think that’s the way to drive successful teams.
The Quarterly: Let’s talk about the performance dialogue, where the backbone of a culture and an organization’s true beliefs always pop out.
Justin Maciejewski: [In the army,] there’s a very mature initial conversation between the person giving the mission and the person receiving the mission around how they’re going to achieve that mission. Then there’d be a dialogue around the concerns. There’s literally a piece of paper with four headings on it, and one of the headings is “concerns,” so you can’t say, “I’ve got no concerns.” That would feel a bit weird. So it takes the fear out of alignment with your boss.
You mustn’t let people pick their own teams, because what you then create is an inner circle. And when you have an inner circle around the boss, you just create a sense of disempowerment for everyone who’s not in the magic circle of power.
At the end of the operation, there’s what we call an “after-action review,” where you review performance of that operation. And the key thing about this is that it’s facilitated by an outsider, not by the person commanding the mission but by someone who’s not directly involved in the operation—for example, someone from the intelligence staff. Generally speaking, the commander comes to that process at the end and says, “That’s really interesting. These are my thoughts, reflections. And what have we learned from this?” And then someone captures what we need to learn from it, and then that gets fed into a review of how we do an operation in the future.
When a mistake is made, you do not hang someone out to dry. Sometimes mistakes are made in battle and people get killed. If you crucify people when a mistake is made in battle, they will freeze with fear the next time they’re facing the enemy, and the consequences of that are far worse. The notion of learning without blaming is at the heart of removing fear from that process.
One thing people realize in this sort of environment is that no one is without fault. No one is invulnerable to making mistakes, because the pressures are huge. People are slow to judge because they know that tomorrow it could be them. When a mistake is made, you know it could be you. I’ve been really shocked by how much fear is used as a motivator in business—in a way that I never saw it used as a motivator in the army. People are very much in a state of fear, not because they’re being shot at, but because there’s an internal fear working in terms of how people are being evaluated and watched all the time.
Justin Maciejewski: I’ve always been struck since I left the army that the army doesn’t have just values; it has values and standards. And the reason is because it wants to help people understand what those values look like in action. So courage is a value; having the moral courage to call out something when it’s wrong is the standard.
I saw this with a young soldier who came to me and said, “Sir, my commander behaved badly in a house last night in Basra. He smashed up some furniture in a search, and it was wrong, sir.” That young soldier had the moral courage to do that.
We would spend 15 or 20 minutes, perhaps half an hour, a week talking about the army’s values—courage, loyalty, discipline—and what they actually meant. Values can be a hugely powerful thing when they’re shared across an organization, but you’ve got to invest in them. You can’t just put them on a notice board or up in an office and have that be the end of the job. In business, I think, we’re still in the foothills of how we use values in the most effective way to create healthy organizations and drive performance.
I would never call my soldiers a ‘human resource.’ They were the soldiers, the battalion, the riflemen. The term ‘human resources’ dehumanizes people.
The Quarterly: What have you observed about the way organizations in the corporate sector look at people?
Justin Maciejewski: One thing is that I would never call my soldiers a “human resource.” They were the soldiers, the battalion, the riflemen. The term “human resources” dehumanizes people.
The army is very mindful of its people because it can’t hire them in at any level. You can’t hire in someone to be a great general on the battlefield on day one. It has to nurture, invest in, and grow talent. Specialists can come in, but the core manpower has to be grown from within; the army does not use headhunters.
A lot of industry and business relies on the fact that it can just hire and fire people, so it becomes a hire-and-fire machine rather than a coaching-and-building machine. And I think that you can hire and fire your way to a certain level of performance, but by doing that, you will never build genuine teamwork and cohesion. The new approach to becoming agile in business is based on building small, tight-knit squads. That requires trust, and trust takes time. You’ve got to bind people to the idea and the purpose and, if you like, the essence of the company you’re building or the business you’re running. You’re never going to get people to go the extra mile if, fundamentally, it’s a transactional relationship.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.Since their origin in software development, Agile processes have been successfully employed in countless initiatives and within a wide variety of business settings.
Building on the original Agile approach, Deloitte’s Agile Internal Audit (Agile IA) methodology challenges both the mindset of internal auditors and their established business processes. It allows the internal audit function to focus on stakeholder needs, accelerate audit cycles, drive timely insights, reduce wasted effort, and generate less documentation.
Of course, Agile methods have only recently been implemented by internal audit departments, prompting questions about whether it is possible to adopt Agile in Internal Audit while remaining true to the IIA Standards. Additional questions about which methodologies to adopt, as well as how to customize and implement them and how Agile projects themselves should be addressed, also invariably arise.
Our Agile IA library gives you the opportunity to explore the basics of Agile IA; their compatibility with IIA Standards; and how to best adopt them to drive efficiency, efficacy, and innovation in your organization and beyond.Demand management is focused on receiving, evaluating, and deciding upon work requests. This is accomplished with prescribed points of entry for new requests, and qualifiers to prioritize them. Agile introduces two key concepts that enhance demand management, and support portfolio and results management (defined later). These new concepts are value-streams and epics. Value-streams are the ecosystem of teams that deliver against epics. Epics are large cross-cutting initiatives that deliver solutions to the end user. As more teams adopt agile across the organization, the need to define value-streams and epics is critical, to ensure coordinated planning and delivery. Incorporating these practices into demand management is essential for agile teams to plan effectively.
Portfolio management is responsible for continually assessing the performance of active programs and projects, against defined criteria. The focus is on governing the portfolio to optimize resources, such that they are fulfilling the highest priorities of the organization. One way this is achieved is funding projects, which have a specific investment amount, a defined scope, and a target delivery date. At the macro level, traditional and agile organizations will conduct portfolio management in the same manner. Even as an organization starts its journey to agile adoption, there is really no difference in how the portfolio is governed. However, organizations that achieve agile at scale may fund value-streams, allow de-centralized financial decision making within the portfolio, and continuously prioritize their backlog of activities within each agile project to adjust to changing business priorities. The implication is that the linkage between portfolio-level decisions and team-level delivery can be broken, if the change in methodology is not anticipated. As a result, PPM incorporates governing and funding of value-streams, in order to make effective portfolio-level trade-offs.
Project/program management implements controls to manage scope, financials, progress, and quality of delivery. Project status of red-yellow-green is the primary method of conveying whether a waterfall-delivered project is in control or not. Since project scope, budget, and timeline are defined at inception, the status is driven from actuals against that baseline. In contrast, the health of agile projects is seen through an analogous set of metrics at the portfolio level. Shown below are the waterfall metrics in contrast with their agile counterparts. The implication for PPM is to ensure clarity on status definitions, and what constitutes red-yellow-green in an agile context. Organizations that are adopting agile should anticipate this change, and incorporate this new set of metrics in their PPM playbook and reporting.Traditional IT was designed for stability and incremental growth based on long release cycles. But faced with unprecedented uncertainty, businesses now more than ever need their technology leaders to be resilient, agile, and future-focused.
Technology organizations are constantly trying to stay on top of new technologies, new market entrants, increased business integration, and ever-changing customer expectations that come along with a global competitive environment. There is no better example of that than the recent COVID-19 outbreak and the global rush at technology and non-technology organizations alike to adjust and adapt to an entirely new market and new way of working. This time of evolving market, economic, and social conditions is the time for transformational, not incremental, change.
Technology leaders are positioned to drive this change, as a recent report by Deloitte and WSJ Intelligence found that 50% of CEOs said their CIO or tech leader will be the driver of business strategy—more than those who named the CFO, COO, or CMO as their top partner combined.1 By reimagining their role and relationship with the business, by reorganizing to partner directly with the business and with customers, and by adopting agile and DevSecOps processes, technology organizations can lead the way in adapting to the pressures around them and creating a resilient organization ready to react with speed and flexibility to evolving global pressures and customer demands.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.This is the second post in a series, sharing a number of observed anti-patterns and corresponding patterns on the topic of business agility (aka digital transformation).We are in the midst of a Turning Point in a 50 year cycle, in the Age of Digital, as well articulated by Carlota Perez in ‘Technological Revolutions and Financial Capital’. At the time of writing, seven of the top ten firms by market capitalisation are technology companies. Less than two months ago, on 26th June 2018, General Electric, the last remaining original constituent of the Dow Jones index which was created in 1896, left the index, as it was contributing less than half a percent. In 2004, GE was the largest firm in the world by market value and only two years ago, in 2016, GE was still in the top ten. This is an indication of how we are in the Turning Point, how the previous industrial incumbents are shrinking and how firms with new business models and new ways of working, leveraging significant shifts in technology have become the new dominant forms of human organisation.
In sharing the anti-patterns and patterns, it is worth noting that everything is context dependent. An anti-pattern for one scenario might be a pattern in another context, in particular based on the current cultural norms of an organisation. That said, I believe that the anti-patterns to be presented are applicable in the context of the majority of large, old, bureaucratic, global enterprises (horses rather than unicorns).
They are based on lessons learnt through doing including learning from failing. Along with many talented people, we’ve been servant leaders on better ways of working (the application of agile, lean , DevOps, design thinking, systems thinking and so on) across a large (80,000 people), old (300+ years old), global, not-born-agile, highly regulated enterprise, with personal experience of delivering change with an agile mindset, principles and practices since the early 1990’s, about a decade prior to the Agile Manifesto, when the term ‘lightweight processes’ was used. The anti-patterns and patterns are also based on learnings from the community, from other horses (rather than unicorns) on similar journeys.
The Kubler-Ross Curve originated from psychiatrist Elisabeth Kubler-Ross’s work on grief, published in 1969. It has been found to be valid in the majority of situations relating to change and we have repeatedly observed this pattern to hold true via feedback from colleague surveys.
The bigger the capital ‘T’ Transformation, the bigger the change curve. If embarking on one large, broad, Transformation, expect an almighty big and deep dip in the curve. The bigger the dip, the harder it is to climb out of and the longer it takes. Given that some firms are facing an existential threat, there may not be sufficient time to climb out of that big dip.
In large, diverse, regulated, multinational organisations, where the cultural norm is most likely to be control or competence based, a capital ‘T’ Transformation with a big dip in the curve, will make the journey a harder and more challenging one. There will be a greater degree of denial, frustration and anger. The change stands a higher chance of cultural tissue rejection, with more ammunition for those averse to change. Things will get significantly worse before they get better.
For organisations that take this approach, with a broad scope, where people leave as a Project Manager on a Friday and rejoin as a Scrum Master on Monday, and in some cases need to reapply for their new role, the chances of genuine, embedded, internalised, long lasting, successful change which leads to improved business outcomes, over cargo cult behaviours and new labels on existing ways of working, are greatly lowered. As per this post, this drives fear, which drives a lack of action and resistance.
When starting out on transforming ways of working, increasing business agility, embarking on a ‘digital transformation’, it is hardest at the beginning. The antibodies to change are strong, there are vested interests at stake, the impediments to better ways of working and flow will be at the their highest, there will be the most amount of dependencies impeding flow, understanding is low, the force is strong with cognitive biases with no anecdotal stories or hard data from the organisation to challenge them and this is Yet Another Transformation (time to put your head in the sand and let it blow over). An analogy is skiing. It’s cold, painful, slow and hurts when learning to ski. It’s hardest at the beginning, uses up the most energy, when snow ploughing. Break past that, and once able to parallel turn, enjoyment goes up, speed goes up, energy usage for the same distance and time goes down, it becomes fun and addictive. Does it make sense to have a large number of people all snow-ploughing at the same time, on poor quality snow, in an environment not yet set up for skiing, bumping into each other, without enough ski instructors to go around?
Furthermore, large, old, bureaucratic, traditional organisations have a limited capacity and a tolerance with which they can change over time. Organisations have a limited re-learning velocity. Re-learning requires organisational unlearning, which is harder than learning from a clean sheet. Behavioural science studies show that cognitive overload is a major theme in rejection of change. Cognitive reasoning is finite and easily depleted. According to research by Dr Wendy Wood, approximately 40% of decisions that people make everyday are not decisions, but are habits and the majority of these habits in going from a traditional to a new way of working, need to be unlearnt.
“The thoughtful intentional mind is easily derailed and people tend to fall back on habitual behaviors. Forty percent of the time we’re not thinking about what we’re doing. Habits allow us to focus on other things…Willpower is a limited resource, and when it runs out you fall back on habits.” (source)
Where the change has not been internalised and embedded, where it is forced across an organisation in a broad manner, it is like one large elastic band, as soon as a leader mandating capital ‘T’ Transformation moves on, the organisation (people’s habits and codified processes) snap back into previous ways of working. It takes 3 to 5 years, best case, for a large traditional organisation to develop a new muscle memory. And then there is no end date to continuous improvement. For more on this topic, see Barry O'Reilly’s book Unlearn (Nov 2018).
This approach is also not living its own values or applying its own principles. It is not applying an agile mindset to increasing business agility. It is big batch, big bang and big risk. It is approaching change in a manner counter to the change being asked of colleagues.
I propose a corollary to this which is that “processes, control points and standards expand based on the number of audit and control staff employed”. This is in an uncontested space (i.e. in the absence of a group of people focussed on optimal ways of working)
Parkinson goes on to say that “the number employed in a bureaucracy rise by 5–7% per year irrespective of any variation in the amount of work (if any) to be done”.
He cites two factors: (1) “An official wants to multiple subordinates, not rivals” and (2) “Officials make work for each other” and he gives the British Colonial Office as an example. In the nearly twenty years from 1935 to 1954, looking only at peacetime years, the average rate of growth of employees at the Colonial Office was 5.89% each year (within a narrow range of 5.24% to 6.55% p.a.), whilst the British Empire shrunk by 76% from 17 to 4 million square miles in the same time period. The size of the Colonial Office was inversely proportional to the size of the the Empire.
“It would be rational, prior to the discovery of Parkinson’s Law, to suppose that these changes in the scope of Empire would be reflected in the size of its central administration. But a glance at the figures shows that the staff totals represent automatic stages in an inevitable increase. And this increase, has nothing to do with the size — or even the existence — of the Empire.” (Cyril Parkinson, 1955)
As large, old, enterprises, with years of organisational scar tissue and 100 year old ways of working are going to be at the highest level of inefficiency and bureaucracy that their revenues can (or perhaps in the Age of Digital, cannot) support, this is one reason why it is sub-optimal to take that organisation and apply a scaled agile framework across the whole organisation in one go.
It is important to descale the organisation, to descale the work, before scaling agility (not scaling capital ‘A’ Agile, which is doing not being).
Instead of a big bang transformation, with one big dip in the curve, achieve a big outcome through early, often and small slices of value.
Pursue evolutionary and continuous transformation aligned to outcomes, linking together a series of smaller change curves. Start in areas which are naturally receptive, the natural champions. The dips are not as deep, the learning and feedback is quicker, there is less risk and the champions, who have been trying to do this despite the firm in the past, are best placed to beat a path through the organisational jungle, likely with a growth mindset and personal resilience.
This approach is in line with the Kanban Method principle “Agree to pursue incremental, evolutionary change”. As time goes by, I have found myself to value David J Anderson’s Kanban Method principles and practices more and more, in the context of business agility, at all levels from strategy to the team.
Hence, don’t take a large team working in a traditional manner, on a traditionally developed product (whether IT or not) and apply revolution all in one go. Apply an agile mindset to the rollout of agile. Achieve big outcomes through (1) small teams, (2) small investments and (3) small slices of value, supported with capability building, training and coaching as well as help to remove organisational impediments. Identify where there is ‘elephant carpaccio’ which can be delivered, when starting out with a traditional waterfall team, likely as per Conway’s Law, with a monolithic system. Eventually there should be no elephant in the room. Leaders should ensure that there is a psychologically safe environment for experimentation and learning.
By way of an example, I’m aware of a scenario where there was a team of about 100 people who had multiple multi-year failed attempts to deliver business value in a waterfall manner. Following this, with the appointment of a leader who had a track record of successful delivery, a team of five was created, working with agile principles and practices. Within 12 weeks, there was a product in the hands of customers, in a production environment, solving a customer need and providing much needed learning and feedback. From this point on, the team size didn’t grow to be above three teams of nine or fewer people each, despite expanding significantly in scope in terms of the business lines supported, due to the success in the first business line.
Taking the original 100 people and applying a frog march of mandated certification, re-applying for your job with a different title and a cookie-cutter approach would not have addressed the inherent bloat at the time (it’s not a 100 person problem, in fact 100 people is a large part of the problem), would not have internalised the change so that it comes from within thus building a learning organisation, is not optimised to context, is costly and does not maximise business outcomes and customer delight.
For large organisations, and the approach that we have taken, where there are multiple business units (each one large enough to be standalone company in it’s own right, and in fact used to be, with their own culture and folklore), the ‘achieve big through small’ approach can be taken concurrently (whilst limiting Work In Progress) in a fractal manner. Each business unit pursues a limited series of small change experiments starting in fertile soil, with a small central Centre of Enablement (CoE) providing servant-leadership support and dealing with bubbled up organisational impediments. An agile mindset is applied in terms of empowerment and not being prescriptive on the How (within guardrails and a common vocabulary). This in turn can be done at the sub-BU level, and so on. The leads from each business unit come together weekly as a virtual team. Applying an agile mindset, all of the virtual teams of BU or sub-BU leads are agile team sized (single digits). It’s quick to spot common organisational constraints and allows for swarming on alleviating the constraints.
A mistake that we’ve made in the past has been to start at the team level and go sideways (more teams), along with the top level support. However, even with specific targeted training, this can fail to engage one or more levels of middle management, also known as the Frozen Middle or more kindly, the Pressurised Middle, as there is not always a clear role to play in the change. This is a common characteristic in any culture change in large organisations and is not a reflection of the people, it is a reflection of the situation they are in and how people in these roles are engaged.
A personal learning, when starting small, from a people perspective, is to have a vertical slice of an organisation go first. The leadership team is team #1. With the existing structure, have a vertical slice of that org volunteer to go first, including leaders at all levels, preferably natural champions, with as few dependencies on other teams as possible. Ideally this will be value stream / product / service aligned, not a role-specialisation alignment, such as just the BAs or just the Engineers or just the PMs. Middle management at as many levels as there are, have an explicit role, coaching and being coached on continuous improvement in ways of working, as per the Toyota Coaching Kata and with multiple-level portfolio Kanban being adopted to focus on visualising and limiting work in progress.
Then scale agility (not capital ‘A’ Agile) sideways, at a sustainable pace, working towards the organisation becoming a network of interdependent services. Go for more slices of the organisation, which are value stream / product / service aligned, supported by a small BU Centre of Enablement, providing coaching, training, shared learning, clearing the path for the teams. Pursue incremental, evolutionary, outcome-oriented, continuous transformation.
This doesn’t mean that scaled agile frameworks are not used. It is up to each team and area to decide what works best for them. Each framework is a valuable body of knowledge and can be a good departure point. In some cases they can provide a common vocabulary and in all cases it’s about trying what works in your unique context, with a focus on better business outcomes (as per my previous post). We aim to avoid framework fundamentalism, preferring to be Omnists. For more on this topic, see Dan North’s excellent article on SWARMing.
Again, at the beginning it’s the hardest, as the rest of the organisation is not set up for Continuous Everything. Several years in and good progress has been made by supporting functions (GRC type functions, InfoSec, Compliance, Audit and so on) also working in a way which supports small and often, conversation over a contract, with multidisciplinary long lived small teams, value stream aligned and in a context-relevant not one-size-fits-all manner.
To help amplify the learning, the overcoming of impediments, and adoption of better ways of working, we have an Exemplar Community. There are benefits of membership, such as additional training, external speakers, shared learning and prioritisation on the pull of the virtual andon cord. You don’t need to be exemplary to join, it is voluntary and there is a psychological contract in that teams agree to strive to become exemplary, jumping in with both feet, with a focus on measurable business outcomes (not activity or output). Consistently these teams exhibit far superior outcomes (for example 23x fewer production incidents on average), provide hard data as to benefits for the critics who are swayed by hard data, provide storytelling for emotional buy in and via cellular mitosis are able to spread better ways of working.
UK GDS have taken a similar path. To quote Adam Maddison, ex-Head of Agile Delivery at GDS from Agile Cambridge 2016:
“At GDS we absolutely haven’t ignored scaling frameworks. We’re quite happy to use features from those frameworks if they truly deliver value. But we are absolutely not wedded to any methodology or framework. We will always adapt features to our own use.”
In both the case of GDS and in our context, the ‘big’ in ‘achieve big through small’ is articulated via the Roadmap, which articulates Strategic Objectives and quarterly Business Outcomes on long lived value streams / products / services. These in turn are broken down into small vertical slices of value, like layers of an onion, as outcomes not activities and delivered via Continuous Everything. Achieving big outcomes through many small steps and continuous learning.
Work towards the organisation becoming a network of interdependent long-lived services, with high cohesion, low coupling and customer-centricityOctober 25, 2019 “If you’re not reinventing your business every five years, you risk losing relevance,” says Neal Larkin, a design associate partner in McKinsey. “For businesses to stay competitive today, they’ve got to be thinking that way.”
“With technology moving so fast, there’s no time for inaction. We’re about doing,” explains Ari Libarikian, a McKinsey senior partner and a global leader for Leap. “Many companies spend a lot of time thinking and talking about their digital future. Leap is all about getting them there quickly by building something new based on the parent company’s strengths.”
Leap teams feature a mix of business-building experts, including specialists in analytics, design, and tech. Most of these colleagues have launched their own successful businesses before joining our firm and understand the capabilities a business needs to survive and thrive.
“From day one, we build for our work to endure,” explains Ari. “The goal is to build and train a new muscle for our clients, who will then sustain and further strengthen it long after we are gone.”
To date, Leap teams have led over 200 business builds, many in less than 12 months. Ralf Dreischmeier, a McKinsey senior partner and a global leader for Leap, explains that Leap’s way of working plays a major role in this success. “We co-locate with our clients and use an agile model to move quickly, while bringing the benefits of a start-up to a corporate environment.”
“Think video on demand for sports but cooler,” says Clayton O’Toole, a McKinsey partner in our Strategy & Corporate Finance Practice. That’s how he describes the over the top service he and his team built with a multinational media conglomerate that launched earlier this year in Asia.
According to Clayton, only about 25 percent of consumers in a national market were paying for sports content, while over 50 percent considered themselves passionate sports fans. So, Leap worked with our client to seize that opportunity, building an entirely separate streaming business that leverages all of the parent company’s sports rights.
The Leap team worked closely with the media company across content selection, pricing and packaging, tech-vendor selection, legal requirements, and talent sourcing. Extensive customer research through deep structured interviews meant the new product’s prototypes and wireframes reflected what customers really wanted.
“The way you engage with sports should be very different from how you watch movies and TV,” explains Eleni Watts, a McKinsey associate who spent 15 months as chief of staff to the company’s CEO. “With sports, you have the ability to deliver unique and interactive features with a greater degree of personalization.”
Testing and iterating with customers helped the team fine tune service features like in-game catch-up highlights and a ‘no spoilers’ mode.
It’s all added up to a winning game plan. The streaming service is on an exciting growth trajectory so far, having already reached 15 percent of the client’s subscriber base in just six months since launch.
For a 175-year-old financial institution, becoming the first agile and design-led bank in a regional market meant Leap had the chance to create entirely new customer experiences. Call center frustration gave way to online banking satisfaction, 10-day lending approvals were cut to three minutes, and opening an account became a 30-minute appointment instead of a three-to-five-day ordeal.
“We were working in an area where design thinking and agile practices had yet to be used in any industry,” says Neal. “So embedding this way of working was an exciting challenge.”
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com Leap partnered with McKinsey’s Digital Academy to build and pilot a capability-learning program that would turn 20 employees into design thinkers.
Over the course of 12 weeks, the Leap team partnered with McKinsey’s Digital Academy to build and pilot a capability-learning program that would turn employees into design thinkers to serve customers in new ways through new digital channels.
By 24 weeks, the team had shadowed and coached over 200 employees and established 13 agile teams. They also worked closely with HR to create and source talent for new roles like user experience designers, engineers, and data scientists.
“We were focused on making design part of the culture,” says Neal. “This means putting the customer at the center of the problem you’re trying to solve, understanding how to do customer research and map out user journeys, and having the technology in place to build minimum viable products.”
The digital transformation helped the bank surpass $10 billion in profit. Having now captured a 40 percent market share, the bank is poised to solidify a number one position in the market.
For years, the lending market was one of the main sources of revenue for a European bank, but recently that space has become increasingly competitive. So, the bank turned to Leap for help.
We built them what McKinsey senior partner Mieke Van Oostende calls a “speed boat,” a digital-lending business for small and medium-sized enterprises. “We had a ton of freedom to move really quickly and test and play in this project,” says Mieke.
Ideation sessions helped shape the product, a clickable prototype brought it to life, and customer tests guided development. “We defined a cadence of work built on agile,” adds Fernando Figueiredo, a McKinsey associate partner. “This allowed us to move fast and keep improving the product.”
We weren’t working as traditional consultants. Our roles were more like entrepreneurs bringing varied skillsets together. Mohcine Ouass McKinsey associate partner
The team worked as one unit in one location over two-week sprints. Daily check-ins ensured close collaboration between disciplines, particularly tech and design. “We weren’t working as traditional consultants,” says Mohcine Ouass, an associate partner. “Our roles were more like entrepreneurs bringing varied skillsets together.”
After six months, the digital lending business was live; it had customers and 40 full-time employees. With its 15-minute loan decisions and cash delivery in less than a day, the digital lender has earned the highest net-promoter score in the market after just a year and a half.Take a look at those new, ultra-successful companies that have, seemingly, come out of nowhere. They may have started on a shoestring budget, with a skeleton staff, but they have the potential to scale rapidly, and almost infinitely, and to grow exponentially. They do things that older, more traditional companies sometimes can’t. Things that traditional companies wish they could do. They tend to respond to market demands more quickly. Their customer base is growing, while those of traditional companies may be on the decline. In many cases, influencers hawk products from these new companies.
Why? Because they are what many old-guard companies are not: they’re agile. Both traditional and new companies can anticipate changes in markets, but the difference is the newer, more agile companies can change direction quickly and seize opportunities. They often operate with higher margins and shorter lead times at earlier stages in their business lifecycle. Further, they can increase or decrease their tech footprint with growth or contraction and launch platforms and systems in new markets. Finally, they can manage their support systems from a single console anywhere in the world.
So, how do traditional companies deal with competitors they may not even see coming? They become perfectly scalable. And they do it quickly, before their competitors achieve the size and scale to dominate their sector. Here’s what that perfectly scalable enterprise (PSE) looks like. A PSE uses technology to leverage access to excess market capacity, align cost structures with growth, and efficiently use scarce resources to achieve economies of size and scale.
PSEs automate everything they can. They limit the impact of poor decisions and capture growth opportunities. PSEs also focus on avoiding waste and outsource wherever possible. Their financial resources are well-managed, and they target wide-moat competitive advantage plays to drive and sustain success.
PSEs can also launch digital products and services at a global scale with faster time to market. They use data-driven insights to enhance their agility, and minimize upfront capital investments, sunk costs, and technological obsolescence. Simply put: they epitomize enterprise agility.
How do companies become perfectly scalable? First they reimagine their business in a world powered by advanced technology. They redefine competitive barriers, realign partner networks, promote an innovation-based culture, and strive for operational and financial efficiency and flexibility.
For instance, a US-based health insurance startup leveraged the cloud to innovate by scaling its business and guiding customers towards better care by helping them more closely track their health. The company built and deployed its new cloud-based, HIPAA-compliant health insurance platform and analytics solution in less than three months.
They have been able to easily manage enormous usage spikes during open enrollment season, disrupting incumbents, and demonstrating the ability to scale to meet demand—and do it with a lean team to continually deliver value by better meeting business needs and improving the customer experience. The platform also afforded members to realize superior outcomes while reducing the associated cost of health care.
Clearly, the cloud is a key strategic choice that underpins the capabilities of a PSE and can help transform their business, and PSEs know that. PSEs value speed to market as a competitive differentiator, and they know that the cloud is the engine for that. It connects. It improves. It evolves. It integrates—at speed—enabling PSEs to start scaling quickly.
PSEs leverage the cloud to enhance their inorganic growth strategy. With cloud-based technology, they can acquire, integrate, and divest businesses more easily—and they can increase enterprise agility and simplify transformations—all keys to disruption. To that end, PSEs with an eye toward future M&A opportunities use cloud-based solutions to reduce future integration or divestiture costs, increase post-deal transition flexibility, enhance business agility, reduce risks, and facilitate a quicker exit when it’s time.
PSE’s use the cloud to make their technology operations more effective. They automate to drive improved productivity, increase accuracy, minimize waste, and enhance business results. PSEs use cloud-based automation technologies to improve operational spend and time-to-market by employing methods and tools that drive improved business outcomes—things like DevOps, self-service, auto-provisioning, integration platforms as a service, continuous integration and continuous development (CI/CD), microservices, and containerization.
PSEs also understand that deploying cloud solutions provides a quicker route for disruptive innovation, because it allows them to focus resources on finding solutions and delivering value, rather than engaging in capacity planning, procurement, and commoditized infrastructure management.
For example, a US-based financial services startup used the cloud—deployed by a lean team—to create an innovative, massively scalable securities trading app with strong built-in security and compliance features that supported hundreds of thousands of users at launch.
The app has disrupted the industry and is successfully competing with incumbents by offering no-fee securities trading capabilities, supported by a highly-scalable IT footprint. The startup is further exploiting the cloud to grow their online business, deliver and update their mobile trading app, securely store customer information and trading data, and perform advanced business analytics.
The bottom line? The competitive landscape is challenging. New, nimble companies are entering the market faster, with the latest technologies at their disposal—and potentially with little to no technical debt to prevent them from making significant strategic moves domestically and globally. Essentially, they are starting off as perfectly scalable enterprises.
Because they’re perfectly scalable, they have many choices—and limited downside if it doesn’t work out–which sometimes happens. Technology is a great equalizer, and acquiring the technology to become more flexible and scalable is critical to success. Getting smart on the cloud is a sound strategy to get perfectly scalable.In this episode of the McKinsey Podcast, Simon London speaks with McKinsey senior partners Sherina Ebrahim and Shail Thaker on how companies can use agile practices to transform their organizations. An edited version of their conversation follows.
Diane Brady: Hello, and welcome to the McKinsey Podcast. I’m Diane Brady. Even before the COVID-19 pandemic, agility was a hot topic. Some companies came into the crisis with agile practices, and let’s just say that others have had agility thrust upon them. But what does it really mean to be agile, and how can companies use those practices to transform their organization? Simon London finds out, speaking with senior partners Sherina Ebrahim, who works in New Jersey, and Shail Thaker, who’s based in London. Here’s Simon.
Simon London: So let’s just define our terms because this is a hot topic. This is a topic one reads about quite a lot. But Shail, why don’t you take a first whack at this. How would you define agile?
Shail Thaker: That’s a very good question to start with. So agile started life as a set of working practices in software development that were really focused on ensuring that product development was done in a customer-focused way—so end-user centric, heavily iterative. All of those things that a lot of people associated with agile at a working-practice level. And we’re in a very exciting time now where those working practices are being scaled up. Not just scaled up in IT, but actually scaled up across entire organizations.
And we are ending up with organizational constructs that look and feel quite different to what a lot of us grew up with over the past 30 years. We’re in a sort of tipping point now, where a lot of companies, a lot of entities, are looking at themselves and saying, “Well, is there an opportunity for us to organize in a different way? How do we organize in a different way to get a different outcome, particularly to increase external focus, adaptability, speed, raw cycle time?”
Agile is, at its core, in its simplest, a set of almost team-based working practices. If you ask me, “What is agility at an enterprise level?” I’d say it’s the scale-up of that in a meaningful way across entire organizations.
Simon London: So maybe, Sherina, just double-click on that. When we’re talking about at an organizational level, what are some of the things that you’re going to see on the ground that would define an enterprise or an organization which is becoming agile in that sense?
Sherina Ebrahim: I think the one thing that also is really important to think about when we think about agile organizations is to remember that it’s not only about what we would typically think about as organization structure.
To really become agile, it’s very much around mindsets and behaviors and really adopting a very different way of working. And so, I was just actually having a conversation yesterday with someone who said, “Well, we have cross-functional teams. It sounds basically the same as what agile is.” And it’s not. If you have a truly agile organization, you have groups of people who are singularly focused on what we would call a mission or a value driver or task, however you want to define it.
And the right groups of people are brought together to accomplish that. So if it’s about coming together to launch a new product, the people from insights and R&D and marketing and supply chain will all come together into a squad or a team. And their job is to say, “Instead of launching a new product in three years, how do we do it in six months?” How that’s enabled is not just to say, “We came together,” and then gave them a task. It is giving them the room to make decisions quickly. It is giving them the autonomy to pull in the right people when they need them, so that they can get the right insights at the right time. And they can actually make choices to move faster than what our traditional, hierarchical, matrixed organizations will allow them to do.
If you’re on a team, you feel quite empowered. You feel like you have an end goal. Everyone on the team, no matter what part of the organization you come from, is incented on that end goal—not what my function or chapter expects of me. Sherina Ebrahim
If you’re on a team, you feel quite empowered. You feel like you have an end goal. Everyone on the team, no matter what part of the organization you come from, is incented on that end goal—not what my function or chapter expects of me, but we’re all driving against the same goal in the same time.
Simon London: Right. Now then, I think an interesting question is, how many organizations are really trying to go big on this? Because I think, as you say, there are a lot of organizations that say, “Well, we have cross-functional teams.” Or there are certain parts of the organization—typically, software development to begin with, but other things as well—that are trying to work in an agile way. How many organizations would you say are really going big and trying to do this at enterprise scale?
Shail Thaker: I think we have to be a little cautious around what we define as going big because the end blueprint of what one company may look like in its fully agile state could look and feel quite different to another, right? And that depends highly on industry contacts, the specific portfolio you have, a whole bunch of things—not least the legacy and sort of historic baggage that a lot of organizations have.
Now, if you asked me how many have an ambition to do this at scale, we’ve done recent survey work across a broad spectrum of companies, across industries, that says 70 percent of companies in some shape or form are piloting agile now.
It is a big difference from running agile pilots to actually feeling comfortable that version one of whatever your agile operating model is, is in place. And with that, it’s not “I’ve done my architecture; now I can sit back and breathe,” but it is having an ambition to say, “I’m not just doing it in IT. I’m not just doing it in these shiny, new digital areas. I’m not just doing it in these particular business units.”
Almost use system thinking to say, “I can have individual teams that work in very much the way that Sherina described earlier. But actually, I need a backbone that supports them. I need an HR system that enables people to move around. I need a finance system and a budgeting system that allow me to resource reallocate. I need to have career paths defined for people.” So I think there are a lot of companies—I would argue even to say most companies—that are experimenting.
And then I think there are a handful of companies around the world who have done it at enterprise scale successfully.
And interestingly, those aren’t the biggest companies. Actually, the ability of some small and midsize companies to move very quickly on this agenda, where this is actually quite existential for them—you do this or you die—or indeed, they have the ability to mobilize the entire organization against this mission: those are where we see some really, really interesting case studies.
But the things that come out of them are that you are getting happier customers, you’re getting a productivity uplift, and you’re getting happier employees with improved engagement. So it’s a long way of saying, “How many companies are trying? An awful lot are trying.”
Simon London: But there are an awful lot—maybe, like we said, 70 percent based on survey work—that are either on that journey or have an ambition to go on that journey.
Sherina Ebrahim: And I think there are maybe two other things to consider. The ones that we see moving faster along that journey are the ones who, in many cases, have to. It’s a do-it-or-die kind of thing.
And that’s maybe a little bit alarmist. And we see that, for example, in the financial-services industry and places where the external environment is changing so fast, such as digitization—how consumers are using technology and interacting with that industry. So you actually have to change in a way that is faster to respond to what’s going on—meeting the needs of consumers. There’s another slew of industries, whether it’s consumer or healthcare, coming right behind as well. So I think that’s one reason that accelerates people through the journey.
The other, I would say, is leadership. There are definitely companies that are not quite on the cusp of “we really must change.” But the CEO or a business-unit leader has recognized the power of what this could be and has started to take the organization on a journey, albeit maybe slowly, trying to really build the muscle in order to get there first.
Shail Thaker: I mean, there are some fairly talismanic examples that are high profile. So I would argue, in the banking sector, you could pick many banks. But the most publicly known is obviously ING. If you look in the telecom sector, Spark in New Zealand is a great example of leadership-led transformation.
And you could argue that, in the pharmaceutical world, Roche has been taking a real leadership stance but with a very different angle around creating agile leaders and what that means. And the list goes on. I would say those are still companies that are on a journey.
Sherina Ebrahim: Just to add in other industries, I think we are seeing it with Walmart, which is in a very different industry that is starting to see benefits of using that methodology.
Simon London: And then there are companies that were sort of born agile, like Spotify, which is one of those sorts of talismanic examples of a company that’s just done this almost since the very beginning.
Shail Thaker: Absolutely. And that’s where, when I refer to the historic baggage of companies, if you’re talking about a 100-person start-up, these working practices, particularly if it’s a tech-enabled company ...
If you’re talking about a 60,000-, 70,000-person organization that is across 80 countries and has been operating in a matrix with very well-established norms, then [becoming agile is] more of a journey. Shail Thaker
Shail Thaker: It’s absolutely the most efficient and effective way of working in small groups. If you’re talking about a 60,000-, 70,000-person organization that is across 80 countries and has been operating in a matrix with very well-established norms, then that’s more of a journey.
But I would argue, that is also where a ton of value-creation potential is, because those are the companies that were built based on a simple premise: the matrix is a great structure for leveraging skill—and frankly, being the 800-pound gorilla and stomping on your competitors.
Alright, that is a wonderful construct for that. It is not a great construct if you have to move at speed. And that’s where, as I think Sherina referred to—whether it is external regulatory pressures, whether it is shifting consumer behavior, whether it is challenge of incumbents by disruptors—this imperative around speed comes in.
Sherina Ebrahim: And what’s interesting about it is, if you think about a spectrum of “born digital,” typically, they start small and can do everything that Shail just described. And on the other end of the spectrum, we have very large global companies—highly matrixed, functional.
What’s interesting is that the challenge is sort of just an area of gray. So we have already talked about how a large organization just starts to think about changing, really think about moving to an agile organization, with the right backbone.
What you see as start-ups scale themselves is that they start to run into the same questions, because you can’t just keep running like that as you get bigger. So they, too, then have to ask, “Well, what’s the backbone that I need to put in place in order to continue to work in this way?”
If you think of agile as an outcome of a particular setup where you’re putting the Lego bricks around which bits are dynamic and which bits need to be stable ... start-ups have a ton of dynamic, not a whole lot of stable. Incumbents: huge amounts of stable, not a lot of dynamic. Shail Thaker
Shail Thaker: But also, if you think of agile as an outcome of a particular setup where you’re putting the Lego bricks right around which bits are dynamic and which bits need to be stable for me to be able to deliver speed and be nimble and all that good stuff, start-ups have a ton of dynamic, not a whole lot of stable. Incumbents: huge amounts of stable, not a lot of dynamic.
So it’s the different ends of the spectrum, but as Sherina says, the convergent, the equilibrium point, for these—there’s a lot of cross-learning to be had.
Sherina Ebrahim: Yeah. And I think the other thing I would add is that, oftentimes, one misconception is that agile is just to “do what you want.” And it’s not, actually. It’s systematized. It’s a pretty structured way in which to work.
And so, this notion of what should be stable and what should be dynamic is really an important distinction that people should think through, because the stable enables people to come to work. They know the framework that they’re working in. They know their role and what might be their career path. And they know where their home is, if you will. And the dynamic is actually ways of working in which you can bring different people together so that they can quickly get something done and then move on to the next one.
And a pretty important success factor, I would argue, is the notion of dynamic resource allocation, which larger, more stable companies are not used to. They're used to yearlong planning cycles, budget cycles, but to be much more agile, you have to think about quarterly.
And so, it sounds easy when you say, “dynamic resource allocation.” There are reams of proof that it actually is a value-creating driver. But it’s a very hard thing to change—especially if—you’re not used to it at all.
Shail Thaker: I think, to dig into the point around dynamic resource allocation as an example of the types of things that are different, there’s absolutely a hardwiring piece. Finance organizations are not built to move money around. We don’t have the management information systems that allow us to track.
We don’t have the forums and meeting cadence and business calendar that free up enough time to make real trade-offs. We haven’t trained leaders to have the right discussions around this. But sitting above all of this is also a massive change in management mindset.
We have an entire cadre of leaders. I will paint this in black and white, just to point out the extremes: “I have been successful as a leader because I was given my budget, and I delivered or overdelivered on my budget.” That is very different from an enterprise-leadership mindset, which is essentially, “We’re all in service of a mission.”
To do that, I accept that, if things change, the budget I thought I had, the financial and human capital, can and should be reallocated. And that is a massive shift from “my number and budget commitment is my bond as a leader, and that is my commitment to the enterprise too.” I am now a participating leader in service of a mission.
Sherina Ebrahim: So in Shail’s story, for example: if you’re incented on making your budget, that’s what you’re going to do. Whereas if you think about an organization that’s agile, you’re not incented on your function. You’re not incented on your box. You’re incented on the purpose, the mission, which is very clearly tied to the value creation of the company. That changes the entire mindset and behaviors of the people. Again, easy to say. Not very easy to flip the switch when you’ve grown up in an organization.
Simon London: So let me just pick up on a term you used earlier, Shail. You talked about a blueprint. That implies to me an overall mapping of the different elements of this end state that you want to get to. Just double-click on that for us. What are the elements in the blueprint?
Shail Thaker: I think the blueprint is quite a key step in a company’s journey. It’s not always the first step, but it is a key step. Companies can start by piloting. But without a 60 percent, 70 percent view of how all the building blocks come together in the enterprise level, it’s quite hard.
And that’s why we think a blueprint is important. Now, what is in a blueprint? You don’t do agile for the sake of it. Your agenda around applying agile working practices is strongly linked to the ability to create value.
And that refers to which parts of your business system actually could create more value by being faster or more adaptable and, indeed, which ones could create more value by having more dynamic resource reallocation. So it’s almost through this value-creation lens that you look at your business.
Shail Thaker: And you identify nodes. So there are bits of your business for which agile working practices are massively relevant and create a huge opportunity. There are, frankly, other bits which don’t matter so much, and agile’s not going to transform them, because they are actually steady, consistent. Now, they play an important role in the system. But the blueprint first identifies these nodes of value. Where is agile going to make a difference?
Sherina Ebrahim: People will say, “We want to become agile.” And so, I think, you have to ask, “To what end and where?”
Sherina Ebrahim: And if you are not clear on that—and again, it seems very simple, but people are not clear—it really isn’t a critical underpinning of success as a starting point.
Shail Thaker: Yeah, absolutely. So let’s take step one of the blueprint as understanding where value is created by the application of agile working practices. The second piece is, “If I have those, I have a set of options of almost dynamic Lego bricks”—that's a visual I use.
And you may think that agile working practices equal a cross-functional team. The reality is, that’s not at all true. There are plenty of working models that contribute to agility—by the way, going all the way back to lean working practices and some quite old-fashioned but very relevant concepts.
There are quite a few more Lego bricks than you might think. The step two of the blueprint is, you apply these dynamic models and choose the right model for the right node of value to create the most value, right?
And once you’ve got that right, it’s great. You have almost a patchwork. Then you have to think, “What’s the minimum backbone I need to put in place to actually get the system working?” And it’s important to think of the backbone in this blueprint as something other than the organizational units you currently have. Often, it could be shared vision, common career path—think job descriptions.
It’s actually thinking expansively about the backbone in the system that holds the system together. As an enterprise leader, you can take a step back and say, “Am I comfortable that this is all building to an end point that makes sense?”
Simon London: So three steps I’m hearing. Number one, really figure out and agree as a leadership team where value is created to your application of more agile working practices—where could it be transformative?
Number two, what are the working practices we’re going to apply, where? And to your point, it’s not always just one thing. It’s not like everything’s going to work on a scrum basis.
And then third, what are the more stable elements? What is the backbone? What are the enablers that we’re going to need to allow us to scale this? Is that right, broadly?
Sherina Ebrahim: And the one thing I think is implicit in your number one, when you said the leadership team really has to be clear on the vision, the implicit value is that the leadership team really understands what they’re about to embark on. And so, what kind of scale or vision of transformation are they thinking of?
That doesn’t mean they have to know today that we want to become 70 percent agile or whatever it is. But they do need to have a sense of, “What are we trying to accomplish if we go down this journey?” Because just doing one or two pilots here or there, that might get you something.
But if you have a bigger vision, if you’re trying to turn the company or a part of the company in a different way, being clear on what that is and how they will have to lead in a different way is actually a very important thing for them be very aligned around.
Shail Thaker: I mean, we look at the success factors, and it’s also the failure modes. And one of the biggest is actually ambivalent leadership commitment. It’s really easy to sit back and say, “Look, I’ve got a whole bunch of pilots going on. We’ll sit back and see how they turn out.”
The reality is, after a while, you can create a huge amount of value in a localized agile pilot. But to some extent, it’s like entropy. You’re shifting the complexity to a new set of interfaces. And you rely on the energy and enthusiasm of the people to sustain that pilot.
That is not indefinite. So pilots can run out of steam, and organizations can lose their window, because agile becomes a dirty word or a failed-pilot word in the organization. And it’s not about learning; it’s actually just that thing we tried a few years ago. So you can’t pilot your way to scale. At some point, leadership has to commit. At some point, there will be—particularly when it comes to the backbone—a switching of how the organization is wired, and that takes commitment.
Shail Thaker: Yeah, well, I would say it’s not so much a leap of faith as an understanding of what the consequences of this are going to be for the organization and you as a company.
Simon London: And the consequences are profound, if you’re going to do it at scale? That’s the point.
Shail Thaker: It’s a transformation, and it is very, very different from how organizations operate today. But that is not to say that the people who are operating our organizations today are irrelevant to the future organization. It’s just that you have to be signed up for the journey.
Sherina Ebrahim: Yeah. I think that’s a really important point, Shail, because I fundamentally believe—and obviously, I’m biased—that whether it’s five years down, X years down, every organization is going to have to embody some components of agile.
The external world, the consumer environment, is just moving in a way that means we have to change. And so how do you actually move from what are fairly monolithic organizations today—everyone has their role, everyone has their function, et cetera—to one where everybody really embraces that it’s actually quite different and dynamic and it will continue to change? That is the point. So how many of our clients, our companies, today go through reorganization number one? And then before that one’s just finished, you’re on to reorganization number two.
Because you’re trying to get it right in terms of what you need to respond. And if you actually get it right from an agile perspective, you will never have to do a reorganization, because that is the fabric of how you work. You should be able to shift and change. And maybe today you work in a stable part of the business, and tomorrow you’ll be on an agile team. If you can just sort of paint that picture, it’s quite different from what it is today.
And therefore, to your point, it’s quite a shift. But at the same time, as you’re on that journey, it’s really important to make sure that people come along, understanding where they are and their place in the organization as well.
Shail Thaker: And to build off that, as we go back to the mindsets and why is this sometimes difficult, there is a perception—and I’ll use the word “perception”—of risk around this, because it feels like moving from classical command-and-control systems to much more decentralized systems. Now, the reality of the risk versus fully accounting for the cost of doing nothing has to take into account that this isn’t throwing all the pieces in the air. It’s actually quite a regimented but different way of working. So there’s that piece around risk that is quite important: around getting this sort of mindset shift.
And the second is, you’re talking about redefining how people value themselves and value impact in businesses. So I am in a system where, if I do well at my job, I’ll also get a pay raise, but I’ll get a new title. And with that new title comes more people. And I manage bigger and bigger things.
One of the outcomes of more fluid resource reallocation and really focusing almost the body mass of the organization around the biggest priorities is that you don’t have as large of a management layer in between. And that delayering is quite disorientating for people who say, “But hang on, if I’m great at my job, there are all of these roles that I could’ve got into.” So this links to some of the things like incentives or career pathing. How do you reward, recognize, and give people progression in a world that is fundamentally more dynamic? So these are all the types of challenges.
Simon London: This underlines for me a couple things. Number one, why it’s transformation if you’re going to do it at scale, because it has to touch all of these: systems, mindsets, processes—I mean everything. And the other thing is, what you’re talking about there again is backbone in a way, isn’t it? Thinking about rewards, career progressions, different roles, and having fundamentally different ways of being recognized for impact compared to a traditional organization.
Sherina Ebrahim: Absolutely. I think it’s to make it really real. For many current employees, it’s very much tied up in how they value their own self-worth, right? My title, my number of people. And so, as you say, I think the backbone parts are all of those things.
And what’s interesting is, the younger employees of today actually prefer to work in a much more fluid, more information-based environment. That’s how they grew up, right? And so that’s also going to play into this as organizations grow.
I think what we haven’t touched on enough, as you think about the backbone, is processes. So this implies that quite a few processes actually have to change, right? One we already touched on was how do you think about budgeting—resource reallocation, right? That needs to be reengineered.
Simon London: Yes, because if you’ve got a plodding budgeting process, you’re not going to be able to allocate capital in an agile way.
Sherina Ebrahim: Technology infrastructure underneath it to help you do it dynamically, right? That’s one of the barriers today: the system doesn’t allow you to be that fast. So budgeting is one of them. You’ve already talked about career pathing and career planning. To some, it’s blasphemous to not necessarily know in three or five years where I should be going. And people have to get comfortable with some of those things—again, not in all parts, but in how to live in a world that has some of these other things. So I think some are going through transformation, and some processes will stay the same.
Shail Thaker: Yeah, company carpools. There’s going to be a whole bunch of background stuff that speed and adaptability will not impact in any shape or form.
Sherina Ebrahim: Right. Not everything will change. There are some that will need to, and many others will stay the same.
Shail Thaker: There is an important clarification. It is absolutely true that the younger generation of workers adapt to this. They’ve sort of grown up in this environment and are adapting to it a lot more quickly, and it’s natural to them.
That is not to say that, irrespective of age, engagement doesn’t go up. So when we look at what the data shows, it’s not that the younger workers are really happy working this way, and the older workers find it terrible. It’s that teams, irrespective of age, see massive increases of engagement. I’m talking about 20 points, 20 percentage points plus, right? So people enjoy working in this as long as the rest of the system allows them to do it and does not massively penalize them or make their life considerably complicated.
Simon London: I was going to ask a devil’s advocate question, actually. I mean, the younger generation adapts to this easily—big generalization, but a lot of younger people, particularly having come into the workforce in the last ten years, have been forced to do gig work, and gig work is almost a form of agile outside any organization. Are we talking here in some way about bringing gig work inside?
Shail Thaker: The gig economy has come up now. I would say “forced” is a very strong word. So that sense of compulsion when we talk about the gig economy is always dangerous territory to get into.
But absolutely. The facts are that there is an element of flexibility and an element of uncertainty on what you’re going to be doing on a day-to-day basis. What I would say is, there isn’t one element of the gig economy, which is uncertainty of income. And actually, that sort of uncertainty stretches so far.
But you still have the security of being part of a mission, right? And this again becomes part of the stable backbone. There are elements of purpose, elements of mission, and elements of security that sit around this way of working that actually allow people to step away from a lot of the insecurities of the day-to-day work in a big company that are negative. It frees up a lot of the positive energy, which is where we see the uplift.
Sherina Ebrahim: I completely agree. I think it’s very important to reinforce this notion of security, for lack of a better word. It’s not necessarily job security as we know it today. But we do know the fundamental fabric of the company that you’re working for and what they’re trying to do, how they’re trying to do it—whether it’s processes, how you’re treated, the ways of working.
And so, yeah, I may not know exactly today that tomorrow I’m going to be in a different mission. But I know that’s how I work. And that baseline of security, which all people want, is one that’s an important thing not to miss. Otherwise, it feels like it’s a bit of a free-for-all, and it’s not.
Shail Thaker: I’ll play devil’s advocate back to you, which is to say that, ultimately, the reason we see the engagement scores go up in the way they do is a greater sense of fulfillment: a greater sense that an individual worker’s time is spent on things that are more value adding, plus a greater connection to a mission that feels more relevant.
Those are things that far outweigh almost the comfort blanket of the old way of doing things, with “I know exactly where I fit into the big system.” So the devil’s advocate back would be, yes, there are elements of the gig economy. But the engagement scores of the outcome show that one of those factors significantly outweighs the other.
Simon London: So I think a takeaway for me out of this conversation is that I assumed that to do agile, you had to be sort of doing squads, scrums, chapters, guilds—the bunch of core processes that you just have to do if you’re going to claim to be doing agile. It sounds like, actually, as this is scaling across different industries and different sectors and different companies, it’s more heterogeneous than that.
Sherina Ebrahim: Absolutely. It’s definitely more heterogeneous than that. And I think the way to think about it may be to walk away from all the terminology and the vernacular. There are just core concepts in different ways of working, as we’ve talked about.
There’s, whether we call them tribes or squads, the right people coming together to accomplish a mission. There’s what we would call self-managing teams, who sort of run themselves. There’s flow-to-work models.
There are a number of different models. And even when you do things that have a construct, which many call tribes, squads, or chapters—frankly, people are starting to use the terminology that works for them—I would try not to get caught up in the language but to ask, “What are the principles around ways of working that really help unlock the value?”
Shail Thaker: There are two things that have been particularly important, I think, when I’ve worked with companies on this. One is really defining for your company how the Lego bricks come together. And that’s which of the Lego bricks are most relevant, because you don’t want to create a whole bunch of additional complexity by doing things in a different way, in a different part of the organization to achieve the same end. And then the second piece is how you solve for an individual team, but that blueprint piece is really, really important.
Simon London: Let’s discuss how you begin. Let’s say, as a management team, after doing an offsite, you’re beginning to think, “We’ve got to go for this.” How do you start?
Sherina Ebrahim: I think there are a couple things, at least, if you’re that management team. When you say, “We’ve got to start,” I would ask that first question on our blueprint, “Agile to what end? Where is the value creation? What are we trying to get to? And over what period of time?”
And in that decision, I would actually make sure you, as a team, really understand what it looks like for both the management team and the mindsets and behaviors, how you have to lead, and what that might imply from an organization perspective.
I think once you get your mind wrapped around that—and it doesn’t have to be perfect, but you need to get at least in the right zip code, if you will—then you can take one or two or three of those value-creating levers and say, “What might we actually start to pilot or try within the organization?”
But then really know that it is a bit of a proof of concept. It’s not a pilot in the sense of “we want to try it and let it go.” It’s, “How do we want to prove some of these things to build conviction for ourselves and the organization?” And then know that, at some point, you’ll want to, as Shail said before, think about how to flip the switch and start to scale.
Shail Thaker: The one thing I would add is there is no substitute to going and actually seeing a company that’s done it. Like, because we can talk about this. You can see it on a page; you can do a workplace.
Until you actually see the deployment of this at any form of scale, go and talk to leaders who have done this before and what their journey has been like. That needs to be pretty high on the list of to-dos for the leadership team you described, because it’s great that they all held hands and said, “We’ve got to do this.” But unless they really know what “this” is or what it could be, it’s meaningless.
Sherina Ebrahim: Yeah, it’s actually step one before you have that conversation. To have a sense of what you’re starting to embark on, go see.
Simon London: This sounds negative, but the failure-modes question is often very revealing. So what are a couple of failure modes that you see?
Shail Thaker: One, I would say, is one we talked about a lot: leadership conviction. And if that leadership conviction isn’t there or you allow the proliferation of pilots but don’t have the convictions of leadership ...
The second piece is the blueprint. You let leaders who have the conviction do things in their own way. If you don’t define enough guardrails around what the way will be—the right, scalable way—then you won’t get any practices scaling up sufficiently to warrant the backbone change.
The third one is, you hope to pilot your way to scale. And actually, as a result, you don’t design the backbone.
The fourth one is capability building. We have talked a lot about this being a massive shift in capabilities, at an individual level but also at an institutional level—both the rewiring of processes and also giving people the skills to thrive in this new way. This is, for most organizations, going to be an unprecedented way of working, an unprecedented capability-building challenge, because you’re talking about a large number of people needing to learn how to do things.
Simon London: At a lot of organizations, in the same way that it used to be the Six Sigma Black Belt world, now you’ve got to have agile coaches.
Shail Thaker: And then the final one I think I would add is actually, look, this is a transformation. And that means some of the classical transformation tool kit is very relevant. But also, some of it isn’t. So thinking that in the classical organizational design, where I’m going to lock myself up with a small program of people in a room I’m going to design and architect, I’m then going to execute for a period, and bang, we’re going to have day one and hit a new structure. Really understand it’s a transformation, and take the right elements of the transformation tool kit that are relevant for what you’re trying to do.
Sherina Ebrahim: Doing the hard work to change the underlying culture, mindsets, and behaviors is a pretty big failure mode. Not doing enough of it. There is such a thing as not quite failing but not quite achieving the promise of agile. And what I mean by that is, I think we’re seeing more and more people recognize a need to do it.
But sort of reading the book, hiring maybe one agile coach or something says, “We’re going to change the labels. We’re going to make some teams. And we’re going to check the box for agile.” No way. Right? Really, you can’t just surface-level get there. You have to do the deeper work.
Sherina Ebrahim: I encounter a number of people who say, “Oh, we’re agile,” and then you ask the leadership team, “OK, you say you’re agile; what does that mean?” Ten people around the table will give you ten different definitions. “It means we have open space. It means we have three teams.” That’s something I would guard against. If you’re going to do it, really do the deep work. And it’s not a little bit of work to do.December 9, 2019 There is a lot written about automation these days and some of it can be daunting. From fear of robots taking over our lives, to automation being a threat to jobs, AI is creating impenetrable skills gaps and employee resistance to change.
First, we believe there will be more than enough work to go around. Our research shows jobs gained and changed by several automation and labor trends will outweigh jobs lost in the 2016-2030 period. Companies will certainly need to ensure that the effect of jobs loss is mitigated with retraining initiatives, and we are already seeing several companies leading the way in developing skills for adjacent roles.
Second, the nature of work and the workplace will evolve in ways we believe can positively influence employee motivation. This strikes us as a good thing, since other than maybe sleep, we will spend a greater share of our lives working than doing anything else. Here’s why work may be more motivating in the near future:
Automation will strip away the dull and the dangerous, paving the way for more engaging work and learning. Very few total jobs are going away entirely—indeed only one percent of jobs are made up of activities that can be fully automated; parts of jobs are what’s changing. That said, automation technologies, including RPA, artificial intelligence (AI) and physical robotics, have the ability to displace a third of the current activities in over 60 percent of all jobs. The activities automation is best at including predictable and physical work, data collection and data processing. As automation strips away the rote and mundane, what remains for employees to tackle are heuristic tasks—the complex, creative tasks on which humans outperform machines. Surveys show that workers see automation as an opportunity to free up their time to make meaningful contributions, which they find more rewarding. Work redesigns alongside automation promote more team-based and agile ways of working. Because jobs are changing, companies are using this shift as an opportunity to redesign business processes and workflows in a way that enables humans to work effectively alongside machines. Many are also reconfiguring their overall design and workspaces to promote greater collaboration and less hierarchy, resulting in more team-based set-ups and agile ways of working. In turn, employees have greater autonomy to shape their day-to-day, and develop a greater sense of mastery and purpose over their contributions, which increases their motivation to drive the work. Accordingly, a New Zealand telco saw over 30 pts eNPS gains after forming Agile teams—exceeding digital natives and thus enabling to attract the best talent. Automation drives increased need for social and emotional skills in the workplace. For centuries, organizations have asked human labor to act like machines. Now, technology allows for automation to be much of this work, and what’s left is asking human labor to do what is truly human. Along with higher cognitive skills, finely tuned social and sophisticated emotional skills—creativity, innovation, advanced communication, negotiation, leadership, adaptability, empathy—will be in greater demand to drive these more complex activities. As these connections-based skills increase, so does deep human interaction. A multinational technology company has experienced strong growth in the last 12 months by leveraging learning and empathy as critical assets for unlocking innovation and external partnerships.
Together, we believe these shifts in the workplace have the potential to drive significant improvements in employee motivation. Self-determination theory sheds light on how to get employees to become autonomously motivated without prodding and continuous monitoring to do work. The theory posits that there are three broad needs that, when fulfilled, cause us to want to perform a behavior: need for competence, autonomy, and relatedness. We recommend organizations bring employees on the journey in helping them understand what’s in it for them, and pay close attention to how employees’ feelings of competence, autonomy and relatedness are shifting to tap into higher engagement and performance – and ultimately, higher work and life well-being.You are an expert, an advisor, and a coach. You’re experienced with a variety of agile topics, ranging from frameworks (Scrum, Kanban) to engineering practices (TDD) and DevOps. You advise clients on the best way to adapt these practices to their day-to-day. You’re a hands-on coach to teams and leaders, helping them understand the role they play in a high-performing agile team.
You’re a teacher, practitioner, and evangelist. You use your expertise to teach others how to build products and solutions with tools like storyboards, backlogs, user stories, and acceptance criteria.
You’re comfortable working with different levels of an organization, from a mobbing session with development teams to discussing organizational changes with the C-suite.To thrive in today’s dynamic marketplace, organizations need to deliver at speeds greater than the pace of disruption. A fundamental change in mindset and ways of working is essential to respond and deliver profitable outcomes. Agile transformations in large organizations are extremely challenging and generally underestimated by executives. Deloitte brings its services across advisory, implementation and operations to enable business agility. We challenge organizations to reach beyond the mechanics of agile to focus on outcomes enabled by agility–to deliver better value, sooner, safer and happier.Leads our agile work in Central Europe and our Enterprise Agility Center in Budapest and helps institutions across industries to shape growth strategy and transform themselves in the digital age
October 5, 2020 In previous research, our colleagues have outlined the importance for agile organizations to create both stable and dynamic practices. A periodic business review, prioritization of different activities, and alignment across organizational units (frequently called tribes) are often together referred to as Quarterly Business Reviews (QBRs). QBRs can be the cornerstone of an effective agile organization, linking overall strategic direction to agile organizational units and team-level backlogs.
When done well, QBRs can bring immense value to an organization by creating vertical and horizontal alignment. However, inefficiencies often occur due to limitations in the ecosystem around the QBR—even if the narrowly defined process is done well. There are five reasons behind these suboptimal operations:
QBR ownership: The QBR and the broader ecosystem surrounding it are at the heart of an agile organization and must have a proper owner. This role spans three main activities: managing the QBR process, ensuring proper content quality, and continuously improving the QBR. A dedicated squad is required during QBR cycles, combining agile, IT, finance/budgeting and strategy expertise, and a strong and respected leader. Broad dependency alignment: During the QBR process, these units set Objectives and Key Results (OKRs) and plan what they will deliver to achieve them. Ideally, a substantial portion of the unit backlog can be delivered autonomously by the owner of the group, while a smaller fraction requires broader alignment. The QBR should serve as a forum to understand those dependencies and resolve them while not making the process highly technical and administrative. For instance, one LATAM company organizes a quarterly fair where each unit leader presents its initiatives and all other leaders are responsible to challenge them and understand potential dependencies. Traditional budgeting: Agility brings a paradigm shift in the logic of budgeting. Instead of projects, agile organizations use cross-functional teams as budgeting units. Agile organizational unit leads must assume resources are relatively fixed, and their job is maximizing impact, generated via prioritization. This is important, because if agile organizational units are subject to traditional project and business case-based budgeting logic, then QBRs cannot function properly. If fully agile budgeting is not realistic in the short term, companies can opt for a hybrid approach. For example, a leading bank uses QBRs to review budget status against delivered business results—and potentially make adjustments in a transparent and fast way during the QBR meeting, if circumstances require. KPI and OKR misalignment: OKRs are among the most fundamental elements of QBR logic, used by many organizations to set aspirational targets with motivating narratives to rally people behind a common vision. In the QBR, these units must define OKRs from strategic company aspirations. Yet, organizations often struggle to draw a connector line between the newly introduced OKR concept and end-of-year key performance indicators (KPIs). A Western European bank defined the value driver KPIs for each agile organizational unit and derived OKRs that helped to achieve these relatively fixed end-of-year KPIs. Disconnect from IT processes: In an ideal agile environment, agile organizational units can release standards and an IT architecture vision. This is rarely the case in large corporations due to legacy architectures and monolithic systems. Given that planning for major monolith IT systems often requires 12+ months, QBRs often need to co-exist with IT release planning. One European telco solved this by synchronizing the timing of IT release planning with QBRs, and then used them as a complementor forum—refining and breaking down the upcoming portion of the high-level IT roadmap.
Building proper QBR practices and enabling the ecosystem takes time and effort. However, once these pain points are addressed, the QBR can truly act as the nerve center of the organization, transmitting key impulses and strategic signals.September 23, 2019 As we’ve discussed extensively, agile organizations operate in fundamentally different ways to traditional organizations (see our previous articles here and here). But what is the role of the leader in this new open, empowered organization?
In traditional organizations, the focus of leaders is to maximize value for shareholders. To do this, they play the roles of planner (developing strategy and translating it into a plan); director (assigning responsibility); and controller (making sure everyone does what they should to minimize variance against the plan).
Today’s complex business environment calls for a new approach to leadership. This approach must focus on co-creating meaningful value with and for all stakeholders, expanding beyond shareholders to include customers, employees, partners and our broader society. In an open system, everyone must win. Otherwise, they’ll simply go elsewhere.
This new style of leader must play four new roles: visionary, architect, coach and catalyst. The traditional roles, while still available to leaders when needed, become woven into the way people work.
As visionaries, leaders shape the emergence of a clear, compelling purpose and vision – a North Star – that resonates throughout the organization and beyond. They don’t arrive at this in the boardroom. Rather, they emerge it from the organization by observing and listening to people throughout the system, offering ideas for consideration, and integrating others’ perspectives with their own original thinking. As visionaries, leaders also work with teams to translate the vision into measurable outcomes that empowered teams can work towards.
With clarity on what is to be accomplished, leaders act as architects. Rather than developing plans, leaders take on the more sophisticated role of designing the organization as an open and empowered system, able to continually plan, execute, and adjust flow of resources across shorter working cycles in pursuit of its North Star. They favor a deeper examination of the system designs at the core of the organization, creating space to re-imagine how products might be produced, or how sales might be generated. This requires letting go of limiting assumptions and beliefs in order to allow new forms of business and organizational models to emerge.
As people are empowered to achieve organizational goals, they need to develop greater business acumen, learn to think more strategically, and deepen their ability to collaborate. Capability building—of mindsets, knowledge and skills—becomes a critically-important area that leaders need to address.
They do this through encouraging a wide range of formal and informal learning initiatives, and evolving a culture of learning throughout the organization. They create environments where it is comfortable to experiment, where people feel equally good about discussing what went well and what could go better. They also build coaching into their team interactions by asking more questions than prescribing solutions, and seeking multiple perspectives to expand the solution space.
As catalysts, leaders unleash energy throughout the system. They do this in four primary ways: remove roadblocks that prevent empowered teams from bringing ideas to reality; foster connections across the organization; help people connect what they’re working on to the organization’s vision and aspiration; and finally, encourage an inclusive and welcoming environment of wholeness, where people can bring their authentic selves to the office, work in energizing and sustainable ways, and pursue the full range of their personal and professional aspirations.
Collectively these four roles aggregate into a very different and more powerful kind of leadership. Leaders – and the teams they lead – find this new approach far more energizing and effective, as it unleashes the full passion and potential of people to deliver impact and value.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.Serves clients on a broad array of topics ranging from strategy to organizational design and transformation across industries, including consumer goods, retail, and fashion; leads our organization design work and helps companies through multiyear organizational transformations, focusing on bringing operating models in line with the realities of the markets, strategic shifts, and other success factors
August 24, 2020 The majority of organizations still use a hierarchical model, where each role is carefully documented and cemented through a system of boxes and lines. In this paradigm, accountability gets buried in the depth of complex organizational structures. With businesses and government agencies alike facing unprecedented disruption, having the flexibility and speed to quickly make decisions and get work done has never been more important.
Digging out from under the many management layers and antiquated hierarchies may seem impossible, but it’s not. Some organizations have successfully “unstructured” to become fitter, flatter, and faster, unlocking massive value. Many organizations are experimenting with dynamic operating models, such as the “helix” model and the agile “network of teams,” enabling them to move at the pace of change around them. This blog post highlights what these organizations have done right and what others can learn from them.
Radically flatten the structure to minimize layers and increase speed Cumbersome management layers are the enemy of speed and agility. Leaders should throw out the old rules about the most effective ratios for spans and layers. In a highly digitally enabled world—where bosses are there to empower and enable their employees, not micromanage them, we see often spans as around 1:30. Even the largest organizations shouldn’t have more than six layers; in truly agile organizations, we often see only three layers. Build a flexible, dynamic network of teams to tackle rapidly evolving problems Whether a global pandemic or some other crisis, organizations of all kinds are faced with emerging, fast-moving disruptions in their industries. They need to be able to stand up and dissolve agile teams quickly, easily, and effectively—and with minimal requirements on leadership time and resources. Provide a stable home base for employees to ensure long-term career development The helix model has gained traction recently. Its key idea lies in disaggregating the traditional split of management tasks into two distinct parallel lines of accountability. The capability line is organized in stable skill-pools, where managers are responsible for the long-term care, development, and training of employees. The value creation line, made up of the highest-priority initiatives, is where employees work on a day-to-day basis. The value creation manager ensures that people know what to do on a day-to-day basis. Empower the ‘edges’ to ensure leaders have access to the best information and rapid innovation The organizational structure of the future is designed to ensure that critical people close to the front lines—therefore to the customer or constituent and the product or service—have a voice and are heard. These people typically are close to where value is created or where risks are borne. Empowering these employees to speak up and get involved often requires a cultural shift and close collaboration with the leadership team. Delegate clear decision rights to lowest possible levels Effective decision making is one of the most important elements of the post-pandemic organization. The flattened structure can accelerate decision making by minimizing unnecessary management layers; ensuring people are clear about their roles, responsibilities, and decision rights; and empowering the front lines to make decisions within guardrails.
For the new structure to be effective, other enablers must be present. For example, leaders should ensure the organization has an effective performance management system, clear strategic planning and resource allocation processes, a transparent and dynamic talent marketplace, and a corporate center that facilitates long-term performance and organizational health.
Organizations should build on the momentum gained from their response to the pandemic and ensure their organizational structures are set up to enable and supercharge their strategic goals—not hold them back.
This blog post is part of a series on Organizing for the Future, which explores a set of new principles such as anti-fragility and experimentation that are becoming increasingly critical for today’s organizations as they build more creative, adaptable, and human systems.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.The ability to deliver in a digital world is more important than ever. Businesses that once mapped their digital strategy in one-to three-year phases must now scale their initiatives in a matter of days or weeks. Agile, analytics, technology, design, and leadership capabilities are essential to enable this, however, building these capabilities can be difficult. Knowledge, skills, and behaviors must be aligned with how teams and key roles create value for the business.
We work with organizations to build these capabilities and achieve aspirations in digital and analytics. We use a broad range of learning interventions to help individuals and organizations develop foundational knowledge, mindsets, and skills on core digital, analytics, and agile topics in order to deliver measurable and sustained business impact.Agile Internal Audit (IA) has been successful in helping functions adapt to, and navigate complexity in a continuingly volatile, uncertain and ambiguous environment. An agile approach allows the function to appropriately plan by regularly re-assessing and focussing on stakeholder needs, accelerate audit cycles, drive timely insights and reduce wasted effort – in this sense it has the power to transform how we think and work, and ultimately, the impact that IA can have on an organisation. Over recent months, functions who have implemented Agile IA have noted that they have been able to quickly, and sustainably rise to the current challenges.
Better impact, quality, performance and decision making as agile teams are used to re-prioritising work based on new and emerging risks and ensuring a collaborative understanding of value and what really matters;
impact, quality, performance and decision making as agile teams are used to re-prioritising work based on new and emerging risks and ensuring a collaborative understanding of value and what really matters; Faster team delivery, reporting, response to changing risks, and closure of control issues through the use of audit sprint cycles and more stable teams;
team delivery, reporting, response to changing risks, and closure of control issues through the use of audit sprint cycles and more stable teams; Happier stakeholders and teams due to greater transparency, team empowerment and more sustainable ways of working; and
stakeholders and teams due to greater transparency, team empowerment and more sustainable ways of working; and Safer and more receptive environments for the delivery of other changes aimed at driving continuous improvement in IA – for example, the use and embedding of analytics, digitisation of IA processes, resourcing, planning, reporting, leadership structures and behaviours.
Agile IA is a way of working based on iterative development where audit requirements and solutions evolve through collaborative, self-organising teams who are focussed on delivering the most important business value and continual improvement; ultimately creating better, faster, happier and more resilient functions.
IA needs to be prepared to respond to a continually changing and complex risk environment. At its core, Agile IA is a way of approaching work and audit planning based on iterative risk assessment and value to be delivered, being focussed on collaboratively agreed greatest risks to an organisation.
With competing priorities, IA must find better ways to engage management. Using Deloitte’s Agile IA framework during audit planning, IA collaborate early and listen to feedback from key stakeholders to understand new or elevated risks in order to assess how to best support through provision of targeted assurance on the areas of greatest risk, with use of an Audit Canvas providing a powerful tool to identify areas of value for all stakeholders.
Importantly, adopting an agile approach does not necessitate greater time commitment from stakeholders. Focussed Agile IA events facilitate regular (but less intensive) interactions with stakeholders with communications designed around the things that really matter. Therefore in our experience stakeholders are very enthusiastic about agile audit approaches due to the fact they have increased involvement and engagement with the process, as well as reduced time to value benefit.
Agile audits are typically delivered in sprints of one to two weeks, with scope and tasks prioritised by value. Agile IA teams have adopted the discipline of frequent, targeted communications, both within the team and with stakeholders. A daily Stand Up event has proven to be very useful at identifying and resolving ‘blockers’ (potential delays) to progress and Sprint Review meetings at the end of each sprint create a setting for early feedback to audit stakeholders and course correction, allowing teams to hone in on what really matters and assess the value of further work.
A sprint Point of View (POV) communicates valuable insights to key stakeholders much sooner and more regularly than traditional, often long and time consuming reporting phases. Given the regular POV reporting and agreement with stakeholders on issues as the audit progresses, audit reporting becomes smoother and more efficient. In addition, as a result of improved collaboration with stakeholders, teams that make use of agile principles have reported improved stakeholder engagement and therefore better responsiveness, resulting in the business taking action to close audit issues sooner, and therefore more quickly strengthening the control environment of the organisation.
It is vital that IA leaders ensure that teams stay connected in an increasingly remote working environment. Regular team communication, such as the use of daily stand ups during sprint delivery and team sprint retrospectives, promotes closer working relationships and enables rapid identification and solution of challenges that might otherwise stifle progress, as well as encouraging a culture of continuous improvement.
Agile’s focus on stable teams also creates psychological safety and trust; producing resilient, self-organising teams who feel more connected and accountable to each other. They are used to working without being managed and function well in ambiguity, which is particularly important when remote working can lead to challenges in maintaining productivity and team wellbeing. Use of Kanban boards (a workflow visualisation tool) allows teams to self-manage their workflow as the team (and stakeholders) can see work in progress. It also enables transparency of workload between team members, helping to identify instances where team members may require support and thereby fostering a more collaborative team working environment.
Those functions who have embraced Agile have reported significant improvements in people engagement, wellbeing and morale.
In 2020, stakeholder needs in response to the COVID-19 situation presented IA with new opportunities to add more value around assurance, improve the advice they provided and increase their anticipation of risk. Many functions are considering where they need to make changes to their approaches and operating models to enable them to thrive in 2021 and beyond.
Functions who have implemented Agile IA to support audit delivery are seeing how Agile ways of working equip them with the mindset and the mechanism to deliver broader functional change. Large scale transformations can seem daunting, particularly in the context of multiple competing priorities. Applying Agile at a functional level enables the safe and efficient delivery of change by helping IA prioritise initiatives by value, deliver them over short sprint cycles and iterate and learn through continuous improvement.
Communication and collaboration are key to delivering value to stakeholders, with flexibility in response to evolving business needs an absolute must for IA. Agile IA is a way of working that has a built-in ability to pivot to rapidly changing circumstances, with strong communication and collaboration protocols established within the team as well as with leadership and key stakeholders. In 2021 functions should continue to focus on improving ways of working at all levels of their operations to help them elevate their delivery of assurance, insight and value.This is where start-ups are able to compete with large enterprises. Instead of discussing, debating and trying to convince leaders this is a great idea, they experiment! Take Spotify as an example, they see their people as innovators and provide an experiment-friendly culture, by promoting key idea validation questions such as [2]:
– what did we learn? Recommendations – what should we repeat in the future, what should we do differently, and why?
– what should we repeat in the future, what should we do differently, and why? Mysteries – which questions and problems need further investigation?
“The consequence in the business world is that start-ups who are more willing to explore new ideas systematically outflank and often demolish established companies trapped in exploitation mode”. [1]. An example of this is Yellow Cabs in San Francisco being forced to file for bankruptcy protection because of ride sharing services like Uber and Lyft [3].
Organisations are realising that they need to adopt an exploration-based approach in order to compete with start-ups. Agile, Lean Start-up and Design Thinking can be used to aid organisations through iterative and explorative based approaches or experimentation.
An experiment is a hypothesis-led and time boxed approach to testing and validating ideas or solving problems in a rapid, repeatable way. Below is Deloitte’s high-level experiment process, which is enabled by a cross-functional team of between five to nine people using Human Centred Design, Agile and Lean Start-up methods to focus on the core problem/opportunity, to iteratively create solutions, and ultimately test a hypothesis. This results in reduced time to make better informed decision on whether to pivot, pursue or stop.Agility has demonstrated its merits and can accelerate speed-to-market, enhance quality, and increase flexibility while reducing costs and complexity. Various agile methods employ various approaches to implementation, but share characteristics. In this paper we discuss:Architect: establish the key behavior shifts necessary and systematically hardwire them in the organization. This step is foundational to activate the aspiration. Our research shows that to make behavior changes stick, companies need to use an influence model with four levers: role modeling by leaders, fostering understanding and conviction by delivering a compelling change story, building the confidence and skills required to change, and putting in place formal and informal reinforcing mechanisms.
The most successful cultural transformation efforts start at the enterprise level, reengineering core business processes to embed the new cultural aspiration and behaviors. For instance, revamping the sales planning process, quarterly review management, or new employee onboarding—all of these are recurring, critical business processes that take up a significant portion of employees’ time and represent moments that matter.HR delivery in a ‘Fast to Action’ Team: A high-level insight in the ways of working, roles & governance
The F2A team is made up of a solid group of HR resources, composed to accommodate the right roles and capabilities for the solution that needs to be developed. A F2A team can deliver because of their team skillset and their complementary HR capabilities. To make their solution fit for purpose they will work in close collaboration with the business and other support functions where needed. The team generally consists of 3 different roles: Solution Owner, Ways of working coach, and the Delivery Team. The Solution Owner is the person responsible for determining which initiatives have the highest priority. The Ways of working coach focuses on the ‘how’, as he/she coaches the Delivery Team in new ways of working and effective delivery. The Delivery Team, as the name suggests, is the group of HR employees that deliver the solution and connect with the right stakeholders to ensure successful completion.
A F2A team guides their work based on the priorities listed on their ‘Solution Canvas’. This canvas contains the identified business priorities, based on conversations with key stakeholders (e.g. CEO, Business Unit Lead) and pre-defined criteria and requirements. New requests for business driven projects that were not on the Solution Canvas, will be reviewed by the Solution Owner. The Solution Owner selects the projects that will bring most business value, taking into account the availability of the required capabilities and capacity. The basis of the F2A team is that the resources stay together and do not rotate. This creates focus, commitment to deliver results, and deep expertise.
Although not always in the nature of HR, it is recommended to have clear KPIs and measurable deliverables when working in a F2A team to ensure the right outcomes are achieved. Finally, when the job is considered done, the team hands over to the business and the standing HR organization and moves its focus to a new priority. This might sound obvious, however it is only possible when the definition of ‘done’ has been clearly articulated upfront. The F2A teams exist as long as they deliver value, if not it is dissolved.Supports financial institutions around the world as they pursue a range of strategic, digital, and agile transformation opportunities and coleads agile service work in banking
Works with clients to define, develop, and implement digital solutions to succeed in an ever-accelerating world. Helps large organizations to become more agile, empower teams, create nimble structures and accelerate innovation.
May 7, 2018 Agility gets hailed as the new order for organizations striving to unlock value in an uncertain and rapidly changing market environment. But, as clients occasionally ask us, “What about its drawbacks?”
As a philosophy, agility has few tangible downsides – but relies on being applied for the right reasons, in the right places and in the right way. Done well, it delivers tremendous impact. Misused, it can trigger disruption and productivity loss.
Firstly, agile can prove difficult to get right. Typically, its new ways of working differ from what came before and it’s easy to go astray. Watch for these common pitfalls:
Copy-pasting : Agile principles are universal, but their application varies depending on the work targeted (e.g., product development vs. sales operations). Emulating someone else's model without a clear vision and deep understanding of agile can cause significant harm.
: Agile principles are universal, but their application varies depending on the work targeted (e.g., product development vs. sales operations). Emulating someone else's model without a clear vision and deep understanding of agile can cause significant harm. Partial agile: It occurs by applying agile to parts of the value chain and leaving the rest as-is; for example, handling agile product development within a traditional go-to-market setting. To achieve full benefits, agile should be executed end-to-end.
It occurs by applying agile to parts of the value chain and leaving the rest as-is; for example, handling agile product development within a traditional go-to-market setting. To achieve full benefits, agile should be executed end-to-end. Insufficient capability building : Agile succeeds when people – including leaders – possess the right set of skills and mindsets, e.g., entrepreneurialism self-management abilities. These must often be strengthened.
: Agile succeeds when people – including leaders – possess the right set of skills and mindsets, e.g., entrepreneurialism self-management abilities. These must often be strengthened. Diluted focus on performance: Self-management sometimes becomes a license for agile teams to stop planning, reporting and delivering results. However, agile requires more discipline, not less.
Self-management sometimes becomes a license for agile teams to stop planning, reporting and delivering results. However, agile requires more discipline, not less. Short-term bias: Agile software development teams must continually decide between new features and optimizing existing software to avoid technical debt. Unless managed, agile tends to bias towards overemphasizing new features at the expense of long-term quality.
Secondly, adopting agile so that it unlocks full value potential is a significant strategic investment. While structure and process changes are considerable, the most underestimated costs often relate to people and tools. Principal investments include:
Productivity loss during the learning curve : Inevitably, the first few agile development projects suffer from productivity loss (averaging 14 percent). But when agile teams conquer the learning curve, they see productivity boosts (averaging 27 percent vs. traditional teams).
: Inevitably, the first few agile development projects suffer from productivity loss (averaging 14 percent). But when agile teams conquer the learning curve, they see productivity boosts (averaging 27 percent vs. traditional teams). Leadership time spend : Agile brings fundamental changes to how an organization is run and led, especially when done at scale. Senior leadership must spend sufficient time developing the agile operating model and supporting its application (e.g., communications, role modeling new agile behaviors).
: Agile brings fundamental changes to how an organization is run and led, especially when done at scale. Senior leadership must spend sufficient time developing the agile operating model and supporting its application (e.g., communications, role modeling new agile behaviors). Potential loss of key employees : Agile unavoidably disrupts the status quo and requires significant adaptation from employees, especially middle managers. Be prepared to lose employees who want off the agile train.
: Agile unavoidably disrupts the status quo and requires significant adaptation from employees, especially middle managers. Be prepared to lose employees who want off the agile train. New talent management systems and approaches: These rank among the hardest aspects to tackle, often requiring surprisingly large investments to talent management and HR systems. This can include investing in capability-building programs, elevating branding and value propositions to attract the right talent, changing compensation bands and structures, and reimagining career paths and individual performance management, among other things.
These rank among the hardest aspects to tackle, often requiring surprisingly large investments to talent management and HR systems. This can include investing in capability-building programs, elevating branding and value propositions to attract the right talent, changing compensation bands and structures, and reimagining career paths and individual performance management, among other things. Improvement of the technology infrastructure : Heavily tech-dependent companies must often invest time and resources up front to enable agile, e.g., reducing technical debt and automating process steps such as testing. In the short term, this will reduce resourcing for new feature development.
: Heavily tech-dependent companies must often invest time and resources up front to enable agile, e.g., reducing technical debt and automating process steps such as testing. In the short term, this will reduce resourcing for new feature development. Employment of temporary capabilities: A sure way to fail is to adopt agile without enough people who’ve done it before and know what good looks like. These capabilities are often scarce in-house and need to be contracted at a premium (e.g., agile coaches, consultants, contract hires).
Agility can have large impact – but only if done properly for the right reasons. It’s not a "silver bullet." The most successful agile adopters employ a well-aligned, situation-specific strategy that weighs the investment against expected benefits.Your responsibilities will range from shaping strategic product designs to managing and transforming agile teams - working with Fortune 500 companies to native digital start-ups.
In this role you will be a part of a highly collaborative team who are adept at solving complex digital problems, combining unparalleled business knowledge with a world-class agile development process. You will be a part of cross-functional units to design, build and deliver new and exciting capabilities for our clients - with the emphasis on creating the foundation for rapid and effective implementation of systems that maximize value from day one.
Your goal will be to disrupt the way companies and organizations work and increase organizational agility for innovation, helping our clients scale agile in their organization is key to succeed at this. To be successful in this role you will need to have strong communication skills to coach and mentor teams and leaders on Agile values and principles. You will be comfortable structuring a large-scale Agile transformation with uncertain or changing constraints.
You will also coach clients on a variety of digital topics including product management, design thinking, engineering culture, and DevOps, and you'll engage with consulting teams as a “do-er” and actively problem solve, create content, and facilitate training as required to best serve our clients.September 24, 2018 Organizational simplicity. Fast execution. Clear responsibilities. Fluid teams. Agile planning practices. Companies in every field are rushing to make these organizational changes to compete in today’s marketplace. But one industry that has been lagging more than most – heavy industry – is using innovative ideas borrowed from the tech sector to bolster performance and respond to increased environmental rules and the need for further cost savings.
What one global chemical company is doing to create agility in its R&D operation offers an inside look at the beneficial impacts such organizational makeovers trigger for not just this industry, but others as well. The company believed it could speed project execution and save a bundle in the process via its 100-plus member process-improvement R&D team.
Projects that once took months to move from idea to initiation now just take days and, in general, are 75 percent faster. Rapid coaching of the R&D team sparked daily improvements. Delegated decision-making replaced the common “hurry up and wait” culture. A seismic benefit: The first agile R&D team doubled its productivity while – in just five weeks – it identified $150 million in potential annual savings. Since then, identified savings have more than doubled as more R&D teams have made the transition to agile.
Projects that once took months to move from idea to initiation now just take days and, in general, are 75 percent faster.
As the backdrop, most R&D team members were chemical engineers with PhDs who spent much of their time alone in their respective offices. Many knew their plant’s front-end processes but had no clue about its back-end troubles. Interaction with internal business customers – and each other – was inadequate, leading to delays and rework. And their time was split across multiple projects that led to inefficient multitasking and lack of accountability.
The transformation developed through the department leaders, who handpicked team members, making sure the team reflected different age groups and behaviors. Everyone got a brief training on the agile concept.
The team applied Scrum – an agile methodology developed by the tech industry for rapid, iterative software development with a “test and learn” mindset. It adopted one-week “sprints” to identify high-value process improvements in the plants, and each week, it held reviews with internal business customers to iterate end products. Accountability was instilled through complete team ownership of the project and peer pressure. Plus, the team got instant feedback about performance.
This was also essential to meet the team’s personal needs. They were used to working independently with vastly differing schedules. We set a 9 a.m. to 3 p.m. schedule for Monday to Thursday to account for personal needs such as child drop-off and pick-up, and Friday was open for them to handle non-project related work. But importantly, during 9 a.m. to 3 p.m. Monday to Thursday, they were 100 percent dedicated to the Scrum team with no exceptions.
Of course, challenges exist that can stymie success. Principally, leaders and employees must develop new mindsets and capabilities that can differ markedly from before. And leaders must manage on output – defining the goal – rather than input, or giving the task.
Highly agile leaders and teams realize that change is constant and adopting to a turbulent global environment is part of the future. Understanding the realities that organizations need to adapt again and again means having intentional, proactive approaches to change. Continually scanning the organization’s environment, viewing challenges with fresh eyes and a willingness to rethink past assumptions, is the path forward to future success.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.Serves clients on a broad array of topics ranging from strategy to organizational design and transformation across industries, including consumer goods, retail, and fashion; leads our organization design work and helps companies through multiyear organizational transformations, focusing on bringing operating models in line with the realities of the markets, strategic shifts, and other success factors
Advises leading global companies in the consumer industry and other sectors on how to optimize organizational design and operating models to improve performance and culture, and boost organizational agility
August 19, 2019 When done well, an organizational redesign fosters improved strategic focus, higher growth, better decision-making and more accountability.
However, a McKinsey survey revealed that only 30 percent of organizational redesigns are successful in terms of achieving overall objectives and improved performance. That means a daunting 70 percent of transformations fail.
Why? In the design phase, meddling by too many cooks often obscures the vision of a future operating model. Accommodating multiple opinions means the design becomes fragmented and vulnerable to individual pain points. Resources can get tied up in tasks that don’t add real value, unnecessarily prolonging the process.
More than 80 percent of executives have gone through an organizational redesign at their current company. They know that a transformation is a marathon. But to get to the finish line, it pays to do implementation sprints. That means taking a simpler, iterative approach; learning as you go; and correcting course more frequently. Under this approach, concept development and implementation are linked, running in parallel.
One high-end retailer, for example, faced difficulties with its siloed culture when redesigning its operating model and online assortment strategy. A series of focused two-week meetings, led by cross-functional teams, helped to foster a common view of what needed to change. The quick implementation of changes led to an impressive increase in its online assortment from 30 percent to more than 70 percent in just three months.
Be bold: Set a clear and ambitious target that will help you substantially transform your organization and let it guide your future operating model. Slim it down: Create a simplified first version of your envisioned end-state that will still deliver a significant amount of impact in the first phase of implementation. Prioritize change initiatives: Don’t kick off all new initiatives at once. Instead, be clear about how the initiatives will be sequenced and how they relate to one another. Conduct implementation sprints: Kick off the implementation in short design-test-apply cycles. Adapt and hone when needed: React to requirements that emerge during the transformation and course-correct whenever needed. Keep your eye on the ball: Stay focused on the actual end product: a truly transformed organization, not a perfectly designed plan. Embrace constant reality checks and adapt the plan accordingly. This helps to concentrate resources on those areas that contribute the most value.
Change is not easy, and the odds are hardly in any transformation’s favor. But tackling the root of the problem by simplifying the design and using a pragmatic approach—through implementation sprints—will boost the likelihood of success.
While we all aim for perfection, we should not do so when designing a new operating model. Sometimes complex concepts, which theoretically are superior to simpler plans, don’t get implemented. Instead, they can draw attention and energy away from more fundamental changes and delay the entire transformation.Agile is one of the hottest management trends for companies across industries, and with good reason. This approach, which encourages collaboration, responsiveness, and ownership, has helped to transform different parts of an organization and generated significant performance improvements. Over the past decade, leading companies have applied agile methodologies to IT, software development, project management, and delivery organizations. All of these functions have volatile processes with multiple inputs and high uncertainty, which made them natural candidates for agile.
To date, companies have been much slower to implement agile in operational functions, in part because executives assume these areas are ill suited for this approach. Customer care, for example, has less uncertainty than other functions, with plenty of repeated tasks and requests. Prevailing wisdom has been that rigid control is necessary in customer care to increase efficiency. Accordingly, this function has long focused on execution and used lean and Six Sigma to improve performance while standardizing interactions and investing in tools to guide service agents in their interactions.
However, the human element of customer care introduces variability and unknowns: customers increasingly demand service tailored to their needs and want their requests resolved without being transferred multiple times. What’s more, the imperative to become more customer centric and adapt to changing customer preferences now calls for introducing new elements from agile.
Agile has tremendous potential to revolutionize customer care and unlock the value of frontline employees, who represent a huge untapped resource. By empowering agents through an agile approach, organizations can infuse customer ownership and creative problem solving in customer care. Early adopters have already achieved impressive results in their contact centers, increasing first-call resolution and efficiency while lowering operational costs. A combination of agile best practices and a sustained investment in culture change can position organizations to capture similar benefits in their customer-care functions.
Currently, many customer-care functions are pursuing a traditional approach focused on standardization. Contact centers often resemble automotive factories, in that leadership carefully plans and orchestrates every step. Due to this top-down dynamic, contact centers have typically been siloed functions, with agents who have adopted a reactive, transactional mind-set. In today’s customer-centric environment, the step-by-step customer-care model is insufficient to resolve today’s more complex customer inquiries. Therefore, a fresh approach—one that harnesses the collective knowledge of frontline agents—is critical to delight and surprise the customer.
The agile methodology, as deployed in IT and product development, is not completely suited for customer-care functions, but it can be adapted in several ways to significantly boost customer experience.
Ownership. A major challenge in classic care organizations is that tasks and competencies are very scattered. With training, agents can quickly resolve simple requests, but they must typically forward complex ones to more skilled agents. The result is that, in many organizations, the first-call resolution rate hovers around 40 percent. Indeed, customers of major companies often complain about being stuck in the organization or being dropped after the third transfer.
Over the past decade, companies have incorporated digital to resolve standard requests within customer care. Yet many of the tasks left to agents are more complex, so a different approach is required to provide excellent service. Taking a page from pure agile methodology, a team or department gets ownership of a certain customer group and is entrusted to take care of all their needs. The team is also responsible for a customer’s satisfaction, revenue, and associated costs of service.
Self-managing. The agile way of working, with a focus on self-managing teams, can help customer care attain the next level of performance improvements. Teams and departments are guided less by input variables (such as average handle times and utilization) than by common targets (such as customer satisfaction, total revenue, and waiting times). Through daily performance discussions and the freedom to adjust processes and care strategies, the team can provide better quality care.
Capabilities and team. Customer-care functions must build capabilities in their frontline organization to more effectively provide end-to-end care. Experts that have previously handled more complex requests, for example, are being integrated into agile customer-care teams or serving as coaches on the floor, joining calls as needed. These cross-functional teams can resolve more than 95 percent of customer requests during the first contact, preventing a negative experience or multiple handoffs.
Enablement. When customer-care agents are part of the resolution process, it accelerates learning; and the combination of experts with frontline agents creates a culture of knowledge and learning. One of the better-known industry examples is US telco T-Mobile, which has a model called “team of experts.”
Agile routines. Most customer-care organizations conduct performance reviews, but they are focused on evaluation and payment rather than joint learning opportunities. Introducing agile routines as biweekly reviews enables teams to assess their achievements and performance of the previous period and decide on priorities to work on for the next period. In addition, teams can implement daily, 15-minute huddles to track progress during the past day. These structures help the team embark on a learning journey that is dedicated to serving customers more effectively and addressing their personal needs.
Leading companies have already applied agile approaches to the initial steps of the customer journey. However, these stages are only a fraction of overall interactions, leaving tremendous potential for improvement (Exhibit 1). Capturing this value requires the entire organization to adopt agile principles and coordinate its collective efforts.
Exhibit 1 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
For customer care, agile principles represent a unique approach: customers are served end to end by empowered agents who work in self-managing teams. Two case studies demonstrate how agile can be used to radically change customer-care organizations in different industries.
T-Mobile was struggling with very low first-call resolution and high customer dissatisfaction. Its agents were often forced to forward calls through the organization to try to address issues, resulting in too many handoffs and declining customer satisfaction. The telecom company recognized that revamping its first point of contact with customers would be a crucial step toward achieving better outcomes. The steps the company took involve multiple elements indicative of an agile methodology.
Executives call their approach “TEX,” for the team of experts that focuses on resolving the requests of their customers and building a personal emotional connection with each customer. These teams, which include a mix of customer-service agents and specialists, implement a collaborative approach to efficiently handle more complex requests. Calls are accepted by the general customer service agents, called “experts.” In the event they are unable to resolve the issue, they bring in a specialist. This approach has two effects: the customer’s request is resolved, and the expert embarks on a learning journey. Thanks to this structure, agents can often resolve similar requests on their own in the future.
At the same time, digital tools are applied to automate standardized tasks so that agents are freed up to innovate, and the specialists are available to collaborate with agents to troubleshoot, share their knowledge, and debrief after calls. Once a week, specialists and agents participate in upskilling sessions where they highlight best practices. Classic team leads are replaced by coaches to ensure sufficient time for development, and administrative tasks are pushed to a support team linked to the department head.
While in the past agents addressed the full range of customers and requests, T-Mobile’s new method allocates a fixed group of customers to a set of agents across several teams. The designation creates greater ownership: in most care strategies, agents who transfer a customer might not come into contact with that individual again. With this new approach, agents know the customer will come back again if they can’t resolve the root cause of the issue. This setup combined with the team’s “profit-and-loss ownership” create incentives for performance on metrics such as revenue, total cost, and customer satisfaction.
In addition, this system combines classic contact-center principles, such as routing and workforce management, with all five agile elements, enabling T-Mobile to significantly outpace its existing customer-care efforts on several key performance indicators: first-call resolution increased by 14 percent while net promoter score rose by nine percentage points. And in a reflection of the efficiency and visibility that TEX promulgated, the contact center reduced the number of times customers were transferred by 70 percent. The new approach has also had an impact on employee morale and talent retention: the emphasis on engagement and teamwork among the squads led to a 40 percent drop in employee attrition. In this way, T-Mobile turned a challenge into a competitive advantage.
A financial services provider faced a different challenge: its contact center was taking too long to resolve requests—sometimes as much as eight weeks. One reason for this poor customer service experience was that the provider had not designated an owner of the customer journey, which created siloed functions that were focused on tracking their own performance metrics without regard to overall goals. To remedy this situation, the provider aimed to streamline processes and reduce the number of requests that had to be handled by specialists, who were sometimes overwhelmed by the volume of issues that crossed their desks.
The application of agile principles led the provider to create self-managing, end-to-end teams composed of customer-care agents with colleagues from other relevant functions (Exhibit 2). Serving as single points of contact, these teams took ownership of issue resolution. This streamlined process improved customer engagement and significantly reduced the number of internal handoffs. To strengthen connections with customers, the provider coached agents to treat requests as if they were coming from personal friends. The provider also aligned performance metrics with the end-to-end customer journey to better track the ability of the team to resolve issues.
Exhibit 2 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Establishing ongoing communication and teamwork across the contact center benefitted both customers and the provider. In just 12 months, customer satisfaction increased by 20 percent, while contact-center costs fell by 30 percent and employee satisfaction rose by 10 percent. The increased visibility also reduced unnecessary rework by approximately 60 percent. The provider used the success of the pilot to roll out the new customer-care model to locations in nearly a dozen different countries.
The agile playbook is well established, thanks to its success in other functions such as delivery organizations and project management. Still, the unique dynamics of customer care require companies to tailor plans for implementation and scaling. Customer-care executives should seek to integrate four best practices into their agile strategies.
Identify customer-care functions for selected pilots. The initial pilots should be concentrated in a discrete area of customer care—for example, around a product line or specific region. The process of mapping customer journeys end to end can help agents think about how their engagement at any given touchpoint contributes to a positive customer experience. The top priority when evaluating candidates for pilots should be to ensure that agents can get as close to the customer as possible. Companies must also determine how best to cluster their teams, as this composition has a direct impact on performance.
All of these decisions share a common goal: to empower employees and give them the perspective and support to think more proactively and creatively about customer interactions. In some contact centers, teams have more flexibility in rostering and staffing plans and eventually transfer part of the profit-and-loss authority to individual teams.
Create an agile culture and mind-set. Since contact centers have traditionally been highly structured, with a command-and-control management approach, moving agents from a purely executional stance to a more engaged, problem-solving mind-set is critical. In an agile contact center, everyone needs to work together and support one another. Employees who may have become used to the standard ways of working may need a compelling reason to adopt a new approach; a clear change story can be the stimulus.
In addition, the physical layout of a contact center can send strong signals about the need to embrace collaboration. At one European contact center of a major telecommunications company, all of the employees who served specific customers were located on one floor with an open seating plan. Specialists were a visible presence, walking the halls, sitting next to agents, and sharing feedback on issues and how to resolve them. These measures serve to make call centers less anonymous and reinforce team spirit.
Prepare for the global rollout in waves. To scale successful pilots, companies must pay special attention to preparing employees for the shift to agile in advance, since selecting the right people to lead the rollout is crucial. Indeed, companies want to put at the vanguard people who are well respected by their peers and can be effective evangelists for agile. And by modeling the desired behaviors, these leaders can reinforce the collaboration and dialogue necessary to provide better service to customers. T-Mobile, for example, had a competition to choose people to participate in the effort. Executives should also reach out to internal work councils to ensure they are on board and understand the new opportunities that agile can offer to motivated workers.
In addition, companies should upgrade their workforce to ensure they have the capabilities to excel in agile. Professional development and training programs can address the hard skills, but it’s just as important to create an environment that helps employees gain the soft skills of teamwork and mentoring.
Go live and then improve continually. The beauty and challenge of an agile approach is that to be effective it must adapt to changing customer needs. Since the contact center has nearly constant engagement with customers, frontline workers will be the first ones to detect emerging issues, recognize trends, and then develop and test new ways of working to address them. Above all, teams need to remain flexible and be open to recreating themselves on a regular basis.
By keeping teams intact, companies can benefit from institutional knowledge and help to maintain morale among workers, who will take pride in having end-to-end responsibility for a product or region. Companies might need to invest in reskilling for agents in certain product segments or regions, depending on evolving customer preferences.
In the coming years, customer expectations will continue to evolve—likely at an accelerating pace, making the quest to please customers ongoing and continuously changing. Agile can not only improve customer-care outcomes in the near term but also lay the organizational foundation to respond quickly to shifting customer preferences. The prize is simply too big to ignore—not just more satisfied customers but also higher-performing customer-care organizations and happier employees.The financial industry, with its legacy systems and processes, continuously demands more projects with a fast time-to-market conversion. Therefore, digitalization has become a driver to revolutionize the industry. Companies disseminate information about products and services, processes or customer behavior in electronic form. The products and services themselves are digital. Furthermore, the speed and power of these digital structural changes is often underestimated. Traditional banks are clearly late adopters when compared to other competitors (e.g., Digital Banks) or industries. It is then in their best interests to implement innovative digital solutions to remain relevant and not lose the connection to either complementary third-party product offerings or competitors.
The banking sector, with long-term projects (over one year), is facing a tremendous change within the next 3 to 5 years. This time of transformation is a major strategic challenge for the executive management of every bank –probably the biggest in recent decades. This sustainable transformation and development ranges from the front office to the back office across every department. Professional and personal requirements as well as qualitative competences required from the employees raise are steadily increasing. Above all, high levels of IT competence and IT affinity are becoming more and more important to all employees and executives. The complexity of IT and the growing security requirements of the digital age are enlarging the number of software solutions, business apps and platforms that support the business. Active cooperation between management and IT consultants is a practical idea to properly adapt and integrate security and business processes.We previously explored tribal culture and planning, where the move towards ‘Agile Finance’ was seen as a move towards a ‘do it once and do it right’ environment. Pivoting our focus now to agile budgeting and the tools that support flexible forecasting, we first observe the process of costs estimation for IT projects (the birth place of agile). Exploring these examples helps to distil the ingredients that enable cost preparation and forecasting flexibility, and then explore how these can be applied to bridge the current IT Finance gap.
For CFOs looking towards change, the questions remain: How do we best prepare the organisation for the future? How do we derive value and create benefits?
There are no easy answers and the change for each organisation is unique. Essentially, the organisation’s design must be sufficiently robust to manage the known challenges of today, and the unknown challenges of tomorrow. To achieve this from a budgeting and planning perspective, it is important to address the perceived tensions between strategic long-term planning and short-term agility, as well as the relevance of shorter budget cycles for seemingly long-term commitments.
The first point to make is that, within the right structure, an agile finance function allows an organisation’s longer term vision, planning and budget forecasting to be shared more effectively through teams and in ways that create alignment and resonance.
Agility in Finance can and should include an increased understanding of ‘cost cycles’. Relatively fixed BAU costs (such as rent) can be managed using agile ‘zero’ budgeting, which is similar to the idea of zero-based budgeting. This involves keeping certain ‘core’ (fixed) blocks budgeted in the traditional way, while the variable blocks are budgeted through an agile ‘zero’ methodology. The advantage of maintaining both is that, in time, the so called fixed blocks of costs may become increasingly flexible as organisations further integrate agile ways of working and change their perceptions of ‘fixed’ costs.
The combination of a shared vision and an agile organisational structure leads to more efficiently structured teams over the long term, where the use of shared responsibilities can optimise and reduce resource requirements. This increases the available options to customise team structures by making Finance a ‘present and accessible’ part of organisation-wide teams. From here, organisations could consider supplementing, or supporting this flexible team structure through additional agile methods such as Flow to Work (F2W). The Flow to Work (F2W) methodology is the concept of where pools of resources can be moved in a nimble ways to address volume challenges over peak periods. For example, moving resources to Finance Guilds where agile teams of specialists in a particular area (e.g. a ‘payment’ Guild with a deep knowledge of EFTs or cash) work across multiple business chapters or ‘tribes’.
As an example, the illustrated below uses a customised value chain, where team structures are based on tribes across functions.Despite years of championing transformation initiatives, too many sales organizations still struggle with lackluster performance. Big investments in training, sales technology, and sales and marketing support have delivered negligible returns. Sales leaders have become frustrated.
It is no surprise that change at this scale is inherently difficult. We have written before about the fact that 70 percent of all transformations fail. There are many culprits in failed sales transformations, including the size and dispersed nature of sales organizations, high attrition rates, and a culture of decision making based on “gut feelings.”
It doesn’t have to be like that. In our work with thousands of sales organizations, it has become clear that advances in the “science” of change—digital, analytics, and supporting methodologies—can make a big difference, increasing the odds of success three to four times. This scientific approach to sales transformations is made up of four elements (see exhibit):
Exhibit We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Too many sales transformations are doomed to fail long before implementation has even started. Sales leaders spend all their energy designing the perfect commercial operating model without stepping back to assess whether what looks compelling on paper is achievable and sustainable in practice, or even why they want to change in the first place.
The best companies start by using data and analytics to anchor the transformation on where they can capture growth. They identify pockets of opportunity, assess the sales function’s ability to capture that growth, and identify the necessary adjustments. The other benefit of this analytics-driven approach is that progress can be easily measured.
A European telecommunications company adopted a micromarket approach to find pockets of overlooked growth. The analysis—based on a variety of data including some provided by reps themselves—revealed exciting opportunities in some markets, while highlighting other, less promising, markets where competition was intense and there were relatively few unserved customers. The company prioritized the 500 micromarkets by growth opportunity, allocating resources accordingly throughout the transformation. Ultimately, it saw 5 to 10 percent more in-store visits by optimizing its store footprint in the best markets while shaving total store costs by 5 percent through eliminating, resizing, or refocusing less profitable locations.
With a clear view of what they want to achieve, successful sales organizations quickly pivot to how to make it happen. This is crucial in building sustainability into the transformation from the get-go. By understanding what the organization’s and individual employees’ existing capabilities are, where they need to be strengthened in order to make change stick, and ensuring that the culture and the tools change too, the organization can flourish instead of flounder.
Successful transformers take a methodical approach to testing readiness, looking, for example, at how well leadership is aligned behind the program, whether performance management for a widely distributed sales force is already in place, and whether the incentive systems match the desired change. There is only so much change that an organization can absorb, so it is critical to prioritize and sequence initiatives. This requires pressure-testing the proposed sales strategy against commercial realities, such as market headwinds, customer preferences, potential for channel conflict, and other considerations. Leadership then translates these priorities into a road map for developing the capabilities that will drive the targeted initiatives.
A global chemicals company wanted to improve its understanding of customer needs in order to target its short-term R&D pipeline. It used analytics to help identify what was hindering its ability to do so effectively and realized that organizing reps by region instead of vertical meant that they lacked the necessary deep technical insights to relay ideas back to the pipeline. It was clear an organizational structure change would be required. However, the company didn’t stop there. It also conducted a robust data-driven capability assessment to identify the full complement of skills that would result in the greatest ability to spark innovation. Finally, it determined that enabling this change would require adjustments to incentives, reporting structures, and performance-management systems.
The company then designed a go-to-market transformation that solved not just for what its future state would look like but also for how it would get there. This approach helped increase the size and quality of the pipeline by more than 30 percent in the first three months of the effort, with sustained gains well beyond that. The company also doubled the impact of innovation on revenue growth.
A scientific approach shouldn’t be mistaken for simply using analytics and data. Experimentation is the foundation of good scientific method, and that is equally true for sales transformations. In a world where change happens quickly and answers are rarely clear, a dynamic approach grounded on testing, learning, and adapting is the only one that consistently works.
For an agile approach to work, people from across functions (such as marketing, pricing, sales operations) need to work together to design the pieces of the puzzle. The most advanced organizations start by using analytics to target the highest-value transformation opportunities. Then, the change leaders must identify and build the simplest tool or process to capture that opportunity—the so-called “minimum viable product” (MVP). Once the MVP is built, small agile teams test it with real customers, using analytics and A/B testing to develop a clear perspective on what works and what doesn’t. Then they iterate the product or service accordingly. Agile principles ensure that sales teams deliver customer satisfaction early.
A B2B transportation-and-logistics company that was struggling with depressed margins noticed that rep performance varied enormously across its 6,000-strong sales force. It needed to introduce a new way of selling that used advanced analytics to target customer opportunities, improved rep capabilities to negotiate deals, and provided a new performance-management rhythm. Given the complexity of the program and uncertainty around what would work, sales leaders realized they needed to adopt a more agile approach.
The company created a prototype targeting tool, new sales scripts, and a customer-relationship-management (CRM) dashboard to help track performance against target. It began to pilot and iterate these solutions with a select group of sales managers and reps. The teams met every day to discuss customer feedback and regularly adjusted their approach accordingly. This enabled many rapid iterations, and over time, new capabilities were introduced in these daily sessions until the team had a radically improved commercial model.
While this agile approach is increasingly common, organizations often stumble because they don’t account sufficiently for how to ensure the adoption of the solutions that agile teams develop.
In the case of the logistics company above, sales managers in the pilot regions explicitly used agile experimentation and rapid feedback loops to understand where training materials should be improved, whether anything was missing—for example, if the initial training was light on handling customer objections to the new sales approach— and where reps were struggling most with the new process. They were then able to iterate and find simpler ways to introduce the new content using a series of field-and-forum workshops and digital modules. These were tested again in a few other locations to ensure they were effective before the new process, and the new way of communicating it, were introduced to the rest of the 6,000 reps.
3. Continuous capability building and performance management: Use tech to build critical skills and track change
“Great sales leaders run their operations with the precision of an engineering firm.” That quote, from the head of adviser sales at a US financial-services firm, neatly summarizes the idea that a robust performance-management system is the beating heart of a sales transformation. It helps set the direction, establishes clear metrics, tracks performance, enables recurring dialogues, incentivizes desired behaviors, and helps managers continuously act to improve outcomes. The problem with these systems, however, is that their insights are backward looking, and the time between their delivery and action taken based on them can be long.
Data and analytics can enable much quicker and more forward-looking action. The best systems deliver immediate insights into what’s working and what’s not, flag deviations from expected performance, and recommend opportunities to improve. When a tech company attempted a large transformation to capture new growth, it tried to realign coverage to match opportunities, build front-line capabilities, and redesign compensation structures, but results were slow to arrive. It turned out that it had limited data on sales, margins, and products sold at the rep level, and no performance-management systems.
The company turned to analytics and an automated report system to create dashboards personalized for each salesperson, highlighting the opportunities they needed to follow up on. Each day, reps now see their top opportunities aligned to the strategic goals of the business, which helps them prioritize their actions. The dashboard also helped managers all the way to the C-suite identify the best-performing reps, see what opportunities they had closed, and where they might need coaching. Reps could also flag where they needed help, which ensured that priority opportunities got the right level of attention.
The combination of reporting, enablement, and coaching delivered an enormous impact very quickly: a 7 percent uptick in revenues for that quarter. This didn’t require a significant investment, just making the information available at the individual level.
Based on what we see in the metrics, performance-management systems can achieve their best results even if they are automated or self-administered. For example, a company looking to improve account planning could set up its CRM tools to check that reps complete planning templates ahead of big sales meetings. The tool could then prompt reps to analyze recent order patterns, develop a clear precall plan, anticipate potential objections, and receive approval from their manager on their approach. Email reminders and other prompts could be sent to the managers and reps along the way to ensure compliance with the new way of working.
A change is transformative only if it sticks. Without support, initial enthusiasm tends to falter and progress can break down.
Leading companies combine advanced technologies and personal support to ensure that doesn’t happen. They hard-wire changes into the fabric of the organization by digitizing processes and using analytics to support new behaviors. They might, for example, price for value rather than volume, segment and prioritize customer opportunities by lifetime value, and track performance deviation and recommend interventions.
A leading manufacturing company recognized the benefits of adjusting its go-to-market approach from “one size fits all” to a model tailored to each segment. However, experience had shown that simply segmenting its customers and training the sales force on the nuanced service models for each was unlikely to work. Instead, the company used technology to embed the desired changes into every facet of its go-to-market strategy.
It began by outlining each customer segment’s unique needs across such factors as preferred method of sales interaction, supply-chain requirements, technology support, and customer service. With those preferences clear, sales executives called on tech to automate some processes and reinforce others.
For example, the CRM workflow was updated to match each segment’s preferred sales motion: customers who preferred digital interactions were switched to a more automated reordering process, while others received high-touch treatment from reps. Sellers were constantly reminded of best practice as they moved deals through the funnel, including prompts that helped hard-wire the changes the company sought, such as reminders of what services or support was available, suggestions for whom to involve from other functions, and guidelines on how much time to spend on the account. The result was significantly improved service levels and customer satisfaction, and a 4 percent improvement in return on sales.
Relying on technology to drive the change alone, however, is a mistake. For change to stick, managers need to provide sales reps with personalized coaching, often supported by analytics that highlights performance challenges, as well. The best managers focus on “microinterventions” to coach their people with feedback as needed, rather than waiting for more formal regular review sessions. The key is making sure all this coaching is done with the same level of scientific rigor as the rest of the transformation by focusing on the areas of greatest value. That includes, for example, being clear about which people to target for training (data shows that training often has the greatest impact on middle performers, who tend to have the greatest achievable upside), or tailoring feedback to a person’s performance trajectory.
As one sales executive noted, “Despite all the benefits of automation, we made sure we routinely checked in with our team to hear from them first hand whether we were sustaining our new model.”
Sales transformations aren’t new. But by understanding how to use data, analytics, and the personal touch, sales leaders can drive change that matters and sticks.The unfolding of COVID-19 has brought uncertainty to all businesses around the globe. Brands everywhere have worked to navigate the disruption, maintain or adjust their business continuity and stay afloat in these uncertain times. Many organizations have altered their operating models to fit the changing circumstances, while others have adapted their services to help the greater cause.
The quick thinking and pivoting of brands across the industry is a real-life case study in what’s known in the industry as “agile marketing.” Today’s connected consumers have more influence than ever in driving the conversation around brands. Companies sometimes only have hours to respond if they want to remain relevant. This means that, in order to maintain their edge, marketing teams should have tools to keep up with the speed of culture.
Agile marketing often thrives on quality and flexibility, and marketers who are excel at it typically depend on a few leading practices to guide them. They develop a clear point of view. They have processes in place to quickly and succinctly respond to complex reputational challenges. They also tap increasingly sophisticated predictive tools to put brands in the middle of conversations when they’re likely to peak.Disruptive business, technology, and societal forces are causing an unprecedented change in the workplace. Our human capital blog, Capital H, offers insights and learnings on the changing nature of work and humanity’s evolving role in it.
Explore the blog by browsing previous topics, subscribing to receive our newsletter, and sharing your opinions on these top-of-mind subjects. Join the conversation and tell us what you think.Your responsibilities will range from shaping strategic product designs to managing and transforming agile teams.
In this role your goal will be to disrupt the way our clients, which range from Fortune 500 companies to digital native startups, work and increase organizational agility for innovation. You will train client teams in the agile framework and a new way of working.
You will be a member of a highly collaborative team who are adept at solving complex digital problems, combining unparalleled business knowledge with a world-class agile development process. You will be a part of cross-functional unit that will design, build and deliver new and exciting capabilities for our clients.
To be successful in this role you will need to have strong communication skills to coach and mentor teams and leaders on Agile values and principles and be comfortable structuring a large-scale Agile transformation with uncertain or changing constraints.Has there even been a time when customers were more demanding of the companies serving them? Industry 4.0 technologies—many barely imaginable only a decade ago—have already enabled genuine breakthroughs in cost, convenience, and customization, creating extraordinary value for buyers while raising the performance bar for producers ever higher.
And then there’s the volatility that never entirely disappears, flaring up in crises that can upend everything from supplier relationships to entire business models—all prevalent in today’s current landscape as Covid-19 creates widespread disruption. It complicates leaders’ efforts to make lasting changes in their organizations—efforts that historically have required years of sustained effort to take root.
Institutions ranging from aerospace manufacturers to tax authorities have nevertheless persisted, focusing their efforts on lean management and agile. Both methodologies have proven their worth as integrated systems for helping improve performance.
The mistake we find many leaders and organizations making is believing they need to choose between the two. In fact, that’s not true. Not only is choosing unnecessary, but the two methodologies complement one another in ways that increase the impact they generate, often by deploying Industry 4.0 technologies to speed transformation. Under this best-of-both approach, top-performing companies combine tools, ways of working, and organizational elements from each to form a custom solution that meets the company’s unique needs more completely and quickly than has been possible.
Lean management has helped organizations create value for over 70 years. Starting in the 1940s with its roots in the Toyota Production System, lean management has spread from manufacturing to service operations and just about every other department and function at companies, governments, and non-governmental institutions around the world. Lean organizations seek to identify and eliminate activity that is not valued by the customer or end user. This systematic analysis of processes and value streams to reduce waste, variability, and inflexibility boosts performance in cost control, product quality, customer satisfaction, and employee engagement—often simultaneously. Moreover, these companies apply a mindset of continuous improvement and flexible working processes in which all employees contribute new ideas and suggestions, so that the organization becomes better over time. Freed from non-value-generating tasks, people focus more on what matters to customers.
Agile is more recent, originating in software development in the 1990s accelerating after the release of the Agile Manifesto in 2001. Over the past decade, agile has rapidly expanded into other industries, such as telecommunications and banking—and, more recently, heavy industries such as mining and oil and gas.
Rather than the traditional process of developing a new product or service—which used to be highly sequential and time-consuming—agile is much quicker and more flexible. Agile models call for iterative development that aims to get an early prototype of a new product or service out into customers’ hands as quickly as possible. Teams then capture feedback and iterate via quick cycles, refining the product or service over time. Agile approaches have since expanded beyond the realm of product development, and companies are increasingly organizing for agility across all their activities.
A common misconception is that lean management and agile are mutually exclusive, based on fundamentally different principles and approaches and applicable for very different types of activities. Lean management is for routine, repeatable operations, this thinking goes, while agile only applies to projects or creative tasks. Therefore organizations, departments or functions need to pick one and focus on it exclusively.
However, that argument reflects a fundamental misunderstanding of both lean management and agile. In reality, both systems have been successful across a range of environments, and both share a similar set of foundational objectives: to deliver value efficiently for a customer; discover better ways of working to continuously learn and improve; transparently connect strategy and goals to give teams meaningful purpose; and enable people to contribute and lead to their fullest potential (Exhibit 1).
Exhibit 1 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
These objectives apply to any team or activity across an organization. There are, however, different ways of achieving them. Both lean management and agile provide team models, ways of working, and toolkits that can be deployed in any way that makes the most sense for an organization (Exhibit 2). The fact that the two systems build on the same foundational beliefs makes their elements highly complementary. Morever, operational excellence often cannot be achieved through lean management or agile exclusively but rather through the combination of both systems, using associated toolkits.
Exhibit 2 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Team models are organizational constructs that bring together individuals in an operating model to deliver value. Lean management introduces team models such as work cells, in which teams work together to complete steps that previously happened separately and were vulnerable to delay. Meanwhile, agile relies on concepts such as cross-functional teams and flow-to-work pools, which follow the same underlying philosophy. Some ideas are similar across both systems but with different names. For example, lean management’s relationship service cells, an advanced type of work cell for longer-cycle projects, have many features in common with agile’s self-managed teams.
Ways of working are approaches or processes that teams use to get work done over time. Lean management includes integrated management practices and continuous improvement, or kaizen, with agile adding “scrum” teamwork management and extreme programming, emphasizing short development cycles and frequent releases. Not surprisingly, some ways of working, such as visual management tools, appear in both lean management and agile.
Typically, when someone says, “Lean management is for routine, repeatable operations,” they are really talking about something like a lean work cell applying a methodology for continuous improvement. Similarly, an assertion such as “Agile is for creative product development” typically conflates agile with a cross-functional squad applying scrum, which requires a high level of communication for a team to achieve a common goal. Such statements fundamentally misconstrue both systems.
The right team model, way of working, and tools to use will depend on the nature of the activity being conducted (Exhibit 3). While lean management indeed was created for highly repeatable and predictable processes, over time it branched out to expert choreography, which coordinates complex interactions so that interdependencies are resolved before they become blockages, and relationship service cells, where processes center on a single point of contact with the customer. Agile found its origin in creative, customer-facing environments, but concepts like multifunctional and self-managed agile teams are now also being used in back-offices or call centers. The best selection of team models, ways of working and tools may be a combination from both lean management and agile.
Exhibit 3 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
A growing number of companies are getting better results under a best-of-breed model than they could by applying either lean management or agile systems on their own. Consider the following two case studies.
A financial services provider was struggling with customer service. Its contact center was taking far too long to resolve inquiries—up to eight weeks in some cases—in part because the specialist teams were overwhelmed by the sheer volume of customer requests. Worse, the firm had no designated owner for the entire customer-service journey. Instead, it operated under a traditional structure in which requests were passed from one function to another. Each function operated independently, tracking performance metrics only for their own slice of the process. No one was looking at the entire experience from a customer’s perspective.
The company used a combination of lean management and agile tools to improve. From the lean management toolkit, it used value-stream mapping and design thinking to completely rethink and restructure the customer experience for a given transaction or process. It also revamped key performance indicators to better reflect specific goals—for example, how fast a customer could get his or her issue resolved. From agile, the company created self-managing, cross-functional teams to improve collaboration and foster accountability. The new self-managing team enabled employees to handle all types of customer requests from end to end. Management also established a single point of contact for each process to reduce the number of internal handoffs and improve customer engagement.
Collectively, this approach led to a 90 percent reduction in the average time required to resolve a customer issue. Not surprisingly, customer satisfaction scores increased by 30 percent, as did employee engagement. The reorganization means that teams are no longer bogged down by bureaucracy and instead can see how their individual contributions have a direct result on the customer experience—and thus on the company’s overall performance.
In the second example, a global mining company had been deploying lean management tools among frontline units for more than a decade with significant success. Frontline operations at a mining site have several attributes—physical operations, a constant workflow, predictable customer specifications and repeatable processes—that make them ideal for lean approaches like six sigma.
However, commitment and progress had stalled in recent years. To jump-start gains, the company began to apply some agile tools, ways of working and team models. Even in a process industry like mining, many activities require cross-functional collaboration and operating in variable environments, from developing new strategies and engineering process improvements to deploying innovative technologies. Agile team models such as the cross-functional squad are ideally suited to that kind of work and delivered impressive results: dedicated improvement squads increased engineering velocity by 200 percent, and a cross-functional “fuel and energy” transformation squad identified and delivered $10 million of value within months.
More broadly, the company found that the agile transformation could be the banner to improve and reinvigorate the existing lean management program among frontline units. The company selected a few specific tools from the agile toolkit and integrated these into daily, lean management-led operations.
The company established four-week sprint cycles—a time period that aligned with the rotation of workers at the front line. At the beginning of each sprint, teams gather to look over the plan for the upcoming four weeks and identify key events, such as major projects, visits by leaders, or onboarding of new employees, along with one or two themes where they want to explicitly focus their improvement activities. Similarly, at the end of each sprint, teams hold a retrospective session to analyze their performance against the objectives for that sprint and identify how they can work together more effectively in the future.
This relatively simple change—combined with a renewed focus on daily standups and visual management—led to a significant increase in engagement among the workforce with over 90 percent of frontline teams actively owning improvement initiatives and approximately 130 incremental improvements delivered within the first three months.
As these two examples show, lean management and agile are both powerful systems, and companies don’t need to choose between them as either-or options. Rather, companies can apply this all-of-the-above approach, choose the tools and applications that are most relevant for their needs, and thus generate even greater improvements across the entire organization.IT leaders who started their journey toward adopting agile will probably recognize some of the patterns described hereafter. As corporations progressively experiment with or adopt agile methodology to accelerate their speed-to-market, they can fall into a common trap if their IT department fails to fully embrace an agile mind-set and behaviors. There is a pattern among organizations that pick and choose what aspects of agile to adopt: they think they’re “being agile” when in fact they’re only “doing agile.” Because they fall short of a full commitment to agile, they fall short of agile’s full potential results.
On the surface, the process looks agile: there is a scrum master who facilitates “agile ceremonies,” the four core team meetings within each sprint (short build phase). There is also a cross-functional team mixing front-end and back-end developers, a tester, and a solution architect. There is a process to plan development and a defined cadence—say, every two weeks—to make, report on, and demonstrate progress. There are talks about a minimum viable product (MVP) when new code is pushed into production after lengthy integration tests. There are new tools, such as Jira, to log units of work and track story points to monitor team velocity (productivity).
However, scratch beneath the surface and there are reasons for concern. The scrum master is only a part-time role whose involvement stops at the end of the ceremonies. The customer-experience (CX) designer is conspicuously absent from the scrum team. Instead, CX has been outsourced. User research was performed before the program started but not since. The product owner, instead of driving the product vision, follows the developers’ lead on which features should be prioritized based on how quickly they can be developed.
The team divides user needs revealed by the early research into front-end tasks and back-end tasks assigned to a front-end developer and a back-end developer. But the tasks, once completed, aren’t reconnected to compose an end-to-end user story. Slowing things down further, the MVP release is scheduled several months down the road to allow for the inclusion of features that already exist in the legacy application.
These kinds of delays aren’t often reflected in team reports. At the end of the sprints, the team productivity report shows, for example, that it has increased regularly, although not dramatically, since the first sprint. The tester is performing tests manually and has gotten wiser at choosing what to test. But experience shows that the results of such a partial commitment to agile are, like the process itself, half-baked.
A half-hearted commitment, for example, lacks the customer-centricity mind-set and the empathy that a CX designer would bring to removing perceived inconvenience from the customer experience. A full-time scrum master would relentlessly work to remove impediments, not just facilitate the ceremonies. Priorities would be business driven, not tech driven, and would be based on maximizing user value, not minimizing time to develop.
Companies that are really being agile wouldn’t disaggregate user stories into mere programming tasks, but would use them as building blocks for a better user experience. And user validation wouldn’t be put off until after a full release. Every user story, each granular slice of the user experience, would be submitted to the test of a sprint review, ideally with feedback coming directly from end users. The sooner there’s a working prototype, the better. Efficiency tools such as Jenkins should be leveraged to automate testing as much as possible and facilitate continuous delivery.
In short, successfully adopting agile methodology requires a full commitment, a complete reboot of mindsets and behaviors. The migration to agile must be accompanied by a thorough change-management plan to first instill, then install, and finally institute agile as the new norm applying to every person, process, and tool.Although more than 70 percent of companies report that agile transformation is a top priority, we haven’t seen the extent of agile adoption among operators that this level of interest would suggest. It’s puzzling. We know companies that go agile are 50 percent likelier to outperform their competitors financially. We also know that agile directly helps operators win four of their core battles: faster time to market, higher customer satisfaction, significant productivity improvements, and a transformed employee experience that improves talent attraction and retention.
We believe part of the answer is a lack of clarity about what “agility” actually means and how it plays out in practice within a specific company. The term is often used to connote a vague notion of being flexible. One executive explained his chronic lateness by saying he was just “being agile with time.” Others associate the term with a type of software development or bean-bag chairs and flexible seating arrangements.
Think back to a crisis you were involved in or a time of urgent and decisive challenge. Maybe you were responding to an emergency in your community, serving in the military, or facing an impossible deadline at work. You assembled people from different backgrounds who were selected for their complementary skills, operated largely without hierarchy, and focused on a well-defined objective. These extraordinary achievements are often remembered as “peak experiences.”
Agile, in a nutshell, is about assembling the elements of that peak experience for every employee, every day, without the need for a crisis. Agility at scale embeds these elements in the very fabric of how things are done by providing the following:
A very clear purpose, anchored in positive meaning A sharp definition of what success looks like Teams assembled with the skills required to succeed without reliance on others A cadence that fosters short bursts of tangible output and regular celebration of outcomes
This is the core of agility—building organizations with hundreds of those great teams (Exhibit 1). However, great teams alone would result in chaos and lack of scale. The other critical piece is a strong backbone that supports these teams by providing a common purpose, cohesive culture, functional excellence, and standards, which in turn enable the processes and platforms that hold the company together.
In our work with multiple operators around the globe, we have seen two successful approaches to agile emerge: agile accelerators and enterprise-wide agile (Exhibit 2). We’ll use examples of agile in action at two different operators—Denmark’s TDC and New Zealand’s Spark—to demonstrate two emerging success patterns for how to organize teams around work. Both operators have reaped significant benefits through their transformation, including the four key benefits mentioned above, and attracted global attention in doing so. Telco executives from all over the world now visit both companies to learn how they changed long-held practices in favor of customer and operational excellence.
Exhibit 2 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
The choice between the two approaches to agile is driven by how agility can best unlock value in a particular company, the maturity of the organization, and the top management team’s convictions about starting small versus undertaking quick and comprehensive change. Common to both is the necessity for a company to be “all in” about agility—only the scope of initial change is different.
Sidebar About TDC TDC is Denmark’s incumbent telco, serving both B2B and B2C customers ~8,000 employees ~€2.8 billion annual revenue (2017) Founded in 1990 Headquartered in Copenhagen
The summer of 2016 was challenging for TDC, the leading Danish telco (see sidebar “About TDC”). The recent merger of its two main consumer brands had consolidated its B2C strategy and the newly appointed head of its B2C unit, Jaap Postma, had a long list of improvements to make in the new organization. TDC’s digital capabilities were at the top of it—market research and Postma’s own observations strongly suggested that the company was not meeting consumers’ rising expectations of online service.
Having witnessed the power of digital in his previous positions, Postma set it as a top priority and tasked Rune Keldsen, one of his trusted leaders with broad, relevant experience, to get this right. Postma and Keldsen quickly concluded that doing things the old way would not produce results fast enough. TDC had invested significant funds in digital for years, but these efforts always tended to take longer than anticipated, and by the time they were ready to hit the market, consumer needs had often shifted already.
To speed things up, TDC decided to inject agility into its digital transformation. It first launched one, then 12 cross-functional agile teams (or squads) consisting of product owners, commercial specialists, frontline experts, customer-experience designers, architects, and developers—all the competencies required to design, build, test, and improve digital customer journeys at speed. Each squad was brought under the organizational construct of a “digital tribe” led by Keldsen. The squads were given end-to-end accountability to do whatever it took to create seamless and engaging customer journeys in online sales and service, while gradually establishing a flexible IT architecture.
Postma and Keldsen knew that to succeed with the digital transformation of TDC, they needed to establish a new culture and attract top talent. A casual walk-through of their Digital Warehouse shows they achieved this. At the facility, which is a rebuilt warehouse next to TDC headquarters, there is no more talking about business and IT, no more “facilitating” middle managers, and no more long steering-committee meetings. In their place are just cross-functional squads empowered to make change.
Eighteen months later, TDC sees the benefits of the new way of working. Its customer onboarding journey, for example, had been one of the main headaches for customers and a key reason for low satisfaction ratings. Post-transformation, TDC’s onboarding experience is now endorsed with five stars by 80 percent of customers. Call volume, one of the large cost drivers for TDC, is down by more than 40 percent now that customers can easily manage their interactions and solve their problems online.
Online sales provide another striking example. Six months before the transformation began, TDC formed a traditional project team tasked with designing and implementing a new digital sales journey for the main products. But with team members located in disparate parts of the organization and working in a traditional waterfall approach, the project team hadn’t managed to release anything by the time it was rolled into the digital tribe. Once they were co-located and equipped with agile techniques like minimum-viable-product thinking, the group had not only built a new sales journey but already generated its first online sales within a few weeks. The first minimum viable product was limited in scope, yet generated momentum, secured sponsorship, and bought the team time to deal with technical complexity of an automated solution that came a few months later. Conversion rates soared. The agile approach had worked.
After the groundbreaking success of the digital tribe in B2C, TDC immediately launched a similar digital tribe in B2B. This tribe is reinventing the sales and service experience for business customers and launching solutions that have not yet been seen elsewhere in the B2B space. Over the last six months TDC has continued to scale its new agile ways of working with three new tribes around digital marketing and product development (a TV tribe and a cloud tribe), all of which kicked off with success.
Sidebar About Spark Spark is New Zealand’s incumbent telco, serving consumers, businesses, and enterprise customers ~5,500 employees ~€2 billion annual revenue (2017) Founded in 1987 Headquartered in Auckland
Spark, New Zealand’s incumbent operator, had been on a transformation journey since 2012, following the carving out of its fixed-access network to a separately listed new entity (see sidebar “About Spark”). Having completed a successful turnaround, rebranding, and IT reengineering, Spark was in good shape and shareholders enjoyed one of the sector’s best total returns.
But the executive team was setting its sights higher. In their view, the game was no longer about outperforming other operators, but being match-fit for a market increasingly made of disruptive digital-native companies such as Amazon, Netflix, and Spotify. Competing or partnering with these companies requires a step-change in mind-set, speed of execution, and time to market, which the old functional organization model struggles to provide.
Armed with renewed urgency, Spark’s top team and board of directors visited more than a dozen companies around the world to understand how agile worked for them and what it could do for Spark. They visited both born-agile companies and companies in different stages of their agile journey. These included, among others, TDC and ING in the Netherlands.
Spark leaders returned home with a simple conclusion: when it comes to agility, they needed to jump in boots and all, and trust the agile process to get them through—“be agile to go agile.” They wanted to avoid a prolonged period in which part of the company had adopted agile ways of working and the rest was still operating in a traditional hierarchy. Companies that fully embraced agility across the organization were thriving. Those that just did it half-way often faced some difficulties. Spark likened this to a person on a dock standing with one foot on the ground and one foot on a boat.
Managing Director Simon Moutter and Group HR Director Joe McCollum called for a three-day off-site in October 2017 for the leadership team to decide if Spark would be in or out. The collective team pledged to adopt agile throughout the entire business, fast and at scale.
The team laid out an ambitious timeline to keep the transition phase to a minimum. In November 2017 Spark launched a company-wide communication about the upcoming journey and appointed leads to the first three tribes it launched as frontrunners: broadband, managed data, and digital experience. Over the following months, the leads of these three tribes built their own organization of about ten cross-functional teams each. In parallel, the rest of the organization prepared the changes needed to tip the whole company into an agile setup by mid-2018.
Along the way, Spark dedicated significant effort to change management and capability building. During the first half of 2018, well before any structural change occurred, hundreds of people engaged in defining and then putting into action a new purpose for the company: “Helping all of New Zealand win big in a Digital World.” This new purpose brought about an adjustment in the company’s values, target behaviors, and capabilities. They also emphasized diversity and inclusion so employees felt comfortable bringing their whole selves to work and working together, to ensure high performance in teams.
Operating in a small, remote market where talent with agile experience was hard to find, Spark selected 40 high-performing employees and trained them as agile coaches in a newly created academy. It also had all employees go through a two-day boot camp designed to build great teams familiar with the basics of agile.
In July 2018, Spark did a “big bang” launch of 18 tribes and moved approximately 40 percent of its employees into cross-functional teams comprised of IT, networks, products, marketing, and digital people. The agile transformation for the rest of the business—channels, corporate support functions, and other units—began immediately after.
Spark’s agile model was built based on a view of where and how value is created in each part of the business. Given the nature of New Zealand’s telco sector, Spark decided to place significant focus on “product tribes.” These tribes own the customer journey, product management, and related systems for specific products like mobile or IT services, to allow full differentiation and rapid improvement. “Segment tribes” take care of attracting new customers and growing existing ones. Finally, “enabling tribes” provide services and capabilities for other tribes. Channels (such as retail, billing operations, and B2B sales and service) and support functions (such as HR and finance), use a mix of squads, self-managing teams, and other team configurations suited for the nature of the work.
Contrary to what the Spark leadership had been braced to expect from overseas companies that had made the leap to agile, Spark’s operating metrics remained rock solid during the transition. Now positive results are flowing in. The new work model with just three “layers” of hierarchy has allowed efficiency through greater focus on productive work. The new 90-day governance cycle—the quarterly business review—allows for more effective and regular steering, higher transparency, and faster decision making across the whole business. Employees are thrilled to work in a setting where they can have direct customer impact, and customers, especially in the B2B space, are starting to notice the difference. In the words of many employees, Spark would “not go back for anything in the world.”
Each of the operating-model transformations TDC and Spark undertook demonstrates a certain boldness. It’s been described as “open-heart surgery while running a marathon”—being prepared to dramatically change a company’s core operating model without missing a beat in performance.
Surgeons inform patients of the risks of an operation before performing it, and we want to conclude this article by doing something similar, so you are aware of the implications of embracing agility.
The impact on your people is profound. An agile structure is built around teams of doers with little management overhead. Spark asked about 200 of its top managers to become agile team members, openly acknowledging that agile isn’t for everyone. Some chose to leave instead. Also, you need to invest in new skills, such as agile coaching, that previously didn’t exist at scale.
You must overhaul your core finance and governance processes. Agile teams need regular direction and prioritization, for which traditional large business cases and multiyear plans that bring comfort to management won’t work. TDC leadership needed to get comfortable dealing with 90-day objectives and funding tribes instead of individual projects. This puts more responsibility on leadership to stay on top of details and to work transparently, which can require a mind-set change.
The people model and culture need to change. Valuing and paying people based on hierarchical position won’t work in a flat, high-speed organization. Extrinsic motivators like bonuses and job titles need to be reconsidered to enable intrinsic motivation in teams. Culture is so critical to success that nurturing and evolving it will likely take up most of the effort you put into your transformation.
The role of the top team is very different. Agile companies require strongly united leaders to sense the market and shape priorities, but then let the teams figure out how to meet them. At Spark, the top team led the change by becoming a leadership squad and adopting a rhythm of standups, retrospectives, and demos similar to those used by the rest of the business. They centered their deliverables around building a great organization that enables other teams to succeed.
If these realities don’t scare you, the best way to start the journey is to build strong alignment and a joint aspiration in your top team. We have found visiting agile companies an enriching and sobering way to start a journey toward agile—hearing the experiences of fellow management teams bypasses theoretical discussion to create a joint understanding of what agile can do for your company. Learn what you want and don’t want from an agile model. Then set explicit targets and design principles to keep you honest on what you are trying to achieve. Taking a decisive approach and basing it on the learnings from companies like TDC and Spark will give you the best chance at success.July 15, 2019 Most sales organizations have yet to crack the code on how to launch a successful transformation. Too many sales leaders still make quick decisions based on feelings rather than hard evidence. And high attrition rates present challenges when individuals don’t pass on their knowledge of how things should work. The good news is that there is a science-based approach that can increase the odds of a successful transformation by three to four times.
A recent McKinsey article, “Meet the missing ingredient in successful sales transformations: Science,” reveals how the science of change—digital, analytics, and supporting methodologies—can increase the odds of transformation success. To reap the benefits of scientific analysis, sales organizations should focus their efforts on four elements: comprehensive design, agile deployment, continuous capability building and performance management, and sustainability.
One European telecommunications company’s transformation illustrates just how powerful this approach can be. The telco aimed to uncover new market opportunities for growth. To begin, it conducted a micromarket analysis using internal and external data (including data provided by sales reps) to reveal a clearer picture of which markets still had a large share of unserved customers and which were saturated with competition. The findings helped the company narrow its focus and decide where to allocate its resources. As a result, the telco increased its store footprint in key markets—garnering 5 to 10 percent more in-store visits, depending on the market—and reduced total store costs through resizing less profitable locations and other tactics.
As with any good science experiment, a methodical and considered approach can help organizations achieve the desired outcome—and gather fresh insights along the way.
Create a comprehensive design. Data and analytics capabilities can give sales organizations a clear view of where to find the most promising areas of opportunity. This can be done by conducting a critical analysis of markets and specifically looking for ways to increase growth.
Thus, before jumping into a change headfirst, companies should evaluate the ability of their sales function to seize these opportunities, and then plan a path forward. In addition, leadership can help prioritize plans to prevent organizations from tackling too much at once. Organizations can perform a stress test of the proposed strategy against the realities of the market, such as changing customer preferences, and use the findings to create a road map and prioritize initiatives.
Take an agile approach to problem solving. Cross-functional collaboration from across the organization combined with the use of advanced analytics capabilities helps organizations identify change opportunities with the most potential. However, the successful launch of solutions to these areas relies on an agile approach in product testing as well as the rollout and adoption of the new process.
Leaders begin by building the minimum viable product (the tool or process) that can capture that opportunity and test it. For example, a sales organization might build a tool that helps better target customers for upselling. A/B testing and advanced analytics tools can validate whether the product is working—or if not, why. Teams should adjust their approach based on feedback and iterate rapidly to improve on the prototype. To ensure organization-wide adoption of the solution, sales leaders can test different training methods to identify the most effective way to roll out the new process.
Continuously build capabilities and manage performances. Successful sales leaders run their organization like an engineering firm. Their operations are precise and well oiled, quickly flagging deviations and making recommendations for improvement. However, most performance management systems—the heart of a sales transformation—are slow and don’t present forward-looking insights. Integrating data and analytics capabilities into the system helps organizations better track performance metrics, which facilitates a manager’s ability to make key decisions. And based on our research, these systems can produce great results even if they are automated or self-administered. The key to success is in simply making the right information available. For example, an automated system using robust data could send prompts to sales reps or managers to follow up with customers or reminders to comply with a new process.
Sustain impact. Organizations can use technology and advanced analytics tools to hardwire new procedures into organizational DNA. For example, a sales organization might want to employ a more targeted sales approach by effectively categorizing customers. An advanced analytics system could group customers based on agreed- upon parameters, making it easier for sales reps to target offers. However, technology alone cannot facilitate a sustained change; it must work in conjunction with people. Managers can offer personal coaching on new technology—and use an automated performance management system to highlight performance wins, for example—to reinforce the process.Agile, cross-functional teams and processes can help brands with more than just keeping up with the latest marketplace conversations.
Ideate, iterate, pivot, agile—once considered buzzwords heard only at the local startup incubator, these concepts are now ubiquitous across global businesses. To create and maintain an edge in today’s complex, demanding marketplace, companies often need adaptive models that can enable them to keep up with the speed of culture, conversation, and digitization. The dynamic social, economic, and cultural environment also necessitates agile decision-making—particularly in marketing, where increasingly discriminating buyers are adopting, consuming, and disposing of brands more frequently and casually.
Many leading brands are separating themselves from the pack by being more purposeful and hyper-focused than ever on the human experience, necessitating a different way of working for their marketing teams. Other brands should follow suit—moving from reactive to proactive engagement in order to address the wants and whims of customers—or potentially be left out of the race. For this, they should restructure their marketing functions, leverage the power of real-time data accessed through digital platforms, and quickly gain insights to design more personalized, human experiences in an agile manner (see sidebar, “What is agile marketing?” for more).
Agility is both a framework and a mindset. It encourages organizations to embrace immediate and novel ways of thinking while helping them restructure in a way that allows their brand to join conversations and moments organically. Here are two examples showcasing how businesses are becoming more agile:
TD Bank maximizes operational flexibility: Realizing the importance of tailoring its services for its customers, TD Bank sought new methods to tap into digital platforms to unlock a deeper understanding of the customer experience. After shifting its marketing investments online, TD Bank needed to leverage customer data more effectively to tailor products and deliver personalized messaging to customers in real time. This required the bank to examine its approach to content generation, while its operational structure required greater flexibility to respond and react to the story the data was telling. To achieve this, TD Bank redesigned its marketing function from a traditional one to one based on “marketing pods”—cross-functional teams capable of rapid prototyping and iteration in producing content. 1
Realizing the importance of tailoring its services for its customers, TD Bank sought new methods to tap into digital platforms to unlock a deeper understanding of the customer experience. After shifting its marketing investments online, TD Bank needed to leverage customer data more effectively to tailor products and deliver personalized messaging to customers in real time. This required the bank to examine its approach to content generation, while its operational structure required greater flexibility to respond and react to the story the data was telling. To achieve this, TD Bank redesigned its marketing function from a traditional one to one based on “marketing pods”—cross-functional teams capable of rapid prototyping and iteration in producing content. JetBlue improves customer service through Twitter: Traditionally considered a no-frills, low-cost airline, JetBlue recognized the opportunity to enhance its brand identity through improved customer service. The company decided to leverage Twitter to support its customers as close to real time as possible on their journeys. Under this program, JetBlue encourages customers to tweet their needs and complaints to its account and ensures they receive immediate replies, explaining what is causing flight delays or other problems. In addition, taking cues from the tweets, JetBlue deploys its airport staff to help passengers on the ground. Through these efforts, the airline repositioned itself as a “customer service company that happens to fly planes.”2 So, what made this possible? JetBlue transformed its customer service operations by removing oversight and hierarchical bottlenecks to empower employees to independently respond to issues as they arise.
What is agile marketing? Agility draws on the key principles of “agile”3 software development. It is a framework that can enable organizations to move closer to customers by helping them embrace adaptive thinking and structure cross-functional teams to increase their speed, quality, flexibility, and effectiveness in reacting to moments in the market. It also can help companies capitalize on emerging technologies such as artificial intelligence (AI) to predict and generate meaningful engagements with customers in nearly real time. Agility pushes marketing to move beyond mere content creation by offering an organizational model for businesses to quickly design, create, and launch marketing campaigns. An agile model can allow companies to validate hypotheses and pivot based on customer interactions and timely insights. Further, agility facilitates learning and assessing the impact of marketing on connections with customers to capture return on investment.
TD Bank and JetBlue are just two examples of companies realizing the need for new approaches to better engage with customers. Across the marketing landscape, our analysis illustrates how many global brands are embedding agile across their organizations in diverse ways. In the agility trend, we delve into common organizational approaches that demonstrate agility in action and discuss the transformation that may be required in marketing departments to implement these approaches.
Being agile typically requires marketers to shift from conventional approaches of generating marketing content to new, tech-enabled, moment-centric ones. Traditional marketing strategies were built around single campaigns, where static advertisements were developed in stages, turned on, and then turned off when the campaign ended. Brands latching on to agile should recognize the need to adapt both the framework and mindset across the organization. They should also build internal capabilities and cross-functional teams that speed up their reaction time to capitalize on societal moments, while leveraging predictive technologies to gain a share of culture and conversation rather than just a share of voice or brand impression. Our trends research surfaced two specific agile strategies organizations are adopting:
Building the “if/then” campaign. With agile approaches, marketers create batches of marketing content to be rolled out in a 48- to 72-hour window, if trends or live events chart a specific course in real time. For instance, printing world championship T-shirts of both competitors in the major sporting event. Sports apparel companies and franchises have scaled this “if/then” thinking to the marketing department. As sports seasons and end-of-year tourneys unfold, marketing teams prepare for possible outcomes by crafting alternate campaigns to prepare for winners in key championship games. This approach requires companies to produce batches of content in advance based on an “if/then” condition and push it out depending on the outcome of the event or trend. Acting in near real time. Brands at the forefront of real-time engagement with customers are doing more than simply increasing the speed of their reaction time. They’re fundamentally shifting their culture and organizational structure—including reconfiguring their marketing departments—to support real-time customer engagement.4 Fernando Machado, global CMO at Burger King, attributes his company’s marketing successes to their “desire to be constantly engaging with our fans and our guests. And we know that we can only accomplish that if we move fast.”5 Moving fast is essential to Burger King’s “Traffic Jam Whopper” program, which debuted in Mexico City in spring 2019. Utilizing real-time traffic data to determine when roads near a Burger King (BK) are congested, the company pushes prompts to digital billboards and displays banner ads within the Waze traffic app. Drivers can order on the BK app through voice commands to avoid texting while driving. The billboards then display updates when food is en route and orders are delivered directly to cars stuck in traffic via motorcycles using Google Maps. Burger King reported a 44 percent increase in BK app downloads and a 63 percent increase in daily delivery orders as a result of this program.6
As these examples demonstrate, the accelerating velocity of technology can create opportunities for brands to continuously evolve their messaging and human experience based on near real-time customer insights.
To put agile to work, many marketers are diffusing the time-boxed, iterative approach across their organizations in three ways. First, they’re recognizing the need to be cross-functional and embracing a newsroom approach—breaking operational barriers and silos by bringing people closer together to produce content in the moment. Second, marketing teams are delivering content in a more agile manner by embracing new ways of working. These include daily standups, scrums, and piloting and testing methods that can enable teams to work in shorter sprints and move away from annual and quarterly content calendars. Finally, new emerging technologies, led by AI and analytics, are supporting organizations in predicting culture and the direction in which the conversation is moving.
The following examples show how some marketing departments are making agile work for their brands and how you can too:
Adopt newsroom-style operations. Many companies realize that embodying agile means improving the cross-functionality and proximity of their teams and, often, restructuring of their marketing function to build newsroom-like operations. Take the example of Taco Bell, which instituted a newsroom model to capitalize on the moment after it realized customers were accessing the brand and were most active on its social media channels between 9 p.m. and 2 a.m. From copywriting and legal to public relations and content designers, Taco Bell brought traditionally siloed groups together, enabling shorter lead times, instantaneous legal approvals, and quicker decision-making. This restructuring helped it gain a share of the conversation with customers in the moment, based on what its sensing and data capabilities were saying. 7
Bosch, a German engineering and technology company, similarly recognized the value of proximity among teams in an agile approach. It abolished its traditional structural hierarchy and created small, matrixed business teams, all reporting to a management board. Each “purpose team,” as they were called, was built around specific product and design goals.8 The restructuring required teams to interact more frequently. Daily standups were instituted to produce content in batches, while the marketing team developed the ability to quickly test and incorporate data to see what was working and what was not. Pilot then scale. Many marketers are piloting agile within a single business unit to test, learn, and iterate how they can make it work for their organizations. For instance, TD Bank in Canada wanted to embrace agile in its digital marketing function.9 The marketing team started with an assessment of the company’s digital maturity across business units to understand where they fell on the digital adoption curve, before piloting agile within a single business unit to gain insights on how to diffuse it across the company. Pulling together six cross-functional workers—from content, analytics, strategy, planning, and leadership—the team developed a “north star” to guide its agile approach with the goal of increasing the number of insurance quotes. Utilizing daily standups and a scrum model, the team ran two-week design sprints over three months, documenting experiences to present lessons learned to the business leadership; the aim was to understand the secret sauce for scaling agile across the company. Lowering barriers to entry by deploying agile in one unit enabled TD Bank to create a scaling plan and adopt it over time. Through the agile pilot, the bank cut costs by 30 percent in the first month and campaign turnaround time within digital marketing moved from four-month timeframes to two weeks. TD Bank also learned that demonstrating the ROI to leaders and achieving quick wins would help other units adopt agile as the company scaled the approach. 10 Deploy predictive sensing. Agile marketing typically requires internal teams to listen to the conversation and produce content in short windows by testing, measuring, and predicting consumers’ purchases, discussions, and reactions. Marketers have predictive technologies and AI tools such as Heat AI11 to aid them in this “predictive sensing” process. Analytics and AI tools can provide marketers with “social intelligence,” enabling them to predict and sense where conversations are heading. Content and conversations recycle every six hours on average; thus, speed in sensing is key to staying relevant. These tools also help marketing teams quickly identify whether their content is meeting its desired results in the moment. Conversations can be forecast 72 hours in advance, allowing a brand roughly three days to anticipate, create, and launch content.12
For example, in 2018, Facebook and National Geographic teamed up to grow a new community focused on “Women of Impact.” Leveraging sensing technology and AI to crowdsource and predict trending keywords and topics, the team created content using agile and expanded the community to four times its original size in just two weeks.13 Armed with such insights, flexible teams can abandon an underperforming idea, pivot, and update their creative approach to capitalize on what is being learned. On the back end, insights and patterns in the data also reveal the impact of the investment, offering learnings for the organization on where to go next.
Marketing leaders and departments can lead the agile charge for the entire organization, and in the process, transform their companies into customer-centric operations. By embracing agile across structures, teams and processes, and mindsets, brands are better suited to act and capitalize on moments to create deeper engagement with customers.Combines knowledge of digital with extensive experience in IT strategy and transformation to advise clients on all dimensions of digital, agile, and advanced analytics
Sid is an expert in the Ops practice with extensive experience in helping clients solve problems using digital, analytics, and lean Six Sigma tools.
October 18, 2019 Imagine a future where smart robots assemble products from multiple manufacturing lines by physically reconfiguring themselves on the factory floor. Security drones handle tedious tasks ranging from monitoring for intruders to validating employee parking. Autonomous vehicles transport parts not only between buildings, but also across the country. And factory inspections are performed remotely from a thousand miles away.
Just a few years ago, these were impossible dreams reserved for the realms of science fiction. But with the arrival of 5G connectivity, combined with advances in artificial intelligence (AI) and cloud computing, these dreams are becoming increasingly attainable for today’s manufacturing organizations.
The hype is intense. With data speeds slated to be 25 times faster than today’s 4G networks and lag reduced to virtually zero, 5G appears to promise unending opportunities to strengthen connectivity and digitization—both within factories’ four walls, and beyond them at every step along the entire value chain.
But which potential applications deserve manufacturers’ attention? Five show particularly strong potential for boosting factory productivity:
Cloud control of machines —For decades, factory automation has relied on programmable logic controllers (PLCs) that were physically installed on (or very near) the machines they controlled, and then hard-wired into computer networks to ensure precise, reliable control under extreme conditions. If 5G consistently meets its performance promises, the PLC could be virtualized in the cloud, enabling machines to be controlled wirelessly in real time at a fraction of the current cost.
—For decades, factory automation has relied on programmable logic controllers (PLCs) that were physically installed on (or very near) the machines they controlled, and then hard-wired into computer networks to ensure precise, reliable control under extreme conditions. If 5G consistently meets its performance promises, the PLC could be virtualized in the cloud, enabling machines to be controlled wirelessly in real time at a fraction of the current cost. Augmented reality —Factory workers are no strangers to performing complex maintenance and control tasks, often guided by standard operating procedures (SOPs) in paper manuals, videos, or—in some cases—even augmented reality. But instructions streamed over 4G networks can be unreliable due to bandwidth constraints, and fail to deliver the required levels of quality without stuttering. 5G promises not only the streaming of high-quality instructions on the shop floor, but also stutter-free augmented reality that can guide people, step by step, through each individual motion they need to make. This will allow shop-floor workers to undertake advanced tasks without waiting for specialist engineers or incurring costly machine downtime. The best knowledge and work instructions can therefore be shared with all workers exactly when they need it, building worker skills more quickly, safely, and effectively than ever before.
—Factory workers are no strangers to performing complex maintenance and control tasks, often guided by standard operating procedures (SOPs) in paper manuals, videos, or—in some cases—even augmented reality. But instructions streamed over 4G networks can be unreliable due to bandwidth constraints, and fail to deliver the required levels of quality without stuttering. 5G promises not only the streaming of high-quality instructions on the shop floor, but also stutter-free augmented reality that can guide people, step by step, through each individual motion they need to make. This will allow shop-floor workers to undertake advanced tasks without waiting for specialist engineers or incurring costly machine downtime. The best knowledge and work instructions can therefore be shared with all workers exactly when they need it, building worker skills more quickly, safely, and effectively than ever before. Perceptive AI eyes on the factory floor —Cameras are already common in modern factories to monitor processes and security. However, their use is limited to focused applications and often requires workers to monitor video feeds. 5G will allow the streaming of data in real time to the cloud, and the use of live video analytics. For example, a security camera could see a disturbance, identify if there is an imminent threat or danger, and dispatch a drone or alert a worker to investigate. Alternatively, the same security camera could provide a more efficient mechanism to measure cycle times and monitor process deviations.
—Cameras are already common in modern factories to monitor processes and security. However, their use is limited to focused applications and often requires workers to monitor video feeds. 5G will allow the streaming of data in real time to the cloud, and the use of live video analytics. For example, a security camera could see a disturbance, identify if there is an imminent threat or danger, and dispatch a drone or alert a worker to investigate. Alternatively, the same security camera could provide a more efficient mechanism to measure cycle times and monitor process deviations. High-speed decisioning —The best-run factories rely on vast data pools to make decisions—with inevitable delays as data is collected, cleaned, and analyzed. 5G speeds up the decision-cycle time, allowing massive amounts of data to be ingested, processed, and actioned in near real time. In several heavy industries, for example, manufacturers have been able to sell excess energy back to the grid when machines aren’t running and prices are favorable.
—The best-run factories rely on vast data pools to make decisions—with inevitable delays as data is collected, cleaned, and analyzed. 5G speeds up the decision-cycle time, allowing massive amounts of data to be ingested, processed, and actioned in near real time. In several heavy industries, for example, manufacturers have been able to sell excess energy back to the grid when machines aren’t running and prices are favorable. Shop floor Internet of Things—The addition of sensors to multiple machines means factories are creating more data than ever before. Transmission through wired networks is expensive to scale, and Wi-Fi networks can quickly get congested—as anyone who has tried to connect to public Wi-Fi networks can attest to. 5G has the ability to support high connection density with tens of thousands of endpoints, thereby truly enabling the use of industrial data at scale.
These technologies are all still at an early stage of testing, but the pilots undertaken to date are encouraging. Long-term, one of the most intriguing effects may be on the humans who work alongside 5G. Far from creating a world of lights-out, human-free factories, industrial 5G appears more likely to allow people to move away from tasks that have previously been considered dirty, dull, and dangerous. Instead, people’s focus will shift to capturing the value made possible by the vast data harvests that 5G will enable—and that 4G could not reliably and seamlessly support at scale.Wave 1: First, teams – across or within IT departments – start experimenting as agile, cross-functional teams. Daily business supporting those teams continues as usual, and overall decision-making power and responsibility remain with the line organization.
Wave 2: Once some cross-functional experiments have proven successful, the number of teams grows. Senior IT management starts to notice the advantage of faster time to market and cross-functional teams are scaled across the previously functionally oriented IT area. Project-based work starts to shift towards a continuous, product-centric flow with incremental delivery. Team autonomy increases as core value delivery to the business begins to come from cross-functional, agile teams.
Wave 3: As the teams mature, their prime focus becomes the delivery of end-to-end customer value. This requires experts across departments to work together, driving expansion of the model outside IT. When project scope and responsibilities cross departments, it quickly becomes clear that existing organizational structures and processes inhibit progress and that value-centric teams drive decisions and deliver value more autonomously across department boundaries. Business and IT grow more intertwined as complementary skill sets are needed in teams, depending on the technical depth of the product.
Wave 4: Once executive management has fully understood the value of cross-functionality at scale, these principles are reinforced on strategic levels. New organizational structures emerge; teams form around products based on the required skills. The organization’s middle management disappears as line managers become redundant to entirely decentralized, collective decision mechanisms. Interdisciplinary teams change their configurations when needed to respond to changing customer or market demands.
Even though the core of organizational delivery will change fundamentally, not all decisions can be made by these cross-functional teams. Like agile ways of working, cross-functionality is not the “silver bullet” that solves all future organizational challenges. Firms need to carefully consider the fit of a cross-functional team for each product and implement this transformation case by case. Cross-functional teams may perform better in highly dynamic, technology-driven environments. In line with the well-known Stacey matrix, cross-functional teams reach their fullest potential in complex environments where future requirements, methods and technologies are far from certain. In other situations, however, the conventional structure of teams as specialized functional units may prove more effective. Companies will have to experiment with different models to find the best structure. Central corporate strategy, governance and overall orchestration among teams will still be required. Furthermore, units that are highly driven by regulatory requirements and legal policies will be difficult to transform and will likely remain as they are today. Finally, depending on the maturity of the cross-functional teams, dedicated specialist services and (central) support functions may still be required; these can be pooled, deployed or integrated into existing cross-functional teams as needed.For many organizations, surviving and thriving in today’s environment depends on making a fundamental transformation to become more agile. Those making the transition successfully are achieving substantive performance and health improvements: enhanced growth, profitability, customer satisfaction, and employee engagement.
More than any other factor, the key to a successful agile transformation is for leaders, particularly senior leaders, to develop substantially new mind-sets and capabilities. This article summarizes our guide, Leading agile transformation: The new capabilities leaders need to build 21st-century organizations (PDF–765KB), to readying leaders for agile transformations.
Before we dive deep, it’s useful to take a broader view of agile, and particularly what sets agile organizations apart from traditional ones.
Simply put, the dominant traditional organization model evolved primarily for stability in a well-known environment. It is based on the idea of an organization as a machine, with a static, siloed, structural hierarchy that operates through linear planning and control to execute one or very few business models.
Agile organizations, viewed as living systems, have evolved to thrive in an unpredictable, rapidly changing environment. These organizations are both stable and dynamic. They focus on customers, fluidly adapt to environmental changes, and are open, inclusive, and nonhierarchical; they evolve continually and embrace uncertainty and ambiguity. Such organizations, we believe, are far better equipped than traditional ones for the future.
While there are many different forms of enterprise agility, they share some common trademarks. We have identified and enumerated these in a related article, “The five trademarks of agile organizations.”
This new kind of agile organization requires a fundamentally different kind of leadership. Recent research confirms that leadership and how leadership shapes culture are the biggest barriers to—and the biggest enablers of—successful agile transformations.
Organizations must therefore begin by both extending and transcending the competencies that made their leaders successful in the past. Leaders need three new sets of capabilities for agile transformations. First, they must transform themselves to evolve new personal mind-sets and behaviors. Second, they need to transform their teams to work in new ways. Third, it’s essential to build the capabilities to transform the organization by building agility into the design and culture of the whole enterprise.
To fully transform yourself, several shifts will be necessary—and leaders will need to make these changes in a disciplined way.
Changing our mind-set—or adjusting it to the new context—is no easy task, but developing this “inner agility” is essential in releasing our potential to lead an agile transformation.
Reactive, or socialized, mind-sets are an outside-in way of experiencing the world based on reacting to circumstances and other people. Creative, or self-authoring, mind-sets are an inside-out way of experiencing the world based on creating our reality through tapping into our authentic selves, our core passion and purpose.
Research shows that most adults spend most time “in the reactive,” particularly when challenged, and as a result, traditional organizations are designed to run on the reactive. To build and lead agile organizations, however, leaders must make a personal shift to run primarily “in the creative.”
There are three fundamental reactive-to-creative mind-set shifts we have found critical to foster the culture of innovation, collaboration, and value creation at the heart of agile organizations:
From certainty to discovery: fostering innovation. A reactive mind-set of certainty is about playing not to lose, being in control, and replicating the past. Today, leaders need to shift to a creative mind-set of discovery, which is about playing to win, seeking diversity of thought, fostering creative collision, embracing risk, and experimenting.
From authority to partnership: fostering collaboration. Traditional organization design tends towards siloed hierarchies based on a reactive mind-set of authority. The relationship between leaders and teams is one of superior to subordinate. Designed for collaboration, agile organizations employ networks of autonomous teams. This requires an underlying creative mind-set of partnership, of managing by agreement based on freedom, trust, and accountability.
From scarcity to abundance: fostering value creation. In stable markets, companies maximize their shares at the expense of others. This win–lose approach reflects a reactive mind-set of scarcity, based on an assumption of limited opportunities and resources. Today’s markets, however, evolve continually and rapidly. To deliver results, leaders must view markets with a creative mind-set of abundance, which recognizes the unlimited resources and potential available to their organizations and enables customer-centricity, entrepreneurship, inclusion, and cocreation.
While these mind-set shifts might be new and require a significant “letting go” of old beliefs and paradigms, collectively, they form a very disciplined approach to leadership. And because of inherent autonomy and freedom, leadership in agile organizations comes from a self-disciplined approach—leading not in fear of punishment or sanction but in service of purpose and passion.
How might leaders help teams work in new and more agile ways? And what does this new way of working require of leaders? There are three essential leadership requirements that follow from all agile ways of working.
First, leaders must learn to build teams that are small, diverse, empowered, and connected. Second, leaders must allow and encourage agile teams to work in rapid cycles to enable them to deliver greater value more efficiently and more quickly. Third, leaders must keep agile teams focused on the external or internal customer and on creating value for customers, by understanding and addressing their unmet, and potentially even unrecognized, needs.
We have found that in addition to being able to lead in this new agile way of working, it is important for leaders to understand the key elements of two other relatively new disciplines: design thinking and business-model innovation.
Originating in industrial and other forms of design, design thinking is a powerful approach to developing innovative customer solutions, business models, and other types of systems. This begins with understanding the entire customer experience at each stage of the customer journey.
In organizations that are agile, each team is viewed as a value-creating unit, or as a “business.” These teams pursue business-model innovation at every opportunity, seeking new ways to meet the needs of their internal or external customers and deliver more value to employees, investors, partners, and other stakeholders.
The first distinctive organization-level skill leaders need to develop is the ability to distill a clear, shared, and compelling purpose—a north star—for their organization. Rather than the traditional executive-team exercise, in agile organizations, leaders must learn to sense and draw out the organization’s purpose in conversation with people across the enterprise.
The second organization-level skill leaders need to develop is the ability to design the strategy and operating model of the organization based on agile-organization principles and practices. Most senior leaders of traditional companies have a well-honed skill set in this area that reflects traditional organization design as a relatively concentrated, static system: one or a very limited number of major businesses, each with a long-established business model, typically coexisting somewhat uneasily with a set of corporate functions.
To design and build an agile organization, leaders need a different set of skills based on a different understanding of organizations. They must learn to design their organization as a distributed, continually evolving system. Such an organization comprises a network of smaller empowered units, with fewer layers, greater transparency, and leaner governance than a traditional model. More specifically, leaders must learn how to disaggregate existing large businesses into a more granular portfolio; transform corporate functions into a lean, enabling backbone; and attract a wide range of partners into a powerful ecosystem.
The third organization-level skill leaders need to develop is the ability to shape a new culture across the organization, based on the creative mind-sets of discovery, partnership, and abundance and their associated behaviors.
Given the openness and freedom people experience in an agile organization, culture arguably plays an even more important role here than in traditional organizations. To shape this culture, leaders must learn how to undertake a multifaceted culture-transformation effort that centers on their own capabilities and behaviors. This includes the following steps:
fostering understanding and conviction in a highly interactive way, through sharing stories and being inspired by the energy and ideas of frontline teams
building new mind-sets and capabilities across the organization, including among those who do not formally manage people, and weaving learning into the fabric of daily activity to become true learning organizations
Many organizations start their agile pilots in discrete pockets. Initially, at least, they can build agile-leadership capabilities there. But to scale agility through an organization successfully, top leaders must embrace its precepts and be willing to enhance their own capabilities significantly. Eventually, a full agile transformation will need to encompass building the mind-sets and capabilities of the entire senior leadership across the enterprise. To do this in an agile way, five elements are essential:
Build a cadre of enterprise agility coaches, a new kind of deeply experienced expert able to help leaders navigate the journey, supported by a leadership-transformation team. Get the top team engaged in developing its own capabilities early on, as all senior leaders will take their cue from the executive team. Create an immersive leadership experience (anything from a concentrated effort over three or four days to a learning journey over several months) to introduce the new mind-sets and capabilities, and roll it out to all senior leaders. Invite leaders to apply their learning in practice, both in agile-transformation initiatives already under way and through launching new organizational experiments. Roll out the leadership capability building at an agile tempo, with quarterly pauses to review the leadership experiences, experiments, and culture shifts over the past 90 days, and then finalize plans and priorities for the next 90 days.
Agile transformation is a high priority for an increasing number of organizations. More than any other factor, the key enabler to a successful agile transformation is to help leaders, particularly senior leaders, develop new mind-sets and capabilities. Doing so in an agile way will enable the organization to move faster, drive innovation, and both adapt to and shape its changing environment.
Download Leading agile transformation: The new capabilities leaders need to build 21st-century organizations, the full report on which this article is based (PDF–765KB).Many companies have accelerated application development by adopting agile principles and modern software-engineering best practices, such as automated testing. Yet it remains uncommon to apply these methods and tools to IT infrastructure and operations, even though doing so presents opportunities to increase productivity and the pace at which digital products and services are brought to market. The typical IT infrastructure organization continues to emphasize stability over speed. Requests for infrastructure services still often go through an assembly line-style process involving many handoffs, long delays, and frequent misunderstandings.
Traditional IT infrastructure processes made sense in the past. But now that the latest technology advances have eliminated the need for manual configuration work and consumers expect to interact with companies digitally, it has become essential for companies to modernize their IT infrastructure organizations, thereby accelerating IT deployments and shortening time to market for technology projects. Four shifts can enable IT infrastructure organizations to operate in a more agile and efficient manner. The first of these shifts involves managing infrastructure much as application developers manage code, by using software to configure environments in a swift, reliable way. The other three are organizational: forming cross-functional teams (or “squads”) of well-rounded infrastructure engineers that work using agile methods, simplifying processes for delivering infrastructure service offerings, and improving how infrastructure teams and development teams work together.
Using an agile transformation to modernize an IT infrastructure organization isn’t easy, but it is worthwhile. In our experience, agile approaches can enable IT infrastructure groups to boost their productivity by 25 to 30 percent in six to 18 months, depending on the size of the organization. The gains can increase further as automated solutions are built and fully adopted. Additional benefits often include improved infrastructure service delivery and shortened time to market for digital products and features. In this article, we explore how infrastructure organizations can modernize themselves using agile methods, starting with a glimpse of what the shift looked like at three companies. We also provide a look at the four shifts described above, along with practical recommendations for how to get the transition under way.
Three companies demonstrate how unique approaches to agile transformation, based on similar principles and tailored to their needs, can help modernize their IT infrastructure organizations while improving performance significantly. At a large provider of software and services, the infrastructure staff of several thousand people managed a global footprint capable of handling millions of active users and thousands of log-ins a second. The processes that the company had used to provide infrastructure services had grown more complex and labor intensive as the company grew, so it could take months to bring new products and features to market.
When the company’s IT infrastructure leaders modeled the effects of applying agile methods to their organization, they saw an opportunity to improve productivity by 20 to 25 percent in 12 to 18 months. Given the scale of the infrastructure group, the leadership team chose to roll out agile ways of working over that span of time iteratively, launching about 150 agile teams to bring new methods and technologies to the entire company. The leadership had teams focus first on improving the infrastructure department’s internal operations by simplifying and automating processes and then on developing self-service tools and application programming interfaces (APIs) that could be used more broadly.
A European financial-services company with a far smaller IT infrastructure organization also recognized that traditional processes for building and managing infrastructure were slowing the release of digital products and services, as well as the adoption of more efficient, sophisticated application-development practices and tools. This company too set out to introduce agile methods and to implement highly automated infrastructure service offerings within its organization. However, its approach was to roll out a new agile operating model to its entire infrastructure organization at once instead of iteratively, as the software-and-services company did. The company also chose to focus from the start on building an operating model and tools that would empower developers to manage the operations of their applications directly.
Another business—a large US-based financial-services company—also adopted an agile approach in its 250-person IT infrastructure & operations group. Like the European financial-services company, it rolled out a new agile operating model to its entire infrastructure organization at once. However, the company chose to focus initially on improving its processes. In six months, it completed a transformation that cut IT costs by more than 35 percent and doubled overall productivity. With the new operating model in place, the company now plans to focus on automating up to 80 percent of its operations work.
Despite the differences between their transformation approaches, these companies followed many of the same principles. In the sections below, we’ll explore those principles in four areas: technology, organization and talent, processes, and collaboration with developers (exhibit).
Exhibit We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
One reason traditional infrastructure organizations operate slowly is that their technology systems require teams to configure infrastructure manually for each new application. To bring agility to the infrastructure function, companies can not only eliminate manual work by building automated systems that allow infrastructure to be defined by software but also provide “guardrails” that enable application-development teams to manage more of their own operations safely. And while it’s possible to build such systems with existing infrastructure, automation becomes easier as a company moves more of its infrastructure onto modern platforms, especially cloud platforms offering a wide array of enabling tools and technologies.
At the software-and-services company, even though the infrastructure team had standardized much of the hardware and virtualization architecture, it still spent a lot of time creating custom virtual-machine and operating-system configurations for product-development teams. Solution engineers reviewed the needs of each application with its developers and then set up the necessary environments, which often involved performing many steps manually.
As part of the company’s agile transformation, agile infrastructure teams implemented automated solutions to streamline the provisioning and configuration of servers. One agile team built and maintained a centralized platform that automated the provisioning of servers and could be accessed through self-service tools. Other agile infrastructure teams, each aligned with specific software-as-a-service (SaaS) products, automated the configuration of those servers for the products they supported, using a configuration-management tool to define the servers’ configurations entirely in code. This change reduced build times for environments from several months to about ten minutes. After these solutions were implemented, whenever a cluster of servers had to be updated or expanded, teams could make the necessary changes rapidly, with minimal manual effort and risk of error.
The European financial-services company chose to automate its IT infrastructure offerings using similar technologies. As part of a broad push to adopt DevOps principles, it also sought to empower application developers to manage their own operations as much as possible. IT infrastructure squads built automated, self-service infrastructure solutions for application developers and taught them how to use those solutions. Developers could then, for instance, produce code to tell the system how to configure or update servers given the unique requirements of their applications.
At traditional companies, infrastructure organizations have long been structured around teams with narrowly defined responsibilities for specific technical functions (for example, managing relational databases or operating systems) or stages of the plan-build-run IT service life cycle. Neither this structure nor the specialization it promotes is conducive to efficiency or agility, because multiple teams must typically work on each service request. To become more agile, infrastructure organizations can organize their staffs into small cross-functional teams focused on providing well-defined services. They can also develop modern workforces of well-rounded engineers who can learn new skills rapidly and work across multiple functional domains to carry out the end-to-end delivery of infrastructure services, as we describe below.
CIOs and technology leaders should bear in mind that engineers in agile infrastructure organizations typically need more diverse skill sets than application developers do. For infrastructure, that makes agile transformations more challenging. The infrastructure organization at the European financial-services company found some of the well-rounded infrastructure engineers it needed by carefully screening existing employees. The most capable ones were offered roles on infrastructure squads charged with building the highly automated self-service solutions described above.
At the software-and-services company, the leaders of the infrastructure group chose to organize their staff into skill-focused “chapters” to help with capability building, professional development, and standard setting. Chapter leaders determined which new skill sets their areas needed and were asked to develop training or hiring plans to meet those needs. For working purposes, the company organized everyone from those chapters into two types of cross-functional agile squads led by product owners who defined and prioritized the backlog of activities that their squads would work on. Infrastructure squads focused on developing highly automated foundational infrastructure solutions (such as server provisioning) that other teams could use to set up, manage, and decommission infrastructure. Product squads were aligned closely with specific SaaS product-development teams and worked to engineer and automate hosting and operations for their applications, leveraging services from infrastructure squads when available.
The traditional IT infrastructure organization’s functionally oriented structure imposes a particular working style—specialized resources complete tasks in a prescribed order, with many handoffs between groups. This working style causes innumerable delays: every time a request is passed to a new group, it goes to the bottom of that group’s task list, where it might languish for days. Frequently, tasks are sent back to previous groups for clarification, increasing wait times even further.
Companies can eliminate many of these delays by creating small cross-functional teams as described in the previous section. Such teams can minimize or even eliminate process handoffs by managing the end-to-end delivery of specific service offerings. They should be empowered not only to deliver service offerings but also to improve their delivery by streamlining processes and engineering fully automated solutions.
The processes of the software-and-services company’s infrastructure group had become increasingly complex as the company grew and added new customer-facing products. That led to the use of project coordinators to help push service requests through the organization. After the company grouped its infrastructure engineers into agile squads, however, the waiting periods that had previously followed handoffs among functional groups vanished. That change alone halved the amount of time required to provide many core service offerings. The company’s squads also redesigned common processes to simplify workflows or eliminate unnecessary steps, such as certain approvals. The number of steps in virtual-server provisioning, for example, was cut by more than two-thirds, and the remaining steps were then largely automated through better engineering.
By contrast, the US-based financial services company mentioned earlier took a different approach to compensate for the limited development skills of its infrastructure organization. First, it set up cross-functional squads to simplify processes without automation. The resulting productivity gains bought employees enough time to learn more advanced engineering skills. Then they began planning the development of automated capabilities to address common requests.
Traditional infrastructure organizations have minimal interaction with application-development teams. Collaboration between the two camps is normally limited to the initial setting up of systems for new applications and the resolution of critical incidents. As a result, typical infrastructure engineers know too little about each of the applications they support to help improve the stability of those applications. Moreover, developers lack the awareness of operational issues they would need to engineer robust, easy-to-support applications. Modern agile organizations, by contrast, make a point of increasing the level of collaboration between their application-development and infrastructure functions.
The European financial-service company described earlier exemplifies one collaboration style: making developers accountable for operating their applications. Involving developers in the incident-response and postoutage follow-up processes for their applications makes them more aware of issues in their application code. Involving developers in operations also encourages them to write code easy to manage and support—they can be awakened in the middle of the night if incidents occur.
The large software-and-services company demonstrates a contrasting approach. Its infrastructure organization continued to support operations for application-development teams but found a new way of doing so: closely aligning agile product squads and application-development teams. The alignment greatly increased coordination and collaboration. Many of the product squads were co-located, at least in part, with the application-development teams they partnered with. Core members of each product squad would attend some of the agile ceremonies of the application-development teams. In addition, the close alignment helped infrastructure engineers to gain familiarity with the applications they managed, so they had a stronger attachment to the success of those applications, which could now be better monitored and supported.
In our experience, the challenges of modernizing IT infrastructure using agile can be overcome using a structured approach to designing, launching, monitoring, and enabling agile teams. (At larger organizations, applying that kind of approach in waves can help the transformation get under way quickly.) This can be effective as part of a broader effort to transform a company with agile methods, or as an effort that is solely focused on the IT infrastructure group. Either way, the key steps in structuring an agile transformation of an IT infrastructure function are as follows.
1. Create a vision for the new infrastructure organization, particularly how the organization should operate and how quickly it should evolve. Several key questions will help IT and business leaders to define their vision for the organization.
What infrastructure service offerings should the organization provide to application developers and business users? Establishing a catalog of infrastructure service offerings helps companies to design and define the scope of agile teams and to decide which of them should own the tasks of delivering and improving those services.
How should the infrastructure organization collaborate with application developers and how should the interaction model evolve over time? Teams that are closely aligned with application-development teams can be beneficial if the infrastructure organization has responsibilities related to operating applications (for example, deploying code).
How quickly should the organization push to engineer automated solutions and adopt cloud technologies? The structures, processes, and skills of agile teams that focus on operations can be very different from those that focus on engineering infrastructure offerings.
How will infrastructure leaders and business executives gauge the efficacy of the transformation? Going into an agile transformation of the infrastructure organization, business and IT leaders should set clear objectives for improving performance and value creation, so that they can track progress and results with well-defined measurements.
2. Segment and prioritize opportunities with respect to the potential to create value for the organization. It is important to assess demand for infrastructure by developing a data-driven understanding of past consumption patterns and projected future needs. Knowing how much work is involved in delivering specific infrastructure offerings helps with organizing the work into scopes appropriate for an agile team. If, for instance, demand for storage-related work calls for a workforce of 24 people—too many for a single team—the effort might be divided among two teams: one focused on block storage and another on file storage services.
Analyzing demand can also help with identifying the greatest opportunities for improving efficiency and with prioritizing the rollout of teams accordingly. For example, a company can realize a great deal of value in a transformation by assigning the first agile infrastructure teams to handle and improve frequently performed labor-intensive services.
3. Design each agile infrastructure team to match the focus of each team with the working methods it will use. Teams focused on developing automated infrastructure service offerings tend to be relatively small—typically with eight to 12 people. They usually find that they work best using the scrum methodology, developing solutions in two- to three-week development sprints. Teams focused mainly on operations (such as level-one support teams) might benefit from longer rosters of up to a couple of dozen people. These teams often use the kanban or scrumban methodologies, which are more appropriate for managing a continuous flow of unplanned or event-driven work.
Over the long term, it is often preferable to have the same infrastructure team own both the planned development work and the unplanned operational work for a specific offering. This approach encourages teams to identify operational issues and fix them. However, at the beginning of an agile transformation, separating out unplanned operational work can help newly established infrastructure teams to focus on engineering highly automated solutions.
4. Create a structured process for rolling out agile infrastructure teams. The process should give all the people involved enough time to prepare for the launch of their teams. Our experience shows that it is critical to provide time and guidance to train team members, develop a strong team charter, align key stakeholders, and build out an initial backlog.
At the software-and-services company, for example, before each agile squad launched, its product owner and scrum master received two days of role training on how to perform their new roles. They then completed a six-week self-organized program, facilitated by agile coaches, in which they designed their teams’ vision, scope, objectives, performance metrics, minimum viable product for improving delivery, and composition. Product owners also had to identify their key stakeholders up front and to review their plans with them and with the sponsors of the transformation so that everyone was aligned. Once the product owner and scrum master had finished these steps, the agile coach would lead the full team through a one-week “sprint zero,” when it received training on agile and built out an initial backlog of work. After the sprint zero, the agile coach attended key ceremonies during the first several sprints of the team to make sure it was stable.
5. Focus on the sustainability of the transformation. Soon after agile infrastructure teams have been launched, governance bodies (such as a committee composed of senior IT leaders) will probably be needed to ensure that the teams are advancing toward their goals, refreshing their objectives as the organization’s priorities change, and improving their use of agile practices. In addition, many infrastructure organizations quickly discover a range of opportunities to build on the agile transformation’s initial improvements. These include revising career models to support new agile roles, adopting more flexible budgeting processes, and making strategic planning more agile.
Addressing these improvement opportunities will take time, but senior IT infrastructure leaders can handle the work by using the same methods their newly launched teams do. They can organize themselves as a team, create a backlog of opportunities, determine priorities, assign owners, and carry out the work in sprints.
Legacy IT infrastructure processes common at companies that weren’t “born digital” can impede the rapid delivery of new digital products and features. Agile methods can speed up the process significantly, and the benefits often start to materialize within the first six months of an agile transformation. A modern IT infrastructure organization that collaborates closely with developers and uses automation to accelerate configuration and maintenance can greatly boost its own performance, along with that of the wider company. For incumbents facing the threat of disruption from digital challengers, this can help make the difference between success and obsolescence.January 3, 2020 The ten most popular McKinsey.com pieces of the last year, taken from the hundreds of articles, reports, blog posts, and podcasts that we published in 2019, reflect the hopes and anxieties of business leaders in every sector: hope for a better meeting, a better mindset, a more agile organization; anxiety over the future of work in America, globalization, the energy transition, blockchain, and more.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
How can senior managers get better, faster business decisions from meetings? Here are the three questions they should ask with every calendar invitation.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Where is blockchain headed? This piece offers a hard-nosed look at the blockchain ecosystem as doubts have emerged about the technology’s true potential.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Debates about tariffs have obscured how globalization has changed. Trade intensity is down, and the flow of services and data play a more important role that isn’t fully captured by how we measure economic growth.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
McKinsey Global Institute’s blockbuster report looks at who will be most affected by emerging workforce shifts and how policymakers can choose to create more inclusive growth.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
A guide to how the best CEOs think and act, based on our proprietary performance database and decades of firsthand experience counseling thousands of CEOs.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Navigating an organization to an agile operating model isn’t easy. This guide describes every element of the transformation that needs to occur.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
This podcast interview explores how leaders can apply structured problem solving to work through the most complex questions we face in any sector.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
What exactly is the energy transition, and what will it look like in the coming decades? This is an essential piece about a sector that’s changing rapidly and how those changes will transform many aspects of our lives.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
On top of everything else they do, Meg Whitman, Doug McMillon, Salman Khan, and other CEOs share what they’re reading for pleasure and self-improvement.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Any company can operate like a tech company – if its IT department can become an enabler and driver of continuous innovation and adaptation.Enterprise resource planning (ERP) solutions are a fundamental asset for most large companies, yet ERP transformations remain time-consuming and complex. An agile approach has the potential to dramatically streamline ERP projects, but IT professionals have long believed agile to be incompatible with ERP. Our experience in helping many organizations adopt agile practices in a wide variety of situations, however, has proved the opposite: that agile can successfully be applied to ERP programs, with quantifiably better results. The methodology simply has to be adapted to the unique requirements of these complex solutions.
Large ERP solutions have slipped to the bottom of IT management’s agenda to make room for trendier topics, such as digital, big data, machine learning, and cloud. But the business benefits of ERP solutions—namely, the enablement of seamless, end-to-end integration across functions and the process standardization across geographies and business units—make them a fundamental asset for most large companies. Moreover, the next generation of ERP solutions, such as Oracle Cloud and SAP S/4HANA, offer even more promising capabilities, both functionally and technologically. Companies focusing on digital transformation or advanced-analytics programs are beginning to realize that, to unlock the full potential of their investments, linking the new technologies to their ERP base is essential.
As fundamental as they are, three-fourths of ERP transformation projects fail to stay on schedule or within budget, and two-thirds have a negative return on investment. There are five main reasons (Exhibit 1).
Exhibit 1 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
First, all parties may not share the same objectives. For example, a system integrator may have the incentive to increase the program’s scope and duration if it makes more revenue from a complex integration. The company, meanwhile, wants to deliver the project and capture its value as soon as possible.
Second, most organizations lack experience in managing major IT projects and multivendor programs. They do not have enough skilled managers, have never set up rigorous governance for such programs, and fail to understand the level of input needed from business sponsors.
Next, ERP systems cover a vast, integrated, functional scope and thus require complex discussions with the business on operating models, data management, and validation rights. These decisions tend to come up mid-program and require executive-committee-level input based on information that is not yet available. The project must often pause for these decisions to be made, slowing progress and even undermining the initiative’s value.
Fourth, activities and deliverables tend to drive ERP transformations; instead, the transformation should be based on business value, which must be quantified, documented, and monitored to drive the program.
Last, most ERP projects are undertaken using a linear, sequential waterfall approach, which delays the project’s realization of value.
These challenges often cause ERP implementations to drag on for five or even ten years. The typical implementation involves long phases of design, specifications, and blueprinting but yields no measurable impact—while shareholder value diminishes, day after day.
The myth that agile methodology cannot be applied to ERP implementations is based on several misconceptions: that an ERP implementation is too big and complex to be managed and delivered by small agile teams, meaning that highly integrated, intricate ERP requirements cannot be broken down into vertical user stories that can be developed and tested in the short sprints that define agile delivery; that ERP is a standardized software, and that hence an agile approach—which is designed for constantly changing or unknown requirements—is not needed or applicable; and that an ERP solution cannot be shown incrementally to end users, as they will not be able to perceive any value before it is fully built and integrated.
In truth, agile practices can greatly mitigate the risks and challenges that plague typical ERP implementations in a number of ways. Agile has, for example, vendors and system integrators work together as one end-to-end team focused on the same set of key performance indicators (KPIs) and outcomes.
It involves a faster pace and greater transparency, making it easier for managers to make timely, critical decisions. Contrary to popular belief, agile does not mean “no planning”—rather, agile replaces long, opaque project phases with two- to three-week sprints so that managers can track outcomes, progress, and challenges.
Agile calls for the business and IT groups to be integrated into the project team, which is structurally geared toward value creation. These two groups collaborate from the project’s beginning, fostering agility for both.
And agile helps to break down the functional scope of ERP into a smaller set of features that small teams can deliver in sprints. This iterative approach helps projects to realize business value quickly.
In short, agile practices are exactly what is needed to manage ERP implementations. It should be no surprise that leading ERP vendors, such as SAP, are now promoting a more agile approach.
Some agile practices can be directly applied to ERP implementations without adaptation: forming small, end-to-end, cross-functional agile teams, with dedicated product owners from the business and end users; working in short cycles of two to three weeks to produce working software (or configurations, interfaces, et cetera) incrementally; adopting scrum-based ceremonies focusing on continuous improvement, with transparency facilitated by the ceremonies and KPIs; and using tools and technologies—such as test automation and continuous integration—that optimize and accelerate the delivery process.
Other agile practices, however, need to be adapted further. For instance, the project’s entire scope must be defined up front at a high level to include clear success criteria, as opposed to agile’s more common approach toward a minimum viable product. Teams should be allowed, however, to refine the detailed scope and to set priorities as they go along.
In addition, to ensure consistent development, more work must be done on the business process and architecture than in the typical agile implementation, so that the work can be split among small teams.
Strong linkages are needed between the agile teams delivering functionalities and the “transversal” teams, which are nonfunctional teams—for example, the data-migration team, the integration team, or the change team that support the functional or feature teams. All teams should be synchronized so that they work in the same rhythm and meet the finish line together.
“Production ready” software cannot be delivered as frequently as in typical agile software development. A phase of end-to-end (E2E) testing and cut-over is needed to consolidate the increments delivered by individual teams and to test complex interfaces with legacy systems; this often takes longer than one sprint to complete.
Finally, a strong agile program management office (PMO) should be added for faster resolution of issues and cross-team decision making.
A classical ERP implementation has four stages: developing an ERP strategy and road map, setting up the program, implementation, and deployment. Each stage can be adapted for agile delivery.
Developing an ERP strategy and road map results in a target architecture with high-level principles and a business case to implement the new solution. This stage remains largely unchanged, but it can be accelerated by doing a rapid fit-gap analysis at a high level, rather than endless blueprinting, and by working iteratively in sprints—to avoid an overly detailed business case. Product owners should be brought on board and empowered to make key decisions from the beginning, and smaller, cross-functional teams should be set up to achieve program goals.
Setting up the program changes substantially in an agile approach; it is much faster, primarily because the teams are empowered to quickly tackle real-life difficulties instead of engaging in theoretical design. This stage includes rapidly selecting a partner that has experience with the solution and agile—as opposed to engaging in a lengthy request-for-proposal process to try to find a supplier and negotiate a fixed-priced contract; building a high-level, macro-feature road map, based on a list of identified improvements, that is detailed enough to determine the size and form of the agile organization needed to deliver the program; staffing and training the organization in agile ways of working; and establishing a strong PMO that will coordinate the functional and nonfunctional workstreams.
Implementing the solution is dramatically different in an agile approach. Implementation happens in several waves to quickly capture value. Functional delivery teams adopt most of the typical scrum practices. End-to-end teams of eight to ten people, from both a company’s business and IT and from the system integrator, complete design, development, and system testing in two- to three-week sprints. E2E testing and user-acceptance testing (UAT) are conducted at regular intervals—as opposed to only once at the end of the development—resulting in better code quality and ongoing test automation. Nonfunctional work (for instance, data migration, training, and deployment) is less affected by the agile approach, although close coordination is needed between functional and nonfunctional teams; for example, because data are required early for frequent functional testing, the data migration team must gather the data to populate the testing environment. Nonfunctional testing and the cut-over phase remain the same as in a classical implementation.
Sidebar How a logistics company used agile for its ERP transformation One of the largest shipping and logistics providers in Europe embarked on a multiyear core-technology transformation. The program’s goal was to replace the old enterprise resource planning (ERP) system with up-to-date technologies and to provide new functionalities. A few years in, the program was fraught with multiple challenges and lacked a business case, business ownership, and robust vendor and program management. Also, the scope was too large and complex to be delivered in an effective and sequential waterfall manner. To get the program back on track, the company focused on three steps: (1) rescoping the program around the most valuable elements, (2) designing and implementing an agile ERP delivery methodology, and (3) establishing a rigorous PMO. To enable agile delivery, a new agile operating model was designed for 300-plus full-time-equivalent (FTE) employees by aligning numerous stakeholders—including business and IT internal clients, the ERP vendor, the company’s system-integration partner, the onshore- and offshore-development partner, and the infrastructure partner. The FTEs and the program were then transitioned to agile delivery at an accelerated pace. To do so, the FTEs were first reorganized into six functional domains, that consisted of 11 cross-functional agile teams, focusing on such tasks as developing and integrating the product catalog. There were six transversal domains with about 15 teams focusing on areas such as data migration and electronic data interchange (EDI). Next, a detailed agile approach was designed to consider ERP specificities, and the new organization was trained and coached in this new approach. The agile PMO steered the program, supported agile ceremonies for the overall project, solved complex issues, facilitated the swift removal of any impediments, and implemented a new backlog management and tracking tool. The application of agile to this ERP implementation resulted in several significant benefits: Enhanced transparency. The project teams put their macrofeatures (“epics”) into a work-flow-management tool that attached each to the increment or sprint in which it was to be delivered. At the end of every sprint, progress was measured, in the number of user stories and story points delivered, and of the entire project, in the number of epics delivered and analyzed. Because of this transparency, the teams could measure and take ownership of their progress, which enabled them to rapidly correct their course using agile retrospectives as a tool. The teams were also able to promptly escalate any impediments to their managers. The managers enjoyed an unprecedented level of transparency; they could now see the duration, cost, and causes of delays each week and take swift action. Moreover, knowing the project’s precise status on an ongoing basis allowed the product owners and leadership to make informed decisions about what to prioritize based on value.
Strong coordination among teams. To foster coordination and communication among teams, the process began with increment planning with all teams—both functional and transversal—together in one room. Then, at the start of every sprint, each team gave its input to the other teams on dependencies. Functional and transversal teams had biweekly huddles. From there, issues were escalated to the weekly “war room,” where all teams met to discuss dependencies and performance.
Rapid, targeted troubleshooting. The PMO, comprising roughly 12 to 15 people, in addition to performing classical activities, served as a SWAT team that could address complex issues on an ad hoc basis. Almost half of the PMO’s work focused on troubleshooting, such as scenario building to assess the impact of a delay in delivering a large interface; building a complex, CEO-ready document about rescoping; providing extra analytical capacity to plan 3,000 test cases; and reorganizing the full operating model as needs evolved—for example, merging functional teams after rescoping and building an efficient test factory based on lean principles.
Agile organization. The 11 agile teams had the capabilities to deliver an end-to-end solution, including business representation. Their three-week sprints included development, solution testing, and a demonstration to end users at the end of each sprint. In addition, at the end of each increment (or three-sprint period), comprehensive, end-to-end solution- and user-acceptance testing was performed to ensure the quality and integrity of the functionality delivered. The teams followed all scrum-based ceremonies and began to realize benefits after only a few weeks.
A detailed agile playbook. The agile approach—which was tailored to the company and ERP—was documented in detail in a playbook that remained a living document throughout the program. The playbook included elements such as how to translate traditional ERP requirements into epics and user stories to create a product backlog, as well as project documentation that was adapted to agile—for instance, simplified technical specifications, since developers were working directly with product owners and analysts, and new terminology, such as the definition of “ready and done.” As a result, the program was able to meet and even exceed its performance targets. Delivery was 20 percent faster than the previous estimate. This was a result of far less rework due to iterative improvements made by working with end users to inspect and adapt each iteration. It was also a result of the ability to better manage project delays, which made them less likely to affect the overall timeline because of the use of intermediary deadlines and having an incremental scope. Additionally, fewer bugs were found by using integrated, end-to-end, and user-acceptance testing for the agile release—as opposed to the two previous waterfall releases—and by conducting more-frequent testing. The scope delivered was three to ten times greater than in previous releases of similar durations, due to better alignment among functional teams. User acceptance of the new solution was much higher, as users were involved throughout the implementation. Finally, the agile team’s morale improved significantly, as measured during agile retrospectives, which contributed to the delivery’s success. Since the project began, more than 100 people have now been trained in the agile mind-set and ways of working, resulting in a new operating model for the company, which reflects the realized benefits of the agile approach—and ultimately disproving the myth that agile does not apply to ERP.
To illustrate, one company undertaking a transformation reorganized people into 26 teams. Of these, 11 were end-to-end, cross-functional agile teams delivering features, while 15 others were transversal teams that supported the agile teams. All agile teams included the capabilities required to deliver an end-to-end solution, including business representation (see sidebar, “How a logistics company used agile for its ERP transformation”).
Deploying the solution largely follows the classical approach, but deployments occur more frequently, and agile practices can help to remove bottlenecks. A “deploy all development rapidly” mind-set can mitigate early deployment risk, analytics can help to optimize the process (for example, the number of “key users” to be trained), and local templates can be designed early by onboarding local users. A shorter hypercare phase can be planned because of the continuous focus on quality. Since releases are more frequent in an agile approach, there is more opportunity to industrialize all steps in the deployment.
It is important to note that, in an agile-adapted implementation, the initial stages are accelerated when compared with the traditional waterfall approach. Most time is spent on later stages, focusing on delivering functionalities.
Much of agile’s popularity is based on its results. Research shows that agile organizations have a 70 percent chance of being in the top quartile of organizational health, the best indicator of long-term performance. Moreover, such companies simultaneously achieve greater customer centricity, faster time to market, higher revenue growth, lower costs, and a more engaged workforce.
Specific to ERP implementation, deploying ERP in an agile way—irrespective of the underlying technology—translates into a range of tangible and intangible benefits (Exhibit 2):
reduction of program cost by 10 percent, driven primarily by having to do less rework in the E2E testing and UAT phases
increase in the program’s value by 20 percent by giving the product owner enough visibility into the project’s progress to focus on high-value items
ability to compress three times more workload into a given period through greater parallelization of functional teams
Exhibit 2 We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Although ERP systems are often considered a “necessary evil,” they are here to stay and cannot be ignored as companies go digital. The traditional, often complicated approach to ERP transformation should be drastically revised and, whenever possible, adapted to include agile ways of working.
Companies and system integrators should dispense with the myth that agile cannot be applied to ERP and instead industrialize the agile approach for ERP transformation. Further, ERP solutions should become more modular so that deployment can be phased—resulting in lower costs and faster realization of value.
ERP transformations are always challenging, but these challenges can be far less daunting with an agile approach.With the rise of these frameworks, a debate has also started on whether frameworks have a place in Agile. The debate was that frameworks were moving back to a traditional way of working and the intent of Agile was to focus on the mindset and principles. At Deloitte, we have seen that a balance between mindset and practices/frameworks needs to be taken to effectively enable the change in large scale enterprise when adopting Agile ways of working.
As more and more of the business has been exposed to agile ways of working, there has been a realisation that agile isn’t just for technology. This has led to Agile being extended to core business functions such as Marketing, Legal, Sales, Operations, etc. to move towards phase (3).
A local example of this is the Australian Real estate giant REA group, where every core business function in the organisation functions in an Agile way. REA started to adopt Agile practices in late 2010 within the Technology services / Software Development group. Shortly after, the success of the technology teams led the then CIO to embed Agile practices to the whole organisation. By scaling Agile into business, organisations have realised benefits such as accelerated product delivery, ability to adapt priorities based on changing market, and productivity improvements.
(We have also seen instances where phase 2 and 3 occurred before phase 1. While this was less frequent, in some organisations Agile adoption was driven more by business functions, such as products and marketing before their IT teams were on the journey.)
As organisations have realised benefits from agile at scale, they are looking to scale these benefits now across the organisation.
Seventeen years since signing the agile manifesto, agile has moved far beyond something that is only for development teams within the technology practice and for complex program delivery. Now, in today’s quickly changing market, organisations are seeing the need to use agile ways-of-working to enable their organisation more broadly, which leads us to Enterprise Agility.
Enterprise Agility in our definition is using new ways-of-working across all elements of an organisation to enable how a business creates ideas, plans, executes, makes decisions, learns, manages risk, and empowers teams.[5]As the business impact of the COVID-19 crisis mounts, leaders in every industry are moving urgently to protect employees and build resilience. Governments are mobilizing to safeguard citizens and manage the economic fallout. Immediate action is critical, but leaders must also embrace a new agenda—one aimed squarely at what comes next.Insert Custom CSS fragment. Do not delete! This box/component contains code needed on this page. This message will not be visible when page is activated.The Life Science and Health Care Industry (LSHC) has always been in the lime light for its strict regulations. Though these regulations are cumbersome, they are deemed necessary in order to comply with patient safety and product quality. In line with the strict regulations, the traditional Waterfall Method was always used in Software Development in LSHC industry.
In recent years, the aspect of being cost –effective whilst not deviating from the regulatory framework has been repeatedly discussed.
The advent of Agile Methodology has disrupted the traditional development methods with its clear focus on continuous development, agility and over all “lean” concept.
“Agile” was introduced as a means to tackle the limitations in Waterfall and other traditional development methodologies by concentrating on continuous improvement and conducting tests in smaller iterations, all the while not compromising on the development quality of a product.Works with clients to define, develop, and implement digital solutions to succeed in an ever-accelerating world. Helps large organizations to become more agile, empower teams, create nimble structures and accelerate innovation.
September 6, 2018 As more companies go fully digital and agile, they start to look more like technology companies. No matter the product or service they offer, companies must embrace that technology is shaping our world and today’s business cannot run without IT.
CIOs can serve as catalysts by setting direction and establishing the system and infrastructure for people to do their jobs effectively in an agile organization. Their opportunity lies in becoming a product visionary, being much less of an IT manager and, instead, defining and driving strategic technology initiatives. The agile CIO is thinking constantly of creative ideas to grow and nurture talent in the organization, encouraging expertise development and further learning. And they love IT for IT’s sake.
Take one CIO, who on his time off learned new programming languages to educate the team. Another CIO organized a hackathon with programmers to recruit fresh talent. Yet another insisted all the members of the team read the classic IT book “Continuous Delivery” by Jez Humble as part of a team-building exercise.
Traditionally, CIOs manage practically everything related to information and communication technology, including policy and practice development, planning, budgeting, resourcing, and training. But in an agile organization, given the pressure to speed up innovation and land superior talent, the CIO position is redefined— a successful CIO fills three key roles:
Architect/technology visionary The CIO is in charge of IT strategy and the IT systems required to support the organization's unique objectives and goals. Analyzing how these technologies benefit the company or improve an existing business process, and then integrating a system to realize that benefit or improvement is key to this role. Responsibilities include: Building the overall IT strategy. Delivering a strong technology/product vision and influencing the direction in meaningful ways. Embracing enterprise-wide IT decisions about systems and technology. Driving strategic partnerships with business ecosystem partners, technology partners and vendors.
Driver of knowledge and talent The CIO is not only an expert in their own right, but also serves as a visionary and leader building and inspiring their team while offering opportunities to grow. Responsibilities include: Managing the workforce (hiring, firing, capability building, evaluations). Setting IT talent performance standards. Ensuring consistency of practices (including architecture, technology choices, DevOps practices, etc.).
Problem solver The agile CIO aligns the team around a vision and creates an environment that empowers colleagues to make decisions and move quickly on delivering results. Responsibilities include: Removing impediments to reach goals and leading key strategic initiatives. Working to guide, direct and give feedback to the team in real time. Ensuring the collection of squads (teams with representatives from different functions working at a single location, with interconnected missions) are working cohesively together; playing the “tribe-lead” role for some IT-enabling squads (core platforms, shared services, etc.).
In their redefined position, agile CIOs actively offer perspectives and skills beyond just technology. They grasp how to be collaborative with immediate team members, the broader organization and customers. They don’t forego their traditional role; if a critical piece of enterprise technology crashes, they must handle it. But, above all, they must possess a nimble mindset. For, in this new organizational world, the CIO could be next in line to become the CEO.​Contracting for Agile software development should focus on enabling a smooth vendor-client relationship rather than on specifying terms and conditions in exhaustive detail.
Government organizations are increasingly looking to partner with vendors who use Agile to deliver software systems. But for government to successfully take advantage of what Agile has to offer requires a change in mind-set for procurement officials.
For most things that government buys, most people aren’t overly concerned with the process of how it is made. From office furniture to computers, how the item being purchased was built doesn’t really matter.
But if you want to buy software that is developed through an Agile process, you need to alter your procurement process. The procurement officials, the lawyers, and the purchasing agency’s business leaders need to embrace a new way of thinking about their role.
Why? Because the Agile process combines design with development and user acceptance. In other words, the software’s final design emerges through a collaborative effort between developers and business users. So the traditional procurement approach, heavy on functional specifications written up front, isn’t consistent with the Agile approach.
The new mind-set of procuring for Agile involves many major shifts in thinking. Five of the most important shifts include:
The Agile Manifesto, which kick-started the Agile movement in 2001, explicitly talks about the relative value of various aspects of software development. The manifesto’s signers declared that they had come to value:
The signers of the manifesto acknowledge: “While there is value in the items on the right, we value the items on the left more.”1 Those familiar with government will quickly recognize that public procurement is strongly weighted to the items on the right.
For procurement officials looking to use Agile, this has clear and obvious implications. The contract has always been a cornerstone of public software procurement, the document that defines the relationship between a government agency and a vendor. Traditionally, a well-written contract, including detailed specifications, was seen as critical to a successful engagement.
This makes intuitive sense, and a linear, rules-based approach certainly feels safe. But experience teaches us that that feeling is often an illusion. The Standish Group’s CHAOS Report routinely shows that Agile projects have a higher success rate than linear waterfall projects, and waterfall is more likely not just to go over budget, but to fail in delivering software that works for users.2 Paper safeguards are of little use if they don’t result in successful projects. Good stewards of government focus on ensuring value from an investment. That may mean rethinking the massive requirement-laden contracts of yesteryear.
In the old contract-centric world, the contracting agency spends months, maybe years, soliciting and documenting user requirements, then “tosses” this blueprint over the wall. The vendor collects it, and many months, or years, later, delivers a final product—sometimes deeply flawed. While any number of sanctions in the contract make it appear “tough-nosed,” these sanctions may prove difficult to enforce as agencies find that the software “is what they asked for just not what they really needed.” This contract-centric approach too often leads to disappointment and disagreement.
In Agile, there is no blueprint and there is no wall. The agency and the vendor partner to build a system. The vendor’s assistance may include project management as well as the heavy lifting of development—but throughout the process the government agency actively participates, helping to ensure that the final result will meet its needs.
More than a well-written contract or massive spec document, for Agile to succeed there must be a leader at the agency with a vision for what the application is going to do: Whom does the software support? What is the business challenge being addressed? How will data enter and leave the system? The Agile process turns this vision into working software.
Agile software development requires software buyers to rethink the role of the contract. Instead of serving as the ultimate blueprint for the projects—detailed specs, precise price, firm deadlines—the contract becomes a guide for structuring the relationship between the government agency and the vendor. The shift in mind-set is profound. The agency is no longer looking to buy a “thing”—in this case a new software system. Instead, the agency is entering a relationship to jointly design and build a new software system.
Hence, the contract doesn’t primarily define the software. The contract’s main purpose is to define the expectations of the relationship. This can include pricing associated with a series of performance reviews, defining “done,” and clarifying the role of agency representatives and the vendor. One of the biggest challenges for IT vendors can be insufficient access to subject matter experts and managers empowered to make quick decisions—these should be spelled out in advance.
No builder can provide a precise fixed cost bid on a house without a highly detailed set of blueprints. The same is true when building software. Because Agile doesn’t provide precise specifications up front, it’s somewhere between difficult and impossible to calculate an accurate fixed price in advance. This means there will likely need to be some form of incremental pricing, which could entail a time and materials approach, or breaking the project into smaller chunks, or paying for “development points.”
Traditional contract management focused on the terms of the contract: Are the correct number of people on the task and are their hours properly documented? Agile leaders can still track that sort of compliance if they’d like, but more important is performance monitoring. One Agile principle states: “Working software is the primary measure of progress.”3 After every Agile “sprint,” hands-on review of the software is critical. One project manager told us, “Paper reviews are mostly worthless. You’ve got to regularly see demos of the software as it is being developed.”4 Bye-bye, Gantt charts. Hello, demos.
Agile isn’t the right approach for every project, and there is considerable variation within the various “flavors” of Agile. But for those procurement officials looking to buy software developed through Agile, a significant shift in mind-set is in order.Financial services need to shift from product to customer focus, embrace fintech and prioritize technology investments to remain competitive. To increase time to market and remove bureaucracy banks are making the radical shift to implement cross functional, customer obsessed teams and agile ways of working and focused on serving customers through life stages (e.g, help me save for my future, help me manage my lending accounts) instead of through their own products and channel structures. Early, and well publicized, experimentation within the banks in this space became a model for other industries to pursue networks of teams, new structures and ways of work. With the maturity and strength of agile capabilities within banking and insurance, financial services will continue to be a hotbed of experimentation around AO as technology, product and business teams continue to merge.April 27, 2020 Over the past several weeks, we’ve been helping leaders of all kinds get the facts on COVID-19 through more than 100 new articles that offer historical points of view, outlooks for the future, and deep dives into the economic and business implications of the pandemic.
In this post, we highlight four articles that focus on the societal side of the coronavirus equation—and offer ways forward on each issue.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
Black Americans will suffer more from COVID-19 than any other demographic group when it comes to health outcomes, job losses, and economic suffering. This is due to long-established disparities—in education, in job opportunities—embedded in the communities where they live. While this article outlines the health risks for black people in America in stark tones, it also issues a call to use this crisis as an opportunity to increase the resilience of black communities and institutions, by a variety of both tried-and-true and innovative approaches. These include using analytics to help erase racial bias in testing and treatment, making an investment in telehealth solutions, and expanding broadband communications in black communities to increase access to education.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
While much of COVID-19 coverage reports on hard metrics—daily death rates, number of hospital beds, rate of unemployment—it’s critical that we also focus on our collective resilience. Almost half of Americans—45 percent—say that the coronavirus has negatively affected their mental health. This article outlines the behavioral-health crises sparked by COVID-19, including addiction, depression, and substance-use disorders, and the staggering economic and social costs associated with them. It then offers pragmatic ways to heal our spiritual psyche, such as community outreach; programs to support basic food, housing, and healthcare needs during a crisis; and innovations such as telemedicine and analytics to reach more at-risk citizens.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
COVID-19 is defining an entire generation of young adults. Waves of college students were sent home from all corners of the world in a matter of days. Many will miss out on a life milestone: graduation. Others are putting academic careers that require hands-on training, such as medicine and performance arts, on indefinite hold. All are facing what can only be described as a dismal employment outlook. This report outlines three scenarios higher-education institutions may be facing as the pandemic unfolds, and presents concrete steps they can take now to keep students and faculty safe—and keep learning alive.
We strive to provide individuals with disabilities equal access to our website. If you would like information about this content we will be happy to work with you. Please email us at: McKinsey_Website_Accessibility@mckinsey.com
In a world fighting pandemic, is climate change still something we should pay attention to? This article argues that we simply cannot afford to do otherwise. What may help the cause going forward, the authors write, is that behavioral changes ushered in by this moment, like the rise of teleworking and virtual events, may stick in ways that mitigate the effects of climate change. Elsewhere, supply chains could be repatriated, reducing certain types of emissions that reside across businesses entire value chains. And finally, public appreciation for scientific expertise could rise, along with a greater appetite for the role of governments in tackling systemic risks.Please use UP and DOWN arrow keys to review autocomplete results. Press enter to select and open the results on a new page.Corporate and business strategy have greatly evolved since BCG pioneered the fields in the 1960s and 1970s with the growth share matrix and experience curve. Today’s business leaders must match their strategies—and their strategy development approaches—to a broader range of environments. They must embrace the opportunities and disruptive potential of digital while maintaining the agility to adapt to changing conditions. Explore BCG’s latest strategy thought leadership to learn more.Topic List. Do not delete! This box/component contains JavaScript that is needed on this page. This message will not be visible when page is activated.